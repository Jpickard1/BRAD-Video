[
    {
        "start": 0.48,
        "text": "hi uh my name is i'm a professor in the department of biostatistics and hold a courtesy appointment in in dcmb as well and it's my distinct pleasure to introduce today's speaker uh han liang who's the bernard family distinguished professor in targeted therapies and the deputy chair of uh in the department of bioinformatics and computational university of texas md anderson cancer center uh dr liang is a comfortable scientist he's he joined md anderson after completing uh his bachelor's and phd in princeton um and uh has been at anderson what 10-12 years now and he's risen really vertically and has touched many areas of science especially in in terms of cancer genomics and his "
    },
    {
        "start": 62.559,
        "text": "main thrust of his work is on bioinformatics tool development and has developed many many tools that are used by over 100 000 users across the world including the cancer proteome atlas tandrick phasmic and some of the dr biowrite which i believe he's going to be talking about today and and he has published over 140 papers and which have been cited 20 over 25 000 times and i can claim to having co-author on two of those at least not not not in terms of citations and not so high in terms of citations and that includes like the top journals such as um cancer-cell nature genetics nature biotech and nature he he has taken on leadership roles in many consortiums especially the cancer genome atlas the pan cancer atlas working groups and as well as his lift of awards is a long winded list of awards and that includes many awards within within the university of texas system as well as being a fellow the uh "
    },
    {
        "start": 125.36,
        "text": "american association from so without further ado i would hand the floor to dr han and uh we would have loved to have him in person uh but i'm sure he's enjoying the 60 degree weather in texas versus our uh indian degree and so yeah thank you vera for very nice introduction and i really miss you and then you are such a great collaborator and friend so so um hopefully one day we can have this in-person meeting um so uh today it's really my great pleasure to join this seminar series to give a talk um talk a little bit about the fundamental scenes in this big data so artificial intelligence big ole mix data and the cancer system um so you can see my slide um i try to so my so this is an id climber so for my um "
    },
    {
        "start": 187.36,
        "text": "so work with our company and software and this work i present part of is in collaboration with nvidia okay so i think we all now agree that we are a very certain kind of big data so in the last 10 years what you see is with the next generation sequencing the tremendous molecular data has been accumulated so this from the genome transcriptome protonics and more recently you see single cell sigma data so i think we are in a very time very same time for this query on the other side we all know this also has a lot of challenge how to interpret this data um so in the last 10 years my group have focused on a big consortium data called tcga or the cancer genome athletes as you probably all know uh this is really provide a comprehensive molecular profiling for more than 11 000 patients "
    },
    {
        "start": 249.68,
        "text": "from 33 cancer type so they for each quarter usually more than 500 patients will generate this multi-dimensional data site from mutation copy number uh gene infection dna methylation even micro expression and also protein expression and clinical data so when you have this multi-dimensional data over the same patient profile this just provides a tremendous discovery power to understanding the magnetic mechanism and also try to identify some clinical biomarker and a new therapeutic target even design a new cycling strike strategy so in the last year of 2008 2018 well when we finished the tcg pump cancer athletes uh we uh to write a paper in um cell so in that cell we talked about the long-term impact of tcga so really one of 500 space scientists working together over such "
    },
    {
        "start": 311.039,
        "text": "big data sites water really i think one key point i want to mention is through large consortium products such as tcga essentially put bioinformatics and computational biology really in the driver's seat of the cancer research so firstly when we think about bioinformation on computational biology more like a supporting uh we are get some do some analysis suggest by a collaborator but really made this huge data available data generation data resource is no longer the bottom line in cancer research it's really hard to use fascinating uh biphoriz2 cutting-edge algorithm to convert this big data into clinical and biological insights so so of course when we talk about the big data it's not only tcga it's really you have uh the international in icgc right you have one thousand genocide and then we also "
    },
    {
        "start": 373.36,
        "text": "have many big consortium like g-tax which provide um normal tissue generation data in code which provides comprehensive regulatory elements elements in human genome and then recently you have you see uk have this biobank where you have half million genotype phenotype cohort and also among us nih stars is all of us the precision medicine aimed like one billion by million people how systematic collected molecular data and then the house data so this all can date fundamentally upon how to use basic data to generate clinical action or very practical for health care so um when we talk about this data of course this state big data present big challenge for bioinformation for computational biologists so "
    },
    {
        "start": 433.919,
        "text": "i think um today right so really what we need is two things number one we need a more effective bioinformatics tool to analyze the data the second one we probably need some fundamental new and visual concept to understand the complexity of the biology and the disease so um my group actually worked on pretty much in that to address those questions we worked on the intersection between bioinformatics and computational biology and systems biology so over the years micro published quite a bit by information to try to help people analyze those large scale cancer genome data and then we also perform a lot of plant cancer analysis which means we focus on the same question we ask the same question in different tumor context try to through this contrast and comparison we try to understand the common principle and the cancer-specific feature so those cover broadening the topic from "
    },
    {
        "start": 495.199,
        "text": "pseudogene iron editing sex effect to more recently um mitochondria and the enhancer and then based on that a third component in group we also developed this high school system biology approach through those combination of cell essay and then functional protonates we try to understand the driving events of mutation gene fusion and try to design new therapeutic drug combination so really that's a big concept of that picture of my research but today i will give you um two topic one is really focused on bi-information two development i hopefully introduced this dr bell right a conversational ai driven analysis of omix the second topic will be a more computational biodesign it's really a plant cancer analysis about the enhancer so we focus on enhancer array i "
    },
    {
        "start": 555.6,
        "text": "propose that this will be very exciting paradigm for banff biomarker discovery so the first part when we talk about the bigger data analysis it's not only the data science b so when we talk about data now it's not a megabyte the terabyte even p so when you talk about this data storage is a problem and more importantly there are so many diversity of data you have different data type for each data you have different analysis for each analysis you have multiple algorithms and then no matter how you try there's always a learning curve especially for those people with uh low computational background on the primarily work on experimental side on clinical side so there's a technical barrier finally when even you spend the time learn some to become the master whole field are just moving so fast you always have new algorithm new data science so you just keep tracking on the recent "
    },
    {
        "start": 616.72,
        "text": "development field it could be very challenging so that's really um uh just to think about the new how to fundamentally change our practice in data analysis so the other big thing you probably all know nowadays we are people have deep concern about reproducibility in those paper especially the photos paper published in top journals you see a lot of paper uh published then the gallery tracks on some paper published they found they cannot be reproduced that would be problematic so our department actually held this very good reputation try to check reproducibility so that's also another unique issue in data science so ideally we want to hire this kind of analytic ideal platform number one uh really want to minimize the communication bar between user under the two you want to make this lower and possible basically you want to people have no background in computationally can still "
    },
    {
        "start": 677.92,
        "text": "using two to do some work number two we want to that result transparent reproducible so which means we do something not only gave the results but also how you detail to reproduce that so essentially you want to remove the black box a third one we want to open development we want to help to engage the whole community to contribute to and more importantly we want to that too it's not static we can really based on the user feedback and the user's data to constantly make progress to learn new ability to make a better judgment for your analysis okay so that's really so my group in the last three years two to three years we really focus on those concepts we guide by those principles we do develop a tool these two called doctor biorite so this is the first uh natural language aren't in analytical platform "
    },
    {
        "start": 738.72,
        "text": "for us to analyze omix data so um i can show you uh the video so here uh these two actually have extremely simple uh interface it's really just like a dialogue just like what you use in um social media like facebook book wechat oh you have this whatsapp so you only have this one input area where you people just can type a sentence directly in this area say um how many you want to ask a question say how many cancer types do you have in tcga that's even simple and then the and release your doctor about right essentially understand this natural language they actually confirm do we want a summary about tcga content data once you confirm this yes then dr wright will go to the literature go to the data profile guided analysis generates a bar plot where you not only "
    },
    {
        "start": 798.959,
        "text": "know the cancer type but also know the sample size for each of these um core form and then of course you see you can also download this feature for your own analysis on pronunciation for example you can ask the question do could you do a correlation between um say between tp53 versus um i thought p10 g versus via vmr2gn in tcga so in this case you're interested in uh breast cancer so in this sentence actually you do not see basically which molecular data type you are looking for dr wright will ask you which data have you are looking for and you say oh you want to looking for the correlation between gene expression so the g infection then dr rat gathered this idea and asked you do you want no test association between these two genes now immediately you see they can generate this scat plot where they show this 2g and p10 really and the brm2r show very positive correlation "
    },
    {
        "start": 859.36,
        "text": "in breast cancer and then you can download that figure and also see dr wright also asked you to read this job so why don't you satisfy this job if you set it by the job you can just say hey yes and then if not satisfied you just go back this feedback essentially help us improve our underlying model how to interpret sentence so here basically you have another um task say how about to do a differential analysis between gender so you're interested in uh female patient and male patient in kidney cancer you just have this sentence and then after i try to understand sentences we want to do association between gender and jfg see you you get this result in this um in our kidney cancer this gender female have much higher impression of dnf dfg and then don't forget to give us um feedback and sum up that's good to me so you may also just want to do a "
    },
    {
        "start": 920.32,
        "text": "quick video about the mutation uh you want to identify something so biomarker could use you just say you do a uh overall math tp53 mutation uh g infection in um in breast cancer so when you just type this sentence you did not specify which data source but in our platform we already have tcga server swap you may choose tcga now dr wright know you asked and then the data scientists they will directly generate this kind of uh do the analysis for you so immediately you can guide a figure see captain america will show you in tcga breast cancer tp53 hydration show a much worse uh survival so uh this kind of analysis of course um you say if they were capable bifurcation they also can do this but what i mean is through this kind of "
    },
    {
        "start": 981.44,
        "text": "natural language driven the ai module you could do this that without just in a few seconds so you don't really need to for this kind of routine bioinformatic task you don't really need to contact you by for the collaboration where usually you have to start email begin to get a meeting for the background so one last example you want to say hi do we do a mutation view about typical mutation in tcga kidney cancer so immediately you'll get this lovely plot where you show all other multiplication in pcg how they're distributed across tp future g so so again you can give a feedback so this just uh show you a little bit idea how these two when you using natural language you can directly initiate some bioinformatic analysis just like you talk to your bipolation collaborator uh to do the analysis "
    },
    {
        "start": 1042.16,
        "text": "so actually um dr byron can do that more than that for example it's not only can do some higher level analysis based on standardized data you also can you know one challenge you know it's really we can do some multiple analysis for example um if you started from some net generation sequence raw data you want to do say you ask a doctor could you do a mutation called it and then doctor writes to ask okay you want to do a single mutation only on your hair match tumor normal pairs and they use to match pairs and then doctor i will ask you where could you tell me the data site for example you are interested in a data set where a public available in a uh ncbi sr archive you just provide id there and then dr wright will ask you a few questions about uh which tco you can't teach you and then conduct your name for this product um then you give then you begin to do this "
    },
    {
        "start": 1102.16,
        "text": "they ask you you want to do the mutation calling based on that somehow based on that horizon data then you confirm so in this case this kind of data processing may take some long time then you can take a break so you can enjoy a cup of coffee um dr wright essentially using some uh cloud resource to this communication recording when they come ready they will send you email saying hey you're there available then you can go ahead to click the button to see um they basically show this um data report in this data record you see on the left side it gives you the index of what we report and then you can go through those general statistics say how many samples so in this case we have five sample and then you're looking for some feature how many um what's the base how many uh rays are there and then you can also looking for some uh sequence quality say fast q uh qcc and quality if this good or bad "
    },
    {
        "start": 1164.559,
        "text": "and then you can also looking for sequence score distribution uh of course for each figure you're looking for you can always download that save that for your own future use and then you can also looking for a quality square distribution see generally loss rates show very good quality and then base content you have atgc see nothing special you have gc content you read so you see that pretty much fits you um you you can try different interaction and you can see the base and content so there's no much um not result based and then you can see the duplication level and our representative sequence so these are like a normal some procedure when you get data you before you do the analysis you have this quick view about gender quality get some feel about the underlying data quality make sure there's nothing weird and then you can see this read mapping some mapping uh rhythmic "
    },
    {
        "start": 1225.28,
        "text": "per critique and so on so far so again each figure you can download uh to maintain by yourself and then you have this duplicability if everything looks good um essentially they output this mutation calling so you see um here we tell you the chromosome the position was the reference allele and then what's the filter and so on so far so you also have different format like um i'm afl so this basically is a typical um coaxial sequencing product where uh you probably will collaborate with you by information uh when you get the data if they can retain results in say one week i think you will pretty happy but now what i'm saying is with this kind of ai driven tool the moment once you get the data you just kick out the product in second then you get a result on the same day you see you here you get vcfl on "
    },
    {
        "start": 1287.679,
        "text": "mfl format you can save your own analysis and then that could be directly go to downstream nano say say identify significant g and do some efficient signature and so on so far so um this is say not only this that this kind of ai dream too can do a higher level data processing they could really run some fundamental basic pipeline to help us standard some rnc horizon data in a single cell data analysis so the other big thing we can think is about reproducibility so for example here is a paper published in microstrategy in nature i think one half years ago so this paper essentially presents some classical cancer genomic analysis the paper actually sequenced more than 500 breast cancer whole genome seeking data "
    },
    {
        "start": 1349.12,
        "text": "and then if you look at paper um they generate some here just some result directly from the paper so you see they provide you some basic statistics from mutation in dell identifies some driver mutation and then they calculate some driver g and they also uh declutter their mutation spectrum to infer the mutation signature they even um do some uh long non-coding learning so this paper is citation more than a certain times so if somebody come to you say hey i'm interested in the paper using the messaging memory doctor they will just repeat this paper frankly this kind of reproduce is a headache for beneficial if i have a student that can repeatedly say in one week i will be very fabulous i will consider that my physician is very capable to repeat but when you call this data loading in um doctor uh by right where "
    },
    {
        "start": 1409.2,
        "text": "you have data load you just ask the same question could you do a mutation call what's the driver mutation you reach and what's the mutation signature you see on the right side through the sinkhole dialog you essentially get the exactly same result from the um published dot see mutation statistics strategy and signature non-coding so that's actually hints a new direction how we essentially use this ai driven tool we can automatically uh repeat some analysis even check the quality especially for those computational driven analysis part okay so behind this what really what how you do this i can show this all in a little slot so essentially we have this interface where people can either text on ones and then we have this natural language processing module they first given the text they "
    },
    {
        "start": 1471.279,
        "text": "could authenticate what you want so you survive analysis disease names the breast cancer gene name you know like a data to impression you tag those texts and then you given this kind of information we feed to underline model we want to using predict to predict what's the intention of the user so that's the extension recognition and then uh through the dialogue usually we ask you to perform this to make sure we really understand what you mean once you get your confirmation understand your intention dr valrat will identify the data profile and then the data script to do the analysis once you cut the analysis they will check whether we have sufficient parameter to do the analysis if other parameters are fulfilled then we submit this job and then depend on this job sometimes it's very simple we could probably do this in local browser some job maybe take a lot of computer resources like those ngs or "
    },
    {
        "start": 1533.279,
        "text": "single cell data we probably need to do fundamental mapping in cloud computing but essentially this job scheduler will do this job in giving the most appropriate computing resource once you finish this job they will collect those raw results displaying that result through a module visualization module so given this visualization module we turn this result into the dialog interface from the dialog interface we ask you to read our job quality it's good on that or you can report about so you just say i don't satisfy this is my comment we take this kind of user feedback to further update and train our model so this is her view how we really implement this ai driven tool so in this case from natural language processing we develop a natural language um understanding so that's more like a brain to help you it's just like "
    },
    {
        "start": 1595.76,
        "text": "your bifurcation try to understand your question you raised and then you have this kind of analytic toolbox where you have a little module and then the visualization module where we already implemented the most common uh bi-information too in different language actually you can also upload a new language for example no matter it's written in r for cell matlab because we use a wrapper to really wrap that module so the module really largely independent from the computing environment and then we have this whole brain uh visualization module from mutation analysis uh complex heat map network view pathway and single cell analysis and also plant cancer analysis and also this is box so essentially when you have the result people choose appropriate tool or module to help you discern the result "
    },
    {
        "start": 1657.36,
        "text": "so so in the future what we want to do is really load more data as i mentioned currently we only have cancer generator but in future you know a lot of standardized data we can load the more data and also we want to implement more pipeline so people have have choice to choose their preference second one currently dr barry can only do the analysis give the result but we can further ask the doctor right to interpret the result in the context of this reason because we can load the millions of the pubmed in that drive so what he do some analysis he sees some significant patterns say breast cancer and breast cancer typically depression associated with survival they could tell you hey this pattern already been reported in three papers all they could tell you uh this pattern actually contradicts in lung cancer so given a result the ability to incorporate that in a "
    },
    {
        "start": 1719.12,
        "text": "current literature will greatly increase your confidence how to interpret the data so the shortest thing is we want to just get more social interaction so currently we have this available you can talk to dr variety you can either bypass or wise in future we are going to make not only one by one you could make this group checking so you have one product you invite your collaborator you also divide the doctor by right as one member in the group so when you do the analysis you just either dr ryan four second analysis so all the people in that group can see the results are discussed together we also have this um more security so when you log in you really have public data institution data on the private data so you don't worry so given your security level it depends if you can see how much data you can assess so if you have very high nowaday security you can not only see public data you also see private data so you can dump them together "
    },
    {
        "start": 1780.159,
        "text": "do your own analysis but if you say only how do some public data modules available public data so well login you can see the data only available to your security level finally we want to make this platform transform to the smartphone so so that will essentially remove all the time and the limit uh space essentially nowadays everyone works remotely i think with smartphone uh now we can communicate this more get a lot of flexible so the major thing is currently i show you example you may think oh those pipeline i can do that my buying physician can do that but that's just the beginning currently maybe you won't have limit but given the time um because you can constantly add a new job a new pipeline you can imagine in two straight years and also because one people use a data feedback we can more and more accurately interpret data more accurately select "
    },
    {
        "start": 1840.32,
        "text": "algorithm essentially this kind of ai driven will become very intelligent very powerful very knowledgeable so that will be young any single person power okay so after we published this paper earlier this year actually we got a lot of medium coverage like a um smart break they will talk about like um how ai really changed data analytics and then that that is party wheel but there are also some concerns say these kinds of concerns like our competition of biologists losing their job and so on so far so well first of all i don't think our doctor ai will replace compared computational job completely but i do believe that's really channel ai essentially shapes the focus from running some routine and the job more and more new algorithm development more are true development so that's really the key thing "
    },
    {
        "start": 1901.12,
        "text": "so i think we are in a very exciting time of innovation that none of them ever do so we as a scientist as a data scientist we really need to transform ourselves adapt to this new challenge how to leave a post ai one we need to have this turned out skill set and more importantly mindset so if you think this open keep open-minded of this kind of thinking this will potentially open new paradigm of research so personally when somebody doing research is more like present idea do some analysis do some tests they write the paper publish okay but nowadays if you think you can start a question immediately talk to this smartphone smart do some uh middle real-time analysis and then this ai2 will help you assess the reproducibility "
    },
    {
        "start": 1961.679,
        "text": "interpret this result in the literature context and then because this is open source um social media platform you can easily engage different people help you developer can provide some new algorithm for your test data scientists will point to some exciting new data biologists who may provide a new interpretation and the way you do this you can if we can copy this with a self-governing system say some lab robot you even can you generate some new data and let's say that free this new data to the system to do new analysis so you can imagine this new uh loop for research product it's combined with a lot of ai driven power so what i'm saying is from now on when we change our concept scientific research it's more like a co-investigation between human and ai agent rather than something "
    },
    {
        "start": 2024.96,
        "text": "people are using some ai driven too so that's a fundamental message i was thinking when we move to that ai error how we really use so in summary this part i want to just quickly mention we believe in general of um literally left after my right really featured by natural language understanding so language only language how people to develop deep interaction deep thought so one cannot really kind of deep sought deep interaction through a software graphic right but really through some conversation using natural language we can push the deep thinking so that's network understanding second one we want to do some artificial intelligence so behind that really how big data no matter from your data usage on pre-literature you build a lot of model choose device data science the "
    },
    {
        "start": 2085.359,
        "text": "right pro algorithm good visualization module and then everything you want to transparent and then everything i believe future will not on the conventional desktop computer server is really mobile driven because now that mobile is really the interface will talk then you also have everything on big cloud computing on your institute's server so this essentially help us make a intuitive efficient transparent and collaborate um sorry yeah so this is essentially the first part of my talk any question or two okay so now i'll switch here you know about uh you know the fda just put up a uh they have a regulatory framework "
    },
    {
        "start": 2146.0,
        "text": "for platforms that have ai machine learning for patient systems and it's worth looking at it was just posted in january and uh you know so because it's kind of software is they're thinking about as software as a device you know and this kind of thing and so actually if you hadn't i think by and large i mean you can make your system conform to it pretty well but i i don't know about the crowd sourcing you know i mean i that that might be one that's not gonna you know because what what there's gonna be or some kind of reg you know regular updates and versions having to do with the control about the training stats and this kind of thing so in order to actually have this be useful as a clinical tool you know there's likely going to have to be compliance with this which might scale down the vision a little bit you know and i'm just wondering if you thought about that yeah so that's a very good question especially given our eterna i'm the answer experience "
    },
    {
        "start": 2207.119,
        "text": "about watson you know so so so far our birth not for clinical use or only focus on basic bioinformatics analysis where you have very clearly defined bioinformatics tasks and then routinely that is handled by our analyst and then we know the right answer for this situation because we know the clear right answer we could easily benchmark the performance and then because we generate a transparent report everything can be trackable so i totally agree with you go to the clinical side like after yeah it's very it should be something should we take a great question but yeah so that's yeah so i guess the thing is just in terms of wanting to use it to kind of like start inds and phase ones and you know the early phase of the clinical that would be something maybe you know something to talk about you know yeah yeah that's really that's great advice yeah yeah yeah thank you so much very interesting "
    },
    {
        "start": 2269.44,
        "text": "so that so that's a that's really two parts so this part we really have people in power a lot of researchers can do things much faster if they have to waiting for their collaborator so my second part is really about the prime cancer analysis is more like a computational biology product so i want to push a idea so our ability to interpret is really go through this pyramid at the the very bottom level we need to get a better understanding about the genome structure once you get the better stats we can help better understand the genome biology from there we can have better interpretation about disease biology how they really dry disease once you develop that understanding you get a useful clinical application so that's really the way so um so let's highlight how fundamentally genome structure is important in our interpretation data so in this case we focus on a enhancer as you know enhancer is non-coding regulatory elements they usually far "
    },
    {
        "start": 2331.68,
        "text": "from their target gene in the 20 space but in the 3d space that enhancer actually could bring to the promoter region and then they could help recruit transmission factor and then turn on the target g so so you can imagine that when you have inactive enhancers well wrapped around the nucleosome but when you have active enhancer um this will polymers two will bind to that region uh chromosome will open um the enhancer come but transcribed by a continuous tool they generate uh some short rfc grid say era enhancer we can call it era okay so we thinking that the er signal could use as a redox for your cancer activity because when you have enhancer activation you find drm but this kind of yearning signal strongly depends on the annotation of er locals "
    },
    {
        "start": 2391.92,
        "text": "so uh about two years ago we published a paper uh in um cell where we do the first time cancer analysis for tcga where you have nearly 9000 patients we use a phantom consortium date using cage sick because khc can really generate a accurate position but that keeps you only cover 15 000 enhancer locus but even for that small side of the enhancer we could quantify the cancer traction level and from there we could develop a integral approach to inform causal enhancer regulation so the things is if we just get the enhancement gene try to do a coefficient they could that coefficient may or may not represent the caudal effect say um but if you really treat out the caudal model we further consider the snape in the cancer say if you have enhancer really called the g equation "
    },
    {
        "start": 2452.64,
        "text": "you would expect to observe the eqtr signal for the slip on the enhancer but on the other side if a coefficient due to the generator enhancer that's reactive model you will not see that on enhancer and the g and co-regulated by third factor you will not see this equals tl signal so essentially what we did is we have 33 counter type we first then defined a tiny co-expression enhancer under the gene pair and then we further incorporate the eqtr signal from g-text and the resultant genome usually can really see there's one slip in enhancer they really cause generic level so that's called uh enhancer gene regulation and then we further have this high sig 3d genome to make sure that propulsion cancer physically uh close to targeting so that's really direct causal uh inherent regulation "
    },
    {
        "start": 2513.359,
        "text": "rather than some secondary effect so with this approach we could build a uh it gene a regulatory network so in this network especially focus on the security target uh each circle represents one security target uh each box represents one enhancer and then one pair first got a lot of tension is this a pdl one as you know pdr1 is a major circuited target for immunotherapy and then we found that there's a chromosome 9 there's a small short enhancer we can call it the enhancer line is which you have this direct regulator's pdr1 so uh we can further validate this say given cell line we can use a crease power to cut now called this uh region in faster nine and indeed in both um this uh messenger and that one protein level you see where you delete it that's the enhancer nine even though only very short you substantially reduce the "
    },
    {
        "start": 2574.8,
        "text": "pdry expression at the both massive level and protein level and even with the user garment stimulus you see the pdi expression levels still much become much lower so that's if you and then through some further data menu we basically bring a model in enough cover b immediate promoter interaction basically f kappa from a dimer bring this sensor knife close to the pdm promoter basically turn on the pdr one so let's just give you one example when you have this detailed understanding about how important circuited job a target to be regulated it could potentially develop a new target but the problem is for this study we only focus on very small side i well annotated the enhancer local so that's due to the phantom but for a large majority region for example for superintendent region you know very fairly young uh really during this concept people know "
    },
    {
        "start": 2636.319,
        "text": "supreme cancer region is really big chunk region in the human genome but they really provide very important role in control cell identity so and t2 development so really when you superimpose those heat modification signal you see some region have very dense um signal so they are really can um defense super enhancer so through study you have quantitative super effective region the problem is when you look at the superintendent reader here just give you this um genome region represent genome reading you have this lot of his multiplication p and then you define this region but if you look at the scale this region easily 7 kb for such a big region essentially you're very hard to quantify er signal because when you have this big signal remember er signal is very big so when "
    },
    {
        "start": 2696.56,
        "text": "you have big region you just have a lot of background noise that background noise will easily overcome those two signals so essentially you get nothing so fundamental idea to understand the superintendent activity is how can we accurately quantify era signal let me repeat this challenge is how to quantify superintendent activity is concurrently accurate quantified er signal transcribed from super effective region so from this we recent published a paper presentation what we really did is we started from a huge one data aggregation try to understand what's the principle governing super-enhanced region from there we identified do some global identify some transcription units in the superintendent reader then we do some downstream application so what we did is when we get a set of core supreme heights region meaning the super enhancer active cross multiple tissue so that represents the most "
    },
    {
        "start": 2758.079,
        "text": "confident super has to read only 5 megabyte region and then we can easily aggregate hundreds of tcga samples together and then we found this region when you aggregate 100 you see some very clear peak so here you can see it is colored by different pig and then they actually form this kind unit so this is when you have this peak they form this very clear it's very uh expression peak in different cancers some of times there are multiple people so you have this quite peak and then we also want to two three this peak location is conserved across different data side so you can using the same practice for gtax where you have normal tc you found this for this region the peak location actually quite consistent even you use a totally different consortium product totally different data you see the peak "
    },
    {
        "start": 2820.0,
        "text": "location actually quite consistent meaning that's really not from some random noise and then further what when you superimpose this kind of peak what we really found is they form this very sharp really just about 100 base pair uh peak whale so this happens in both tcga on the left side and then the t-test on the right side across different disease cancers have quite different tcuc era forms this very sharp peak and then we also went there because it's only 100 base pair this reminds us the ribosome nucleus of the nucleus of ramping is only 100 so we we're also looking for this big location we found for those people they are flanking the bike tr a transition binding motif so on the both sides you see a very clear uh motif on that peak side "
    },
    {
        "start": 2881.28,
        "text": "so that also highlights this really potential due to a enhancer where being bridged some important motif and then um well we further collect those because we wonder what regulates p one hypothesis is regularly really due to the underlying nucleosome so we collect uh the nuclear profile generated by laminates so from 29 different tissues and then when you have this nucleosome position new um nukism position on the peak you see there's a well positioned peak corresponding to that peak so i want to make it clear because we do multiple tissue so one there's a um nuclear occupancy there's no that peak but when this nucleosome uh off you'll see there's an activation for that er signal so but when you simply impose the signal across macro tissue under the nuclear position you'll "
    },
    {
        "start": 2942.24,
        "text": "see a well positioned nucleus of corresponding to that peak so that's really um if you look at that the peak position cross different lineage because in the mouse and the peak they also generate some nucleus on binding profile you found even the sequence actually not conserved the nucleus of position is quite conserved so now we can see those era peak we observed actually due to some very evolutionary conserved well-positioned super um nucleosome so based on that we can propose a model how that er really you see that erp is really when you have this well-positioned nucleosome here highlighted in right in green color so when this libra occupant that you turn off that um er signal but when you have this activation "
    },
    {
        "start": 3002.48,
        "text": "uh they train the polymers to recruit some transmission factor binding to that they have some transcription activity you observe some ear signal but because that er signal is such consistent from that locus you see a peak when you observe across hundreds of samples but when you look at individual you don't have this power because that very weak translucent easily get lost in the background so that's really the working model for our understand the er signal now the hypothesis how can really have two observations one is this kind of superior cancer region contain multiple year and still local where they can generate very sharp er exhibitions only 100 bits per long second one when you have this er locally potentially coincident with well-positioned nucleosome so that's a two important observation for such kind of supreme cancer locus so we then want to do the global "
    },
    {
        "start": 3064.96,
        "text": "discussion we extend our own assets to 370 megabits superintendent region and then um we do some we studied some nuclear some position where basically you look at the pca there's a one pca component called pc3 that's corresponding to the nucleosome position so um to make it very simple it's basically an active pcs ring meaning that position how well well-positioned nucleosome position occupancy so based on that principle based on the local extraction peak based on data newton we actually identify 300 000 er locus in that super enhanced region so this is each locus hybrid clear star endpoint only 100 base parallel so now you have extremely high resolution era locus then "
    },
    {
        "start": 3125.2,
        "text": "we can validate this say given those locus for certain reasons they have er signal you see they have very clear cave signal around the era peak we annotated but for the mass majority reason because you don't have the k2 signal for the mass of directive our er signal really can give a lot of new uh locus so the reason yeah is to interrupt like i just want to give you uh we have till five so yeah just two minutes sorry for that yeah so so basically we have this why we believe your answer could we because we believe in cancer is a good way to address the tumor hydrogenity you can imagine that what we got is about sample if you want to do gene level correlation say essentially you do gene expression with phenotype what you look at is uh aggregation different cell type "
    },
    {
        "start": 3186.16,
        "text": "uh so when you do this spin half correlation this correlation is very weak but suppose you do enhancer each some type of your specific enhancer enhancer a control your fan blue gene fashion so when you do the enhancer suppose this phenotype is controlled by um enhancer a well do your cancer level you would see a strong correlation in other words if you do a gene level because we usually use about example you essentially confounded signal by different cell type but when you do the sound type enhancer you really have this power so for example if you look at the learn to predict say immunotherapy so you have the menoma patient same pdi1 treatment some get to respond some muscle response so if you look at the paper if you're using the coding gym on the left side you see there's no energy because the sample size is limited really you see a uniform p-value distribution there's no system gene "
    },
    {
        "start": 3246.8,
        "text": "so but if you look at the enhancer you really see this in p-value in reach even game of q f 0.05 you have about 164 locus and then if you do this here map this er signal can really separate these two clinical response and then if you do a gene site arrangement based on the enhancer you can really see that the cdx this enhancer regulate uh the biology cdx t-cell exhausted on cdx intention so this perfectly matches what we understand how t-cell and that play low in the immunotherapy so this just gives an example because we use a specific enhancer that probably can deform t cell so we can make this clear phenotype inference but when you do the gene level because you essentially get aggregated signal from across all the cell type you love the power so this kind of pattern also has also "
    },
    {
        "start": 3307.2,
        "text": "can be validated by independent uh cohort so what i'm saying here basically say super enhancer get a decrypting sensor signal uh locus by erp and then this erp discretion regulated by dynamic wealth position signal we our last provide a high resolution map for this er locus so people can easily use the hardship of quantified people in cancer signal and then we believe super uh er signal provider much better return power for quantitative traits beyond generation so and then i think that we're close to time i just want to sound the first part is really my challenge of fellow julie leaders decipher to make this very powerful and legal tool my second part is really my postal fellow function make this enhancer analysis help provide and then i will send my funding resource and stop here um here is my favorite sentence sharing "
    },
    {
        "start": 3367.52,
        "text": "with you the best way to predict future to create so yeah so i will stop here happy to answer any question thanks a lot hun um sure go ahead brian yeah hi thank you so much for the second part of the talk it was fabulous uh you know one of the things that has been confusing me a bit is the super enhancer really involves a number of enhancers really kind of three to forty teams that are likely on you know adjacent pads or at least you know spatially uh close so you know so so you know that's one thing that i think is an opportunity for some continued analysis because focusing on a single nucleosome which is terrific gives you one enhancer but doesn't give you a super enhancer doesn't describe how that gets in and out of the transcript of compensation not a criticism "
    },
    {
        "start": 3429.76,
        "text": "i totally agree i think that's once we fundamentally understand this map the next step is really how to see their synergistic effect aggregation effect and they build the model so that's actually perfect exactly what we try to see how a g there are some multiple uh equator units how they signal really talk to each other determine a specific cell type direction profile that's totally on our gender yeah so that would be good to talk i was um i would love to have a chance and dear and i are collaborating i'd love to have a chance to be able to speak with you more about that yeah that would be great yeah thank you so much so han i had a question about the first part the doctor bio right yeah is that sitting on what databases is it querying for doing at this point you plan to uh so two parts one is good yeah so currently we have some wildly used the data like tcga icgc ccle each of these 100 we are "
    },
    {
        "start": 3493.76,
        "text": "planning to add more data sites like uh we have this pediatrics and then you have the genie so we can essentially add more data set to that just because mac group has limited manpower at this moment to try to make the basic function infrastructure more stable yeah but definitely we can add more data and also actually one way is if your current data not available we are going to record this if there are sufficient user current data site which is not available we are going to add those data to the to the platform yeah are you participating in cp tech yeah that's actually one thing we're going to do that to try to add the cp tag to the to the data set yeah because i can see a lot of people want to do that joint analysis between tcg and cp tag can you conduct your analyses from the existing cardiogenomic data we already have yeah that's actually if once we load the data all those module visualization module when already "
    },
    {
        "start": 3553.92,
        "text": "available you can easily say if you ask a question we we cannot question what's the correlation between 2g at the messenger level we can easily by know that the tbi data we can ask what's the correlation between 2g at the protein level what's the correlation between messenger and protein level so all the question if we use it yeah yeah i'm gil ohman i'm part of the cp test yeah no i don't i know yeah actually you are the leader for if you can so because i'm you know right yeah yeah i'd like to get capture you into this yes yeah you can talk to them if you can cb tiger consortium allow load a lot of data so people can easily just current so basically now they have any questions they just come to dr barrett to say what's the tpp3 correlation mutation with say p10 protein in cp attack they will do guide result immediately good that's good do you exploring some of the biological "
    },
    {
        "start": 3616.16,
        "text": "implications for the erna storm i mean you know there's there's probably other things that it does yeah that's actually so i think there's an controller g and then confirm the specificity and then we are now doing a lot of like a clinical application try to see um era whether they could as a potential micro biomarker fundamentally for those therapeutic target gene we try to see how the gene pattern is regulated by the enhancer because when people really think how the g and alkyl gene boost up on tumor support they usually think it could be um due to copy number they due to mutation they due to dna methylation they due to gene fusion we believe there's one way one one more way is try to disruption of the enhancer regulatory elements also another powerful way to perturb those kgn yeah that's one thank you "
    },
    {
        "start": 3680.48,
        "text": "you know just one more so when you show the uh when you show the scans on the nucleosome positioning you know you show all those kind of like scans from the additional tissue types you know it's hard to kind of tease them out but then when you show the other slide uh you know that showed the nucleosome positioning uh profiles at least on the center nuclear zone was a function of different species and things like that you know it it did show a lot of uh you know a lot of variability actually you know there was uh so is there is there something that that we could learn from all of that because i i was um i was yeah about that so so uh there are several things number one things is um when we have this profile the nucleosome profile we are there's no such such systematic process we are collecting those nucleus from data from different literature uh so it's a meta-analysis you can imagine even though we make a lot of effort treasury mapping "
    },
    {
        "start": 3741.44,
        "text": "because they are not like a concern they could have be some variation noise so for that part we really want to see some general pattern um yeah i agree there could be noise one thing because there are some fundamental noise when we do this kind of aggregated cohort the other is when we inform that uh enhancer for example maybe there's some variation when we define the boundary of that because intrinsically er expression level so low so even we have hundreds of them we can see shape the boundary maybe not vary so that's another thing yeah so why yeah yeah yeah thank you yeah i'm looking for i have several colleagues scheduled we have to talk tomorrow we have we can have one by one discussion yeah hopefully you enjoy and then we just talk to dr wright i'll show you that yeah yeah i did try it on the side by the way "
    },
    {
        "start": 3801.76,
        "text": "it was very cool so on that note there are no more questions thanks a lot han for taking thank you thank you bye "
    }
]