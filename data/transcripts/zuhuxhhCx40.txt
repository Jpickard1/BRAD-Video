it's my pleasure to introduce uh dr alfa lee when i was a post-doc he reached out to us with this really cool idea about how to use random matrix theory to come up with a baseline for one of our models that we were doing for um ligand driven drug discovery and then that next summer i met alpha at one of like gordon research conferences and we hit it off and it was just uh such a flurry of ideas and i really enjoyed uh getting to know alpha and i've been following his work closely he's i was at harvard and now uh he's been in cambridge with his own group and uh recently he's been running as he says a drug discovery biotech company in the open publicly so we'll hear about this coven moonshot project which is really innovative approach to collaborative drug discovery and uh he's got some really exciting ideas about combining machine learning and structure and ligand-based uh drug discovery so i'm i'm thrilled to get him have him a chance to come and present to us and for the graduate students that are here uh you're invited to stick around for an extra 30 minutes after to have a conversation with alpha so please join me in welcoming alpha to present today yeah thanks so much uh for the uh invitation uh pleasure to meet you all um virtually um my job today will be about um the covert moonshot initiative which is in open science initiative trying to uh find science cultural main protease inhibitors with a crowdsourcing open approach um and i will first talk about uh moonshot and our progress and then the second part of my talk i will focus on uh specifically uh diving into how machine learning has aided moonshot and some learnings we have got from applying machine learning in in a very prospective um setting uh in the open trying to find an actual drug uh before i talk about moonshot let's take a step back and um and ask the question well why do we need an antiviral against covet seeing that you know vaccines are now available um why do we still need to do drug discovery um the reason is that we think antivirals are operating in a very complementary way to vaccines uh first uh vaccines are known to not be completely uh effective uh in fact there's age groups which may not be successful to be may not be appropriate for vaccinations and uptick still leaves a big problem more importantly orally available pills are often much easier to make much easier distribute much easier to administer and antivirals have a large window of opportunity to work when a patient develops a mild to moderate uh symptoms it is known that the end stage of covet usually occurs with immune overdrive whereas where there's a clear window of opportunity when the patient develops a mild to moderate illness where an antiviral could be very very uh useful and more important antiviral can also be used in a prophylactic sense administered to patients who has been in contact with people with other uh confirmed cover positive patients so we think um antiviral in particular orally available antiviral plays a very important role alongside with vaccines and public health intervention in combating this pandemic so focusing specifically on like therapeutic intervention against covet if you take a step back and look at all the viral mechanisms one protein particularly stands out as an eminently druggable target and that's the main protease the main protease in a nutshell enables the virus to replicate itself and inhibiting the main protease thereby shuts stress down on viral replication and therefore trying to drug and target the active site of the main protease or m pro is is a very viable strategy to go after covet uh more moreover the main protease is also distinct in sequence to any host human proteins therefore going after the main protease minimizes the risk of unintended targets and off-target effects and so this is a uh going after the main protease is definitely not a new idea um even back in saskoff one there has been a lot of work uh targeting the main protease establishing the mechanistic um relationship between a main protease inhibitor and viral death and to some extent even in vivo models of a viral infection showing that there's a very strong disease target linkage um what what is even better about the main protease is that it's actually a target a protein that is broadly conserved across many pathogenic coronal viruses sars1 a mers covet and many other coronal viruses actually if we align the sequences uh we realize that they are the main process itself is broadly conserved which means that having a having an antiviral against covet might mean that this antiviral could be broad spectrum and the structure of the main protease was released back in february of last year revealing that the binding site actually shows remarkable similarity with of saskof1 uh in fact uh the the drug that is currently in the clinical trial uh for m pro inhibition uh produ um produced by pfizer was actually a program on uh for science cough one back in 2003 to just follow the pattern and shelved it until now however apart from the drug that i mentioned um on the clinical trial by pfizer there is actually no human chronovirus and pro-inhibitor approved as a drug however there are drugs for cats um for main protease the feline coronavirus is a very similar coronavirus to um in in terms of emperor sequence identity to the human uh saskoff 2 and there is a compound in late stage clinical investigation for cats so again another piece of evidence that there's a strong target disease linkage and m pro is a eminently druggable target however looking at the many different drugs clinical candidates and advanced clinical candidates um currently undergoing investigation there is a there are two common themes which um emerges the first is that they are peptidomics which means that they look like a they are very big molecules and peptide like the second is that a lot of the compounds work via covalent mechanism trying to form an irreversible covalent bond or reversible covalent bond with a cysteine residue in the catalytic site in fact the pfizer clinical candidate which i alluded to is both a peptidonic and a covalent compound and peptidonics are a notoriously hard to develop into oral therapeutic and not surprisingly uh the pfizer drug uh or the physical candidate i should say um is an iv drug um the same with other covert medications like rem deserving so there's a an acute need to develop a orally available small molecule drug and more important and in addition to that the covalent mechanism that a lot of these drugs operate in does raise the concern of idiosyncratic risk down down the line and so another desirable feature is if we can develop a small molecule non-peptidomatic orally available drug that operates on a completely reversible mechanism that uh appears to be the quickest and safest way that we can get to an oral antiviral and so that in a nutshell is the premise of moonshot um trying to find uh a uh orally available uh small molecule antiviral the whole project started uh back in i guess february of uh uh february fourteen 14 2020 uh almost a year ago or actually just a year ago the main protease was cloned and produced by martin walsh in oxford then frank determined the atomic resolution of the structure in february 20th i think replicating some of the work done by a chinese group then near london and wattsman did a covalent screen finding hits in february 25th and then march 5th um they cut they on a single day they collected 150 a thousand five hundred co crystals um and in march 18th uh they released the crystal structures on pdb and on the diamond um website so all in all in just over a month they went from cloning the protein to doing a fragment screen and the fragments completely cover the active site which is beautiful here here is a snapshot of a zoomed in view of the active site and the fragments that decorated the active site um showing that different regions of the active site the peop the different pockets um in the canonical nomenclature the p1 prime p2 p4 and p1 um including here the yellow box shows the region where the catalytic cysteine residue which is a residue primed for covalent a covalent mechanism um are densely populated by fragments and that seems like a treasure trove if one were to think about developing something out of that because there seems to be a lot of opportunity for fragment expansion and fragment merging the bind the fragment also binds very deep into the binding site meaning that there is actually quite a lot of mileage one can gain from just looking at these fragments in case another um zoom zoom zoomed in image showing that a lot of the fragments just overlay beautifully onto each other again teasing us with the idea that maybe fragment mergers or fragment expansion could be a way where we can rapidly get to potent inhibition as i said all the data were released by martin and frank and nia and others directly online and back then i was in actually in california i'm starting my startup postera and we looked at the data and we looked at frank's martin's tweet actually and i was on twitter and looking at that and i was like wow that's like great and one of my co-founders were like let's you know really help drive this effort from a fragment screen and a structural biology work into potentially a drug against npro um and we're really emboldened by this idea and the open science ethos and so we want to take it one step further and actually launch a drug discovery effort out of um these beautiful structural biology data and so moonshot was born almost a week later the premise of moonshot is well there are a lot of um fragments out there that frank and others um accumulated and and and released um why not re release this to the medicinal chemistry community and in the and and like-minded colleagues and ask them out of these fragments how would you merge them together from a protein inhibitor and what are the fragment expansion ideas that you you would suggest us to do and we literally have a website with a uh with a catcher with a chemical drawer and ask people around the world to chime in look at the structures and draw their favorite compound and submit um seems like a very naive idea but we thought well why not um back then was the first wave of lockdown and we hoped and reckoned that a lot of medicinal cameras are probably working from home and hopefully they would have some time to chime in and nature came also kindly ran a correspondence piece for us um advertising this um effort uh to the world scientific um community we thought um i mean trying to um draw molecules from fragment merger seems like a rather niche activity um wouldn't say it's necessarily the past time of most people so we thought maybe we would get you know 100 submissions and you know as long as those submissions are great like that should be at least a good starting point that in this initiative we can think about how to build on that and actually nucleate the community but we were incredibly humbled and emboldened by the response that we got uh to date we now have 16 000 designs submitted to our website from 450 designers around the world and and and that and that includes a lot of a very experienced medicinal chemist from the industry in fact ucb farmer joined the consortium and they dedicated 10 percent of their time that mad camp design time in helping us come up with ideas and a lot of retired chemists from the likes of pfizer extra seneca just uh freely joined and gave us their ideas and their insights um to date uh we have made synthesized and tested over a thousand seven hundred compounds in example i would uh talk a little bit more about the synthesis part and the testing part later in my talk and learnings that we gleaned from uh making so many compounds so now there is a lot of compounds um we have established like even due after the first week we got like 2 000 compounds submitted up the first week so we established uh very quickly that there is actually a lot of interest in helping us and we were really emboldened and humbled by the support from the community but then as you can glean from these statistics we can't obviously make all the compounds and we in fact made only around 10 of it um and so the question becomes we now have 2 000 compounds like what do we do with it and how do we decide and how do we rapidly triage so many compounds uh to figure out which one shall we made and know that back then it was a year ago we were still very much in the fragment to hit stage um the probability of a compound being hit is is on average pretty low so we're trying to make as many as possible and that's where um a machine learning technology which i would take a deep dive later on becomes incredibly useful in a nutshell i will talk about that later in the talk we use machine learning to design synthesis route at scale so basically we take all the crowd source ideas put it through a machine learning algorithm the algorithm connects to our partner contract research organizations like inamin ushi and sci life sciences in india and automatically designs the synthesis route and then we know exactly how hard it is to make a molecule in a particular cro um so that we can say hey this is a one-step route two-step molecule three-step molecule and then in the first round just say whatever that can't be made in two steps well we are going to wait till another day to make it and that allows us to rapidly turn the synthesis wheel i would talk about this a little bit more later later in the presentation um but just to say that this effort has spiraled into a global collaboration um we literally um our collaboration spend most of the world um ranging from virology in in israel to structural biology in oxford folding at home which is the world's um i think at one point became the world's only excess scale computing resources because so many users wanted to chime in and contribute and donate a cpu time to voting at home and so we for a few months i think became the world's largest supercomputer uh running free energy calculations um etc um this map summarizes only part of our only some of our collaborators and we are really really fortunate to have a lot of people are willing to work for us um pro bono and this allows us to establish uh a uh i guess a relatively robust essay cascade um going from uh enzyme enzymatic biochemical essays done in actually two places oxford and white spin so we do two assays for every molecule in two different method fluorescence and rapid fire cytotoxin crystallography that's done weekly and then compounds are then promising compounds are then ran in live virus essays again ran weekly in israel i think that input is really useful having weekly turnaround and viral essays and then tier one at me uh pk and then right now we are at the pk stage and beyond that we have also aligned collaborates to ascending those tolerability efficacy studies and other diagnostic essays and so this cascade at least the ones highlighted in green and yellow is running on a weekly basis where we cycle compounds through the different assays depending on whether they pass potency threshold and i think this open science approach um where all the data is being released immediately and we claim no ip and no patent means a lot of people uh uh very kind the contributors are in a position to collaborate with us to allow us to establish this uh sa cascade which generated a lot of data which i will go on to talk about later so i may ask well how does the crowd sourcing actually work and has the crowdsourcing actually yielded um uh anything and this is an example of a submission actually from that um website i mentioned a few uh slides ago we launched a website moonshot and then ask people to submit things this is one of the first submissions actually that we got a person a triphon sarganis in oxford basically looked at the fragments and proposed and proposed the following merger shown in the box he literally um said let's merge these four fragments together and he thinks this compound triune4714 a76b6 would be an interesting compound is actually purchasable from mq and mo port so we bought it and this compound is has an ic50 or 23 micromolar not bad seeing that it's starting actually just from fragments right it's not even a we're not into hts it's just fragments so that sounds like an interesting hit um and this is an example of a hit that we got from the crowd and the whole moonshot project is completely open science where we release all data uh the minute we receive it back to the website and to solicit more people uh submit and ask more people to submit things to um and ideas to us and this cycle has continued now many many times um i think we are now on our 40th week or something of essay results and so um this iterative um data release crowdsourcing data release crowdsourcing cycle has it converged onto four i think salient um non-covalent series um the minor pyridines the oogies the cranial and benzoyl triazoles uh one primary series and three backups and the four series on on you know the and so 2d view uh looks are very different they they have very uh different chemotypes and bond um connectivity but gratifyingly they actually share a very similar mode of binding as in they span similar regions in the binding site and basically fills the binding sites up pretty well and that's nice because we have now many different chemical matter and chemotypes that spans the binding site and obviously different chemotypes would have different admin profile and tox profile and so having all these diverse starting points and chemical matter allows us to make progress in understanding whether we can graft one chemical matter from one series to another and vice versa um just give you an example of how this iterative crowd sourcing uh driven lead optimization has worked so i mentioned this uh uh person in oxford submitting the first compound it's literal uh we call it a minor pyridine because it was synthesized from an amino um coupled with a phenol of acetic acid um that was 24 micromolar we then immediately released it back to the crowd and sometime later folks at ucb a pharmaceutical company submitted this compound going from from methyl pyridine into an isoquinoline um that is now significantly more potent and then um it was suggested why not cyclize it to form a benzopyrene this this gives a little bit more conformational of rigidity again now the potency has improved uh through a chiral resolution low and behold it improved 2x and finally adding a methoxy in the quaternary carbon gives now an 80 nanomolar inhibitor against the main protease and this is this 80 nanomolar inhibitor is actually also active against livestock of two virus with a uh 500 nanomolar ec50 and at every stage of the process we have rapid um structural biology feedback so that this so that we act we actually um guided by uh and enabled by uh very advanced um structural biology insights and inputs um this project is obviously not about ligand discovery are we about drug discovery and we have also addressed acne problems in uh lead optimization for example the first benzopyrene compound that we got has a relatively low solubility and a very relatively low half-life in human living microsomes and we have been able to rapidly navigate and away around this chemical space showing that if you turn a benzopyrene into a tetrahydroquinoline that improves both solubility and human liver microsome stability um which essentially forms an extra it creates it has an extra hydrogen bond donor and therefore not surprising it reduces the long p and interestingly if you add just add the chlorine there uh to the fennel ring you also improve a metabolic stability and the punchline of that is that we have now found actually multiple ways to maneuver in chemical space where we essentially retain potency but we can navigate the admin space in a very facile way in terms of where we want to be we actually have a target product profile of what where window hit um and the the column on the on the left are so our key target product profile in terms of uh high potency against the biochemical assay are good viral antiviral properties important pkpd properties we have a semen above ic50 for at least a day and then hopefully a broad spectrum again active against the broad spectrum chronovirus definitely wanted to be oral wanted to be a uh class one from biopharmaceuticals so uh highly uh we aim for high solubility um a long half-life and so um the standard um safety pharmacology co requirements and progress to date we are almost meeting the proteas uh activity and viral replication uh uh goal um we are now we are still in the process of uh doing uh a set of uh mouse pk studies and corona spectrum studies to understand uh the pk properties and we have actually got compounds of oral exposure already although the half-life can definitely be improved solubility is doing well in terms of safety um because the compounds are extremely um small they're actually very very ligand efficient and so um this com compounds are pretty clean in a protease panel panels and also uh pretty clean against safety pharmacology uh panels and uh i would emphasize that um perhaps it is a a consequence of um the ability of nuclear a lot of ideas from disparate sources from the crowd we have actually converged onto a set of compounds that is extremely extremely um liquid efficient in the sense that um a very very small compound leads to a i would say surprisingly high potency if you compare it against precarious candidates based on capital pneumatic those those are pretty big um uh uh molecular species whereas here we are dealing with a really small compound yielding a nanomolar a low nanomolar antiviral uh inhibition in the enzyme essay and the nanomolar inhibition antiviral assays so i think that gives us a lot of hope and and and and and uh promise that actually these uh we are we are landing onto chemical matter that can be rapidly developed into a promising drug and here's a leaderboard of our current uh top compounds um the first row is the benzoyl pyramid which i alluded to is not soluble and rapidly cleared we have now solved the clearance problem in several ways and as you see now we are in the regime where we are landing compounds that have reasonable half-life reasonable solubility clean off-target effects um and clean us and no selectivity problems with decent um hopefully decent vivo pk although that's something that we are now rapidly gathering data for and exploring now the pk sar space and again the compounds are still very very small and a ligand efficient so that's the sort of where we are and the next part of the talk i want to take a step back and and i guess reflect a little bit on now we have ran the design test cycle um for you know 40 something cycle what is the rate determining step i think there's perhaps a lot of excitement in the literature on you know potency prediction and predicting a bioactivity of ligands and designing better ligands but if we sort of take a step back and you know just try the number of calendar days in each part of the design make test cycle what surprises me is that the design stage uh you know we typically would have a an hour-long meeting every week talking about compound design people go back home they can do machine learning or docking or fpp max will be a week to design a compound i mean if you just do standard sar then you know you can just draw a compound and that would be like hours right synthesis on the other hand even a very simple compound um would take like two to three weeks to make um and just purify and lcms and all the sorts of fun stuff they need to do in in to to confirm that the end of the compound so that can be three weeks or you can even go up to eight weeks if you're unlucky right and even then you may have to drop the compound because you really can't make it testing is high throughput uh biochemical as a virus is a bit of a pain you need to go to bsl three laps so you know a day to a week even pk like studies where it can be done into two weeks um shipping is the amazing bit uh i've never respected dhl more in my life um before being involved in uh moonshot it's actually um a time sync um if you run it over and over again it's amazing how fast we have gotten shipping to i guess from the good old days of weeks to now less than a week but still it's like one week of the design test cycle so the take home message is that actually um synthesis is the rate determining step if you think about design make test cycle now obviously one could argue that if we can design the best compound then you can just make the best compound and that would be the end of it rather than going round and round and round however if we think about it um to if you make a wrong compound or we don't know whether a compound is a two three week compound or eight week compound that is like a two to three x loss in time if you want to compensate it in the design stage then you really need to improve your enrichment factor by a lot to compensate that um and so an incremental or even a significant statistically significant improvement in let's say enrichment factor auc or whatever metric we use for potency prediction um that's great but if you can't accurately forecast whether a compound can be made quickly then you just sync a lot of time for relatively little benefit and so that's one of the i think uh take home that we got from running this many times is that actually synthesis is incredibly important and it's actually one of the if not the rate determining step and trying to reduce synthesis by improving quality of design in theory would work but you really need the design to improve by a lot compared to the baseline which is you know standard sar or docking or whatnot so trying to achieve that delta is hard but what we find actually which i will go and talk about in the second part of my talk is that trying to shave off time in the mix stage is relatively achievable with machine learning in particular having trying to have a very accurate estimate of whether your compound is easy or hard is something machine learning can definitely help so i'll focus on the mix stage for the remainder of my talk because this is a one of the fairly painful stages of this process and it's a stage where we think machine learning can actually help in excel in accelerating the whole cycle so again um why is synthesis important well synthesis is important not only in the abstract sense it takes a long time but also because it's a large variance in time it takes for example the compound on the uh on the left is a is one of our first pencil pyramid hit it is a um you know a bicyclic it has a bicyclic uh structure the benzopyrene um it looks relatively complicated but it's actually a one-step synthesis it takes enemy in a week to make this and purify this another week to ship the compound on the left is a slightly different configuration of a six-membered ring with an oxygen there um this beast took two months to make and we almost failed to make it um only with a lot of attempts we can actually make that compound um and so relatively complex the take home of this uh observation is a relatively um complex compounds complex looking compounds can be very easy to make um if you have the correct inventory and relatively and and compounds which have the same complexity could actually then be astronomically hard to make because you just have several steps that are that turns out to be a minefield and the slide that i put there with rats that's like attempts failed attempts failed attempts failed um so have been able to forecast these minefields that's very important um so how do we do that well let's take a step back and think about like how do we how should we um accelerate synthesis using machine learning well one way to accelerate synthesis using machine learning is well if we can predict at least the outcomes of chemical reactions accurately well that would avoid a lot of these um red um uh uh failures shown in the slide and that might help right and then we go unstep further and start planning synthetic routes so then okay let's answer the first question how do we use machine learning to improve our prediction of chemical reaction and that leads uh nicely into trying to learn the what i would call a language of chemistry uh this machine translation approach to reaction prediction which we developed uh in the last couple of years the idea is basically that rather than thinking about necessarily sketching out the mechanistic steps in a chemical transformation um and trying to you know infer from the arrow pushing in oracle classes um or you know dft calculations between theoretical chemistry why not lean on the vast amount of reaction data that is currently available we should just basically download from patterns and just you know treat a chemical reaction as machine translation where the reactants and reagents are the input and the product is the output and you can just you know effectively google translate your way to reaction prediction um that seems like a very um naive idea but we actually showed that this uh really uh naive model of effectively natural language processing approach to reaction prediction has a tested accuracy of over 90 on a data set of reactions available in u.s patents and is 10 more accurate than the best human experts when this benchmark gains a data set released by an mit group and more importantly the model not only knows the correct product so given reaction and reagent predicts the product but the model also returns an uncertainty score and it turns out that using this uncertainty score we can predict whether a prediction is right or wrong so and with and the auc of that prediction is 88 89 in other words the model is 90 accurate in predicting the correct product given reactants and reagents and 89 correct in predicting where when its own prediction will be wrong to i mean that's all numbers to give you some chemical context of what that means um concretely the model can predict challenging transformations like chemo selectivity he we can see two here are two a mites which one get reduced first uh the original paper find it's challenging to predict the model correctly predicts that stereo activity is a standard um uh diastereo selective uh reduction uh which phase is the hydra being delivered on the model correctly predicts that as well and here there's a competition between bayer villiger reaction and oxidation the model again correctly predicts that um so that's so some examples from the lecture um you may ask well these are selected examples perhaps is there like a general way to quantify or qualify the power of the the accuracy of machine learning-based reaction prediction relatively some baseline um and so we took a data set actually published uh in in in 2018 where the authors try to predict the outcomes of um electrophilic aromatic substitutions uh that's a notorious class of um reach of selective chemical transformations where the goal is for example here is a bromination the goal is to predict which carbon hydrogen bond will get brominated i mean there are and in top molecule for example there are uh five carbon aromatic carbon nitrogen bonds so there are five possibilities and experiments may observe one uh product and the question is can we predict which product should be formed favorably um and the authors in that paper used semi-imperial quantum mechanics and we showed that molecular transformer effectively achieves the same accuracy than semi-empirical quantum mechanics and obviously incurring a fraction of the computational cost so how how does that actually help moonshot we built this uh you know in my academic group a few over the last few years that then get integrated into my company postera into a product called manifold which is then offered for free to moonshot where basically we prioritize and generate synthetic routes for all every crowd source designs and that approach using uh machine translation based reaction predictions we can then once we have a good forward prediction model we can go backward and basically do a tree search to find out uh which building blocks are actually uh which mod where the model can be made within san steps from commercially available building blocks and we can specify which building blocks we allow to use any means building blocks or ushis building blocks etc and we can return a a number of steps metric to guide us and medicinal chemists in the team which compounds are worth going after so give you some examples of like why um we think why machine learning approach this approach actually um i think achieves a speed up i think you know one can always argue whether a machine learning based model knows chemistry better than a human chemist and in fact i would argue i would talk about a little bit a few slides later in the talk that the surprisingly on paper very high performance on machine learning models can well be explained by data set buyers as well but i think one thing that we find machine learning to be uh really powerful uh in solving is just the sheer problem of data set size for example if you think about the number of building blocks available um i mean in the good old day of sigma aldrich um you might know like roughly what building blocks are available and therefore you can just do 10 disconnections um however in in the last few years we have seen the explosion in commercially available building blocks and even in a means database they have over 100 000 highly functionalized uh building blocks available that you can disconnect too and nothing's disconnecting to building blocks that already on the shelf in kiev is a much better idea than trying to ask people to make things from scratch and this building block libraries exponentially uh growing over time and trying to just remember hundred thousand building blocks not going to happen i think that's like a a a great time saver and opportunity that machine learning uh really seems to be able to accelerate and help and there's a recent paper by an astro senator uh a group uh showing that actually uh your simple a mite coupling with sufficiently complex building blocks can already produce really complex diverse and new molecules again showing that you know people are always we are always like um bemoaning how chemistry is constraining drug discovery which is obviously true but if we translate some of the hard chemistry into making complex building blocks then when you're actually doing the synthesis you can just use robust chemistry to couple these building blocks together and that approach can well be sufficient to yield complex normal and diverse molecules if you think about it that's not dissimilar to how you know biology assembles complexity from 20 amino acids uh here goes um a a pathway of different structures so if you have sufficiently complex building blocks even the humble amide bond can in principle yield interesting molecules give you a concrete example of how this id this uh rapid triaging works in practice uh the route on top is a route attempted by our cro partner trying to make the molecule shown uh on the right they start with a protection then a urea formation and then an n a relation which failed actually and then they would de-protect the problem is that the nl relation failed and even if it has exceeded it'll be a four step synthesis um once we saw that we put it into the algorithm and actually algorithm say hey um a an advanced building block is actually lying just on the shelves of their inventory and so they can just literally pick up the advanced building block couple them together it's a one-step synthesis and you get the final material and that was done and delivered in a week um not these are really simple you know freshman chemistry uh but again the algorithm is able to rapidly decide which compounds are actually makable using easy building blocks which compounds are not another example where the cro suggested this route on the top is a five-step synthesis they they suggested that based on experience with a similar product a molecule molecular transformer suggested a three-step route which is a lot um easier to or to execute and again the reason why we know that route existed is because um we have access to real-time building blocks and that's not a critique of you know human campus not being able to keep track of building blocks because building blocks are a funny object they are constantly evolving and there's no obvious pattern building blocks that are in stock today could be out of stock tomorrow and vice versa like for example these three um i would say you know relatively similar building blocks uh dichloro bromochlorine dibromo one is available uh nineteen dollars for 100 milligram one is out of stock and it's 451 bucks uh per point per 100 milligram and the other is like four to six weeks and it's like 689 uh 685 bucks for like one gram vastly different prices vastly different um time scale to make and there is no rule of pattern or whatnot it just literally depends i mean a lot of the everything we have depleted a lot of enemies building block and now a lot of the moonshot um the building blocks which we use to make moonshot cameras are now out of stock so the the name of the game i think is that machine learning algorithms can you know rapidly be in sync with all these building block inventories and therefore suggest dynamically which compounds are makable which compounds are not and that's again that's i think another reason why a lot of the synthetic accessibility scores you may see in the literature is not unnecessarily applicable because what we need is not a gross synthetic accessibility but synthetic accessibility is actually dynamically changing evolving depending on building block availability um another great thing about machine learning which we have found out during the project is that it is really good at doing mundane tasks um we got 2000 submissions the first week um and you know the if if if we were to manually go through it will take ages um but but the algorithm can easily go through all compound all the 2000 submissions in less than a weekend um and find which compounds which is uh can be made with less than three steps um and and if you go through one by one it could take weeks so again really good at going doing very mundane things quickly um and that's and that's great because you know um you can quibble whether algorithms can make better molecules i don't i don't think it knows it has the creativity that chemists would have but at least it can blindly go through compounds and with reasonable accuracy filter out the obvious bad actors um the next question we asked is you know molecular transformer is great but it's ultimately like a little bit unsatisfying that um you throw you know uh a language model of chemistry in and get a language model chemistry out just like google translate like we know chemistry exists we know physics exists there must be something in it a black box is quite um unsatisfying and then so we took a step back and asked you know what is unsatisfying about a black box what do we want from a what do how do we want to interpret a black box and that really got us back to the drawing board to ask the question well um suppose we want to like interpret molecular transformer what does it mean and and how should we do that and we uh nucleated into sort of two ideas about interpretability and trying to understand what the model is actually doing the first idea is or two criteria actually the first criteria is counterfactual which is a reaction x occurs because of a certain functional group which means that a functional group is not there reaction x will not have occurred the second criteria for interpretable models we we knew we we thought is the idea of evidence synthesis if a model reaches a particular prediction that must be because of a certain data point i mean if you ask your undergraduate student to like answer an oracle question you you want you know first schedule the mechanism which is the counterfactual and second if if the student is writing a term paper then that shouldn't better like cite some references that's evidence synthesis and i think you know a model that can do both um would cease to become a black box so we wanted to like answer those two questions and really understand what the reaction prediction model is actually doing in practice seeing that you know we run this model many times we see a lot of great predictions but some just some predictions just catastrophically failed so you say well is there like a fun is there like a scientific way of trying to understand these ml models um to give you a really short summary of what we did um we developed a way called input attribution um which is remember i said in molecular transformer we give the reactant the reagents input and predict the products well suppose we consider a selective reaction so reactions where transformer predicts one product but not the other well can we attribute this probability difference back to um selected functional groups in the reactants or in the reagents if we can do that then we can say hey are these attributions actually physical we know how a reaction happened like physically so we know roughly what should be the important things uh a physics space or model or a intelligent chemist should be looking at so we can then cross-reference whether the model is looking at similarly physical parts of the molecule well that's one idea another idea that we we basically created is something called data attribution which is um a model in a very abstract sense takes the input transform it into some model latent space and then it spits out an output so can we measure similarity between reactions um between the reaction you're asking the model predict and any reaction in the database in our data set by thinking about you know the the latent space distance between the reaction that we are trying to ask the model to predict and the reaction in the database again this is not some reaction uh chemothematics tool but it's literally asking we open up the model look at exactly the numerical uh weights and parameters said the model assigned to the input and we look and and we use that to look at which reactions are similar to which reactions according to the model um so we're looking at data attribution according to the model so in this way given a reaction the model can say hey that you know this is the adjacent reaction in the training set and then we can see where that makes sense or not um a really short um summary of what we of what we have done so this is a hypoxidation reaction um there are two alkenes one now king can get epoxides over the other because one is more electron rich um we asked the model hey like you predicted one alkene get epoxided by the other please tell me why the model successfully um attributed to the presence of two methyl groups and that makes chemical sense the methyl groups donate electrons into the olefin making it more reactive we validate it with further example you know we can construct fake artificial examples of selectivity between a more or less substituted olefins and we indeed show that the model does learn this stereo this electronic effect um if you think about input attribution this deals odor reaction um the model produces something nonsensical we say hey like why did the model predict something stupid so we you know look at which reactions the model deemed the most similar and low and below those are not deals all the reactions at all so of course like if you've never seen a disorder reaction you will not predict the dose of the reaction um that's not bad um and this in general allows the user to actually understand like if if a model spits out an outcome um the user can actually ask the model hey like tell me why you made the outcome based on like which part of the molecule have you been looking at when you make the outcome to prediction and which other reactions are relying on to support this reasoning and the user can then infer from this metadata whether the reaction is believable or not now what is interesting is that um we realize that actually the if you ask them all to predict selective chemical transformations um the model can often predict things um the right products for the wrong reason for example um if in a class of electrophilic aromatic substitutions where there are multiple different sites the molecule reaction it turns out that we can arbitrarily bias the model to predict one substitution pattern by changing the number of substitution patterns the model sees in the training set so effectively the model can be fooled in predicting parallel substitutions so two substitutions two substituents being opposite to each other on a benzene ring by having a lot of pair forming reactions um in the data set and that has nothing to do with the electronic structure of the benzene ring it just has something to do with there is a lot of parallel substitutions the model sees and therefore whatever benzene rings you feed it it will just shut the substituent in the para position and we find that the model is actually intriguingly fooled by these data set bias and these data set bias is actually quite prevalent in the literature for example the para substitution bias actually um originates from the medcam literature and there's a whole paper dedicated to this bias and this actually started in the 70s uh because because topless uh of topless tree fame a well-known guide to structure activity relationship actually suggested people when they make a compound always make the power chloro and the para methoxy as a way to probe structure relationship therefore there's a lot of compounds in literature with a power substitution pattern and therefore that permeates in the data set giving a lot of power forming reaction and as such transformer just if you learn direct one data set will just say hey whatever ring you give me i would just put whatever para and that would almost certainly be correct yeah because the data set is biased so we can fish all these like very interesting things about the data by really trying to unpack the black box just to quickly summarize um the moonshot initiative been going for now a year and we hopefully show the open science crowdsourcing this patent-free collaborative approach allows us to rapidly execute a fragment to lead campaign um taking a step back um i think one of the learning system synthesis is uh incredibly rate limiting and also very costly and that we see concrete potential in using machine learning to accelerate synthesis uh by having access to evolving building block inventories and i've not touched on that but actually very simple library enumeration type ideas which again leveraging on synthesis can work remarkably well in the hit to lead phase so rather than think about complex sentences you can think about simple synthesis but done in a parallelized library format um to end i would like to thank my many collaborators we wrote about archive paper with over a hundred people on it and they all really contributed substantially to the project and i would like to mention five uh collaborations which we met which uh which we meet uh uh frequently uh almost weekly or more than weekly frank mandel from oxford near london from weizmann john from mskcc ed griffin from my chemical a former med chemist um in astrazeneca and annette on delft from oxford and and the and them together with all our moonshot network has been a phenomenal in supporting this program and uh we are very very indebted to the support of the community and all our contributors and with that uh thank you very much for your attention and we'll be very happy to answer any questions thank you that was a really wonderful talk please those who have questions if you want to unmute please do so and if you're shy you can put the question in the chat and i can ask it as well alpha can i ask a question um your approach goes against the dogma that pharma won't make drugs that they can't patent so um because they can't make their money back on their investment so i'm wondering how do you see the discoveries you have being followed through to actual clinical application uh that's a great question i think um in pharma is actually showing quite a lot of interest in the covert space i guess covert might may invite them to revisit this paradigm in helping open science efforts and actually folks like the ndi uh the the initiative of neglect tropical diseases neglected diseases they have already pushed um several drugs into market without any patterns uh and i think uh the the the way is twofold is actually the first is even without patterns there are other uh forms of intellectual property like market exclusivity that farmer can leverage and and second is that there's a lot of uh charitable organizations like gates uh and the welcome trust in the uk in this space actually quite interested in starting to fund uh drug candidates in the eye and the enabling stage so uh the the message we got is that of the discovery stage is hard without uh funding but we are hopefully seeing a way to uh bridge that and we do have some reserve funding to bridge that but once we get to ind enabling studies and forward there's actually a lot of national organizations international charities willing to take this up together with charities like the ndi and live art and other medical charities to at least go to clinical trials thank you okay i have a quick question you you motivated this program off of an incredible need to treat sars kobe 2. and through this you developed a model and a system for drug discovery and especially this you focused on this prediction of synthesis but another reason to do experiments rather than discovery as a way of testing or developing the model so i'm curious if you had a budget and you had to do experiments to better train your synthesis prediction what would that look like and how could you leverage your estimates of uncertainty for instance to focus in on things that your model doesn't know and would know better with better training data oh yeah that's a great question um i think if we had budget we would probably focus on like specific challenging reactions like uh focal heart rate cn coupling cc coupling or other enabling reactions um like like and do a um reaction screen of the different reactants against um different solvents and ligands or whatnot and collect that data so that the algorithm can uh really learn i mean rather than saying a suzuki reaction shall work in this step uh which of the optimization might well work with the algorithm could say this is the right condition go run it i think that that will really help and then and conversely if if after the reaction screening suzuki actually cannot work within the ligand space that is commercially available then the algorithm would then have a piece of the neck of data we have been trying to leverage and sort of harvest all the reactions in fact we have a system of um scraping all the reactions that have been run as part of moonshot but one thing we find is that um in in lab chemistry often a failure you don't really know whether it's a failure or it's just a different condition to make it work and conversely success could well be attributed different factors it may not necessarily be only things that a chemist would write down because there could be unknown factors contributing that particular success so i think probably the next step would be much more controlled um settings where you focus on specifically hard reactions and then build a data set based on that to augment the machine learning model more questions so i have more questions about how your network can possibly fail so um is it possible for it to uh potentially present impossible chemistry or do you have hard set rules on how to filter those reactions out or basically give us a clearer picture on what a a non-accurate case would look like yeah that's a great question a a non-accurate case would be um something like this uh where uh it should be there's all the reaction and the model just predicting some nonsense um and that is because it has never seen this reaction before and with a attribution method we can then understand that this is in fact the case and in fact the user will be uh would use this to say hey like this is the similar reaction from the literature and you can look at it and say hey like you know these reactions are actually quite distinct or looks pretty dodgy and therefore you will have a feeling that this would be a bad reaction in the retrosynthesis algorithm though we constrain the model to actually uh focus on robust organic reaction at least in the in the hit finding stage and so this constraint means that the model will not be at liberty to go for wild disconnection so it may well predict the wrong product or the wrong isomer of the product but they would not predict some wild chemistry because there is a constraint that there is only certain types of reaction at least in the early stage of the project in the late stage we relax at that and we get some more subtle selectivity issues potentially but in the earliest if we constrain it to go for certain types of reactions like the standard 50 or 100 met cam transformations and that means the model could could mispredict the exact product but it can't go for wild disconnections i hope that answers the answer to your question yes it does thank you we're approaching the end of the hour so let's uh thank alpha again for this wonderful talk yay and uh for the graduate students or or others that want to stick around alpha has um about half hour to to chat and it would be great to get uh some of the graduate students to you know to a chance to to meet with alpha