[
    {
        "start": 46.07,
        "text": "today "
    },
    {
        "start": 127.93,
        "text": "welcome everyone to the tools and technology seminar series for any of you've never been here although most of you had such as a venue to discuss tools technologies methodologies sometimes newly developed or currently in development and process and to get some feedback on also existing tools technologies methodologies there may be using novel ways or just may not be well known to a lot of researchers so there is a sign-in sheet we'll send that around in a minute if people could sign in that would be great it helps us with the pizza and I'm pleased to present our speaker today actually George who is a grad student in DC MMB and as part of the Sally kipper lab hello good afternoon thank you guys so much for coming so thank you for introducing me and today I'll be talking about BAM QL which is a "
    },
    {
        "start": 189.709,
        "text": "tool that I have been using recently to help with some of my analyses and I found it to be very useful so I thought that it would be really cool to introduce it to you guys to tell you guys about it so that maybe you guys would probably find it useful in your and your research as well so this is a paper that was published last year by these individuals and what they did was that they were creating a query language for extracting reads from BAM files and it's foo what our BAM files there are the binary version of alignments mapping files they contain sequence alignments and whatever correspond being descriptive information for those alignments and they are also pretty familiar to anyone who has been working with sequence data and what the authors were seeking to do was to provide an intuitive way to extract relevant reads "
    },
    {
        "start": 250.61,
        "text": "from bam files so here I'm just showing a couple of properties of Sam files and their binary form BAM files that researchers used to select relevant reads for further analysis and here they're showing the different mandatory fields that are located in D Sam files and also here they have these descriptive what they call Sam Flags and these are just numbers that have different sorts of information about the qualities of those reads and what Bank ul queries can do is that they can filter the BAM file and select specific reads based on these and other criteria so why use BAM QL usually when an individual is doing some form of sequence analysis only a subset of the reads within their file or is what's going to be continuing into further "
    },
    {
        "start": 312.02,
        "text": "analysis and to have tools to be able to select these reads or but if mostly desired and so for standard BAM file manipulation tools you usually have a limited filtering options and they're not usually that expressive or user-friendly depending on what sort of queries that you're using to select your reads of interest and also if you are using the sound flags to do your reflection it can be a bit of confusion especially if you are students who haven't had much experience but using BAM files then you'll probably be a little bit confused and how you want to select your reads from using the flags you can also use general-purpose programming languages like Perl or Python to filter your files but these are usually you create those pieces of code for that one project that is that you're working on and you probably won't "
    },
    {
        "start": 374.0,
        "text": "be using those specific codes again outside of that current analysis and when you're doing something else again in the future you're probably going to have to write something brand new in order to get whatever is relevant for that other project and also there's apparently are checking disparities between manipulation languages and bad api's so if you are unaware of these different types of disparities that might have some kind of effect on your future results and you probably would not know that those things are there if you have it if you're not aware of those and there's also the potential submission you to mismatches that are difficult to detect so like again if I as a students when I first started working with these sequencing files I was not very much aware of all the different sorts of caveats or shortcomings that I might have within my own ability of trying to "
    },
    {
        "start": 437.24,
        "text": "select reads from these bad files so before we start talking about the different things that the bank ul can do I just wanted to make a note about what it is and what it isn't so bank ul is a querying language so what it is it's like you have your BAM file you tell it give me these sorts of reads and it'll pull those out for you that's all it does so and it can also use it to subset bam files so you can just have your different fill you end up with a number of BAM files possessing the reads of interest or disinterest so when it is not it is not an analysis tool and you can't get any kind of summarized relevant interesting from it so for example if you wanted to have like with the Sam Tools stats option it usually activity like different sorts of qualities of the things within your file this is not going to do that for you so "
    },
    {
        "start": 497.3,
        "text": "you're going to need other tools in order to get those sorts of relevant information so how do we use this situation so this is the vascular query syntax and what it is the thing that makes it but like I guess makes it the most useful is what if they call predicates and the predicates are what you're using to ask vamp you all to fetch whatever reason you have of interest and you can also have multiple credit predicates using logical connectors and your predicates to be BAM flags or mapping information depending on what sort of questions that you want to have answered you can also have a file a bank below file that contains a list of queries so if you have no desire to be inputting things one by one through the command line it can be automated and you can have a list of things that it can do for "
    },
    {
        "start": 559.35,
        "text": "you so here it's just a table showing all of the connectors and predicates that the bam kilo situation uses and it's pretty brief but it does a whole lot of stuff so we can go through it we can cover it all this is just a link showing the online manual that holds all of this information in greater detail but we're going to go through anyway so you guys can see what it is about - so for the BAM flags so these predicates match reads that correspond to specific flags in your BAM files and you can also do flag number combination queries by combining relevant predicates and I thought that was actually pretty useful so here I just reiterates the previous table that I shoulda four and this is "
    },
    {
        "start": 619.92,
        "text": "you're showing the different flag numbers and they're also their slam flag property and if you look over here at the Banfield predicate this is where they're coming out with having it be an intuitive query language because it's just like kind of similar to regular English so like is it peered question mark and it'll just pull out all of the paired reads for you right like already use the first of the peers if it read one it'll just pull out all of the read ones for you so these are I thought like this was like absolutely awesome to me when I saw how wonderfully easy and absolutely intuitive that these are and so I guess like people who are a bit more experienced in using them files you're probably have more knowledge and probably maybe have a more of a preference for using flags and they also have a predicate where you could use the wrong flag number so if you don't want "
    },
    {
        "start": 680.43,
        "text": "so if you have something in your head like I'm always used to using the flag numbers you can also do your queries with those as well and so for the wrong flag numbers this is a website and I used to use so this is fun Picard and what it is that you can input whatever flag number for a read and you hit explain and it'll tell you about the flag so if you're interested in knowing what sort of combinations that you can use in order to generate different flags this is just like an online source that I was using a lot when I was doing my things but I don't need it anymore now because I have words the numbers are useless to me now you're not irrelevant whoo this is just an example of showing like how you can get the BAM file based "
    },
    {
        "start": 740.79,
        "text": "on map treats and so like here if I want the unmapped versions I just send them the stuff ask them once and the output is they give you like what I'm the number of reads except eight and the number of reads rejected and they have to separates you don't have to have your outputs you can just use the ask them number and it'll tell you how many reads you want but if you want your results to be typed into an output file the output files are usually in BAM format and then you end up with you can end up with multiple files containing what sort of relevant reads that you want yes question so this is the number of unmapped reads and this is the number of marques including chimeras and supplementary alignments I'll talk about that a little bit later good job so yeah so all of your information is in there and this is kind of like information that you have to "
    },
    {
        "start": 801.18,
        "text": "have in advance cuz like you just asked I know how many situations I put in there what is up with these numbers so you can also figure that out later on in your analysis next forward so another form of predicates that you can use are the mapping information by the heads and these are just ones that select reads due to whatever design attributes that you want so like for example if you want all of the reads on a particular chromosome you can just do that you can tell them chromosome enter whatever value you have there and it'll pull all of those out for you one of the caveats for this chromosome function if that if your chromosome is not labeled in this form of format it's not going to work so like here for an example like they have the numbers and the letters corresponding to "
    },
    {
        "start": 861.93,
        "text": "each other but like when I was doing my novel that wasn't how my chromosomes were labeled so when I was trying to pull the chromosomes outs it was crying so you have to know in advance exactly what situation that you're working with and also you can also pull out the leaves of whatever quality and here is just a probably value between 0 to 1 and if the probability of error is less than your specified probability then you'll pull those out and also yeah different ones but you guys can see here so like you can get you make peers if here the asking for split parents to check if whether or not you're paired be dislocated on another chromosome and you can use this function to check for chimeric reads and also if you have different read groups in your in your BAM file you can also just tell them I want all of the read groups of some volume and they'll pull them out and place them in a file for you "
    },
    {
        "start": 924.51,
        "text": "I thought Alice awesome and this is just like another one showing how you can get reads based on quality and here I just asked some random value and they pulled them out for me and like here you can see I only have one BAM valid output which is the ones of high quality and what if it rejects it just weren't typed it to anything so you can also fetch things on position so if in your analysis you are thinking to yourself you have some form of nucleotide information of which you want to fetch you can ask Bank ul to select all reads that have a nucleotide within a specified range so for these extension beyond your position can be returned so if you're looking for something within a space if your read extends beyond that "
    },
    {
        "start": 988.23,
        "text": "position he needs if you don't want it out like if you want it to end at that position you have to keep in mind that there will be reads that are extended beyond the position that you that you specify and also official mapping status of the read is ignored so if you have a combination of maps and unmapped reads within your file your unmatched reads will also be located in your outputs so you want to you can combine auto predicates in order to make this query a little bit more useful to your to your arm to your results or you can just remove them before asking for them and so here you can just ask for after before or within some form of range so this is an example of selecting range based on position and here it just shows "
    },
    {
        "start": 1050.06,
        "text": "these two random positions on chromosome 1 and this is how many reads that it accepted and rejected and here if you have for some position after before it just pulls everything within that region next so you can also search for specific sequences as well with this Korean language and so the sequence predicates receive it you can select whatever nucleotide within a specified region and that would give you the amount of reads for that and I'll put it out into another BAM file and so for the nucleotides accepted or your basic nucleotide values and also of your combination ones as well and so they have these two different methods that you can use to ask for nucleotides and this one is a degenerate match and so "
    },
    {
        "start": 1113.3,
        "text": "those are for the ones that have multiple nucleotides within that value then it can fetch all of those and I'll show you guys an example of direct to but for this one on left reads and reach that do not contain that nucleotide at a position dos won't be selected so here I just have a table showing uh the are you packing up your type based codes and two like here um these are the different nucleotide codes and what sort of basis that those can match for and so for the degenerate matches if you added these values here if you have any of these combinations it'll pull those out for you but if you ask for an exact match so if you have a sequence alignment that that has one of these values within that space then it'll pull that one out for you so you can also use these as an exact match if you know that information in advance so here I just had a couple "
    },
    {
        "start": 1179.6,
        "text": "of examples showing how you can select range based on specificity with increasing specificity so like here at this position um the nucleotide is a but um it's like if I ask for n it will return any yes for the B which returns with CG or a teeth then I still get those if any of those were there but I'm here for the wine if it's a C or a T I still get those meats but if I ask for an exact match for the Y then it's looking for a y value in this space and then they're saying that there aren't any there so if you are so if you know in advance what sort of value it is that you're looking for you could do the nucleotide exact search and if you're not too sure you can use the regular nucleotide search with one of the generic sequence nucleotide sections so they also have a "
    },
    {
        "start": 1248.0,
        "text": "couple of miscellaneous predicates and so these are just extra predicates that do not fall into any of the previous predicate countries categories that I'm talking about but these could be useful for BAMF analysis so here you can search with some regular expression in the headers of your reads and you can ask them to pull those out for you if you have relevant information in those sections you can also choose a sample of reads based on some random value and so you can give it a provided with a probability a probability and they will just choose a random sample of read so if you want to do further testing and you wanted to have some random sample on which you want to do an analysis with you can grab a section of that and do that as well and this is just an example showing the random one and it would just "
    },
    {
        "start": 1309.679,
        "text": "choose your from your query sequences some random amount and that random amount to be approximately whatever value it is that you put in there so one of the things that I was talking about was combining predicates and you can do that using these logical connectives and some of these might look pretty similar I think similar familiar to you guys so these are from the lowest to highest precedence of logical connectives and so one of the things that I wanted to emphasize was this or function so in my experience this or is exactly one but they have this current one here so here at least one expression needs to be true in order for it to read to return those reads and in this "
    },
    {
        "start": 1370.21,
        "text": "version exactly one expression has to be true so don't be fooled and there's also this if version feel like if you have some form of condition that you want you can have that information and of course the and and the nots so this is just an example of using the logical connectives to subset a BAM file and select here you can search for different things so this here just asking for some value within the chromosome name and just just like 20% random stuff from it and it'll pull that out of freedom so they have another function that we call the BAM QL chain and this one was really awesome and I "
    },
    {
        "start": 1430.929,
        "text": "was very happy for this function and I was really glad that it was in here and what it is is that you can filter your bound file through a chain of queries and how this is different from the logical connectives is that the logical connectives save your outputs into one specified output file but with the chain queries it has multiple output files our correspondence to each of the queries that you specify and they have three different chain methods that they use for the query so the parallel chain is their default method and what it is is that to give each feed to all queries it's what that looks like it's like if you have some reads and you have three queries it's just going to give all of them to each query and whichever read is in here it's gonna pull them out back so "
    },
    {
        "start": 1493.99,
        "text": "for the series method they give each read to each query in successful succession so if you have you want each read to be it can only go to the next query if the previous query was a successful match like for this example next like it's just going to go one by one and whatever it meets a not successful query it does not continue on throughout the queries until it reaches a match so depending on what sort of question that you're asking you're going to get different outputs and then there's also the shuttle one where a read is given to each following query if it feel the previous and I think this is probably what most individuals will probably be using because like here for "
    },
    {
        "start": 1554.72,
        "text": "the shuttle chain all it does is that it goes to each one and it separates them based on whether or not it is successfully in the previous query and then if it's successful in the previous query then it's attached to that one and it's not going to be in any of the others so depending on how you can have the same queries but whichever differing chain method that you choose you can have different outputs so that's also one of the things to keep in mind when you're trying to selects I see faces of confusion question okay so what the series chain perhaps be better drawn as putting arrows in query one the query to now because I only have two passes query one does it go to query to that is correct clear like from here to here you "
    },
    {
        "start": 1615.259,
        "text": "identify yeah and you're not each step you're narrowing down the set yes most inclusive that one bow only those that past one and two are stored by - yeah sorry so it's like a progressive filter that is correct and this is just an example of what the change filtering looks like so for this section here I had a couple of reads that were identified two different libraries and I just asked them to pull out each of in each header to search for the library identifier and then to stick those into BAM files containing that library itself and it just popped out all of the difference reads into their separate library files so I had individual bam files for each library and that was really useful for downstream analysis start out with sorted that is correct yes they are sorted and in nexts they "
    },
    {
        "start": 1679.58,
        "text": "need to be sorted but they don't necessarily have to be indexed so i'm do you can tell it to ignore the index if you want to and it'll still work fine so but it does have to be sorted so one of the things that they did was compare their bank Euler method to other methods used for for all I think bam files and next so they wanted to see how efficient their querying language was in comparison with these other tools and languages so what they did your comparison to was to Sam tools this sum bound Bob to this Python module in Python and this bio sound tools in Perl "
    },
    {
        "start": 1739.669,
        "text": "and there's also this um this library in C and so they just did some comparisons to those to see how their how their methods hold up [Music] so there is the all powerful sound tools it is one of the basic analysis tools used for allowing sequencing information and it can do all of the stuff with high-throughput sequencing data and it accepts these different sorts of alignment mapping files and it also uses this ACF library internally and like I said before in most standard sequence analysis workflows you're going to see and you're going to be using sound tools so of course it did their comparison with that one so there is this sound bamba' I don't know if anyone has ever worked with this one I have not but this is a high performance tool that is used "
    },
    {
        "start": 1801.289,
        "text": "to work with Sam and bam files it's pretty similar to Sam tools and it's written in the D language and I thought that's kind of cool I hadn't heard of that before so D comes after C and it's kind of see like food that's why it would be and so apparently this sound bomba and Sam tools were in head-to-head combat for a couple of years until Sam tools caught up with paralyzed bam file reading so they're kind of like on even ground now so I don't know if anyone is familiar with this one but that's where they stand now and PI fam is a Python module that works with genomic data sets and it uses a large array of high throughput data files so you don't only need to use it to analyze your sound files so I thought that this was really awesome I probably will be using this in the future because since it does so much it also wraps the HTF library C API and you can also "
    },
    {
        "start": 1862.539,
        "text": "access some tools and VCF tools with this module sounds like this is really cool I'm glad that I got to find out about this so that I can use this in the future and bio sound tools is a Perl interface that uses a some tools library so it it doesn't do much in itself but it does it is able to manipulate some and bam files and it's very similar to something mostly because it uses the same tools library so the HTS library is um a C library that it's used for reading and writing high throughput sequencing data and it is used in many sequence analysis passages so sound to specie of tools and parts and uses if this HTS library and bam kill itself also uses this I'll this library so this seems to be the foundation upon which many of sequence alive sequence analysis "
    },
    {
        "start": 1923.5,
        "text": "tools are built upon and they just use this tab is so for their performance test what they did was they had these triplicate runs on this workstation and they used this 10 GB BAM file and so this was an index sorted a male human whole exome sequence and they made sure that from each implementation of the different packages that's all of the reefs that were selected were identical so it wasn't like any being left out on the side and the tracks were written as simply as possible without intentional optimization so I'm so I'm guessing that would be when they were doing this they just wrote it how an individual we righted three out of the box rather than using methods or different sorts of "
    },
    {
        "start": 1984.28,
        "text": "techniques to make it more optimized and so for all of these packages in Montrose they all ran six Tests so for the all tests all it was supposed to do is copy the input and this what they did to measure the baseline cost so for the peer tests they wanted to select all parent reads and then for the chromosome lie test they want to select reaps on the chromosome why and so for the mitochondrial test you're supposed to be able to select reads and their mate pair if that make pair exists if it's unmapped or not on the mitochondrial genome and then for the nucleotide tasks to be able to select reads the SE and this position and then also to do the chain analysis where to just pull out all the reads on "
    },
    {
        "start": 2046.23,
        "text": "each of these chromosomes and stick them in a file so here they showed a couple of examples of the the code that they wrote and this one is for the relocated for selecting reasons getting on chromosome y and people who are familiar and probably look at this and be like what what what's going on here I don't know why but I said they said that they just um they wrote them as simply as possible and without optimization and I wasn't too sure that looking at this was exactly what that was supposed to be but this is what they did and "
    },
    {
        "start": 2108.47,
        "text": "yeah so this is just what the ad you can go and you can download their files and you can play around with them if you want they were pretty short though I'll give them that I think they're just doing it wrong Python they're not using 5:00 a.m. so this is a plain old Python regular expression so they're just for the coma so my version cuz I also kind of talked about it on this like foo here I just highlighted the check marks that we had so for the different sorts of codes that be routes they wanted to compare the filtering compiled the filtering capabilities of the various tools and "
    },
    {
        "start": 2170.089,
        "text": "foo with the bank UL since this was all the things that they had implemented in their in their tool it of course has everything but for some of the other ones there were elm like missing dedicated filtering or filtered means by mapping were limited and being able to filter sequence were absent so for those they probably had to have switched to the base code in order to get their desired outputs previously not implicated in the version of these tools in which they did their tests which would probably be most recent since this came out last year so I'm pretty sure that if these individuals wanted to have these these abilities in their tool they can "
    },
    {
        "start": 2233.73,
        "text": "probably just sit down and whip it up and stick it in there and everything will be fine but at the time of this testing these tools either did not have this ability or was limited in its capacity it's talking about raw Python yeah I think they just wrote this code and then for like actually going through the BAM file and pulling out some of the stuff they probably use some of the Python things to help with it rather than just testing the Python all by itself read that reference ignore case "
    },
    {
        "start": 2306.27,
        "text": "for reading file if Y is a match yep yeah there's probably some stuff in here for Python but I haven't used it so I'm not too sure yes and so here it's just a table showing their different results from their analyses where the best performance is highlighted in bold so bam ql isn't always the best performer but it's did pretty okay in some of the versions for example system time seems to be consistently the best I'm sorry repeat well with someone care by the system it depends on I guess what it is that they want if you don't care about it "
    },
    {
        "start": 2366.859,
        "text": "then you don't care about it but if you do care about it then you do so then if you want something with comparable system time then want to do that feel the difference in both ha and bam QL is consistently the doctor best they're just putting the response in the time for me yeah yeah and they use a pretty um a pretty large file too well a good a good amounts of information within their file so yeah so so these are for the different tests that they had so for example selecting mitochondrial sequences collecting the nucleotide sequences selecting the parent and sequences and doing the chain one and in "
    },
    {
        "start": 2429.71,
        "text": "addition the performance for the all tests and for the Y test but um so this is what they had and I thought it was good of them to show that they didn't do so well all the time so for the pros and cons so some of the things that I want to talk about for this thing is I really enjoyed using it I thought it was absolutely magical how I can just have these words and all the things that I wanted would come into my hands without me doing too much hard work it was pretty easy to install on docker but if you aren't using a space where you have ultimate control then it is a nightmare and I could not do it so I had to have "
    },
    {
        "start": 2490.7,
        "text": "IT install it on flux for me I'll be able to use it on on my work machine they have a couple of specified bistros in which when you go to their web page to do the installation and if you're working on those it's like absolutely easy I'm so like I just went on docker and pull up and the boon to space and I was able to get it running in like minutes but like other than that yeah so that's I would say that was a con I thought that it should be able to be usable anywhere and everywhere at all times irregardless of your position in life on your workspace the bomb analyses were really quick so the fact that I was working with weren't that large so I'm like four guys talking about whether or not the amount of time use is really that relevant like my stuff was done in "
    },
    {
        "start": 2551.96,
        "text": "seconds and I found that to be very useful for me that I can just pretty much breathe through it yes yes just the filtering and the querying yeah so just um like in the future analyses I had stuff that I wanted to do but I did it wants to go through it and pull them out myself so using the bank cool to just say give me this give me that and just have the whole list of back files that had the specific reach that I wanted each analysis to be performed on was very useful for me and I thought that it saved a lot of time boots in filtering out and subsetting the BAM files and getting into the next step of Fourier analysis yeah and also you can do the multiple BAM file separations in change so I was using a change function a lot to just just parse it through and to "
    },
    {
        "start": 2612.529,
        "text": "just pull out a whole lot of the different sorts of beads that I have used the documentation online was not that helpful so I would say that that is a con that if you were to look at it online like I have it here and it looks so beautiful and easy but that's because I had a bit of tire error before I was able to become an adequate user and in doing so I looks like hey this is really easy why did the online manual make it so difficult so I guess it just depends on how you're able to accurately articulate the usage of your tool and that is all questions comments concerns yes fine this is great thank you very filtering "
    },
    {
        "start": 2672.83,
        "text": "and clearing birth direction many of those reads I Sam is a terrific tool because it leverages the HTS live furthermore you can be lazy evaluation of those filters but or whatever queries you've applied to the sequence and do your analysis step by step on those reads in your script you don't have to filter and then do your analysis later you can just do it right there in time sumail it is yeah like I hadn't used it before until I read this paper and it told me about it and then I went to look at it I was like hey this is awesome why don't I know about this so that's definitely a tool that I'm definitely gonna be using in the future but I probably will also use BAM file as well because words yep you can go on github and I don't want to "
    },
    {
        "start": 2739.24,
        "text": "[Laughter] and the other questions thank you [Applause] "
    }
]