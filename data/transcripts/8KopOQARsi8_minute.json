[
    {
        "start": 0.0,
        "text": "welcome everybody let's go ahead and get started um our speaker today is todd holland he's a neurosurgeon and research scientist who specializes in brain tumors he is an assistant professor of neurosurgery and he did his post doctoral training here in the um translational molecular imaging laboratory under the supervision of doctors daniel oranger and hong lac lee his postdoctoral work focused on the application of deep neural networks to advanced imaging methods to improve the speed and accuracy of intraoperative brain tumor diagnosis which i believe he'll tell us more about today and he has recently joined ccmb as an affiliate faculty member so we're excited to hear about what he's doing so todd i'll turn it over to you thanks for speaking to us and we're excited for your talk all right thank you everyone for being "
    },
    {
        "start": 60.96,
        "text": "here uh as things get more and more in person it's good to see everyone out so um yeah so i'm a neurosurgeon and he um you know my work really focuses on how we can use techniques from computer science artificial intelligence and bioinformatics to improve the way we operate on brain tumors both in terms of how we improve the way we diagnose brain tumors and also how we treat them and those two are obviously related so this talk is really about how i have been applying a novel imaging technique to a specific set of artificial intelligence methods in order to improve brain tumor diagnosis and particularly brain tumor diagnosis in the operating room which is where i spend a lot of my time so uh there we go okay these are my disclosures uh i am a shareholder and one of the companies that makes uh the "
    },
    {
        "start": 121.2,
        "text": "imagers but unfortunately i haven't seen any benefit from that yet so uh so yeah exactly so so this is really the problem that i'm faced with daily as a clinician is that you know we see these brain tumor patients and they come to us after they have a seizure or a headache or a new neurologic deficit and all these scans look about like this right there there's a lesion in the brain contrast enhancing the radiologists tell us what it looks like rim enhancing with surrounding cerebral edema and they just describe what this is but ultimately this does not give you a diagnosis and the only way to get a diagnosis is to obtain tissue from these tumors and the problem that we face is that there's lots of different ways for us to get tissue you can do a small biopsy you can do a large resection you can do a subtotal resection lots of different things that we need to take take into account to make sure we don't hurt the patient but we also give them the best possible therapy we can if that was the only problem it wouldn't be a big deal but the problem is that diagnosis actually determines the "
    },
    {
        "start": 182.08,
        "text": "treatment right so if you have someone that has a tumor that's very responsive to chemotherapy radiation you don't want to do a big surgery you're going to hurt the person right or for example if it's multiple sclerosis and you you know you see it and it looks a lot like this which they can you want to do a biopsy and then get the diagnosis and back out you don't want to do anything at all because that's a whole different set of biologics and anti-inflammatory medications so we run into this loop problem where the the best treatment is defined by the diagnosis but we don't have the diagnosis yet because so we don't know what the treatment is so this is this is the issue that we face daily and this is just a silica this is where this is what my world looks like a lot of days so this is the brain this is a patient i did last week and we i do a lot of awake brain tumor surgery and you know this patient is awake and talking to us and we've done our mapping we want to find out where all the most important structures are like language and motor function and we've done this and you can imagine we still don't know is this a multiple sclerosis lesion is this is this glioblastoma is this lymphoma all of which have different treatment options "
    },
    {
        "start": 243.519,
        "text": "so yes please that's the surface exactly we do yeah so we have uh frameless stereotype navigation that we use yeah and that's an important part for localizing where we should best enter the lesion unfortunately still it comes up short in terms of what we're actually dealing with but we do use navigation for for all of our our craniotomies and please stop me at any time i would love for this to be interactive um so we have developed a solution but it's a bad one i don't think there's any pathologists in the room but i think they'll agree with me on this so this was a paper that i found harvey cushing is like the person who invented neurosurgery back in the uh turn of the century and uh he defined a method that was intraoperative diagnosis where you take a little piece of tissue you do some staining on it and then from that a human a pathologist looks at that and tells us what they think the you know the best approximate diagnosis could be now this is not a final diagnosis this is a tentative sort of best guess that you "
    },
    {
        "start": 303.84,
        "text": "can you can get from very rudimentary um analysis just from using light microscopy and some simple staining like hematoxylin and eos and staining so the images you can see on the left look a lot like the images on the right and these are images that came you know from two years ago or something and there's a lot of problems with this it's really a quick and dirty method where we we freeze it and then we section it and we stain it and all of which introduce artifacts which makes the diagnosis that much harder specifically for the pathologists the humans the reading list so this really sets up this is the state of the art this is this is the standard of care that we have which there's clear limitations so the question is can we develop a streamlined intraoperative pathology workflow that is fast efficient and accurate and nobody has been able to do this constructively for the past hundred years since it was initially invented so so this is really the the overview slide of the whole research program that i have been a part of the top arc is the normal standard of care where we have a conventional pathology lab that usually lives on site "
    },
    {
        "start": 365.759,
        "text": "somewhere near the operating rooms but sometimes it's off site where i did my fellowship it was in a completely different hospital which made it completely infeasible we do h e histology and then there's a neuropathologist who's on call which they do not enjoy and they have to read these they have to be called out of their lab they're doing their animal experiments and they have to come in you know you get their page and they say you have to come read this this intraoperative frozen pathology specimen which they don't love all of which takes anywhere from half an hour to to two hours and then the lower arc is what we're working on so we're about we're trying to replace each one of these stages and the first bit is the imaging and what i've been a part of is developing stimulated raman scattering microscopy and the translation of this imaging technology from what was optics labs into now the operating room we're developing how to process these images and uh we've developed a system called stimulated raman histology and then where my really scientific work has come in in terms in terms of application of ai algorithms specifically computer vision trying to translate the latest "
    },
    {
        "start": 426.4,
        "text": "stuff that's published on archive and all these amazing techniques that have come out really the last 10 years we're trying to leverage that to do the best that we can for really intraoperative decision support automated diagnosis or augmented diagnosis however you want to call it and it it gives us an order of magnitude faster time for us to to get this diagnosis back um so it's it's been a long a long haul uh this isn't even the start of it but um we have we started in a this this is an image on the upper left of an optics lab at harvard where this technology the imaging technology really started and my mentor dan orenger actually was really instrumental in translating this into it being a clinical tool our initial prototype imager is in the middle and then the what we're using now actively what is actually a commercially available system from invenio is this neo imaging system which we now use regularly in our operating room so that i use this today i had an operation this morning and we were using this to image a pituitary specimen so um it's really been a true kind of translational science it's been "
    },
    {
        "start": 487.599,
        "text": "a wonderful thing to be part of something where it actually goes from the top you know and now we're actually have a clinical tool and we're doing research with the data that's being generated from this imager so this was the original paper 2008 published in science so chris freudio the lead author is actually the main r d person at the company that builds the microscopes and sunny she is a very seasoned optics investigator and this is the idea so just a quick overview so spontaneous raman spectroscopy maybe we did an organic chemistry in undergrad but really it's just shining a laser beam at something and you actually just collect the scattered photons and you look at the spectra that's generated from the media and that spectrum is determined by the actual biochemical properties of the tissue so you may see it infrared you do this if you have a you know a purified substance you're trying to determine what that substance is similar thing can be applied to biological specimens and that's what we do the problem with that and people have tried to do conventional raman spectroscopy is it's really slow there's a lot of averaging and the signal is very weak so you really have to spend 30 minutes to an hour just imaging the same "
    },
    {
        "start": 550.16,
        "text": "single spatial position in order to get the spectra which you see uh right here and uh you know you get this nice spectral information which has important biochemical information but it just takes too long this isn't a feasible thing for us to do in the operating room so the idea with stimulated raman scattering my microscopy is rather than using a single laser beam you actually use two and by using two if you're if the difference in the wavelength between those two lasers is just right you get this non-linear resonance of specific chemical bonds in the tissue so in this case there's this so the wave number 2845 and 2930 you get this narrowband non-linear amplification of the signal and you can generate an image from that you can capture an image at this very narrow band wave number and that's what gives you these images on the right hand side now this is from the original paper i'm going to show you images that look a lot better than this but this is how it all started and we're still using this same technology in order to generate our images exactly yeah the stimulation is really "
    },
    {
        "start": 611.2,
        "text": "from this these uh two coherent lasers that are that are amplifying these raman active chemical bonds yeah yeah so uh there's really two main frequencies so we pick this strategically most i mean these are these are um you know normal biological specimens so there's a lot of carbon so it's actually the ch2 symmetric stretching mode which is the main one and the other one is the ch3 uh resonance which is really common in proteins right methyl groups right so that those are the two that we focus in on and actually our images i have some pictures of this uh here we go perfect so the 2845 on the left is the ch2 symmetric stretching and the 2930 is actually going to highlight mostly protein in the image the methyl groups that we see so so we're basically getting the we focused in on these because they highlight different specific things even though you know some bright pixels are bright in both images but they seem to give us this excellent "
    },
    {
        "start": 673.279,
        "text": "chemical contrast that we're looking for in terms of generating the images and the thing that i'll point out that's different about this this is something that's really hard to communicate to people or say why don't you just do h e right there's a lot of h e data right the problem with h e is that the image contrast is completely artificial right it's a stain that we use that's just something that is easy to differentiate nuclei from cytoplasm but it doesn't reflect the concentration of let's say lipid like fatty acid tails or if the concentration of protein or blood or whatever it may be so but this is the order to get that image there's no staining right there's no special stain there's no fluorescence nothing right yeah it's near infrared there yeah so yeah you got it yeah so so this is again where you know it's like we're you know there's the the advantage of this is that it's not stained there's no you know there's no processing that goes into this i take a hunk of tissue out of the brain and i put it in a pre-made microscope and we put it in the image "
    },
    {
        "start": 734.48,
        "text": "and we get these images out so our initial iteration was this this blue green color scheme which i actually really like because it makes the images look cool and futuristic but the pathologists don't like them so much but the images on the right hand side are actually the one-to-one correspondence between the tissue that we image and the h e which everyone knows and loves right and we basically see really good similarity between the two two imaging modalities definitely i love it i love that you point that out this is great i love it so the advantage of this you see how bright some of those structures are in the blue green color screen the stimulated raman scattering microscopy image the reason for that is because we're actually imaging myelination in the corpus callosum i think uh so we're actually imaging these these dense lipid-rich myelination that's happening you don't get that in h e that's not something that h e can handle because there's not something that's specific to either the the hematoxylin or the eosin so this is "
    },
    {
        "start": 795.44,
        "text": "where you're actually reflecting back to you something important about the tissue itself rather than just this is more you know basophilic versus acidophilic right something else so you're getting some kind of you know directionality effect on the skin right exactly right yeah yeah we image definitely the white matter we image and particularly white matter tracks look fantastic in this that's one of the things that the pathologists really like is that for these infiltrative tumors it can be hard to differentiate intrinsic brain tumors like gliomas versus metastatic tumors they both look very malignant but if you see a lot of myelinated axons add mixed with tumor that means it's got to be an intrinsic tumor right it has to be something that's actually biologically part of the brain itself so that's something that has been a real important difference in h e "
    },
    {
        "start": 856.72,
        "text": "um that has driven a lot of adoption from the pathology side is they see these advantages to having this this um this uh label-free imaging that highlights specific things so yeah there are limitations so this this is all x vivo imaging uh so we're in we're taking a piece out and then we squash it into an imaging chamber the imaging chamber thickness is about 120 microns that can change a little bit but it's it's imaging and transmission where you actually do get the reflected laser on the other side the objective there is an epi transmission mode where you're actually getting the reflectance back it's technically more uh challenging but it is doable some of the i think actually these images may be in epi mode but um uh point being is that it's an optical sectioning and you can set that i think we have a set as default at like 20 microns but that is a parameter you can adjust right exactly right we were just talking "
    },
    {
        "start": 917.279,
        "text": "about this yesterday actually in lab meeting what what the exact resolution was and it is yep um right yeah so uh so one of the things after we had shown that this image is brain tumor specimens really well we wanted to show okay you know you need to be able to do something with these images you want some quantification and this was right before i got into the lab even though i was sort of involved with some of this but you know using really simple what i think of as biomarkers and in this case it's exactly some of the things that we've talked about how much myelin is in the image how cellular is the image what's the ratio between the ch2 and the ch3 channel that's 2845 and 2930 can we can we use that to make some predictions about the degree of tumor infiltration which is ultimately what we are interested in as neurosurgeons and sure enough you can i mean this is these are simple very simple classifiers which are really just trying to say what is the likelihood that there's tumor there or not just based on really three features so the three features were axonal density nuclear density and then protein lipid ratio and from that the "
    },
    {
        "start": 977.6,
        "text": "bottom right is the classifier value and again this is just a you know a binary predictor where you have uh one if there's tumor zero if not and you can see we had really good results um so this is very preliminary this was sort of the start of the introduction that happened prior to me uh for the uses of computer vision for quantifying tumor infiltration um so i like to point this out because this is something that i think is confusing for some people who who don't look at this from the perspective of bioinformatics how do you make a diagnosis really like what do you have to do to get there and there's if you get it on the most basic elements there's two things you have to have some data some observation right some measurement that could be an mri it could be sequencing data it could be you know it could be optical imaging whatever it may be you need some data point and the other thing a bit is you need some analysis right you that data doesn't come pre-interpreted and that's what you need in addition to the raw observation and the assumption is always "
    },
    {
        "start": 1037.919,
        "text": "that humans make that interpretation right whether it's defining normal ranges for sodium levels whether it's interpreting mris and the point that i like to make is it doesn't need to be that way there are other ways to make interpretations and you know we can potentially assist humans in making those interpretations using a lot of the new ai or even old ai that's available to us now at our disposal for improving how we um how we treat patients so this is where you know this is sort of the point of the talk is for a diagnostic system that that i'm referring to in this case for both intra-operative diagnosis and even post-operative diagnosis and even for molecular classification which is what we're going after now we're saying that you can do this with optical imaging which has important quantitative information about the underlying biological specimen and in order to do that interpretation we can use artificial intelligence okay so everything that i've shown you up until this point was really done in an optics lab very controlled setting you know "
    },
    {
        "start": 1099.679,
        "text": "everything's perfect very well controlled but at some point we needed to actually do this in real patients and that was where we developed uh we had an imaging system a prototype which i was a part of and we also wanted to make this easier for physicians clinicians to be able to use so everything on the left we sort of already talked about but the image on the lower right looks like an h e image but it is not that is taking those two channels 2845 and 2930 and actually developing a coloring algorithm that turns this into the same color scheme lookup table that we all know and love and that's h e and this was a pretty it's always seems fairly mundane to just color images this was really important for us to get a lot of um backing from our pathologists and also getting us enough confidence to be able to use these to use these techniques in the operating room right ultimately we need somebody to do something with these images and we were able to develop this so once once we we had this we then kind of decided well let's show this to pathologists let's show this to the to the real you know "
    },
    {
        "start": 1160.559,
        "text": "professionals and see how they do looking at conventional h e images versus our own virtually colored h e images and when you do that and you ask them to make specific diagnoses it turns out that the concordance right the cohen's kappa so the agreement between the two is quite high so uh it this this particular statistic accounts for random agreement so if you do that anything really above 85 or 90 is near perfect concordance so we were able to show that for multiple different diagnostic tasks and um these were shown to pathologists in random order and you know they weren't told which is which they were just asked to to make diagnosis based on this so this was part of the clinical validation uh but oh yeah go ahead uh yeah so it was it was kind of a two different things one is there's a clinical diagnosis that comes from the um the clinician pathologist who's reading them at the time of surgery so we have that but in addition to that we also have the "
    },
    {
        "start": 1221.6,
        "text": "final diagnosis which is different that's where we have paraffin embedded images and slice them really nicely and then we can do all the immunohistic chemistry or inside dehydration sequencing that we need to get the real final diagnosis so we also have that as a sort of ground truth if you will and you're it's a good point though because pathologists are wrong about this intraoperatively right that's part of the problem that we know historically we have some values on this that some their accuracy rate best guess is somewhere about ninety percent the problem is is that that's not ninety percent for getting this final diagnosis where this is for sure this is a whole grade two you know idh mutants glioma or something it's is this a glioma or not is this a metastasis or not right so it's these very coarse diagnoses that you know defining inaccuracy is hard but i'd say 90 or so yeah so anyways so that's how we got the ground truth um and this was our really first uh introduction into um i guess what you can call deep learning at this point this was pre "
    },
    {
        "start": 1281.919,
        "text": "uh this is pretense or flow actually um so we we had some people in lamp who had some familiarity with some feature extraction software so this is where you're computing low-level image statistics and in this case they use what's called wind charm which is fully automated you can put in any image and you're going to get you know a fixed dimensional feature vector again 20 you know 2048 or something and you can just use that as features for a multi-layer perceptron in this case so this is just a normal feed forward neural network and at this point we had enough image had enough patients and enough sort of tumor classes to be able to train this and validate it and that's what we were able to do similar as what i was mentioning before we had these really coarse diagnoses so nl on the right hand side sorry i guess does this work no that's okay um okay no problem so this is normal here this is low grade glioma hybrid glioma and non-glial right and this is where sure okay so if you have these really broad categories maybe there's something "
    },
    {
        "start": 1343.2,
        "text": "to it it's somewhat helpful but again this doesn't get nearly to the granularity that you need for actually really good decision support in the operating room for how best to operate on these patients so this was our first go at it really a feasibility study that we could do this this larger scale computer vision based decision support and then this is where i really came in and started developing my own ideas and my own techniques for this and one of the things that we knew we knew we needed the original study in nature biomedical engineering was was focused on adults and i thought well why don't we do this in pediatrics one because it's a lot more important because uh you get a lot of these lesion lesions in this area called the posterior fossa which is where the cerebellum lives and they all can look very similar and they all similarly have different really different prognoses but also have different surgical goals and i thought okay well you know we have a we have a fixed set of diagnoses that can happen for these patients is there a way to kind of tailor a a specific classifier for this task using "
    },
    {
        "start": 1405.679,
        "text": "our images so i kind of went back to basics and i'm really interested in single cell anything and i think it's important for any diagnostic system particularly for computer vision because we know the computer vision is going to be better at doing single cell analysis than humans are there's really high frequency features it's really hard to do to somehow give a summary statistic for all the different cells an entire image and i think that's where computer vision can really shine when we are looking at single cell features so i was doing that we were just doing simple segmentation and then computing some morphology uh characteristics of the cells that was true for two different cell types in this case one were the tumor cells and the other one were these tumor associated macrophages which we know are very predominant particularly in malignant tumors so we were able to develop two different pipelines that were able to segment both tumor nuclei as well as tumor associated macrophages and again i'll just emphasize the reason that that's easy for this is because uh in this lower image down here see these bright areas this is actually um these "
    },
    {
        "start": 1466.159,
        "text": "are lipid droplets that these phagocytic macrophages just you know they're just you know chemo taxing around they're walking around in this tumor and they're actually phagocytosing these lipid droplets from necrotic cells so these show up really bright beautiful they're full of foamy lipid membrane right so this is something that you cannot see effectively on h e again a major difference between our imaging technology and uh and uh h e uh so these are just some statistics that we were able to compute so things like uh nuclei count uh tumor associated macrophage count uh and then the comparison between these two and then again here's just some um some different uh features cell morphology features these are huge numbers this is i think this is like 750 million different cells so there's a lot a lot into these but um and then uh similar things so so this is where you know i wanted to ramp up what we were using in terms of the prediction and random forest for those who don't know is a decision tree based model you can uh use these really out of the box and they're actually quite robust they tend "
    },
    {
        "start": 1526.48,
        "text": "uh to not overfit much and you can you can do simple classification with this uh and we were able to do that and for this we were just trying to focus on is this normal brain or is this lesional is this low grade or is this high grade and again a simple decision point but that was really important for differentiating these pediatric tumors uh as to how you need to treat them whether you need to be aggressive surgically or or if you can just do a minimal subtotal resection and and back out and uh you know here's our results we were able to do really well um we really had kind of a 100 accuracy but again it's i hate saying that because this is cross-validated data we these are all the patients that we had in our entire data set but nevertheless this gave me the idea that we could potentially do this at a much larger scale and um i was excited about this project particularly because first time we've done anything really with sort of single cell analysis and using that as as a way to do prediction so okay um i i include this slide because i "
    },
    {
        "start": 1586.72,
        "text": "think there's a bit of variability in terms of how familiar people are with a lot of the traditional computer vision digital image processing and then uh deep learning or convolutional neural network based image classification so traditional vision i've kind of been hinting at it's where you have an image you want to compute some statistics there's no learning involved whether it's edge detection or histogram of gradients or scale and variant feature transform and fft whatever it may be but you're going to get some fixed number of scalar values that serve as your features from which you can train whatever classifier you're like k-nearest neighbor logistic regression random forest whatever you want the learning is happening with that second stage right so with logistic regression whatever it may be the learning is only happening just on those features right ju you've already got your features there's nothing interesting that's going to happen there you fix that as your as the data scientist the difference with deep learning and with specifically deep convolutional neural networks is that "
    },
    {
        "start": 1648.799,
        "text": "you allow the model to learn what the best features are so you're not going to tell it whether it needs to look for an fft signal or it needs to determine what the you know edge what the number of edges are or needs to learn a specific edge detector like should you use a sobel edge detector or something like that all of that should be learned end-to-end based on the data now one of the problems with this is a lot of people know is it does take a lot of data to train these these are very over parameterized neural networks and there's always the the presumed risk of overfitting in order to get this done um you you want to have a sufficient amount of data to train these well people have been coming up more and more with ways to alleviate the burden of doing uh of um of needing a lot of data but this is the the gist and this is the main sort of core difference between what i think of as sort of traditional or classical computer vision versus deep neural networks the other thing i want to point out is there's nothing bad or inferior at all about conventional computer vision right there's a lot of very good applications for all of these things it's not like one is better than the other or you're "
    },
    {
        "start": 1709.919,
        "text": "not cool if you're not using deep learning none of that is true it's it's just this is the difference in techniques um this is a great uh slide that i stole from yon lacoon who invented convolutional neural networks but this is the idea is that for the top row traditional pattern recognition you have some feature extractor that's non-learned uh and a trainable classifier uh there's some like feature extractor then mid-level features this is basically svms and then you have a trainable classifier on top and then deep learning is where you're basically training at end to end and you can you can train all these parameters throughout the network so this is this is my my introduction to convolutions here so this is what's happening in convolutional neural networks those of you don't know it's like a convolution is really just a new it's a it's a numerical operation that's defined uh using a matrix and usually the matrix is small it's just like you know three by three or five by five that's what's used in conventional neural networks and uh this is an example of what would be an edge detector so anytime this filter is going to look over every single receptive field in the image it's just going to march all the way along and it's going "
    },
    {
        "start": 1770.0,
        "text": "to compute the inner product between this filter filter one in this case this edge detector and the underlying receptive field and it's going to give you a scalar back that's sometimes called the activation if you especially if you put it through a non-linearity and uh you can orient these any way you want of course like normal edge detectors and if you march this over a block m you get this feature map here where sure enough uh the edges are highlighted edges that are bright on the left to dark on the right and then if you throw away all the zero values sorry non sorry the uh negative values you get this um you get this map over here where everything zero is dark and all the things that are bright are yellow so this is a nice edge detector here you can do it in the opposite direction and you get these other highlighted edges or you can do it on the diagonal all that looks great you can do it on different images and you get different results right you're going to see different edges depending on the uh the underlying image but then if you look at this in biological tissues "
    },
    {
        "start": 1830.399,
        "text": "you kind of stop and you think that looks a lot different than this where you have this beautiful nice solid line right everything looks fantastic the problem here is it all looks noisy i don't know there's not that much information to me using a linear edge detector for biological tissues it's probably important but i don't know that why would i use this feature this specific edge detector to do classification i don't have any reason to believe this is any better than just a random filter right there's no way to know that so the idea is is don't don't define it don't hand engineer it let that be learned so that's what convolutional networks do and there was a big turning point big breakthrough in in 2012 um where um alex net was submitted to the imagenet um challenge which is now a big uh image classification challenge now it's gotten so good that i don't know it's kind of a joke because we beat humans now and the error is it's hard to know what the label is for some of these images but the point being is that there was a huge jump in the in the overall "
    },
    {
        "start": 1890.72,
        "text": "performance of these networks when we submitted the first generation of convolutional neural networks versus a lot of the older computer vision stuff so i encourage you all to go back and read this this paper it's sort of a landmark paper in computer vision since that time everything has gotten bigger and deeper and more parameters and you know the models tend to get better especially with more data we know that depth is important we know that in general the deeper the networks the better the the performance and people have tried to figure out ways to build these networks uh better and better so okay now that we've gone through all that can we use a convolutional neural net to do much more robust and granular brain tumor diagnosis and it turns out we can and that's what we did a couple years ago and the general workflow is what i've mentioned is patient comes in with a brain tumor has an mri we do surgery we get a surgical specimen it gets loaded into our microscope that lives in our operating "
    },
    {
        "start": 1951.12,
        "text": "room we acquire an image these are large images about three by three millimeters sometimes five by five millimeters and then we just actually uh patch these so you can densely sample from these you can pick your step size and you generate the number of patches that you like we do a little bit of image processing and these images are again raw images we don't use the h and e because those are post-processed images and then from there we're able to feed that in for into a neural network that we can train based on these patches and then we also developed an inference algorithm that we can use to basically sorts these into diagnostic and non-diagnostic diagnostic and normal brain we obviously just want to for focus on the uh the diagnostic tumor regions and then from there we can just have an output a probability distribution over the classes that we are interested in for brain tumor diagnosis so the way this looks in terms of output so everyone is on the same page as you define some set of diagnoses you know we did the 13 most common brain tumor types and the output is just a probability "
    },
    {
        "start": 2011.12,
        "text": "distribution over those those diagnoses so you just have a high probability density where the network thinks this is like this is a likely metastasis likely glioblastoma whatever it may be um and you know to do this work well i'm a big believer in this and part of my lab is really about you know uh anybody can publish you know ai papers on anything you can have an excel spreadsheet and you can write an ai paper the problem is that in order to actually make a difference is that you have to do some very robust validation and testing to demonstrate that this is going to generalize well and i believe that the only way to do that is one of two ways you either need to do this completely prospectively potentially blindly or you need to have a prospective and completely external multi-center data set it is held away from you it is not yours some other institution is actually going to keep that data away and they give it to you and then you predict on it right so that's what we did we had a multi-center prospective trial that we used after i had done everything that i could to optimize the network doing all "
    },
    {
        "start": 2071.52,
        "text": "the cross-validation we then had three three centers and we compared it our our imaging technique versus our sorry our imaging technique with our model versus humans with conventional frozen sectioning and see who wins right so um these are some of the results this should always be in any uh trial where it shows you what's been included and what's been excluded and why it's been excluded and then also these are the centers that we included columbia miami and michigan and these are the results on the left-hand side is conventional diagnosis on the right-hand side is stimulated ramantology and a convolutional neural network diagnosis and we design this as a non-inferiority trial that's important because that determines your sample size so we were able to design it as that just to show as good as conventional diagnosis and it was so we were able to meet our primary endpoint and we looked at two different metrics this was part of the recommendation from our initial set of reviewers they say you need an overall accuracy which in this case we beat the pathologist but what's "
    },
    {
        "start": 2131.92,
        "text": "important is that the pathologist actually did a little bit better for some of the rare classes so that means that the mean class accuracy so that's how well you do averaged over each class they do a little bit better as well and you can see one of the interesting things about this it's not exactly clear from this but there was no overlaps in the error none and that's really important this is where i think this this kind of work really shines because it really demonstrates how we can use these techniques to augment what humans do we can actually improve human diagnosis by using these methods it's not competitive in any way so if you have a network that's going to predict well on the on the specific tumors where humans are going to predict poorly that is a good thing for everybody so this is an example of how that could potentially help with with this um so an important step for me and feedback that we had gotten which i agree with entirely is that if you're going to do conventional image classification in a clinical setting what happens when you feed a tumor in that the network has never seen i've "
    },
    {
        "start": 2193.04,
        "text": "never seen this diagnosis a rare diagnosis i don't know what to do with this it's going to give it a diagnosis that's definitely going to be wrong right because it's never seen it so one of the things we wanted to develop was a score that would tell you what's the likelihood this has been seen in the past versus whether it's something well within the distribution of images that we've seen prior in the training data set so i was able to develop uh this uh mahalanobis distance distance based confidence score and uh really all it is it's a we call class conditional meaning that you're going to minimize uh this quadratic form of the mahalanobis distance where um f x is the image that's gone through the network f and you're going to subtract that from the specific class mean this is the mean vector for class for let's say glioblastoma whatever specific brain tumor class you have so you're going to get a vector out here this is the sim this is the precision matrix the inverse of the covariance matrix and then again this is the quadratic form of that so it's the same term here and uh you can you can compute this for "
    },
    {
        "start": 2256.079,
        "text": "uh any tumor any anything that goes in and if it's large enough you can actually set a threshold to say if it's larger than this specific scalar value i i don't want to predict on it it's something we haven't seen in the past um and uh so sorry guys i think i may be oh sorry no oh it's here uh so again so when you compute these scores sorry uh blue are tumors that we've seen so these are classes uh tumors that live within the um within the training set and the red are tumors that don't so things like choroid plexus papilloma clivochordoma these are all rare diagnosis that we see in neurosurgery but not frequently and uh you can see if you project this onto the first and second principle component you get a large variance away from the center um these these are computed along the layers of the neural network you can see red red far away from the origin is bad and then if you project this into what's really important which is the linear discriminant axis that's where if you draw the decision boundary for values "
    },
    {
        "start": 2316.96,
        "text": "greater than or less than zero do you separate these two different groups meaning trial tumors or common tumors that we included versus rare tumors and we were able to develop a linear decision boundary which is great so one of the knocks on deep neural networks is that they're black boxes right they're uninterpretable i don't know what's going on in them it's especially bad for any diagnostic system because it's important for clinicians to trust the prediction right why is it predicting this in the absence of that sometimes i think it really hinders people's belief in this work and i think it's our job for you know myself and people in my lab and people working in this area to sort of dispel that and try to do what we can to make it somewhat interpretable so one of the things that we did was what's called activation maximization uh this has been published in the past but the idea is is that take your train network so that the weights are fixed in this case uh theta here uh pick a spot on the network preferably somewhere deep because "
    },
    {
        "start": 2377.839,
        "text": "sometimes it's quite a bit easier to understand what's happening and what you want is rather than optimizing over the parameters theta and the network you actually want to optimize over the image x so here h is the location in the network this is the again the network the function that you are computing l is the layer j is a specific filter in there so you can imagine you're way deep in the network 100 what does it say 159 layers in i'm picking i'm picking filter 12. all right way down there now i want you to give me the image that's going to activate maximally activate that specific neuron really i want you i want to see that firing down uh way down in the network and i want to optimize the image for that that's the arg max part here our contribution was that this this x subject to rx means that we actually uh invented this regularization term that helps make the images look better and if you do that you actually get these really cool feature maps you get these really cool activation images here so this is like for example filter "
    },
    {
        "start": 2438.0,
        "text": "12 this is filter 101 this is 148 etc and you can see that it actually has learned to identify specific features and the images it's learned to see you know is this a small cell is this a large cell is there complex chromatin is there axons so this one i especially like this one got a lot of reaction is that it's actually looking for what we were mentioning before myelinated axons which was uh you know a big find there's no reason for this there's no reason for you to believe that this is necessarily going to happen when you do the same experiments for any natural vision problem for example if you're going to train this on imagenet it looks like noise i encourage you to look up this technique because it does not look well at all we have this supplemental figure in our paper but if you do this for natural vision we still don't quite understand what these feature maps look like or these activation maps look like but ours is different because this is an iterative process you can make these cute little gifs you know the sun not just helps anything but you're looking at the network slowly optimizing the image um as a as a gradient ascent steps "
    },
    {
        "start": 2498.88,
        "text": "in the image space usually you're doing gradient descent steps in your parameter space for your network but this is the opposite where you're slowly developing from a random image that's just gaussian noise you're going to go to something that maximally activates some specific convolution within your network you can look at these throughout the network you can do this at any arbitrary position and if you do that you basically get more increasingly complex patterns which is good that's there's this hierarchical composition to deep convolutional neural networks there's a belief that that's how the the brain works the human visual system works as well but uh this is sort of what you get as you march up uh deeper into the network um you can quantify this i don't want to go into this too long because we're running out of time but uh you can quantify uh what what is being activated based on different tumor types and when you do that these are the same filters this is the equivalent what i was showing you before with the block m and the convolutions and what i was mentioning earlier except this is for the learn convolutions here "
    },
    {
        "start": 2559.119,
        "text": "so filter 148 and layer 159 if you develop those same feature maps you see for example where this specific filter 101 really picks up these large cells with complex chromatin structure same thing here if you get these axons this is what it's looking for and if you look in gray matter which makes sense because gray matter is normal brain you're going to have myelinated axons there you also get similar bright activation so so when talking about convolutional neural networks the the convolution part really refers to this feature extraction part this is where you have to go from an image variable size whatever it may be down to some fixed feature vector right that fixed feature vector is really what holds the semantic content of the image what what are the relevant things to look for to do some task whether it's object detection or classification semantic segmentation whatever it means you're going to you're going to write a caption from that image "
    },
    {
        "start": 2619.119,
        "text": "all of that information must be contained at some point in a single feature vector 512 you know you know 2000 whatever it's going to be and that's where the difference between what i think is vision and something like nlp or classification or you know an mlp and the important thing to look for is that once you finish that visual feature extraction how do we make sense of it what's going on in there and in particular with respect to the the tasks that we gave it in this case it was image classification so if you do a dimensionality reduction technique called uh t distributed stochastic neighbor embedding that just takes high dimensional data and projects it into the plane you get this and i intentionally color it this way because it's an unsupervised technique doesn't know anything about brain tumor labels or what classes or any of those things all it really tries to do is say if in this high dimensional space if there's a high probability that this specific point is going to be my close neighbor then i want it to be a close neighbor in this low dimensional space that's really what the whole algorithm does and when you do that uh you see sure "
    },
    {
        "start": 2680.4,
        "text": "enough that the same tumors tend to cluster together which is what you would expect this is what you want right this means that similar tumors look similar when you get done doing all the visual processing and the cool bit about it too is that you actually see some of the similar tumor types clustered together so gliomas here this is glial up here particularly parasitic gastrocytomas diffuse logarithmic gliomas glioblastomas epinephrines that's all in the glial category non-glial tumors tend to cluster pituitary meningioma and then interesting small round blue cell tumors don't worry about what that means but it just means that they all look alike cns lymphoma as well as medulloblastoma also clustered together here too so basically we're doing what we want to do we're extracting the right features they may be yeah yeah there are a different sub to excellent point yeah so we're actually uh working on that experiment so there's very well-defined molecular subtypes for medulloblastoma that we know are different tumors it's really not one disease and one of the things that's important is one of the "
    },
    {
        "start": 2740.56,
        "text": "subgroups in particular we know surgically has a different goal so we've been thinking about trying to do that specific thing that you mentioned so great great point um you can do because we're doing this patch based classification you get semantic segmentation basically for free because you're densely sampling over the whole image and the good thing about it is that if your step size for your patch does not exactly match your receptive field you can actually uh you can improve the probability there's a smoothing that you can do based on pooling the probability for each one of the the um the uh the sort of the patching regions that you're using so again uh you know as you go through you're going to get sort of a probability density and there's this averaging that's happening for each location in your image and you can average over that not based on some simple averaging like median filter or gaussian blur or something like that but it's actually where there's a probability that's being output by the network and you can average that probability based on the prediction of "
    },
    {
        "start": 2801.52,
        "text": "the specific neighboring patch region so this gives us these nice smooth looking heat maps and this is great this is really important when you're going to interpret these as humans you want to know if it's wrong where it's wrong and why it's wrong so the other bit that's really advantageous is that particularly you've got the margin of a tumor you can say are we at the margin and where is it right is it all this stuff normal brain versus tumor um and here you can see this red is tumor and green is normal or gliotic brain we're able to delineate this margin really effectively and uh really help for um how close we are to getting to normal brain when we're resecting these tumors you can do the same thing with metastasis even when the brain looks normal you can have these metastatic rests of tumor which can be important these are all microscopic tumor infiltration um and then the one bit the extension of this was that there's embedded within this big problem is a set of really hard problems and one of that is differentiating recurrent tumors from what we call pseudo progression which is when you have a tumor and "
    },
    {
        "start": 2862.8,
        "text": "you're treating it with radiation or chemotherapy there's a tendency to though for those tumors to end up looking or should say the adjacent brain to end up looking really angry it will enhance it will get inflamed there'll be edema and sometimes it's true recurrent tumor and that's that's bad you want to know that versus oh maybe it's just pseudo progression and it turns out that humans have a really hard time with that and it's because the actual treatment makes the underlying tissue look abnormal even when it's not it's basically just reacting to all of this treatment effect so they actually have tried to develop strict guidelines to help clinicians determine whether this is recurrence versus pseudo progression and uh it's it's still very much an open question they're all basically equally bad we've tried some things they've been retracted some things don't get reassured don't get reimbursed by insurance etc the the important bit is that one of the most definitive ways to do it is if you have a histologic diagnosis and the difficult thing again is this is "
    },
    {
        "start": 2923.359,
        "text": "the heat map for pseudoprogression and recurrence and non-diagnostic but the thing i want you to see from this is these images are large and they're very busy there's just a lot going on there's blood there's necrosis hyalinated uh blood vessels there's just there's just a lot of gliotic tissue so it makes this problem really hard and we wanted to attack this specifically because it's clinically relevant but also humans really struggle with it um this is the the algorithm that we developed that i developed to make to for specifically for this problem because this is different than what we're showing before before you just get a discrete probability distribution over the classes just pick your arg max whatever it's going to be what is the most probable diagnosis that's your diagnosis it's a little bit more complicated that but that's the gist this is not like that the problem is that there's they're likely going to predict some probability that this is tumor right because it looks bad this is bad tissue and we don't have with all of this we don't have single patch level labels these are all weak labels we have a whole whole patient or whole specimen "
    },
    {
        "start": 2983.52,
        "text": "diagnosis but the problem is that you have to set some threshold you have to say if it's above this probability for tumor recurrence then i'm going to tell you this is recurrence but that threshold is not known a priori that's going to be a function of your data set but also the underlying model that you've trained right the annotations that you have all of those things are something that you you don't necessarily know a priori so we basically developed this method that allows us to threshold this uh diagnostic recurrence based on pooling the probability distributions and also throwing away regions that we think are non-diagnostic um we can if anybody has questions on that later we can talk about it so i was able to define what we thought was a was an optimal threshold at 30 percent uh this was based on a cross-validated data set that we used um again these are less common pseudo-progression particularly is less common but i really tried to max out what we could with the data that we had did a lot of rigorous cross-validation to find this optimal tuning and then um this is what you get so "
    },
    {
        "start": 3044.24,
        "text": "again there's it's much more mixed and nothing really looks normal the treatment effect doesn't look normal and then you can have a mixed recurrence as well as treatment effect and then you can have dense tumor as well but in the end we again we did this external validation we had this columbia had this data set they were doing something completely different they were doing rna-seq on recurrent tumors so we were able to benefit from that and uh we had 50 patients and we were able to do really well 96 accuracy and in particular what i liked is the sensitivity was 100 because it's important as a clinician you want to think about what's the important things to not do how do i not hurt somebody right that in a way is a difference between accuracy and sensitivity or any other metric in this case you certainly don't want to miss if it's recurrence if it's recurrence that's bad you don't do anything right so you want to set your threshold to be on the lower end so you're diagnosed your tool is more sensitive than specific let's say for example so the last bit here is i think the initial title of my talk but in saying all of this "
    },
    {
        "start": 3105.119,
        "text": "the general momentum of brain tumor diagnosis and i would say cancer diagnosis in general is defining tumor types based on molecular features what that means is for this specific tumor is this mutation present or not or are these three mutations present or not or is there some chromosomal aberration is there some epigenetic alteration all of those things are the tendency that the the world health organization is moving towards to define these very rigorous diagnostic classes it's true for brain tumors it's true for lung cancer it's true for a lot of different things so um so the 2016 came along and sure enough there was a revision to the the brain tumor classification scheme and uh they said now intrinsic uh diffuse gliomas which are the most common malignant brain tumors are going to be defined by a set of molecular features and that's that's the "
    },
    {
        "start": 3165.44,
        "text": "deal if you're going to give a real diagnosis you have to do immunohistochemistry or sequencing or some tests to define this group so again the histology this is where we stopped this is this is we were in the histology land here so we were able to tell you whether this is an astro and oligo or glioblastoma but everything uh you know south of that line was idh mutant is now the molecular feature so idh mutant idh wild type atrx loss p53 1p19q codillation so all of these things now are are absolutely essential for defining these these diagnostic subgroups of diffuse gliomas so the question is can we extend a lot of the techniques that we've developed here to the molecular classification of diffuse gliomas now i'll tell you this is a much harder task because now you're mapping pixels to tumor genotypes right there's no specific reason and humans aren't able to do this but how do you know that a specific mutation "
    },
    {
        "start": 3226.96,
        "text": "is going to generate a visual feature difference right because that's what that's what this task is about can i map a set of visual features to specific molecular subgroups and that's the hard part it's true for medulloblastomas glioblastomas whatever it may be and that is something that is really a superhuman task meaning that humans currently can't do it and it's an open question as to whether this can be done people have tried it on different data sets like mri uh h e but there's yet to be something that i think is a real uh robust um generalizable uh approach to it but i can tell you we're working on it and we have a um a pathway to i think get this done um certainly we have used much more i would say high power technology to do this optical image feature extraction my phd student chang jang he's here he's been working on a lot of contrastive learning methods to get this done and then in addition to that what i've been trying to do is really develop this multi-modal training procedure where we're actually using sequencing data "
    },
    {
        "start": 3287.44,
        "text": "from tcga open source we can actually train a gene embedding model from that and then the actual the classifier can use the semantic information contained within that genetic embedding layer to be able to do classification on visual features so there's people have done sort of gene to vec models um but it hasn't been done constructively for visual tasks it's been done in natural language processing and natural images people have tried to to kind of combine sort of semantic features with visual features but it's yet to be done robustly in in a biomedical data set so that's kind of what we're working on and i can just tell you that preliminarily the data is looking quite good particularly for some of the most important diagnostic mutations this idh which is uh i suspect dehydrogenase which is by far and away the most important mutation in gliomas um we're uh improving more and more with the additional data that we get and also with this gene embedding "
    },
    {
        "start": 3347.44,
        "text": "uh uh method that i was mentioning to you earlier so uh that's it for in conclusion srh is a rapid label free optical imaging method that provides high resolution diagnostic images i'm sorry this is digital images of fresh biomedical specimens and uh the combination of srh and deep neural networks can achieve rapid and accurate brain tumor diagnosis so uh oh sorry guys let me go back there we go so this is my group uh up and coming uh fantastic energetic group i run the machine learning and neurosurgery lab um so again if you're interested in any of this stuff we are hiring we we have some uh projects that we have uh funding for and need help with so if you're interested at all please please reach out to us we'd be happy to meet with you so that's it i think i got done in time right oh yeah any questions please "
    },
    {
        "start": 3407.599,
        "text": "go right ahead amazing technology thanks besides [Music] oh yes that's a good question so i've been involved a little bit in sort of the fda approval of ai uh and i can tell you that people still don't know how to do it meaning that i think that there just isn't a good precedent it's not an attack on the fda or anything i think it's really hard to know how to toe this line of what is really useful i mean what are we i mean we're all trying to help people while trying to help patients so we need something that's useful but we also need something that's not going to put the company at a lot of liability for risk right like if you if you're an ai system and you make a wrong diagnosis like you you know you don't do you don't so diabetic retinopathy for example huge space for for computer vision you know you don't triage someone to being seen by an ophthalmologist when you should "
    },
    {
        "start": 3468.559,
        "text": "have you know what what do you do with that now a patient goes blind or something it's like so what happens and the problem is that a lot of the companies are like i don't want anything to do with that i don't want to be we don't want to be liable for hurting anybody and i think they mean that in earnest but at the same time that's what the tool is meant to do right so it's not hurt people i mean as a triage so i think it's really challenging to know how to make these products really helpful but not having the liability fall back on these companies for making diagnostic errors in the case of this i think we run into that the thing i'm interested in these these high bars like i want to do these really interesting scientifically complex things and with the company that we work with they're like no we want the simplest product you can think of i want to like is this tumor or not they even want to do less than that to say is this even is this tissue that you can use for diagnosis or not which to me is not interesting at all right but there's this tension between what you know what "
    },
    {
        "start": 3529.839,
        "text": "they can do feasibly and what they you know trying to minimize the amount of risk and the fda same they also want to minimize the risk of their products while at the same time making something clinically useful so i think we're still sort of towing that line but i think we will get there it's just a matter of making these models better and learning more and more about how to make them uh into you know usable and feasible clinical systems anybody else anybody online well i just like to congratulate you tremendous trajectory of work and a very substantial lesson in how long a path it is to document and explore all the variables and come up with a system like this it's quite impressive of course yeah it's definitely been a a long road even though you know you have to really enjoy the the process and [Music] you know it's been a lot of fun and "
    },
    {
        "start": 3590.319,
        "text": "i think i consider myself a fortunate part of something that really started in um really in a lab i mean it was on an optics table at a chemistry lab and to see this through to now where i'm using it in the operating room uh to treat patients is i mean i think that's a gift i think a lot of writers don't ever get to see that so you know even at this early stage i consider myself quite fortunate while they're still great i had a question "
    },
    {
        "start": 3652.0,
        "text": "yeah in vivo basically yeah so that was uh something that we we have been working on that so there is a working prototype of an nvivo image where you you have a probe basically it's a handheld probe and you can you can do this use the same sort of fiber laser technology that we do now to capture the image but it's sort of in this handheld device i do think that's feasible i mean i you know there are ways to do that um the one of the major challenges is that we're acquiring these two channels two image channels and they're spatial sorry they're temporarily separated you cut you acquire one the laser shifts and then you acquire the second one that in itself is not a problem exactly so it's the movement of the actual either the brain or your hand like how are you gonna hold it still right so it's like do you mount the actual handheld thing using some rigid arm or do you do you hold it or you try to do this extremely robust sort of error correction algorithm do you do it on the software side all of those things i think are good questions to have but i do think that in "
    },
    {
        "start": 3713.599,
        "text": "the long run we need to develop methods that are um you know in vivo that are non-lethal that we can image these things um you know uh without having to remove tissue because you know it's it's a it's the right observation to have that let's say you're at the margin of a tumor and you're imaging and it's normal brain right you don't have to cut that out to tell whether it's normal brain or not you want to know in the resection cavity uh yeah i think it you definitely lose image quality the deeper you go especially in this epi reflectance mode where you're basically shining the laser down and you're trying to collect all the laser that comes back to you in the objective and the handheld objective but i think they've gone something as deep as 80 microns or something so it's it's fairly it it's doable and this is where again this is one of the things that i believe in is again it comes down to the clinical task if it's if it's for margin delineation right that's basically a binary class is this tumor or not right when it's when it's quote unquote simple "
    },
    {
        "start": 3774.88,
        "text": "like that uh you might not need your images to be as good right you can take some noise and you can still have a fairly robust classifier so that's where i think you know understanding what you need out of the data out of that observation is is important you know not only for what you build and the actual objective that you're going to use and all those kind of things but also if you want to if you want a classifier an ai sort of computer vision decision support model to go along with that knowing what the expectations are from the data itself and you know if it's a binary classifier you can you can maybe make your objective a little less good or you can take some noise in the data set right "
    },
    {
        "start": 3838.24,
        "text": "there is yeah i'm glad you mentioned that so we have a whole research program in lab right now based on exactly what you said and it goes back to the noise question is so we have very good theoretical models for where the noise comes from and it and it has to do with this combination of this additive and multiplicative noise and we believe it's probably gaussian distributed as most noise is um but we know that it's not so simple when you're gonna like deconvolve the image or or in this case we're trying to use uh you know uh image to image networks like u-net to try to denoise these images now we we know that we've tried this if you just use simple gaussian noise it doesn't work so you can't just say oh we're going to use we're going to noise these images to to train a unit to be able to denoise them using some conventional loss function like mean squared error or something like that for whatever reason you can on your training set beautiful "
    },
    {
        "start": 3899.68,
        "text": "looks great perfectly denoised right but then when you actually take a new image that's just come out of a patient it does not work so we have been trying to use exactly what you said where let's learn let's use what we know about the optics of stimulated raman scattering microscopy to determine what is the best noise vector right that we can use to try to deconvolve this this sort of you know inverse image problem so we have been working on that and it's important i don't think you can do you know we're doing image classification but i think if you want to improve image quality you have to understand the optics of the the system for sure excellent thank you all "
    }
]