[
    {
        "start": 0.0,
        "text": "his contributions both training students yes well thank you for having me here in CC MB I feel less than the least of these sort of thing its case so today I'm gonna tell you a little bit about on some experimental and computational strategies to help identify compounds in metabolomic s-- um and as i'll mentioned this work is all not not just my work but it's done in collaboration with everybody in the metabolomic score and our new compound identification development core no conflicts of interest to declare ok so i'm an analytical chemist by training I'm in still I you know it closest to my heart I'd say um so I what am I going to tell you about bioinformatics or that's relevant to bioinformatics and computational medicine well I think it's not a stretch to say that that omics Sciences and informatics are intimately intertwined there's no way to have filmic science without a way of dealing with the data classically we think about that in terms of you know interpreting "
    },
    {
        "start": 61.199,
        "text": "data you know putting biological meaning to - you know big data set but what about compound ID this is kind of an unusual thing if you're familiar more familiar with genomics I'm trying to identify what genes you have is sort of a matter of course it's not something that you spend a lot of time on with modern techniques so why is this a challenge in metabolomic so we'll talk about that a little bit and and there's a few topics that will break down the talk in - first we'll talk about figuring out what's the difference between an actual compound and just a feature in your data set I then will talk about how you go about taking those compounds and getting the best data that you can to help identify them when you need to talk a little bit about synthesizing all of that data into a manageable useable entity that will help you not just on the project you're working on but thereafter and then finally we'll talk a little bit outside of my field of expertise but I think maybe potentially of interest to this group about about how you could go about improving the search strategies that are "
    },
    {
        "start": 123.27,
        "text": "out there that identify the true unknowns and the UM the the known unknowns in your data set okay so background so why is compound identification even a challenge in metabolomic I'm welcome here we start with the classic central dogma of biology if you can even call that call it that anymore where we have the genome the transcriptome the proteome in the metabolites need and all too simple line where we see that genes in encode RNA RNA proteins etc and when you look at the what this made is made up of and it from an analytical standpoint the genes are maybe 25,000 maybe more or certainly that's static but not really because we have the epigenome we have we have all sorts of transcriptional regulators things things that make the genome much more complicated but it's at its heart made up of four base pairs or four bases arranged in pairs and the same is true of RNA proteins happen to be a little bit more complicated there's a there's a "
    },
    {
        "start": 183.47,
        "text": "larger total number of them especially when you factor in post translational modifications but they're still made up of about 20 amino acids maybe a few more gets a little more complicated with your posterior translational modifications so primary metabolites well we don't really know exactly how deep the metabolize but it's probably not a million different compounds at least not endogenous compounds in a human for example but what's different about the metabolism aid up of so many different structures of chemical chemistry is in the metabolomic ant take it apart the same way we can base pairs of DNA or amino acids out of a peptide and then of course just to re-emphasize this is not the way that the the that biology actually works the metabolomic communicates with the proteome communicates with the transcriptome back and forth and all of that ultimately determines you know type of the organism okay so let's look at "
    },
    {
        "start": 244.37,
        "text": "that on what what I mean by by the chemical diversity is just a quick picture with a few different chemical structures all of these things I consider metabolites right these are all smaller molecules less than $2,000 really less than $1,000 in most cases and they're they're really diverse right so we tried to apply the same technique to detect and identify all of those things we're going to run into some challenges and of course another characteristic of the metabolomic of the podium is that the dynamic range is very large we don't really know how deep the biologically relevant the tab alone goes if you look at the but just looking at reference ranges for four metabolites these are clinically measured blood tests it goes anywhere from millimolar topeka molar concentration and all of the compounds listed here are clinically relevant in some way shape or form in the complexity of the abalone is much greater than what can be measured by standard clinical assays so um this is this is what we're "
    },
    {
        "start": 305.33,
        "text": "contending with so okay i what is what does metabolomic look like for those of you who aren't perhaps as familiar and well a typical untargeted metabolomic and i should say if you're not familiar untargeted metabolomics is where we go after everything we can find in the sample right where you take where you take a sample you extract it you use a method that that is sort of universal in its detection strategy and you look for everything I'm so sample but preparation basically is taking your tissue or your bio flu of whatever it is getting the metabolites out removing the things that you don't care to look at like proteins or DNA typically that's done with a solvent extraction then a typical metabolomic analysis method would be to inject that sample after it's been prepared on to an L CMS or a GCMs there's alternative techniques and a Mars one but this is a this is the workflow that we'll focus on today then you take the data that comes out of the lcms or GCMs we'll look it a little bit more in detail in a bit and you detect features in that data set so anything "
    },
    {
        "start": 365.69,
        "text": "that looks like it could be a metabolite could be it has a mass um it has a retention time looks like a chromatographic peak because we're doing chromatography on the front end you use software to detect those features and mark them in your data and then okay so then you've run presumably multiple samples different types you're trying to get biological insight you need to align those features that are the same so you look for something or the software looks for something which has the same mass because mass spec metric masses and it lines them up so now we have a table with all of the features and the were detected in your sample set and sometimes you get missing features so you can do recursive processing to make sure that you're not missing features in any sample and you get an alignment able okay then what typical workflow would be to look at that data set and say okay between my biological sample groups are there any features that change right is there anything that that differentiates "
    },
    {
        "start": 425.78,
        "text": "group a maybe my control group from Group B my experimental group my drug treatment group I at my post intervention group and tools that can be used to do that include multivariate statistics PCA ap LSD a simpler things just like basic univariate statistics things that will pull out differential features and then and only then you notice here we are at step eight in this whole workflow we get to feature identification in classical and targeted metabolomic so you don't worry about what you've got until you get to this step right here you found the differential features and you go after only those features that showed some biological interest and then once you've got those you try to do your biological interpretation pathway mapping etcetera if you came to a metabolomics workshop or if you're familiar with metabolomic so you know that there are other ways of doing the tableau mix you can use the target of workflow where you where you look for specific things specific metabolites of interest or you can do a hybrid workflow where you look for some things that you know are going to be in your data set and then you add in this "
    },
    {
        "start": 486.41,
        "text": "untargeted workflow and you try to look at what what's differential that you didn't already identify but this is classically how untargeted metabolomic s-- is done okay so I don't think it's any surprise to you that the metabolome is a complex entity and metabolomic data set is a complex entity - it may contain over 20,000 features in a single sample set and typically if we do our best approach with a sort of hybrid targeted on-target approach we might identify maybe 400 features maybe if we're doing really well a thousand or so metabolites and that's what gets reported if that's where we leave it but what are all these other features what about the other 90 thousand features in your data set well it turns out what you're actually looking at is not a complete snapshot of the identified metabolome what you're looking at in a metabolomic data set is "
    },
    {
        "start": 546.63,
        "text": "really a subset of the features so the features that you're able to detect and identify represent really a small fraction of the total features in the data we know that there are we know say that we have you know five thousand metabolites that are known to be present in human body just a very rough number I and we don't detect all of them so we know that there's a subset of the metabolomic we can't see on these are real features but they're not and they're not detected or identified in our data set but then we still have a large sort of unknown area all these all these features that are detected and not identified so the question is are these unknowns are these all biologically meaningful features that would enhance our biological understanding of the system we're studying if we were able to identify them well let's talk about that a little bit so the question the spoiler on the answer is no and the reason is because there is degeneracy in "
    },
    {
        "start": 609.54,
        "text": "untargeted metabolomic data a degeneracy means that forever for any single biological metabolite that you detect you may not get just a single signal for it in your data set you may have multiple signals and where those signals come from well electrospray ionisation is a typical way that we take a metabolite and introduce it into a mass spec the process of forming those ions I although it's considered a soft technique where we don't get very very much fragmentation we do see degenerate signals arising we can have isotopes so basically mass spec measures masses if you have the the the predominant masses typically the the mass in in which two molecule contains all carbon-12 atoms we can see masses where we have one carbon 13 maybe two or three carbon 13 so that those are isotopes I'm generally fairly easy to understand what's going on there but we can also form addict so instead of forming a M + H ion which is a your molecular species the proton on it you might form some "
    },
    {
        "start": 670.74,
        "text": "smaller amount of saudi ated species or a doubly so dated species or a potassium species and your mass spec will record those things you might also find that some portion of your metabolite of interest fragments in the mass spec and gives you neutral loss Peaks and so all of these features represent degeneracies so that brings me to topic one which is really more of a shout out to other members of the audience who have who have done our work in this area so how do we discern actual compounds that we want to spend time identifying from from just features in the on-target metabolomics data okay so I'm not going to spend too much time on this because if all is given to talk here in recent memory she's probably brought you well up to speed with all of this but it's relevant for what I'll talk about further so it's worthwhile just mentioning I'm so the goal is to reduce the redundancy and untargeted metabolomic data before we go after identification of other known unknowns and so what do you what do you do to do "
    },
    {
        "start": 732.3,
        "text": "that well we need a full data set to look at that and we need to look at we need to look at the compound spectra and we need to look within each spectrum we need to look at what what isotopes might be there we need to look at features and say do they look the same do they show up at the same time on our column do they look like they correlate with other features in the dataset and then using the combination of all this information we can go ahead and start to preliminary at annotate things that look like they're at a neutral losses features that don't represent new biological meaningfully meaningful data okay so as I mentioned computational approaches to do the state of reduction rely on a few properties of degeneracies one if you're familiar with chromatography these features tend to Co elutes they show up at the same retention time because they're being formed in the source of the mass spectrometer they're not they're not present in a in solution in your sample in a vial of necessarily or "
    },
    {
        "start": 793.379,
        "text": "if they are there they're just representative of what happens to the molecule that you're actually interested in I they also will tend hi pairwise intensity correlation with other features that they represent that are that are degeneracies of those same biological metabolites and that that will be true across samples if you have a big data set if you have two features that represent the same metabolites chances are they're going to correlate with one another in terms of their intensity their abundance and also they're gonna have discernible mass relationships the shift in mass from one feature to another should correspond to some chemically determinable entity okay so how do we how do we deal with this well this is this is the shout out part of the talk we can use various tools and there's there's other tools that have been developed but a great one that we have that we use here in the metabolomic score line is called binner developed by Karnataka marine catchment and others Janus Wigington bill also I have "
    },
    {
        "start": 856.089,
        "text": "developed this software and what it does is it visually annotates features in a data set that may be addict and it will highlight for you using sort of a visual display of correlation matrices between between metabolites that have similar retention times it will highlight metabolites that have high correlation coefficients and those that have lower correlation coefficients and if you have metabolites with high correlations or features with high correlation coefficients that's a sign on that you might be looking at a degenerate feature and it also uses mass shifts so you can observe differences in masses between features that that show up more than once in the dataset and let you let you get an idea that hey I'm seeing a mass shift that's commonly occurring at $22 chances are I may be looking at a sodium atom that repeatedly occurs that works for things that you can figure out what they are it also works for things that you might not know what they are even if you don't have an annotation that defines what that what that what that "
    },
    {
        "start": 916.959,
        "text": "mass shift is due to if it recurs frequently in your data you may get a sense that this this mashuk shift is some sort of an addict or a fragment that's commonly occurring in your data set and you can read all this paper if you're interested but it turns out that this actually works really well on a deformation can be really extensive and complex in some cases and so taking a very simple molecule leucine we see over ten addicts that whose structure can be definitively assigned after a careful analysis of the data and so what I'm getting at here is this sort of informatics focused approach helps us pare down what we actually want to spend our time with our analytical techniques looking at and we don't want to be looking at 20,000 features of which 70 percent are redundant we want to be looking at the thirty percent of features that represent a chemical compound that we may or may not know "
    },
    {
        "start": 977.89,
        "text": "what it is I'm just as another piece of information because I'll be talking about MS and ms/ms a lot later in the talk I've been our annotations these annotations of hey this looks like a feature that's redundant to that other feature in your data set that can be checked using analytical techniques like ms/ms so here we have an MS ms spectrum that shows that we have a sodium fluoride addict and a sodium chloride or made addict of and then and then yet another level a sodium formate or made addict of a single molecular species so we can use ms ms to help help confirm okay so who does this leave us a degenerate agenda see reduction is important so now what we've got is a picture where if we look at the entire observable feature set we still have a limited set detected and identified there's some that we're missing in our dataset and we have a large region of degenerate features that that look like "
    },
    {
        "start": 1038.819,
        "text": "they might not be a unique feature of biological interest but it still leaves us with this white space here this this true unknown features that we haven't been able to put our finger on yet and our worth some further follow-up work okay so how do we tackle them right and how does it intersect with bioinformatics so bear with me on this one so I how do we discern compounds from features and on target metabolites okay so just a sort of we revisit a compound identification focused workflow I'm in metabolomic so what would we do okay typically we would acquire quantitative ms1 data on the samples that we were trying to study because we need that to derive insight in turn so the disease state or the experimental manipulation they're performing and then you're going to acquire some tandem mass spectrometry data on representative sets of those samples I'm you know necessarily they do need to do that every single sample in your data set but "
    },
    {
        "start": 1102.43,
        "text": "you want it to be under representative identical preferably chromatographic conditions to get deeper insight into what some of those features are and then you'll do what we already said we'll do statistical analysis to detect knowns and knowns of biological interest and then we're gonna attempt to identify the unknowns of interest based on the ms2 data of authentic standards and I'll talk a little bit more about that okay so what's the problem with that workflow sounds fine well one one problem is that the ms2 data that you get is kind of constrained by the chromatography that you used for your quantitative analysis if you wanted to run a thousand samples you can't be waiting for your instrument to to run for you know eight hours per sample it'll be a prohibitive data acquisition time and so I we we if we set up our ms2 acquisition where we really need detailed information about all an individual sample you may be constrained by that a little bit you may not get as deep coverage as you would need to really identify unknowns I'm "
    },
    {
        "start": 1163.18,
        "text": "especially the lower abundance features which are less likely to produce high-quality spectrum okay um so how does let's take a quick step back and talk about tandem MS what am I talking about well basically mass spec takes all our metabolites turns them into ions and what we do typically is we'll we'll measure the mass of those ions if we're doing standard MS one type mass spectrometry and then we'll we'll quantitate those ions and that's as far as we go but to help identify we can take it a step further so we can select day one of those particular ions that's being performed that's being formed in aspect at a time and subjected to collision induced dissociation what does that mean that means you break it apart into fragment ions and so from one precursor ion we get multiple fragment ions and then we can select particular product iron ore measure the mass of all of those different product ions and detect them okay so what does this do for us I it's it's useful both for metabolite identification and we'll "
    },
    {
        "start": 1224.47,
        "text": "talk about that soon and also it's useful for improving selectivity so instead of I'm just saying okay we have a mass of a single ion I'm coming out is that a metabolite that we're interested in and we also know how it fragments and that can tell us more definitively that what we're looking at okay so alright so we can get ms/ms data how is that useful for for compound identification I'll talk about that more and when we get to the spectral search got to be part of the talk but suffice it to say right now ms/ms data the way a molecule fragments can be sort of a signature of of the the identity of that compound a particular compound gold fragment in a very reproducible way if you take data acquired by somebody else on a similar type of instrument you can compare the spectra that you get and if you have a match then you're moving in the right direction toward identifying that compound so okay but the first thing we need to do is get a ms/ms spectrum that's worth something right it needs to be it needs to be of decent quality so "
    },
    {
        "start": 1284.77,
        "text": "that is a good ms/ms spectrum and how do we get them well a good ms/ms spectrum would have more than one single ion it'll have multiple high abundance fragment ions I'm going to have low background noise will have sufficient signal-to-noise that we can we can observe the background and all of our major fragments will be well above that that is that is useful for for compound identification what's a bad ms/ms spectrum look like well one characteristic of small molecule mass spec is that sometimes we get few or even only one major fragment i mean sometimes that major fragment is the paradigm that the the ion that we sent into the collision cell to break apart just didn't break under the conditions that we gave it the other characteristic is that you might have lowest low total signal and high background noise so in this ms/ms spectrum based on the total abundance and based on familiar with the how the instrument works and what its signal noise threshold typically are most of these Peaks that we're looking at back down here are probably noise and "
    },
    {
        "start": 1347.26,
        "text": "this is the so we don't have a lot of really useful information I'm in this spectrum to help identify a compound so okay great how do we go about getting better ms/ms vector so that when we go to use our informatics approach to identify compounds we have some degree of success okay so I'm going to tell you if you'll bear with me for a few minutes a few approaches you could use to improve your your your coverage of your ms/ms identify compound well one the simplest thing you can do is you can just inject more sample usually we're not sample limited in metabolomic you can get all the blood plasma you want you can get all the tissue that you want there are certainly exceptions but you can just inject more on your instrument okay so as you move from you know a to microliter to a five might clear to a twenty microliter injection at the same sample what does that do well I'm jumping ahead here using the spectral search strategies that I alluded to earlier we can look at compounds that we confidently identify and we can see that as you as you "
    },
    {
        "start": 1407.559,
        "text": "increase your injection volume you do in fact increase the number of compounds that you detect and that's a true across different modes of chromatography here we're looking at a blood plasma sample on reversed-phase and hydrophilic interaction chromatography and we're increasing our number of compounds identified but you can see um that these curves are leveling off we're studying this in more detail right now and we find that you go much further than this and and you're at a flatline you're not identifying more compounds by just loading more on your column the reason is one reason is your column loading capacity is only so much if you're familiar with chromatograms you can see that some of the peak shape that we had here a nice sharp Peaks are turning into sort of more blobs and-and-and are in our chromatography is degrading a little bit as we go up in injection volume and as you push that limit further you you are limiting your ability to separate species and thus you eventually reach a point of diminishing return another problem is you might lose the retention time alignment with your quantitative "
    },
    {
        "start": 1467.86,
        "text": "ms1 data so you've got a challenge now to go back and say okay I identify this in a high sample volume injection whether it show up in my quantitative work so we get this point of diminishing returns so we need other strategies here's another one for you on so instead of just acquiring ms/ms data on a single run of your sample we can do what we've termed iterative ms/ms data acquisition or certainly not the only ones to use this approach this is now adopted by major instrument vendors so what we can do is acquire ms/ms spectra on a standard run of your sample and then have the instrument take note of what features it already acquired ms/ms data i'm so in this case in the first injection we say at a particular retention time right here and we have three ions that that were the highest in the spectrum that we were able to get ms/ms information on so all three of these ions were able to be fragmented and acquired ms/ms spectrum but at that retention time we might have missed all these lower abundance ions and the "
    },
    {
        "start": 1528.309,
        "text": "instrument may not have time to go back and try to acquire ms/ms data on them before the peak is done alluding from your column and so if that was all you all you did you wouldn't have ms/ms data on an awful lot of signals in your sample one thing you can do is then say okay in the next run of the sample I already know I got these three three species I acquire data let's leave those out and just acquire ms/ms on the next three most abundant species and then keep going on down until we've reached to the point where we're no longer acquiring useful ms/ms data and so this is great this this it takes a little bit more time to analyze your samples but it does let you get much deeper ms/ms coverage on it by excluding those previously selected precursor ions and a rolling basis and this doesn't prove ms/ms coverage but just like with with the the previous approach I it has its point of diminishing return if you go four or five injections of your sample "
    },
    {
        "start": 1589.72,
        "text": "you've usually reached the point where you're not identifying anymore compound so what else can we do okay here's the strategy that I want to spend a little bit of time talking about which is fractionation right so I'm instead of doing instead of limiting yourself to the chromatography that you you first started out with what if we took that same sample and we broke it up into fractions I chroma chromatographic li so in other words and I'll show you what it looks like in the next slide so looking at the chromatogram you know these early fractions I these are not really well retained on the column I they tend to be uh you know overlapping with many features with many other features and that limits the mass specs ability to acquire a good quality ms/ms data on any of them um so what we would like is to take these features that are not very well retained on this chromatography and move it to a method of chromatography where we can get better retention for intermediate fraction for our little instructions where we're not seeing much signal I would like to inject more of it "
    },
    {
        "start": 1651.78,
        "text": "and now we have the ability because we've we've removed all of these high abundance features if we isolate this fraction only we can optimize the loading capacity for this particular fraction independent of what we do with all the rest of these fractions and for a high abundance fraction where we'd really do a lot have a lot of signal what we need to do is optimize our chromatography so that we pull apart some of those high abundance features from lower abundance things that are present in that in that in that region of the chromatogram and help get better ms/ms coverage of some of those lower abundance features which are probably the unknowns that are really what we weren't able to get deeper on so what does that look like analytically so here's my you know your key analytical chemists slide we take we take those samples and we we fractionated them using a semi-private of scale column as I mentioned we're not usually sample limited we can put more on our column and we split the flow between a mass spec to tell us what we've got and a fraction collector and then we take those fractions we dry them down and we can analyze them a second time and we "
    },
    {
        "start": 1713.94,
        "text": "using our LC ms/ms instrument and now we can tweak the chromatography here the injection conditions to get better ms/ms coverage and then we have to assess that data and say did this make a difference did we get better compound identification and so there's there's some informatics there okay so just to look at what what the data look like when we do that type of I'm workflow I'm going to show you three different modes a fraction collection sort of multi-dimensional chromatography here and the first one is a reverse phase by refer reversed base of reverse phase was the first column of semi prep column that fractionated and it was also the second column and what you see here we see some consistent background ions which are prevalent feature of metabolomic data we can usually manage those pretty well by I'm just saying what's present in our blank and excluding them but what you also see is that the features of interest that the chromatographic Peaks sort of elute along a diagonal in this chromatogram and that's because the chromatography is similar on our first on our two "
    },
    {
        "start": 1775.299,
        "text": "dimensions what we can do so why would we even want to do this at all well what it does let us do as I mentioned is it lets us take these role abundance fractions and inject more and take these high abundance fractions and inject less and that overload our column and thereby sort of optimizing our loading capacity but what it doesn't do is spread all of the features out over a wider range of separation space so this is a simplest approach you can use okay here's another method so instead of just using basically the same gradient separation on both dimensions we're still going to do the same general mode of chromatography but we're going to alter the gradient fraction by fraction to sort of optimize it for the things that we're looting in that fraction for the early eluding fractions we're going to use a very weak solvent so that those features can be retained for the later looting fractions and we're going to use a much stronger solvent so that they will and and the goal is to spread out all of the features and all of the "
    },
    {
        "start": 1836.41,
        "text": "fractions over a wider range of separation space it turns out that this doesn't work perfectly all the time it works very well for for some of the fractions it doesn't work as well for the stuff that was way early or way late in the kinetic so there's a limited range of things that we can improve here with this approach and then a final method is we we switch our mode of chromatography entirely in the second dimension stead of using a reverse phase chromatography we use a reverse phase in the first dimension and hillock in the second dimension and as you can see here we make better use of our separation space and so what this is done is made the job a lot easier for the mass spectrometer now instead of having to acquire ms/ms information on all of these features in a single run we've broken it down to a sort of a much lower feature density per unit time and the ms/ms should be able to go deeper into our into our metabolomic a but what's this look like how does this affect our ms/ms acquisition as I was mentioning "
    },
    {
        "start": 1898.15,
        "text": "okay we want to compare you know the best case to the best case so I we might get maybe 700 features with useful ms/ms per run and if we got six runs by the time we've gotten down to iteration six we may have only 25 to 50 useful ms/ms spectra in there so that you're going to look at it's sort of a diminishing return as you move down from one run to the next of course not every ms ms spectrum immediately means you've identified a compound but the more unique ones you get the better i'm with vaccinations um we may not always get 700 features in every fraction we may sometimes be lower in but we tend to see in most fractions 400 to 700 features with ms ms per run but we can spread this out over spread the sample out over 30 fractions so you can see just by multiplying you you definitely have a higher number of useful ms ms spectra that you can use okay how does this "
    },
    {
        "start": 1959.23,
        "text": "translate into identifications oh well here is a here's a preliminary analysis of some data so in the first method the unfractionated plasma we just did I we just did a single run and we looked at how many features we identified we get 120 180 muni compounds using a very simple identification strategy of ms ms search score of 700 and i'll show you more about what that means a little bit and just validate it yes okay when we look at those spectra those are reasonable matches chances are if we went through and poured over the data in the tailor we'd be able to add a good number of compounds to that but this is this is a reasonable and automated way of looking at if we look at the second approach I'm an iterative ms/ms approach of the unfractionated plasma so this is just doing multiple runs like I already showed you I'm using the various different modes of chromatography comparing them in total we're able to identify about 167 unique compounds so "
    },
    {
        "start": 2020.04,
        "text": "we've improved our sample our compound identification roughly 50% what about when we use fractionation so when we use fractionation using the various different strategies we were able to detect in the same sample same using the same final mass spectrometry analysis method 348 unique compound so we've more than doubled the compounds that we were able to identify in our dataset so this is this is really useful as an approach it does take some time to accomplish but if you're just doing it on a representative sample rather than on every single analysis that that time compared to the time it takes to analyze the rest of your data is actually quite reasonable okay so let's just look at fraction by fraction between the three approaches since I showed them to you and we have the gradient approach we have the isocratic version we have the the orthogonal chromatography hillock approach the north non orthogonal gradient typically does as well as other methods on metabolites that were really "
    },
    {
        "start": 2081.389,
        "text": "well retained out here on the first dimension so things that were things that stuck well to your column we were already actually doing a pretty good job on them I should say that what we haven't done yet in this particular data set is really optimize the column loading fraction by fraction so we should be able to do even better on some of these lower abundance on medium fractions and so the HEI method as we expect does a lot better on some of these fractions that were really not well retained on our on our on our first dimension of separation so that works and the gradient method I'm sorry the isocratic method where we're trying to spread out doesn't show as much promise overall but if it's going to work best somewhere it works best in these sort of intermediate fractions where we have intermediate retention and we kind of can tailor our chromatography to to work well on those particular okay what is its translated into in terms of ms/ms coverage I well I can we "
    },
    {
        "start": 2142.41,
        "text": "detect things that are really of interest yes we can so if we did a single one ms/ms on and unfractionated human urine sample i we can see a feature with them in the MS one data with the feature with a mass of 276 point 1 2 3 but we don't get any any ms/ms coverage on it here's what happens when you do fractionation you take this feature it has in fraction 19 we can find that feature it gives a nice peak and we can search that peak against the database and it turns out that the metabolite that we're looking at is benzoyl x ago mean which is a urinary cocaine metabolites so we were able to detect this minor feature in a in a cool human urine sample that probably comes from drug abuse and and there's many other examples of features that were able to pull out using this approach that can provide biologically meaningful information okay so of course this right this approach is not the only way that we can get more information there's "
    },
    {
        "start": 2203.1,
        "text": "other approaches that are useful the compound ID I'm in just because I'm in the little chemist I have to mention that NMR compound synthesis a chemical organization all these are important analytical strategies that we can use to add to the picture to help identify our compounds okay but we want to get back to the bioinformatics where is the bio informatics and why did I make you listen to this whole topic to hear well the the challenge along the way is really what we do with our data so the challenge that we're grappling with right now is how we unite our fractionation based compound identification data with the high-throughput data so it's only useful if we're able to go take the features that we are able to identify and go back and find them in the in the quantitative metabolomics data and another challenge that were that we're working on and having that's what this how we identify what is a high quality ms/ms spectrum which is something that we think we should be able to get a match for it if "
    },
    {
        "start": 2263.7,
        "text": "we had it in our database but versus what is a low-quality ms/ms spectrum okay the instrument went and got data on a particular hand but we don't think that I we're not getting a match because the you know the compound is unknown to our database we think it's happening because the quality is just low and so that's a that's a challenge there and so when we've looked at fractionated versus unfractionated you know looking at looking at features that were able to detect via a you know commercially available database versus compounds that we measure ms/ms i or in an unbranded sample you look at the scoring and you can find that there's some indication of metabolites with high score on the commercial database that we didn't see and our unfractionated core these are these are new identifications that we wouldn't have been able to make with our with our unfractionated score here compounds that that we can find in both the fractionated and the unfractionated sample but they have a low score against "
    },
    {
        "start": 2325.97,
        "text": "our commercial database these are features of interest right these are features that we can reproducibly find they're in our quantitative ms1 data but our database isn't helping us identify them so these are the new metabolites where we want to spend our time working and then of course there's a bigger picture question which is i you know i've mentioned i've kept mentioning ms ms spectra are essential for identifying compounds how do you go from an MS ms spectrum to a compound identity while you do it with scores but then how do you interpret those scores well we'll spend a little bit of time talking about that if you okay so hopefully I've given you the sense that there's a lot of information in this data set you do compound fractionation you have many many unknowns how do you deal with it well there are some tools that are out there and let's talk about them briefly but first let's bring back up this workflow for just a second remember as I mentioned compound identification is usually relegated to the very end of our workflow when the resources probably are the most limited to dive deeper and so "
    },
    {
        "start": 2387.53,
        "text": "this following this workflow for all of our studies following a a project focused workflow and prevents work so okay let's say we have the resources we go and identify some features of biological interest we put paper on them and that's the end of the road that workflow may or may not help someone else who comes down the line you're later to try to identify those features and their data set if they don't happen to know that they should be looking in a study of cancer metabolism in in pancreas cells and you're working in the liver I with response to exercise it doesn't matter if you identified if they identify that feature you're not going to be able to find it if you don't know where to look so um we need improvements to this project focused workflow to help facilitate compound identification for the long run within a lab and and especially between labs so ok what tools do we have well and there are metabolite libraries and databases which are designed to span multiple "
    },
    {
        "start": 2448.27,
        "text": "projects so these are things like HM VB the human metabolite of a sore mass bank us which is a sort of a user-generated mass spectral library and so these features will many many spectra that can be searched against any data set they tend to be well curated so they have high quality spectra in them that's good you can also buy commercial databases like like NIST the problem with them is that they don't contain very much method method specific or especially sample specific information and metadata which is really very useful to identify compounds so okay we know that we have a metabolite that's present in human or that's present in the human metabolomic we don't know should I be able to see it in a particular tissue and what is the relative abundance of that metabolite and what is what is it going to look like on my mass spec when I go to acquire the data so these databases are useful and they give you a place to start but they don't they don't answer the whole question ok so so um the other "
    },
    {
        "start": 2511.81,
        "text": "part of the picture is spectral Stewart search right so we acquire an MS ms spectrum we want to be able to search it against a database so that we can use what's already out there while there's limits to those databases and those search strategies as they exist right now a lot of the search tools that are that are presently existent for the field of metabolomic SAR listed limited to a specific instrument it's architecture so that works great while you're running on an Agilent mass spec or on a thermal mass spec but as soon as you want to share your data and share your methods with someone else you have a problem the databases are proprietary you can't get your data out in a usable form or more likely you can't use your software that you've you spend a lot of time investing in analyze someone else's data or to interpret an unknown and someone else's data so that's a challenge so some of the most well-known tools for example nist ms search there's an advantage to that software in that it's on its platform agnostic this is a tool developed by "
    },
    {
        "start": 2572.55,
        "text": "NIST compatible with all sorts of vendors mass spec data and it's it's very powerful at it's very visual it helps you look at an aspect ms/ms spectrum and compare it with the library spectrum and say do I really have a good match it has very useful scoring strategies which we'll talk about in a few minutes but it's designed to kind of be self-contained and it's relatively limited to low throughput work it doesn't automate this identification task which really becomes a routine part of your metabolomic Swift flow there are other software packages which are very automated this is one also developed by nist i'm called ms pet search which can do spectral search from large data sets very fast but they typically work with a command-line interface and they don't let you visualize your search results to say do i believe this or not you're stuck looking at only the scores so what do we need well we need a means of tracking compound ID efforts across project both within a lab and between "
    },
    {
        "start": 2633.66,
        "text": "the lab and so what I'm just briefly going to mention to you right now and talk about some of the features up for a tool that we're developing um we have a tool developed by Sasha Raskin under under a larger tool that we use in our lab called the MRC squared data analysis tool box which can help with these tasks so what this software does is first first of all it integrates with our limbs so we acquire data on our instrument doesn't matter what instrument it comes from it automatically can be imported into this compound identification workflow and searched against against both external and internal databases of metabolites um so that facilitates our workflow a little bit it lets you search against many different databases it has presently the NIST 20 it has access to the NIST 2017 database which we have license for it I mean can use MEDLINE search results it can use a open access search results like masbate that USA can use in silico generated spectra "
    },
    {
        "start": 2693.98,
        "text": "like with like lipid blast if you're familiar with that sort of space i'm so we can it can sort of unite spectral search against all of these tools it can take these data these search results importantly we could use an existing command line tool to do all of that but it's important especially in metabolomic s-- to be able to visualize our search results so it lets you generate head to scale visualization and command and look at that side by side with your scores and say do I believe this search result and really importantly it also lets you manually annotate these features once you've spent time looking at this feature and you think you agree with what the spectral search says you can say yes I've reviewed this the squirrels are good I am going to assign this as my identity in this sample you can say well it looks possible I have some some comments that I think this is this class of molecule that I need further follow-up on this metabolite using "
    },
    {
        "start": 2754.45,
        "text": "different strategies so you can flag it for further follow-up identification steps maybe you need to run get better ms/ms maybe you need to run in a mark all of those things are potential things that you can flag and so on this software is really useful for us in that way so what are we doing with this or the software right now I'm as I as I mentioned this is being developed by sacha it's still in active development but we have now a complete set of ms/ms data for a wide variety of different human and animal tissues and we're expanding that data set all the time all of the results from those compound ID focused experiments are loaded in the tracker and they can be used not only in the context of identifying what's in those particular samples but they can be used for other studies too if we find something we annotate it we can use those results to help identify the same features and other sample sets that we run using the same or different methods and so we're going through all those features I mean it is still somewhat a manual and fast process right now to say is this a match that I believe I've "
    },
    {
        "start": 2816.7,
        "text": "identified my compound and and and ultimately we want to develop a curated sample specific method aware a database of annotated features and use these results in our future studies and be able to share those results as part of our work with the metabolomic consortium and out to the wider community on and and what we're we're in the process continuously refining the software to better achieve that okay now on to the the topic which I've been hinting at told you a little bit about this spectral search on thing all throughout so spectral search is really a key thing that you would do in an attempt to identify an unknown or even to you know validate a something that you putative Lee identified but there's limitations to spectral search and so as I already mentioned I missed MS searches a powerful search tool currently the most widely used I would say at least among platform-agnostic schools and it uses a fairly straightforward means of "
    },
    {
        "start": 2878.02,
        "text": "comparing your experimental spectrum with library of curated spectra and that's a strength of nist ms is it has its own library of maybe 20,000 authentic standards that have been analyzed by various different aspects and I mean calculate it calculates scores to to assess how closely your experimental spectrum matches with the unknown spectrum and two examples of that are a dot product approach and a reverse dot product approach the difference is that one eye takes into consideration only Peaks that match and looks at a relative intensity values and and and other factors in terms of mass alignment and and and and intensity a dot product is a reverse dot product looks only of those things that match dot product looks at all the features in the data set and and will effectively penalize you for signals that you have that aren't in the in the library and it also has this also has a a sort of a "
    },
    {
        "start": 2938.47,
        "text": "proprietary software specific calculation on the temps that attempts to really focus in on on exact matching identities and so sometimes going looks great you can take your unknown mass spectrum and you can match it perfectly with the library spectrum I mean you get very high score values I should say that all of these scores and NIST are scaled to a value of a thousand where where zero would be no match and a thousand is a perfect match so in this case we have a incredibly good match for l-carnitine which is a common a common urinary plasma ubiquitous metabolite in most tissues so and you can look at the next back best match for a unique compound on the list and we have not nearly so good of scores so in this case it's unambiguous at the compound that we're looking at I'm at least as far as this library is able to tell us is in fact l-carnitine so great okay if everything was that easy I wouldn't be here talking to you today but it turns out a lot of the matches that we look at are not so good right um so here's what looks like a reasonable mass spectrum we have good "
    },
    {
        "start": 2999.099,
        "text": "signal-to-noise we have multiple Peaks this was the best that nist was able to do when we said try to find an identity match for that spectrum and we have a score of 80 for a dot predicate of 525 83 a reversal you know you know we're only looking at the things that matched with the exact library spectrum were pretty good but but there were obviously missing a lot so so if this was where we stopped we would have no idea what we're looking at here but we can use an alternate approach which effectively allows for for neutral losses with versus your library spectrum so we say okay we're not only going to look for things that have exactly match your library spectrum we're gonna look for things where we see some matches but we also see some matches masses that have matches that have mass shifts compared to our predictive metabolite and in this case our search result comes with this hybrid approach I comes up against a tetraethyl een glycol which is probably a polymer that's present in the sample "
    },
    {
        "start": 3059.13,
        "text": "collection vials and is not actually a biological sample but it's an identification of at least a metabolite class or a feature class on which gets a lot a lot closer to knowing something about what this feature is but let's say we want to know these things exactly we want to know what we're looking at without any sort of question well it's helpful to briefly look at how that's done in other fields and so in proteomics it turns out that that that compound identification based on ms/ms spectrum is sort of a solved entity so how do they do it so easily well it is necessarily easy but the approach that youth is used in proteomics you take your mixture of proteins you digest the peptides you acquire ms/ms data i'm very similar to what we do in the tableau makes so this is this is very much metabolomic workflow with the exception that we don't digest up our metabolites there aren't small enough and so then we identify using ms/ms spectral search in proteomics not unlike what we do in metabolomic but we instead of using "
    },
    {
        "start": 3120.03,
        "text": "experimental spectra we are able to use in silico generated spectra peptides tend to fragment in a very reproducible manner so if we know the sequence of peptide we know pretty well on what the ms/ms vector might look like and then we can use scoring strategies very similar to what I just showed you to say what's the best match for that peptide if we find enough peptides that look like they come out of a protein we can pretty well definitively identify a protein and I then we have another tool that is incredibly useful to say how good and how certain am I about the quality of that match and that's false discovery rate estimation on so the way that we do that is we generate a decoy database so we take the the the proteome that we were going to search against and we basically scramble up its peptide sequence so we have a random sequence of amino acids that are about the same size as the proteins that were in that database and then we in silico digest that scrambled database and we generate what's called a decoy ms/ms database and then we search our spectra that we acquired experimentally against "
    },
    {
        "start": 3182.099,
        "text": "both the the real database with with known actual peptides in it and the scrambled up database and we say we see how many matches do we get both ways and you can either do them separately or you can do them as a combined database and you look at the distribution of scores and you can say ok well I know that I'm getting some portion of false matches with low scores because they line right up you know I get as many matches or more matches against my decoy databases as my target but then I have a portion of the score distribution which is unique to the targeted database and these are my real identifications and you know based on how many of our identifications are coming from this portion of the distribution versus coming from you know hitting against our decoy spectrum we can estimate a false discovery rate and gives us confidence and effectively this works so well that in modern implementations you don't have to look at your ms/ms spectra at all anymore well why doesn't this work with metabolomics there's some problems first you can't scramble the metabolite database the same way you can scramble up the peptide database and "
    },
    {
        "start": 3243.85,
        "text": "even if you could if you could figure out how to do that how to take Peaks and scramble them up a collision I'd induced dissociation fragmentation of small molecules is currently still a little bit more unpredictable than what you get with proteins or peptides so if you try to in silico fragment and and and see what your mass spectrum would look like it probably isn't gonna work out so well and even if you did that and you and you you generate a good ms/ms database i you may run into a challenge where for those compounds with only one or two fragment ions you're not gonna be able to get a good match anyway and you won't get an accurate estimation to false discovery all of that said it's certainly still worth trying and so there is there is a desperate need for better techniques to estimate false discovery rate in metabolomic search strategies and this is an example of a recent relatively recent paper in Nature Methods from a group that attempted some unique methods at at taking a real spectral library and digesting it and generating a decoy "
    },
    {
        "start": 3305.74,
        "text": "database and so as I mentioned this isn't my specific field of expertise but others Alexi novitskiy these are our co PIR api on this grant and and and his postdoc who again are working on this challenge right now and about how can we use a decoy databases and get an estimate of false discovery imitable so in summary i hopefully i've shown that that like conventional metabolomic state interpretation there are all sorts of bioinformatics pertinent challenges lots of lots of ways we can use software and tools to help get deeper into the metabolome we really want to you know remove the redundancies before we go about it analytical techniques play an important role but and then we need the tools to manage all the data that's generated to help us identify compounds and and not duplicate our efforts as we go back to do it again in future datasets FDR or more rigorous statistical methods are really needed so that we don't need "
    },
    {
        "start": 3367.33,
        "text": "to go spend hours or days or weeks or months poring over our and I'm a spectra but for the time being given the challenge that it exists we need to bring all of these approaches to bear to compound idea metabolomic sand we need to go out and make this process more routine we need not just computational statistical but we also need experimental and we need biologically aware approaches that say hey I found this metabolite this unique metabolite in this particular sample set under these chromatographic conditions if you're doing something similar look for this metabolite and if you're not then and you you're seeing something that looks like it and if it's never been seen in that particular sample site maybe you want to be more careful about what you're looking at so hopefully I've given you a flavor for some of the from some of those challenges and what we're doing to tackle them so with that I'll acknowledge Chuck Brandt and and all of my collaborators in the metabolomic score you make a lot of all of this work happen on NIH for funding and I you know we're pleased to be one of these compound and efficient identification cores and thank you for your attention "
    },
    {
        "start": 3430.39,
        "text": "[Applause] I have a question so chose I think the fractionation strategy that you're working on I think that's you know fascinating and it looks very promising at least from what I can go so I'm wondering how do you see the future workflow was once you have implemented that and you know with the compound tracker and all of this so you're able to hopefully extend the repertoire of known compounds right to mention that you don't have to subject all your samples to fractionation if you're you know running an experiment which has 200 samples it's enough probably to do one or two or something like that so do you see that going forward as part of the workflow or do you think we will reach a point where we'll be confident enough with the goal would be to get to that "
    },
    {
        "start": 3492.119,
        "text": "point where we don't need it right but the question that I think fractionation is really useful for is for going is is for figuring out how deep the metabolomic goes right do we do we stop are we content with what we can see in the in the in the you know in a high-throughput metabolomics run or do we do we want to look a little bit deeper as instruments get better we we recognize that there is increased depth in metabolize I get a good quality ms/ms spectrum so I think it's its approach or its if practicality is a and doing a really good rigorous job characterizing a particular sample type so we expand our knowns and we know what to look for and second in in going deeper into the metabolomic for if we had the sensitivity they look like they could be biologically interesting let's go make a method that can find them and can keep up with the biological throughput so I "
    },
    {
        "start": 3553.259,
        "text": "think I think that's where it where it potentially has has used but no I don't want to do it every day Charles and brilliantly talked about a terrific introduction to the whole subject for someone abla congratulations to your membership is a faculty and a session B to the M Reed Center if there's any discussion today I had a talk which for everybody who doesn't know that's the center here for early life exposures and later live disease risks as much about Environmental Health Institute of NIH now I was at the precision medicine well conference in California last week and they had over 2,000 scientists and investors there are yes they had seven simultaneous tracks one of which was microbiome and microbiome including the problems of antibiotic resistance "
    },
    {
        "start": 3616.2,
        "text": "some rubs these days especially ASB and some here is to hotel from the metabolome which compounds are which modifiable compounds and which ones from the microbes are ten times or hundred times more cells than we have inside us which ones are from our exogenously environment from food and pollution and all that do you guys do those kinds of analyses and what kinds of things are you finding these days right so we do certainly interact with my microbiome and those interested with a microbiome on a relatively routine basis but most of the work that we do in that in the metabolomic score that microbiome pertinent is on the targeted side right so we're going after short chain fatty acids for example which are presumably largely derived from the microbiome we have had projects in the past where we've been going after specifically microbiome derived "
    },
    {
        "start": 3676.36,
        "text": "metabolites things that are that are known not to be endogenous li produced but our products of a bacterial metabolism on a particular drug for example turns out that most of those most of those features are very low abundance so they're they are hard to detect in the in the samples and approaches like this where you where you use chromatography to you know hair down the the you know the abundant metabolites and look for what you what you what maybe a Mike microbial Drive metabolites are very useful but truth be told there's an awful lot of overlap right there's an awful lot of overlap between the microbial metabolism and metabolomic discoveries straightforward question so you know a lot of it kind of has to be done in a little bit of a target way if you find a metabolite that "
    },
    {
        "start": 3737.26,
        "text": "is you know produced by your your your bacterium of interest in the dish you can go and look for that in a in a metabolomic study too to find a true unknown that is present in your sample well all of the workflows that we've shown here are effective but you're at that point where you've now gotten the metabolites that let's say you've gotten good signal-to-noise you've gotten good ms/ms and there's no math no match for that in your database right you're at a point where you have to do a really much more challenging analytical workup on that feature you're looking at you're looking at synthesizing a standard for what you think it might be and validating it that way you're looking at trying to run isolate enough to run NMR and so those are very challenging and very slow steps and so we haven't we haven't spent a lot of our time working on that level of of "
    },
    {
        "start": 3798.06,
        "text": "microbiome I will say on environmental exposures we certainly look at samples where there are known environmental exposures and we we we detect metabolites that are environmental orange and all the time phalates are routinely detectable in our sample sets where exactly they're coming from is a is another unknown but then those show up right there's there's no surprise in compounds that are that are environmental or origins but disambiguating like your like your colleagues want to do you know what's coming from the host what's coming from the gut what's coming from the environment it's a big challenge and strategy many years ago in the early days before the omics especially John Donne Yeats at Scripps is a pioneer in mass spectrometry from proteins fed this expensive experiment fed animals small animals C 14 and 15 labeled amino acids and then you could trace metabolism and "
    },
    {
        "start": 3860.26,
        "text": "what happens to them in the animal it wouldn't be so expensive it's less expensive than labeling the mouse would be labeling the microbes that should put into the gut or whatever you do with them in microbiome and then maybe you might have a more efficient way of determining which compounds came from which and interesting idea or not the challenge with the pedal in terms of a rapid right so so we can put we can put traces yet I'm not commenting on views of the relevance of the microbiome here and the microbial metabolites I think there's a diversity of perspectives in this room and maybe two chairs apart in the room on the microbiome there but but with respect to the tracers phasers are incredibly useful in the tableau mix right we can we can give a mouse or a human a metabolic a substrate and and track it I you know label it substrate c-13 labeled glucose being the simplest but c-13 labeled anything a c-13 labeled drug and see where that goes if they're able to "
    },
    {
        "start": 3922.38,
        "text": "get enough of it in our blood or in the tissue to be able to detect and look for the metabolic fate labeling the microbes I my expectation is by the time that you detected anything that was produced by those labelled microbes and the microbes would have pulled in fuel from the gut and would would have turned over their metabolomic ompletely so you wouldn't you wouldn't be seeing very much of what was left you'd be seeing you just be seeing you know their response to the fuel is that they were pulling out of out of out of your body you know turnover of things like proteins and you know the genes there's a lot slower you might be able to detect signal there over a longer sort of timeframe let me just make a comment we actually did the opposite experiment dan teitelbaum rester so are we actually looking for the effects of total parenteral nutrition and actually labeled the TPN and could actually find the metabolites being generated that the the TPN fluids of nutrients are actually crossing the gut into the microbiome "
    },
    {
        "start": 3983.729,
        "text": "instead of the opposite way and we can actually see the metabolites accumulating there so it's probably easier to go that way because it's easier to label up the mouse or give the mouse certain differences that can be transferred into my car bomb but you can feed the mouse you know they both stuff and seek it the metabolites but boy living up the microbiome is stuff inside a a living a you know host it would be a big challenge any more questions well if not let's st. Charles [Applause] you "
    }
]