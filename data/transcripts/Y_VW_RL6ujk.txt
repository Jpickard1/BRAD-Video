hmm we have ismira Chris krishnamurthy police user's name is not correct um she is a third year PhD students in com in computer science at the University of Michigan she received her Bachelor degrees from caritech with major in electrical engineering and minor in computer science she now works with Professor Gina wins on developing novel machine learning techniques to classify Healthcare data do please give a warm welcome to Meera hi everyone my name is Mira and today I'm going to be presenting on my work entitled Amaze which stands for a machine learning approach to index free sequence enrichment and this work was published in nature Communications biology in June of this year and it was done with piyush ranjan and John herb downward Robert Dixon and my thesis advisor Jenna Wiens and I just want to preface this by saying that I adapted this talk from some slides that I made for primarily a computational audience so it might be a little too basic for people that have more of a biological background but hopefully you'll still enjoy um okay so um the overarching goal of this work was to improve infectious disease diagnosis and specifically to help to move towards a pathogen identification tool that is accurate fast and cheap and efficient so accurate to ensure correct treatment fast to ensure treatment can be given in a timely manner and cheap and efficient to ensure the accessibility of the method and the ability of it to be used at the bedside um so traditionally infectious diseases are diagnosed using culture-based methods and so um in doing so clinicians will typically take a sample from a patient that could be stool saliva or blood makes a sample with culture media and weight for growth and then use biological tests to perform the pathogen identification and classification and so two drawbacks of these methods can be that one these methods can be inaccurate because not all pathogens can grow mixed with the culture media so they can all be detected using this method and detection is necessary for treatment these methods can also be slow because it can take several days to detect growth and that can negatively affect a patient's ability to recover so more recently people have been moving towards using metagenomics for disease diagnosis and so metagenomics is the study of the metagenome or the collective DNA from a clinical sample so to use it to perform disease diagnosis clinicians can take that same sample from a patient but then input it into a DNA sequencer and the output of that the metagenomic sequencing output is all of the DNA from the sample and then they can use metagenomic classification methods to classify the pathogens in that sequencing output and so metagenomic classification involves mapping DNA to a classification label and existing metagenomic classification methods do this using the reference database that you see on top there and so um the problem with metagenomics for disease diagnosis are um that there can be copious host derived sequences in samples so this is what um a lot of samples that you can get from a patient look like and so in blue we have the microbial sequences which are informative for pathogen detection because they could contain the patch that pathogen derived sequences whereas in red which occupies a lot of the sample are the host sequences which are not informative for pathogen detection and in this case host is the patient from which the sample was collected um so copious Host Drive sequences can cause Downstream classification methods to be inaccurate because these methods aren't especially sensitive to host sequences especially when these sequences are noisy um it causes them to be slow because they have to classify a lot of uninformative sequences in the hope of getting to a pathogen derived sequence as well as costly because a lot of host genomes can be large so you have to store all of these to perform that classification um so to alleviate the aforementioned problem prior investigators have employed host depletion steps and so host depletion is a binary classification task of determining whether a DNA sequence is from a host or not so in order to use host depletion instead of this kind of typical pipeline where you have your DNA you input it into a metagenomic classification method which will use a database with both host and microbial data to perform the pathogen classification you can employ a host depletion method before that class metagenomic classification method that'll remove the host sequences inputting the microbial sequences only into the metagenomic classification method and as you can see here the database that that method will need is a little bit more lightweight because you don't have to store those host genomes anymore so the benefit of using host depletion are that it allows Downstream methods to be more accurate because it gives them a slightly easier classification task faster because they have to classify less sequences and cheaper because they don't need to store those large host genomes okay so um previous work in computational host depletion can kind of be broken up into two different groups um one is cause pairwise alignment an example of this type of method is minimap2 where a query sequence is aligned to a host reference genome and in this case our host is human as you can see here the query sequence perfectly aligns so it output that that query sequence is from The Host um the other type of host depletion method are lookup tables like Kraken 2 and centrifuge where you have your query sequence that's broken up into kmers or subsequences of length K in this case k is 3 and then each of those subsequences is mapped directly to a subsequence in a database and that label is assigned to the query sequence and as we can see in this case all of these subsequences are mapped to the human and so we output a human classification labeled so the issue with these typing methods are that they can be inaccurate on sequences from error-prone Technologies because they're building their reference database is typically using reference genomes which are very curated and have very few errors in them unlike sequencing output that can have sequencing errors in them and also these methods can be costly because they require the storage and memory to store reference databases um so why do we think machine learning could help so we thought that machine learning would allow for more accuracy as well as cost Effectiveness for accuracy we hypothesized that an ml-based approach would be more robust to sequences from error-prone Technologies because we can build a training set with reference genomes and sequences from error-prone Technologies we also hypothesized that an ml-based approach would use Less storage and RAM than existing host depletion methods because we can learn patterns from raw DNA sequences without the Reliance on the external database so our contributions are that we developed a novel machine learning based host depletion method a maze that can perform host depletion more accurately and cheaper than existing approaches and we rigorously evaluated our approach by first providing a comprehensive comparison of our approach and existing alignment and classification methods in their ability to perform host depletion and we also evaluated our approach as a pre-processing tool applied before Downstream microbial taxonomic classification to see what the gains are using a maze in the entire pipeline so we used five test sets for our evaluation and each test set varied in the percentage of reads of the sample that pertained to host we go from one percent to 99 we used human in our host fraction and bacteria and fungi in the microbial fraction and each of our test sets contain nanopore reads and we focused our evaluation on nanopore reads because nanopore sequencing currently produces the longest reads and is the only platform that produces real-time sequencing data both of which are useful for clinical Diagnostics um so we had some different evaluation metrics that we were looking at to look for accuracy speed and cost and efficiency so accuracy again is important for ensuring the correct treatment for our host depletion comparison we looked at General classification accuracy as well as sensitivity and specificity where sensitivity is the percentage of host DNA that was correctly identified specificity is the percentage of microbial DNA correctly identified and then for our pre-processing metagenomic classification comparison this is a multi-class task we looked at overall accuracy on the host data and microbial data and then for Speed we looked at wall clock time and cost and efficiency we looked at storage vram and RAM usage so for our first comparison we compared amaze's ability to perform host depletion to other computational host depletion methods where a hypothesis was that a maze would be more accurate and cheaper than camera and Alignment based approaches at performing post-depletion so just again um for the schematic workflow of how we were using host depletion for each method we inputted the metagenomic sequencing output and we looked at how well those methods were able to separate the host sequences from the microbial sequences and the Baseline methods we were comparing a maze to our Kraken 2 centrifuge and mini-map2 and all of these methods just had host DNA in the reference databases so first I'm going to be presenting our results on accuracy we have host fraction on the x-axis and then accuracy sensitivity and specificity on our y-axis um amazes performance is in purple the other methods are in different colors and for all of these metrics higher is better and you can see across host fractions a maze consistently achieved a higher accuracy and sensitivity as well as comparable specificity compared to all of our bass lines now looking at cost in this case lower is better a maze is still in purple we see that a maze required Less storage and as well as remain competitive with respect to Peak memory usage compared to baselines and performs a lot better than minimap in green and then for classification time we see for Speed we're lower is better again a maze remains competitive with respect to speed compared to baselines and especially is faster than centrifuge whose speed um gets much worse as the host fraction percentage increases okay so now moving on to our metagenomic classification comparison where we compared the metagenomic classification pipelines with and without a maze and our hypothesis was that a maze would improve the accuracy and efficiency of metagenomic classification methods so just as a reminder of the comparison that we're making here we're comparing the pipeline highlighted in Orange to the pipeline in purple where in Orange we're just inputting DNA into a metagenomic classification method um in purple we use a Maze Before the metagenomic classification method and here we focus our comparison on centrifuge so it's a maze plus centrifuge and centrifuge alone and we focused on our comparison with centrifuge because we found that centrifuge actually outperformed Kraken on every metric except for classification time so first I'm going to be presenting my results on accuracy so in this case we have in pink centrifuge alone in purple amazed plus centrifuge for accuracy again we higher is better we see that the pipeline that included a maze consistently achieved a higher host accuracy in terms of peak memory usage where lower is better a maze reduced the peak memory usage requirements for centrifuge and then speed again where lower is better the pipeline with a maze is classification time decreased as the percentage of host data in the Tessa increased and then the pipeline without a mazes classification time increased and for most of the host fractions Amazon speed was better than that up the pipeline with amazing speed was better than the pipeline without so oops um so our contributions just to summarize again we developed a novel machine learning based host depletion method that can perform hosted deletion accurately and cheaply and we rigorously evaluated our approach and found that it had higher accuracy and lower storage requirements than other computational depletion methods as well as improved the accuracy and cost effectiveness of Downstream metagenomic classification methods thank you thanks Mina um so the next speaker that we have is Vincent Zhang he is a Nigerian lab and is currently conducting research on machine learning with applications in dentistry previously also worked at a multi-disciplinary design program and works with a student team on speakers and sound recognition and vehicles and just to remind you all the questions will be taken at the end when all the stickers are done oh yeah yeah hi uh do I use the mic or on this one oh okay this one okay hi uh my name is Winston uh so I'm gonna be talking about it's not a like a study or anything but it's just some of the research that I've done uh for my prelims and it kind of kind of like the application it has to personalize medicine um so uh atrial fibrillation is just like a common uh a regular heart rhythm condition where uh like a regular electrical impulses originating from the heart atrium uh causes the heart to beat irregularly usually the heart beats according to the sinus mode uh but an atrial fibrillation there's different causes that can cause the electrical impulses to become abnormal and you can see an example where the typical heartbeat has like regular spacing between each each beat in the electrocardiogram and this condition's uh quite common and they can often lead to more serious conditions like our failure and stroke uh so most commonly uh so people use the electrocardiogram to detect atrial fibrillation and the electrocardiogram is just a surface it uses surface centers on a person's body and measures electrocal signals electrical potential on the surface and using this electrical potential it can detect signs of or like the internal state of the cardiac electrical activity and this is pretty commonly known where uh the electrical potential as it travels from the SA node down the hearts into the ventricles uh it shows up in as different electrical signs on the ECG surface uh the atrial fibrillation event it can be reflected on the ECG quite clearly uh because each heartbeat is is kind of irregular in timing and it can draw very clearly on the surface electrical potential um so generally in literature there's uh two common approaches for for looking at kind of the ECG um ECG waveform and kind of figuring out if a person has afib or not generally people look at two um waveform details one is the premature atrial contraction or PAC uh people call it contraction or complex but it's basically uh a in an early uh heartbeat that follows directly after a normal heartbeat and and again it's kind of self-explanatory premature right and then uh this after uh people collected a lot of ECG data and from AF patients they noticed that uh and in the ECG directly proceeding an AF event or during an AF event there's a lot of these premature contractions in the heart and generally this can signal that the heart's about to go into a state of atrial fibrillation and the second uh feature that a lot of papers use is called heart rate variability and this again is looking at the intervals between our Peaks and the electrocardiogram where our Peaks represent each heartbeat and irregularity within the uh intervals between RPS can signal the start of an atrial fibrillation event so we can see that these methods have like very good atrial fibrillation performance on like publicly available data sets and recent recent papers have reached very high performance on some of these test data sets where um using uh powerful models like CNN or uh HIV features they can achieve really high performance metrics and sensitivity and specificity however uh there is kind of a lack in literature of connecting these types of electrocardiogram features like uh the premature contractions and the HRV to kind of the underlying physiology right so uh and atrial fibrillation there's kind of different causes that could cause atrial fibrillation and this is quite clear to Physicians who are treating atrial fibrillation in the surgery room so if if we can somehow connect these surface ECG features to and the underlying causes of the condition that can teach us more about the conditions and provide a good screening tool for Physicians so um here uh here's an example of kind of the two major causes for atrial fibrillation in the heart uh you can see uh there's a topic Foci which is abnormal nodes driving The Irregular Heartbeat so usually on the right you can see and a kind of like a 3D model of the heart surface and and the colors you can see are kind of representing the the course of the electrical impulse as it goes through the heart um so when the heart beats the electrical impulse usually starts from the top sa mode and it passes through the heart down through the ventricles uh in certain uh paths right through the mouth through the heart tissue um but in ectopic full guide there's irregular nodes that that kind of take over the SA node and and they they start messing up the Rhythm and um from like an abnormal location so that the heart doesn't beat in the in the correct way so the ventricles might get the electrical impulse first or and so on so it can cause a regular Verity which causes AF uh and and diagram a so in this diagram the top part you can see that the blue impulse travels out from the uh from the white dot which is the identified Foci which is causing the irregularity and then the second potential electrophysiological cause is is uh hypothesized to be re-entry which is uh which can be explained as um kind of like a cycle of cardiac tissue that keeps depolarizing itself so the the depolarization or the electrical impulse from the SA node uh it might travel around a certain node on the heart tissue on the heart surface and this this known might be caused by scarring um or it could be caused by a Shima ischemia where the heart tissue is like part of the heart tissue might have died and basically uh if part of the heart tissue kind of can't cannot transmit the electrical impulse sometimes electrical impulses will will cycle around that area it could cycle around only a couple seconds or almost hundreds of Cycles around that place so if the electrical impulse doesn't travel in the correct motion down the uh from The Atrium to the ventricles it can also cause uh the irregularities in Atrium beating and so these sources uh are are pretty easily seen through electrograms which is basically uh the Physicians will put in a catheter inside a heart and map the surface of the cardiac tissue and however on the surface uh it's not as well known on the surface people usually just use machine learning models to identify uh irregular heartbeats to kind of predict atrial fibrillation but as to whether the atrial fibrillation is caused by ectopic Foci or re-entry that is still hard to tell using ECG uh and then uh you can see that from these two sources there's uh generally Physicians use what's called ablation therapy to kind of Target the node that's causing the issue so usually um in both ectopic Foci and re-entry there's there's usually a part patch of cardiac tissue that might be the focus points for the depolarization to circle around or the depolarization uh that's coming from that area so using a catheter we can induce um intentionally induce scarring on those areas to break up the abnormal electrical conductivity uh and generally in atrial fibrillation patients um after mapping the cardiac tissue and finding these targets uh this type of ablation therapy has proven to be the most effective so far um compared to drug treatments and uh generally you can see after a couple spots of ablation usually the irregularity can be transitioned back into a normal sinus rhythm and so the current methods they usually use invasive electrograms which which involve moving a catheter through the vein into the heart or expensive vests for locating atrial fibrillation driver positions in the heart um but however ideally most patients will be um be collecting 12 lead ECG when they're in the hospital and so any any type of patient who has like asymptomagnetic atrial fibrillation or potentially they might have atrial fibrillation in the future they generally won't be undergoing these invasive procedures and will only be able to be screening in the hospital using 12v ECG and so there's been studies that have been done where ECG might be able to roughly classify the location uh on the heart to where or where the driver of the atrial fibrillation might be and so on and so a potential study designed that I um uh I've been thinking about is uh patients undergoing cardiac procedures usually have these electrograms like the basket catheter you can see at the bottom there um collected during the surgeries but then they also have 12 lead ECG so any type of correlation between the frequently used ECG features and then the major driver mechanisms such as the re-entry or ectopic Foci might might lead to more discoveries regarding the potential uses of 12 lead ECG for identifying patients and underlying physiology for atrial fibrillation um and also potentially the ECG might be able to identify locations within the heart tissue where the drivers might be located and so uh usually you know early detection of atrial fibrillation is pretty important so uh usually in normal patients the cardiac tissue can look like that on the left um but then after you leave atrial fibrillation going for a long time the cardiac tissue starts to get fibrosis and more and more spots more and more nodes on the heart tissue become potential triggers of atrial fibrillation and so uh any type of ECG prediction such as some some results from our lab previously uh can that can predict atrial fibrillation can catch asymptomatic atrial patients um and during ECG screening so identifying kind of the causes of atrial fibrillation within the 128 ECG uh before the actual atrial fibrillation occurs can be very useful um for precision medicine so a detection of atrial fibrillation using ECG can help Physicians tailor treatment for the patient which is kind of the point of precision medicine and then early prediction of atrial fibrillation uh can give more lead time for the Physicians thank you thank you so much fun it was really interesting talk on ECG um kind of highlighting the fact that how diverse this entire field can be the next third speaker that we have is chengpo Tang um he's a member of the machine learning for data driven decisions research group led by Gina wins under the machine AI lab his research focuses on developing and applying machine learning methods to solve important problems related to healthcare his work aims to identify and trusting technical challenges and proposed novel solutions that are broadly relevant to Ai and ml all right thank you um let me see if I can hide this all right good um hi everyone um my name is shrumpu and I'm a PhD candidate in the division of computer science and engineering uh and today I would like to introduce our work on uh or like the early identification of patients admitted to hospital for coming 19 at the risk at risk for clinical deterioration and this is based on our recent publication in the British medical journal uh just this past February but before I tell you the all the details I want to tell you uh start by telling you a story so in early March of 2020 the first few cases of covid-19 cases were recognized in the state of Michigan by late March as our testing capacity improved uh the number of cases quickly Rose though Michigan medicine started with just a handful of cases um without intervention it expected a number of admitted patients with covid-19 to quickly increase exponentially in the coming days a surge was expected in April on March 24th the governor of Michigan issued the state home order and the university transitioned into being fully remote on March 26th so this exponential increase combined with the lack of tools and potential shortage of resources led to tough questions when hospitals are at capacity and run out of beds they need to decide which patients to admit and which patients to send home at Michigan hospital leadership were began to explore converting an indoor track into a field hospital to meet the increasing demand around that time Michigan medicine partnered with us to look at computational tools to for clinical decision support for coming 19 and specifically tools that can help us identify which patients are at risk of clinical deterioration if we can identify which patients are likely to deteriorate or die in advance then we can anticipate their needs and allocate the limited resources accordingly this may mean de-escalating low-risk patients to the field hospital or self-care and as well as allocating the ICU beds to the most high risk patients to stabilize their conditions such models could help hospitals manage a surge in kubernetes patients given that with along with the rest of the world we knew little about the disease we took a data Centric approach and leveraged the contents of the electronic health record using these data our goal is to learn to map each patient to a risk of deterioration we can then use this risk to sort patients from low risk to high risk and then allocate the resources accordingly our motto would also reassess the patient's risk repeatedly over the course of their admission as new information becomes available and as patients are admitted and discharged to obtain this model we first want to Define what constitutes clinical deterioration we wanted to capture patients that would need respiratory support cardiovascular support or patients that will likely die in the hospital because of the disease in consultation with our clinical collaborators we arrived at the following composite outcome definition which consisted of in-hospital mortality invasive mechanical ventilation hyphoon nasal cannula as well as intravenous based pressures and these constitute the different outcomes that we Define as clinical deterioration because there were only a handful of culminating cases at Michigan medicine whose data are available it was really challenging to train a machine learning model therefore instead we were trained our model On a related cohort which our patients with respiratory distress that are admitted to Michigan medicine for the past five years after training the model we used all the available covid-19 patient data for validation which measures how well the model would perform on unseen patients and this reflects how well we expect our model to perform in the future our final model is an ensemble of 500 linear models based on nine clinical variables but this is not what we started with at the beginning we leverage the entire contents of the EHR which consisted of over 15 000 variables and using these many uh features can certainly help us learn accurate models but it also poses various challenges in terms of debugging and integration into the HR System and it may lead to models that are less robust to reduce the feature set we adopted a hybrid approach where in the first stage we relied mostly on clinical knowledge clinical domain expertise to remove variables that are uh that do not match with their intuition and in the second stage We performed an iterative data-driven variable selection process to further narrow down the feature set so to evaluate our model we first looked at its ability in trianging the high risk patients which are those that will experience the deterioration outcome early in the admission and in our validation cohort which are all covid-19 patients from the year 2020 there were about 20 percent of the patients who met this high-risk outcome uh the m-ters model performed uh achieved good discriminative performance with an auroc score of 0.8 and a significantly outperformed another model called The Epic deterioration index which is a model that was already running in the EHR system at Michigan medicine we also consider a secondary use case which is The Tragically low-risk patients who will unlikely who are who are unlikely to deteriorate during during the remainder of their stay after being in the hospital for 48 hours and uh on this task the M curves model was able to flag the five uh five percent of the lowest risk patients with a negative predictive value of 95 percent so without making too many errors and uh for each of those uh flag patients uh we have the potential to save 9.25 9.2 bad days uh if those patients were discharged early instead of being uh having them stay in the hospital so at this point we have a model that performs reasonably well the ultimate goal it was to package the model up and uh share it with other institutions but before we do that we want to make sure our model generalizes and it performs well on other patient populations as well therefore we collaborated with the following 12 external institutions to validate our model on their patient patient population in order to do that traditionally uh we would typically ask each of the institution to send us their data so that we can run our model on their data but given the time constraint of the pandemic this was not feasible because of the extensive data sharing agreements that's required to um like to move these sensitive patient data so instead of sharing data we shared code with the collaborating institutions we had sent our model code and pre-processing code to each of their to each of the collaborators at those institutions and have them run our model on their data using their infrastructures and we were able to achieve this in just a couple of months so uh let's look at uh the overall results so the anchors model in the end was evaluated on over 9000 comma 19 patients um from these 13 institutions for uh who are admitted during a one-year period um and uh in terms of the discriminative performance our model performs consistently well across both the internal and external cohorts achieving aroc scores of around 0.8 and when evaluated on demographic subgroups of biological sex age and race and ethnicity our models similarly performs consistently well across each of the demographic subgroups and finally across different time periods throughout the pandemic where we look at a three-month period uh three month periods in the in this entire 12-month evaluation period we see that although there were some slight dips in the middle portion where there were slightly smaller sample sizes for certain institutions in the end our model performance actually is stabilized and was also performing consistently with the overall performance foreign so at the same time of the external validation we were also working hard to integrate our model into the EHR system at Michigan medicine and right now the mqurus model has been running uh admission medicine since last year and providers can actually now log into their patient's chart and pull up these uh the mqurus scores for their patients and starting from January this year the mq scores have been used by the rapid response team to drive some of their workflows and specifically every morning they will print out a list of the highest risk patients and the are rapid response team will proactively attend to these patients throughout the course of the day when they have some downtime um I want to conclude by highlighting a few of the main takeaways that were Key to Our Success first we uh given that we have limited data with for the queen 19 patients we leveraged data for related cohort that's similar enough but also um like similar enough but gave us more data to train the machine learning model with and second we relied on clinical expertise to make sure our model is robust and matched with their intuition and lastly uh we shared code instead of uh sharing data allowed us to conduct this extensive large-scale external validation which helped us verify the generalizability of our model and uh I want to once again mention the publication which will uh which contain more details because I only have 10 minutes to talk through and our code is also uh code for the model and pre-processing is also publicly available online and I want to also highlight the lead student authors including Fahad kamran myself um or canopolis and uh Benjamin Lee and the two lead senior authors Dr Michael schoding and my advisor Janet wings and many more of the collaborators who were who like contributed in various aspects to this project and all the funding sources thank you foreign especially the interesting part of data um code sharing instead of data sharing that was interesting um so the fourth speaker is Chang um sang He's a member of the machine learning in neurosurgery laboratory led by Todd holling his research focuses on computer vision machine learning and biomedical data science um he's especially interested in representing learning and integrating observations from multiple modalities such as histopathological images and Etc okay oh can you hear me good okay so today I'm going to talk about uh the rapid automated analysis of skull-based tumors their surgical specimens and image using optical Imaging and public markets based on disorder okay and it's based on the paper that we recently published in the neurosurgery Journal that was actually featured on the coverage uh so let's start Dive Right In into the background I don't think the future is working so here so the here's the problem that we're trying to tackle right so the problem here is that we have a lot of patients with brain tumors but we don't really know what type of tumor it is just based on the MRI image that we have right so uh the problem is that the treatment of these tumors actually based on uh the diagnosis so in order to have the right treatment we have to know the diagnosis and typically to get the diagnosis you have to access the surgical specimens so typically what happens is these patients will get into surgery and a slice of their tumor will be taken out surgically and the specimen will then undergo a pathology workflow but the current workflow is very slow it's labor intensive and of course a lot of a lot of tissue processing and this is not optimal right so this is the process I'm talking about usually when we get a surgical specimen it will get sent to a Pathology lab and the technician will have to process the tissue right it will have to uh suction the tissue freeze the tissue and then stain the tissue and then take a picture and send it to a pathologist and the pathologist who is on call will have to look at the tissue and then call the or and say this is a diagnosis and this whole process can take uh from half an hour to up to two hours and during this time the surgeon is just waiting uh so can we do better right we want something that's faster more efficient and more accurate right so here is the alternative workflow that uh we are uh using here at the University of Michigan so uh if uh a lot of the surgical specimen can actually image using a new microscope called stimulate rum histology right in this technique will take only up to a minute to image the specimen and this specimen we're trying to develop the method to basically analyze these specimens using artificial intelligence and computer vision and the goal is to get the diagnosis time to under one minute right so this will significantly reduce the surgery time and make and allow Pathologists and surgeons to provide better care for the patients and here is a panel of some of the images that we can get from a stimulated Ramen histology we can see that it highlights a lot of cellular features in the supercellular structures such as uh worlds in in the the right middle panel in the circle right so and we know that a lot of these structures correlates uh to the type of tumor so let's talk about the methods that we're going to use to analyze these images right so many of us are familiar with convolutional neural networks right so uh into in summary the image gets passed through many convolutional layers which we call the backbone right so the backbone is responsible for learning most of the visual features from the image and it does the most of the heavy lifting of the learning right and from here we hope to learn these rich expressive features for these images right and these features are then learned using a fully connected dense classifier and the entire model is learned using a classification loss right so this law supervises the learning of both Networks uh there is a better way to learn these representations called contrastive learning and it's based on a pretty simple idea is that these similar data should really have similar representations right so let's take a look at what it means in the world of computer vision right so uh when we're using these contraceptive Learning Without supervision right so that that is we're learning without needing the label for each image we can use self-supervised contraceptive learning where basically an image can go through different augmentations or different Transformations and we know that since they come from the same image they must be similar right so they're where the loss function will try to regulate that these representations are close to each other um we can also use the labels that we have right so we can use supervised contraceptive learning to basically figure out that different pictures of dog are similar to each other because they have the same class right and we can use the loss function to make sure that to attract these features and make them repel images from different classes so uh with a contrastive learning framework we will need two steps to train our model we will first train a backbone using the contrastive loss and then we'll train the classifier with a frozen backbone right so let's take a closer look right so when we're training the backbone the same image will go through different Transformations and do a pass through the same network right it's the same weights that's learning from the two images generated from the same image and we know that they're similar so we will use the loss function to enforce attraction between these two images and repel everything else and the second step is once we have our backbone string we can actually freeze it as in we can just stop learning the backbone and we'll just learn the last layer in our network uh which is a dense fully connected layer so from here let's take a look at the results right so we can see that uh with a supervised contraceptive learning approach plus a linear classifier we can outperform all of the existing methods in pretty much all the metrics and we can see that self-supervised methods perform slightly worse but keep in mind that when we are learning these models the majority of the learning are happening without any supervision right the backbone is learned with new labels up to to look uh further close into what these metrics are we can see that the models are making a lot of mistakes uh in metastasis right so in the supervised learning and in self-supervised contraceptive loss the models are learning are making a lot of mistakes in metastasis and that's because that's a very diverse class uh these images uh the appearance of these images depends on the source tumor where the tumor is being metastasized from so they're very diverse and we can see that with a supervised contrastive learning since we're trying to enforce these representations to be similar regardless of the source we can see we perform much better in the metastasis class foreign to evaluate the model performance is to look at Disney plots so Disney is a feature dimensionality reduction algorithm basically to reduce the embeddings into a lower Dimension such as 2D so we can actually visualize these embeddings and we can see much better discernible clusters in our supervised contraceptive models right again because we're enforcing these labels uh we're enforcing these representations to be close together depends on their label regardless of their underlying pathology right so these histology images are actually very big so when we are processing these images we will divide them into small patches so we can run inference on every patch and create a heat map of the tumor margins so we can see that the model uh provides very good margins for both uh the Dora and the pituitary gland but when there's tumor infiltration and this is very good indicator for surgeons to tell them that maybe where is the better place to operate and this is also one of the feedback that we got from our reviewers because uh emergent and deniliation is a very important problem for a neurosurgeons when they're working with uh meningioma cases so usually what will happen is do a sample at different places in the brain and then each of these samples will then be Central pathology to basically figure out where the tumors are right because they look very similar on the MRI image so we can see that the model provides excellent margins uh given the different samples being sent through the model so so this is what we have done so far what are we going next right so we're affirm Believers in open science so we're releasing a part of our data uh in the into the public and uh one of the projects that we're working on is to basically open source our data in our code so if anyone can train similar models using our data another future direction is molecular classification because in your oncology a lot of these diagnosis are moving beyond just the histological diagnosis people are moving toward a molecular diagnosis from sequencing and certain mutations are very good indicator for a certain type of tumor so uh currently under review is one of the papers that does molecular classification with the SRH images so in conclusion uh we talked about how SRH is a rapid label-free Optical Imaging method that provides very high resolution digital images using fresh surgical specimens and it doesn't require any tissue processing and the combination of SRH and AI can achieve rapid and very accurate histological and molecular diagnosis so surgeons and neuropathologists can provide better care for the patients all right that's it thank you thank you Chang so we went from host to ECG to covet and to brain images um the fifth and the last speaker is going to be Andre she's a third year PhD student in Gohan's lab she is also part of the team which developed dcnn based algorithm and won first prize in 2017. um she is broadly interested in harnessing state-of-the-art machine learning algorithms I am so sorry uh to provide better solutions for biomedical research and Healthcare um hi hi everyone my name is Hari Zhang from Guam lab I'm sure that I'm I'm honored to introduce you guys our previous project about deploying identifies digital biomarkers for Parkinson's Disease um so first of all these are highlights for this project so this project was based on a previous competition on on interim challenge about Parkinson's digital biomarkers and this project was derived from a first place algorithms in this dream Challenge and so the other highlights of this project is that we um come up with a kind of new augmentation method which will come back the noise and an in-house environment towards your interests will introduce a lot of Randomness to the movement records and in our daily lives too and we can base based on this kind of noisy on signals we can still come up with a very accurate prediction and second of all we um and use the interpret interpretation of this um um a Machinery model um and to try to um explain how our machine model allocates the kind of pathological information from a number of movement signals and our method would pave a way for large-scale Parkinson training in a few apartments and screaming in the future because Parkinson is kind of like early onset disease so using our um on The Daily Record a collected from our mobile phone every day we probably be able to screen on a Parkinson from before it starts at early stage um so um this come up to their study design so all of the data in those in this project was collected from an a mobile phone app called Empower so this app was designed by an exchange Network and by the hotel was used um as a training data set in the dream challenge so using this kind of app you can which can freely be downloaded from a Apple Store and you can start to record your movement signal and on using those signal um we can um we developed our model to detect your our Parkinson's disease so this kind of walk-in processes consists of three kinds of different phases uh which like the um the subject will be asked to take a walking on task by about 30 seconds towards a point and state 30 seconds there which is called resting point and then we'll reach turn to the original state on so during this process the walking signal will be recorded by the two kinds of sensors including implemented in everybody's smartphones which is gyro scope and their extra longer and the signal is presented on either on on at the right panel which is like the series of wavelength So based on the Walking signal we developed we use on convolutional neural network to make the predictions because walking signal here has shared some um characteristics where the image which is there also continuous data um so um based on but we we have to also pinpoint that every patient they um can they contains three different kind of walking phases and also for each patient they have multiple uh they could have multiple records so except for using convolutional network we use the different pooling methods to Ensemble the all of the predictions from different kinds of records and from multiple kind of multiple records for each patient to make the final prediction um so I want to introduce the augmentation method we use this to combat the noisy background in the in-house collection from our smartphones because for everybody our smartphone can be positioned at different Stoney State and different positions on everybody's body so first of all with the content normalize which is to normalize the original ordinance of the smartphone and we also use the kind of um a very frequent used augmentation method which is also using image it's still randomly scale on on the magnitude or the x-axis of the on of the signals and then we did random rotation because the original direction of a phone on each person's body could be random so we don't want that kind of information to intrude our final prediction so that's the other kind of augmentation we used um so this is our results on using um both our normalization and augmentation compared to uh without using it so we'll show that I use on the learning curve on the left side will show that using uh the augmentation map after using augmentation method um you will like the um they will delay the convergence of the learning curve and also both the learning curvature will reach on slower um validation loss compared to not using it so this shows the augmentation method these are currently effective for this kind of noise and on the right side we show like using both normalization augmentation method will significantly improve the performance of a machine learning model so this is basically our secreting on winning the dream challenge um we also compare different kinds of signals like using because there are two kinds of sensors implementing my smartphones um we compared extra barometer signals and also gyroscope signals and there's no huge difference but we also compare like um there are 3D signal like there's three axes of the different signals or just do the sum square of the three axis and apparently through the ACT through using 3D signals contains more information about people's movements so it has better um performance and also uh we try to compare like using a different kind of because each person has contained multiple records we try to compare how uh the different kinds of methods for the record prediction of which person so um we found out that by pulling a maximum prediction of each person like the most severe records of the oil shows better uh on prediction performance than than using the main so it probably defines that the most severe uh walking record for the person probably shows how has more information to indicate the person's Parkinson's status um so I want interesting thing is that which visualize our convolutionary Network by salience map so we expect this kind of method with not only like we and our goal is not only to get the um best performing method but we want to know why this kind of what kind of signal the convolution network located in the walking signal so here I put the example of the patient and the health control record here on both Rebecca and Australia map was shown here we found two interesting things and one thing is we apparently spotted the kind of symptoms by naked eye like how the um pathological walking record can be looked so we show like the product steps and the walking trimmers in both the um what can signals in a patient but we also notice that um one interesting thing is our machine learning model like the most salivency was located in the um resting face or on the or the resting record in the patient so we we kind of feel like the restroom trimmer might play a more important role in diagnosing parking Parkinson's movements and this kind of thing also was in accordance with uh results like we compared um a production performance using three kinds of walking fish the outbound resting and return and we found that using the arresting record only um has better performance than using the walking record um so um we do some interesting Downstream analysis using our machine learning model um so um in this um uh in in this part way kind of like um made our prediction by demographics so I have to point out that because our data set was totally crowdsourcing from a phone app so there are apparently bias in terms of gender and um age on in our data set we show that a majority or one they're um there are three three folds more male than female in this walking record but uh at meantime female contribute more record per person than male and we also found that there are more people more younger people under age 35 in this data set which contribute to most of the healthy controls and there are older people on their contributing most internal Parkinson's disease patients which will kind of properly introduce a bias to our data sets um we kind of correlated our predictions to the different biomatic demographic informations as well so ubdrs here is kind of a classification system or um for um to evaluate the severe severity of Parkinson's disease so basically a higher um score or higher updr score the gets the more severe the carbon has this is it is so we found that there's a um a positive correlation between our prediction and the updrs of each patient which is totally expected and we also correlate the fund there's also positive correlation between the disease duration and their Parkinson's disease prediction which is also expected because we know like Parkinson's disease is a neurodegenerative disease it's irreversible so it's likely the longer um the longer they suffer from this disease the more severe Parkinson's disease gets we found some interesting results probably um on not um probably we need more study about this but this is totally from this data set we found like and there's some a little correlation between on the education level and the practices this is like the higher education level that gets the more severe on the on Parkinson's disease um yes but this is probably totally a bias here in this data set and also something is also extracted um between the employment status and um the Parkinson's status protection like the proper retired people because they're really older so it's more likely they get a higher prediction of their Parkinson's disease and for younger people they're especially for employ in people employee or students there's less likely they get predicted for practicing duties um so we also evaluated performance um versus the training size um of our model so this data on this figure shows like how and the the on the the prediction from most well increase as the increase of a training size power which of plateau after about 500 individuals and 5 000 records so this kind of shows like our uh our training data set is adequate enough to train um I get performing machine learning models which are it already which the pattern of the maximum prediction performance here so we also evaluates the on correlation between um the average on record for each individual and the prediction for performance when I reset people with five to three to five records shows the best training performance here um um probably because they have the largest number of data set and also like adequate and shows adequate information for each person um so on this project was previously published and patterns now we also have a lot of Downstream um study according to this one we use not only like the um not only walking record we also use voice record typing record and memory record to do to make Parkinson's disease prediction which is in our Labs other Publications and also that our code is really Joshua here and I hope you guys do feel free to check it out um and thank you everybody I wonder if you guys have any questions about this can all the speakers come up here um is starting to walk let's say a delay before the first step so a clinically a feature among Parkinson's patients is a hesitation in being able to make the initiation of the Walk but I don't see any evidence for that in the in the um slides yeah I we we kind of noticed like in many people they're kind of because the record didn't start at the first one so the record but like um um we didn't show like a parent's signal around the starting point like probably like the more rest and trimmer shows more about that so you only counted once they finally started um speed of walking um like um like the rest and trimmers or like the resting face in the walking kind of shows more signal because according to the our model probably there could be like a a data set buyers or something um I kind of like I I understand like your question but um so um so it shows like healthy control they also have a card of starting but not much because they hit the bottom and they would take a walk probably um healthy people they also like start like they they also hide a little bit but um yeah but we didn't systematically study that thank you are there any more questions to the speakers yeah I have a question okay um so I have a question from uh Winston um when you had the ECG patients did you also cater to the role gender and um uh into the model and how did that affect the model if it did uh for a weekend okay yeah so uh in previous results we did uh ECG prediction of afib um and then previous results we had agent gender matched controls yeah and but we did not include EHR data for the prediction we were purely looking at the waveforms but when we separate the training and testings that we make sure uh that the agent genders are are equal yeah thank you are there any more questions uh sorry I I I was hoping students will ask first um so this question is to Sean Paul uh so you assumed there was I I guess the the initial covet emphasis was on respiratory disease and so you used a respiratory risk distress model however later it became clear that the people who are the most at risk of dying were people it was more like an overreaction of the immune system which may not be in common with your initial training model that that was my understanding at least so have you tried after the fact I know at the beginning when you developed this model you didn't have data have you tried to make a new model that's based only on covet and how is that diff different if you did yeah that's an excellent question so I think I so due to the space and time constraint I didn't mention one important detail which is that even though the models are trained using the previous years data we actually did the model validation using a small subset of the covid-19 patients data and those were exclude excluded from the final evaluation uh performance um so I think that's what we sticked with at the moment um and uh there are some outgoing efforts to like further evaluate and perspectively evaluate the real-time performance of this model because it updates its score every four hours and the doctors are reacting or like the clinicians are reacting to the scores and making some changes in their decisions but we have not uh trained a new model based on covid-19 patients only um but that's certainly something we will look into in fact Mira was just um like also like going to start looking into some of the downstream analysis of this project as well yeah thank you thank you are there any more questions hey great talks uh so I have two questions so first for Chung um you mentioned like your one of your papers that you're working on is uh looking at um the Roman histology and also the molecular typing so are there any cases where those two pieces of evidence have like given contradictory um assignments of like what kind of tumors you're looking at yeah so the uh these are really different types of data SRH is more of the histological image so that's just the image and the molecular labels comes from sequencing or amino uh chemistry so like they're like labels so you can put on the on the slides so like one is the labels one is the data so there's really not really a space for it to contradict does that make sense yeah it makes sense I just yeah I was curious there's ever contrasting and the other question is Premiere actually um so could you like talk briefly about your model architecture like what kind of model what kind of features you encoded them as and like what features were the most important in the end for making that decision yeah um so we used uh like I think a lot of other people um who presented a convolutional neural network to um solve to um build a maze um and I think some details about how it differs from past work so no past work specifically was looking into developing a host depletion method but um past work has looked into multi-class metagenomic classification but two of the weaknesses of previously proposed Solutions were the Assumption of a fixed input size and also not training on data from both reference genomes and sequencing technology and in contrast to that we assumed a variable input size and so we used a global average pooling operator at the end of our model to ensure that we could classify sequences of all links and also we trained on sequences from a combination of reference genomes and nanopore data and we found that so in contrast to solutions that pad to the max length we classified sequences more quickly compared to solutions that truncated to the minimum length we improved in accuracy and then we also improved upon approaches that solely trained on just reference genomes and only data from specific sequencing Technologies yeah yeah I was just curious I think he found like specific like motifs or just like if in the end like the post and microbe like DNA sequences like had anything different about them the paper to show specifically oh um um so one of the specific motifs that we found was so we used a like I guess a similar saliency map um uh method to determine the motifs that were most contributed to um a host classification label as well as the microbial classification label um so in blue is what contributed to a host and then in red is what contributed to a microbe I think one of the biggest things that we found was that the um 15 MERS that contributed most to a microbial classification uh label contained at least one CG and I think CG there's like CG suppression that occurs in vertebrates and so that was something that um we found that matched with biological intuition interestingly enough though our model was much more robust to changes in percentage of CG in the sequences than existing approaches uh amaze and purple was much more stable to changes in the percentage of CG and sequences than other methods who are much more sensitive to I guess the CG that they expected to exist in the host and microbial system yeah yeah that makes sense I was just curious about that specifically thanks uh actually another question about Amaze so uh so y'all use it to do host depletion for I guess swabs so removing human DNA to just leave you with microbial DNA but I'm curious but this approach also worked for other post-depletion problems like for instance I know someone I worked with was just recently talking about trying to do host depletion for Mouse xenographs where you have human tissue on mice say you only want to look at the human tissue sequencing when you take a sample you have to remove the host Mouse DNA could you do something like that or where those sequences be maybe a little bit too similar since they're both from mammals or yeah so I guess we were focusing on um like uh uh vertebrates that are typically host versus yeah so we included uh I think we only trade I think we trained on Mouse and pig and human reference genomes as well as uh mouse or human nanopore sequences as our host fraction so I think it would classify Mouse and host um the same way but I think that our um training setup and our architecture could work well if you wanted to distinguish human and mouse you would just have to train it to do that cool thank you um are there more questions to the speakers so this is also for Mira um you mentioned training on sequences of different links I was wondering um if your sample only had charts you would see data available is there an effect on the performance metrics at all um oh so so we train on Long raid sequences but you're saying if we train on yes if they were if your sample only had short reads sequencing available um so I think for um if it was single end short read sequencing um it wouldn't be affected for paired end since we only deal with single and I guess you would have to pick one or uh concatenate I think we found that performance tended to increase as the sequence length increased but we were still able to do well on sequences of all legs and I think that was present in our data thank you so much um are there any more questions for the speakers given that there are no questions to the speakers please give them a big hand for doing this thank you so much