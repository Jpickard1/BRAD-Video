butI so today she will tell us about a comprehensive approach to detecting and correcting spurious transcript on inference due to the our army sick with misalignment thank you and saying thank you for the wonderful introduction actually I often find myself like have too much things to do and then never find time to forget things done so it does help me to build up my confidence when you say that I accomplished a lot thank you so much but it is true that I have been trying my best and I always thought that maybe it just took me longer to finish certain things than other people so I always find myself beating in there and commit myself to something but then it's always take longer to to finish so because I came from the background of doing data mining man Yi Rigaud and continue to do that nowadays like everybody move to big data and we find of the attacker it's a quite fascinating area to work in and I can really use my past experience in doing data mining and to help in this field in my group who we have a quite a wide spectrum of a project actually a it's open led by a graduate student and each one of them take a different direction so whenever with a bag of interesting project today I'm going to share with you one of this during you know those words today I have met quite a few people and in a very interesting conversation and learned and also mentioned a few times that I do have other project very different from this one but if you're interested I can share with you later for gene Caesar so how we start who came that so a few years back and when I was at human C we were part of an NIH Center at that time the center was doing the the origins seemed is to using laboratory mice to study depression so in that project we have really many many samples of different mastering and then we want to in this case we want to do a differential gene expression analysis well it's a relatively small project within that overall scope so at the beginning we said well which is to microwave and then then later we realized maybe RNC it's a better way to do it so we would run RNC ASIC and now that time is was our first time to actually look at our N Sync data it's a lot more it's a much richer than my career data but then we actually learned many lessons odd way I will say so and that's how this product came along at the beginning we said well maybe we just downloaded a recommended analytics pipeline and by Illumina and then we can just get the result and then because I got time when we gather data it's it's about a month's to the time we need to give a demo tool I'll give a talk to an IH program officer so we're under the pressure and then we just try to get some reasonable without fast but then we were really surprised sooner you know next way and we have to come up with some solution so for our any second Alice accessor this is the standard preference some of you may already know this you know in your heart so you start with read write read basically just you know short segment fragment right come from somewhere from the a transcriptome and then because you don't know where they came from when you just gotta read for maybe the sequencing center and then a typical wave that connects to alignment right either to the reference genome or to the reference transcriptome so once in this case in this joint here let's assume we do to do the alignment to the reference genome and then now you so hopefully you know most of your read high percentage of your rate can be aligned like this so and then the next step is to another you know algorithm to do the assembly so and to basically tell you that which transcript is Express and by how much okay that's a typical pipeline and if this thing is done right and then we hope that you know it can give us quite accurate estimate of gene expression level and also it will help us to detect a novel transcript that people didn't know about this is less noisy you know then the microarray data is you know high risk high res much higher resolution and but twice we all know our ASIC data is much larger than a typical microarray did right it's obviously come with a new challenge that we have to face and I'd quite so I sustain your pipeline recommended by a lumen at that time top height is one of the you know commonly used alignment algorithm and the coupling is one of the commonly used the assembly algorithm to in-floor the transcript transcript the level so basically you know the the output of top head would be the input of the coupling right and then so this is exactly what we did at the beginning once we get the data and then we'll run this with all of them you throw them in random okay we saw that okay great and then because our goal at that time was to do the finish with the expression analysis right everyone did for every sample would you'll say well which gene transfer is highly differentially expressed so but there was not as easy as we thought because all of our top-ranked transcript differentially expressed the jeans if you have our pseudogenes are annotated Sidonians I mean we have to go down to the list very deep in order to hit a like a routine somewhere so and in that case one of our goal actually in a project was to study her and authority okay and then we need fun something but the fact they stick is actually update to what other people report in their paper so you know it's quite controversial that piece of without we can't just to show that to a program officer and and then we saw the buddhic explanation what happened right and so I have to really dig into the data I bet time believe me we were I'm a very high-pressure like to find out what if any of something must have gone wrong and then but at that time I thought first time to to do the artistic analysis a week we didn't have much experience so so we were you know quite worried and there's a little bit of statistic would we find in our sample and then about we notice about five to ten percent of the fragment have not four linemen by multiple element I mean that a lead can be aligned to multiple location of the genome by puppet okay and then of course you can see that so to give you some ambiguity right because it can only came it can only come from one location right and but you will have had to report more location you need to know I mean you want to know which one is the correct one right so but this number varies right because I depend on what the parameter you said well how many mismatch you allowed in alignment things like that we also notice that about five percent of the reporting the gene by coupling corresponding to known non-functional pseudo gene okay because these are they already people annotated those pseudo Jane saying they're not functional so but a lot of them are but those I talked to my collaborator and those are very very suspicious because we have a lot of a lot of judo team pop out in the list but those after those are the a small percentage of those that we my collaborator are very sure they're they're wrong so but then another 15% are I know so we don't know what they are and we search through all this public database and nobody said anything about those okay and of course yes there may be some novel things that people didn't know about pepper but you don't expect that 15% this is quite high for that percentage so basically we said well we'd better make sure that we did analysis right before we claim that we discover anything new or our contradicting with what other people say so we look at the examples this is one of the cuff links transcript we just plot this this black curve is the the power-up height of the read align to this location I mean this actually this I didn't show the intron park so this purple vertical line representing the eggs add some Junction I just you know left out I just left how the intron part okay so for this gene there are seven x exhaust okay this is a gene it's called three don't ask me what function of this gene I don't know the function of this but this is one of the genes I know they didn't assemble and then you can see that this is the number plate right aligned to the location you can see this it's a quite a lot of reader line to this location to this gene and then but this memo is really go up and down or go up and down right quite a lot and this this red bars here represent the brown bars here mismatches so which means that if you see this just means that this location if you look at the read all the way the line here and you see whether they're the basis they have the base agree with the the reference genome are not way if they do not agree and but all this read are consistent with each other but just disagree with the reference genome and then maybe this reader takes this alternative allele there right and then we just use this bar to indicate that so you can see that if it's a random sequencing error you shouldn't really expect to see this high bar right perhaps pretty low you wouldn't see it right down to the bottom here so once you see this high bar you know that you know they can't be viral and created you to signal zero so I would like to see what let's focus on this little region where you can see this oh there's a very low red curve here anger does represent a settle for about over two thousand fragment that can also be aligned to somewhere else this is not very unique alignment okay so that's kind of our eyes so well what happened right and then let's do mean why focus on this and see what happened so I truncated the this is the what in that green box okay I just zoom in and then this is you can see clearly this red curve and this is another location on chromosome six of the mouse genome and then you see that quite similar right curve there it had to be this 2600 fragment can also be aligned to this region as well okay and then again this black curve represent the power of hive of the weed can be aligned to this region you can see that in addition to this this group of a small group or a fragment there's a lot more read that that are aligned to this region uniquely right they have no other alignment but this region is a an annotated region we don't know we couldn't find any anybody said anything about this region but what we if you look at it I serve this hi to my discovery it's a my size over two thousand here so it's it's not a small number that you would say well this is just random error or something like you want to ignore it but tip no.1 hang it over this because these are too many too many fragment here but but what he can't compare in comparison with this you can see that whatever the valley here right first man into the peak here right there's reasonable hypothesis and that could it be possible that all of those rate actor came from there originally from there but for one reason or the other I'll I'm here right and then I actually verified that's the case in this particular example and in this case actually it is the actual axon Junction has a problem because in this region there's no axon Junction and if you if you run cuphead before right so the the way they identify recognized egg-bound junction is there's some heuristic they basically chopping the waiting to maybe four different pieces and that hopefully some of these four different pieces can identify you know have a good match and then they sort of try to narrow down where the country is in this process and then they could well miss that if they means that when they couldn't get the right alignment another reason is that most of these alignment algorithm right if they also made for the best alignment based on the score number of mismatches in India and the if there's a second best with just a slightly worse score they don't recall that so which means it could be like the linemen here it's just slightly better than alignment there but then only these alignment is in your result you never know it could be aligned to there so we think of that could be a problem there's other reasons too for example if they have an unknown sniper India right but you know mate which make other way to come from here and actually it's maybe more cool you know similar to the to the region here because we okay we should always keep in mind the reference genome we use it's not the genome of the sample in the experiment there will be always difference and they're not sequencing error right some other difference you know about some of them you don't right so so we are those difference and non difference would make hassles problem too but there are no and then if they fail to map that's and it's not hard to rescue that so in this you've done how I believe this you know none of this read should be here but based on this many read the line here no matter whatever Zam you use to call this transcript it will report this as a transcript because it's just way too many to you know say that's that's not true so so we we when we do this analysis and investigation exploratory medication we did compare between biological radical technical repair to figure out what went wrong and then we find that there this pattern is highly consistent between all those replicas and but if you have a different mouse strain right and then you observe similar things but maybe that pattern show up for different region or different pseudo gene and then but they were always there and this will cause a huge problem when we do differential expression analysis right because when we you know hopefully diff using different mouse trained you see how they response for example differently to environmental fact or to drug and then and because of this artifact of the alignment right we can mistakenly think that some searching or students differentially expressed but actually they're not it's just a alignment computer you know the wrong impression so and because there they're highly consistent between this but across the comparison group there could be different so and when people study okay try different alignment algorithms for different you first algorithm when they said okay they give similar result maybe these are real but after these are not real we also try the different alignment ever some different inference algorithm and it's pretty consistent about to be which means they all make mistake at same place so now we basically focus our study on a multiple alignment why because we think that's give us some indication where the problem might be okay even though at the beginning you know the standard recommendation from from the nominal is that once you see once you align your you read and then you threw out all this read with multiple linemen because we don't know we're not sure where they came from therefore they're not reliable we don't want them to mess up with the inference and then you only use this once with unique alignment master sort of standard recommendation that at least I heard at a time that's what also what we did in the beginning but we realize that maybe it's too soon to throw those out maybe those amount of alignment give us information like help us to crack this because not by said I had a multiple I mean you know those regions are similar right the men have this problem and then we can use that in Premiere to help us to practice identifying the crisis so let's look at what are the main reason for having multiple alignment so first is what we found is a is a process and pseudogene so for process you told it they don't have intro okay so you think about alignment especially if we will read a cross not to exon right and then if oh there's another location without being into our way of course it's easier to align right it's not surprising that they will have a better alignment score sometime and so that's one of the reason sometimes is a non process as you do then it does have some intra but maybe you know they like Nikolay because they have similar sequence to dia to the parent chain so it's uh as a result some of the reduced ill have them out of alignment and another third readers I simply like you know we just have repetitive sequence there and then that's you know would cause some of the reader can be aligned to multiple places so so that's the sort of an alignment our random hand all of this and the reality actually is that we cannot really control what happened right so because although alignment works like okay you have us a suite you have a you give a reference genome and then you specify how many needs matching now you want Allah and then the alignment algorithm Bezier try to find the best match right and output that if there's more than one match with equally good score all of this can be output okay um that's a face with that which means that I depend on the you know what the sick actual sequence and what the scenario and then the word the read line to learn to the genome so it's a it could be one of this scenario the first one is that well if we are lucky then we can properly at any fighters the splicing Junction and then maybe we we can get it right and then and then the smackle scenario would be that we some of the read can only be aligned to the process decision because it helped us re better school there and then the third scenario would be aligned to both location with equal score so most location output it and then that's exactly what we observed in the previous example you can see a small percentage about ten percent of a little fragment have can be aligned tables and then the other ninety percent are unique okay so so this make us believe that we really shouldn't have described all the way to be smarter alignment we should take advantage of them yes that so now our town becomes like can we you the model to predict right which the the transcript output backups in case actually cost wanting to express June which one corresponding actually not Express Jean so we want to build a binary classification model to help us to predict that we try to avoid to use a term like predicted universes you don't even because you didn't have its own meaning and the some of you live in are actually expressed so we don't want to go into that error like try to argue which way it's doing a pseudogene we basically just try to predict which one is first which one is not expressed so and in order to avoid confusion we don't call like an output from a cufflink a gene or a transcript we just call them fragment attractor basically the other region that has a lot of lead align to okay so so what we do is that we first to run the standard pipeline okay and keep all the multiple alignment I and you then then coupling he gave us a list of those transcript they report it right and then we take each of them how each of them a fragment attractor the reason why we want to focus on those right is a it will help us to remove some of the noise or in random alignment and be I please you know they are the ones that we need to be careful because the coupling already reported want to make sure we choice is false right which one is not right if we're covering doesn't report it then that's a secondary consideration okay so from the cufflinks without and then we have a collection of fragment attractor the first thing to do is to to build a graph to represent the sharing of those alignment okay so what we do is that way we have an O to represent each program in the chapter and then we have an edge connecting them if there's a lot of alignment right if they're some rate can be aligned to this location in that location then we have an edge and where the weight of the edge will be the number of reads that can be aligned to those and then just for our video in fact so we we just basically color Colton but the actual model doesn't look at the color at all right so and we don't use this in this information in the prediction model this is just for our human inspection so if we go back to this example right this act returned to be an easy case because this graph and I have to know we know that this one is alone you know passable gene and then this one is unknown region and then this is on how many wait under so this is a create a single case and some time we see it look slightly more complicated and those are the you know gene and those are the annotated a solution right there are some Cheryl indeed in them and some time is like this this about 6000 fragment I'll have some kind of sharing relation between them and it's represent about 20 percent of the output from the coupling you can see that something the sometime the problem can be quite messy so so now what do we do after we create to the sharing so this is like a cartoon representation let's see if we only have three of those and then they have some kind of edge connect them and this is a typical scenario like fragment attract a attract a is a they have a you know similar sequence right to this part and this release means like oh there's a different exons okay and then their son rate can be aligned to both places right and then their son read can only be aligned to one of these two places and that's true you know you may have like a three-way you know sharing right and then there's this blue part means that I know this is unique to see not shared by others and this is unique to be not to share that okay let's see how we deal with this scenario so what we do is that we because if we look at the real data we don't know the Guangzhou's it is very hard for us to build accurate prediction model we start with a simulating the data okay because it's hard to me in this case if we think the problem is so it's like you know misalignment right and then we can simulate lots of lead and see where they align to right and then analyse that information how it has to build prediction model so so if they have a shared alignment that means they're similar sequence and aligned sequence and then we we want to look at and what do we call consistent mismatch that's corresponding to this kind of a vertical bar psych center is like this set of read takes around alternative allele okay and then there's a number of those consistent mismatch they're an unlikely took to because by sitting in a row it turned to be that if it's not functional pseudo trained tend to accumulate you know higher weight of those kind of mutations so we should see more of those picks than a functionally and then the number of exons and here are some other other features that we use that everyone we have 14 features and but those are the interestings like you know once and then we build a classification model using simulated data we can simulate slots update and and then to do the prediction because we know the ground truth we know which one is correct so in order to creates the training instance we always look at a pair of linked fragment attractor you know they have shared alignment okay so we first treat one of them as target when we try to predict whether this one is Express or not right using the information of the features of this one together with a linked fragment attractor this one just got assistant one okay we use both features to predict this one and then let's create one training instance and then we basically want to see whether this one is and Express or not based on all the information and then we can just swap the row between them and the prick to whether this one is an Express or not so for each pair each thing edge we have two training instance and then typically we would have likely if I have a friend when a will have you know several of them connect to that so actually what we did was so this is simplest way of doing this may not be the best way but it works so this is a target we try to predict and then we have like because there are four edges we create one at a time okay and then we have a four prediction for separate prediction and let's see three of them said probably expressed and one of them said is not expressed and then our metal classifier said the wafer any one of them suggest is not expressed we think this a is not expressed the reason here is that if this a is not expressed means all the read align to this came from somewhere else and science you have a twenty five one of this other location that may be the origin of those read you're fine right it may not come from all of this it only come from one so that's why it's asked one of the suggesting this one is not real right then then we'll find so after the prediction the next step what we do is that a lot of rescues of the least alignment we want to basically literally go into the vampire to take this guy off alignment to move it to the right location i'ma fix the band fell in that way okay and after we fix the been found now we come up with a new vampire and then we this is the whole pipeline we basically run cufflink again to see what's the difference before and after this collection and this is the standard pipeline this is what we add so basically we quit share the graph and then extract features doing the prediction and then when the assembler again okay and compare the before and after so to saw some of them without how this tablet works so we have this fits in our study that when samples from a three-mile strain is a six-week cross and it's one of our goal is to study parent of or attack so each one don't from each sex have a three to six replicas for each class and we a sprint issue is about in this study of about 10 million fragment is a hundred base pair pair and week for sample and to minimize the bias of different mouse strains because they have different distance genetic distance to the mouse reference range so we actually created what we call synthetic genome for each of these strengths by add it's the reference reference is very close to the string black six and to basically go to the non snip database or India database to edit the reference genome by inserting those snips and emails to make that as closer to the to the parent as possible so to minimize the the bias so so the fact that exam how I show you even after that so you have that same so because this is a real data so we don't know the gwon truth but what I can show is that this is the before and after to the blue data before and the red dot is after so this shows the the number of reported transfer spec and transported by castling I decrease okay so and each each of this is one sample we just group them by the cross and by the Mayo and fill their sex okay which is good news to some extent but we don't know this is suggesting good or bad right so it just say oh we have a less number of transcript to worry about now we say well let's compare with the reported transcript to to the ensembl database because in the study we didn't use any of the annotation from one sample and then let's see well highlight the corresponding to the known database it tried to be despite that the number of transcript dropped actually if we can't how many transcript exactly match the transcript in assemble the number actually increased so this give us some indication well maybe whatever we did they explain official races because we didn't use on some more information during the whole pipeline it was not part of the information we incorporate but you know if that's true for every sample we have is that must mean something it's like but then the the director of crack and we we make actually it does help us to rescue some of the transcript and then this is the number of pseudogenes reported okay and then you can see that dropped to third of the Moga they still one-third remaining because when we did that fraction was very conservative you will not handle potential or 99.99% sure we're not to do going to do any correction and then this is the number of transcript that are unknown right in the result it's also drop about by about 20 percent okay so for this set of results we think about maybe this is quite good so and then so it's a it's a it's quite very interesting and my collaborator really like and after this one actually you know we run the differential expression again and none of the top ones are no longer no longer till audience so other interesting real change that suggesting so so we also just to test our you know accuracy this is a simulated data so we can we can know the brown shoes so we also test a different alignment algorithm here that show two different alignments might have had the way I used before and one smile splice is another one meanie you know focus on identify they're really good and identify exon Junction okay so Toronto know whether that's the one that would make a difference or not and this is a after what we call between see their pipeline and then before and after you can see that the to recall is pretty high and then but the the the precision is not as high if you if you look at that this is because mainly because of a cufflinks if you have experience with cufflinks they tend to report or report transcript or genes record genes so we if you try to establish correspondence with the genes report by cufflinks with genes in a not even assemble and then ever some of them corresponding to the same gene you can find that so today and in that case when we we calculate the the precision we always so like you know if let's see three of the genes reported in correspond to one here and then we come one of them is correct the other two more spirits because that's not the ideal is a without we one it's maybe too harsh in some exam but we just thought because we always report many many more dense than actual number so we didn't like that part so it's a letter you know that's just a candle thing or not not right okay so they'll see you learn from this study so of coordinating recent pipelines not perfect and it's useful to understand how it works and then as I said the beginning we learn this in hard way because it's always like we try to save time and just take whatever are there and then try them and anymore we have to go into and figure out what the problem is and then throughout that process we really learn a lot and then also another thing is that misalignment of the read can create actually bigger impacts and people already know that because people say well that's maybe just due to you know random errors and which means all those you know misalignment should be uniformly distributed across the genome and that would mean easy to overcome but the reality is that actually they're very clustered and the time we only give you spirits or reading of the transcript and then the last lesson we learned that we cannot really afford to throw away the multiple linemen because they are the only hope we can use to crack this kind of mistake so if you want to try this you can you can download it's open source and that's the paper which we publish in last year's snd so what things turn what we're working on now because throughout this process it will also talk to the team who develop top hat right because right after we publish that if they also released half a tool which aligned to the transcript and then and then they said that well maybe you know because the transcriptome is becoming more and more complete even though still incomplete but that we should take advantage of that more and more so that make us to think well maybe we should really use that in a in a more I'm in a more profound way so so in the I mean in the previous star that we have that we spend really a lot of effort because for each sample we have you pick many hours to just do the alignment and I will take another couple of hours to the you know the table had taken many hours and the coupling take maybe two hours and it will ask many many hours just to maybe change a one-parameter or figure out what went wrong itself so there's some many hours on computer cluster you know to be actually invested at or for that study we saw that it would be nice if we can make it faster so so this is our current thing so it's going to be presenting this year's SMB so what we develop for this really would say well maybe if we can take advantage of the and the current known transfer transcriptome and then without doing the alignment so maybe we can get it done faster so our approach what we did is that we studied transcriptome and extractor is extracting from Team a small number of informative gamers and you start and once you have the count of those gamers in your raid without doing alignment just count how many those occurrence and you can use that to build using the other big you know what not as big as cufflink it's a lie see the small graph actually and then do the influence and then it has to be you can get s equity result as coupling is to not more accurate actually in our study is slightly more accurate if we will you use simulated data for the real data we don't know which one is more accurate about no story that have very very high correlation so so if you believe one you will believe the other there is essentially give you PI same result but if you look at a time span yes again when we did this with you actually on having implementations that work on one thread but all this alternative algorithm they have they can run on multiple spread right so so for the rest we all run a thread all together and then for the wicked RN scheme around you and one and these are cup hats was coupling prototypes so you can see all these things and but if you compare to this the CPU time per sample this is about slightly less than about 10 minutes right personal and compared to all of this you can see it's a lot this these are like hours this is just 10 minutes and then you can see how many times we can we can speed up this is a 44 million you know hundred days there so so that's a that's how we're using and then right now we're we're we're working on the you know final manuscripts and also prepare for the release of the software it's going to be released in the summer we're also at the same time saying that well because this is only using the gnome transcript all right yes which means we do not have done be fine now or transcript if we want to identify normal transcript actually we can start from this use this as a writer anchor and to see what's not there but also you read that's a way but we're working on that don't have a readout yet that'd be very interesting we can talk more so this is this new new radar we have thank you well one of the reason we wanted to make it faster is that it really very hard to try different parameters when each one takes many hours we spend so many because one thing well maybe the number of mismatches we said the parameter right allowing this mattress is not appropriate right and then we try different parameter than you know a few days passed and that it's a it's very tedious so but that's actually one of the motivation we want to use this and then we can just use said that to search for the best parameter setting we has a kind of a great computing based Network because to really search through the Department of space you can do that because each one is like no more than 10 minutes sometimes faster so you know you feel can budget like a day or two right then you can't really search swell you know please another parameter space to get you the best more questions sorry cut merge and captive to see if you can really read abundances if any of the spurious transcripts can be removed via their own method we tried I cannot because if the lineman is in the band foul is wrong the lineman right in and then you can you can use IG beat we just meteorites that to see where this oh yeah so it's a big part of that right so of course when you run those cuffs compare cuff deep right it will tell you there they're different right and so the we think that the only way to fix it it's actually to go back right before you know you're on cuff link and then or in that case we went twice right why is for help at identify where are the PI of read aligned to write in a second I was there well then we try to fix those alignment and then rank again so that's literally what we I thought that's one of the procedures of captive is when they converse the GTF back to the same file and then we estimates the per transcript read so but I don't think they changed the band file no they go from the GTF back to the BAM POW to convert to we estimate the reads per transcript yeah but you have to change the bang file your order to get it right right this time because if you don't our doesn't change when you still gather you know whatever you got because you know the type I of greatest ill there you cannot ignore if that's real enough the true environment when you cannot you cannot ignore you know that's the tomb anyway today but if you know if you believe that's all of them actually all of them read originated from another location right a Medina you should really just edit your band foreigner and the chain to that so that's that's what with India and more person so very impressive work so I think these problems are somewhat recognized to many people but you know it's really good to see the seven soft software that actually does the more systematic way to correct order is possible misalignment problem you know because a because a standard pipeline actually these are most of the large-scale groups are they making their own way to fix these problems so it's not complete to how those probably add a more adult method but there with some some correction compared to for example chair bodies group has a thousand genomes the RNA sequencing data and with their own way and they made their own way to the quantification so compared to those like state state-of-the-art way to do this quantification so that's that's more complicated way than just using the center pipeline that there was a recommended by Illumina so do you do you have a sense that how much your outcome will be better than those kind of outcomes I think it's really depends right because we don't have we didn't have time to really compare our possible ways and then the reason we will track your reason for us to suggest this way is that for other than those you know a handful of groups that who are who can afford to have their own and honest happen many many people using the standard one yeah and then they probably already did their top hat plus cuff link analysis right and having this is really easy for them to use you agree that this is very useful I just was wondering well how much this I mean if you you might be able to show that this is actually better than that your body's quantification for example so if that that's that's something I think it'll be good to try and assess oh yeah that'll be good to try but we stopped trying I'm saying that if they really you know intentionally try to identify this wrong alignment and a crack for that and I think it's maybe they can you know they can do similarly not without but if they just account for some random error right then that's the we're dealing with different type of waiver because these are not caused by sequencing error they sir to some extent and not even completely caused by the difference between your sample versus reference genome is really you know inherent to develop you know repetitive means in in the in the genome so that you know you once you get this wrong and if you don't crack that because they are not random they're very clustered problem so can ask questions oh and you showed the example in the mouse data we're actually in the caste Gnaeus strained and those spread spread two strains are quite different from the reference strain so I would guess that in this case mapping is much harder and it's going to be very telling you so your software will be very very helpful in the case of a human are in a sequencing alignment do you have a sense how much improvement you'd expect we hadn't tried on human so I don't really know but I hope that trade will give you some you know the improvement but we haven't never tried thanks yes great luck so in the beginning you mentioned some statistics like 15% reports are annotated or some ago pseudogenes somehow may be long or maybe two copies were absolutely and neither one made expressed so those actually are bigger numbers and maybe some like a hidden scientific things findings can be fun of long Xia so I'm wondering from what are you two are maybe your Futurity rubbishing can you use approach or improve it somehow to identify more things along the Army's siga data and for example maybe toast some 15% annotations or maybe something nerdy you can find some new teams which one are predicted to be G what was awesome seeing some genes which were reported to be genes but never been found any study well we hope that ties it's going to be a long process because it will take a lot of effort to really validate that right we can always make hypothesis but is the validation part I actually rely on my collaborator to help me do it right so one of the recent project arted is to really look at the pike pike bio sequencing that's have much longer read but higher error rate we we are currently developing neighbors and actually you weekend we want to combine be able to combine it just to type of lead but we don't have a my students to implement it so we don't know any result don't have any result yet yeah right yeah how much difference in terms of the line and so we can see the percentage of reader that are being able to align increase I think seven percent on average you know you see some of the difference you know I forgot the number four how many transfers are different to people you know with different up there are some difference yeah it's not things that we can even easily annoy we try to that that's why we use the synthetic genome because it does create a difference okay so let's thank we again [Applause]