[
    {
        "text": "think that's actually the only",
        "start": 0.539,
        "duration": 4.321
    },
    {
        "text": "announcement I have today so with that",
        "start": 2.28,
        "duration": 4.019
    },
    {
        "text": "I'm pleased to present today's speaker",
        "start": 4.86,
        "duration": 3.36
    },
    {
        "text": "we have again Lee who is an associate",
        "start": 6.299,
        "duration": 4.621
    },
    {
        "text": "professor and biostatistics welcome to",
        "start": 8.22,
        "duration": 4.26
    },
    {
        "text": "mine we're just getting started all",
        "start": 10.92,
        "duration": 3.24
    },
    {
        "text": "right again uh feel free to start when",
        "start": 12.48,
        "duration": 4.139
    },
    {
        "text": "you're ready okay thank you",
        "start": 14.16,
        "duration": 4.44
    },
    {
        "text": "thank you everyone for coming and thanks",
        "start": 16.619,
        "duration": 4.641
    },
    {
        "text": "for having me",
        "start": 18.6,
        "duration": 2.66
    },
    {
        "text": "present online",
        "start": 21.3,
        "duration": 2.639
    },
    {
        "text": "[Music]",
        "start": 22.19,
        "duration": 3.37
    },
    {
        "text": "she'll probably have to leave a few",
        "start": 23.939,
        "duration": 4.021
    },
    {
        "text": "minutes early but if you have any",
        "start": 25.56,
        "duration": 4.2
    },
    {
        "text": "questions feel free to shoot me an email",
        "start": 27.96,
        "duration": 4.56
    },
    {
        "text": "or if I cannot answer the question",
        "start": 29.76,
        "duration": 5.76
    },
    {
        "text": "during the talk so uh without further",
        "start": 32.52,
        "duration": 5.52
    },
    {
        "text": "Ado I'm gonna introduce some new methods",
        "start": 35.52,
        "duration": 4.74
    },
    {
        "text": "that we developed recently for",
        "start": 38.04,
        "duration": 4.38
    },
    {
        "text": "microbiome data analysis not only based",
        "start": 40.26,
        "duration": 6.18
    },
    {
        "text": "on this uh idea of amalgamation to deal",
        "start": 42.42,
        "duration": 5.94
    },
    {
        "text": "with this microbiome compositional data",
        "start": 46.44,
        "duration": 5.52
    },
    {
        "text": "and this work is a joint work with my",
        "start": 48.36,
        "duration": 6.24
    },
    {
        "text": "postdoc Dr Yen Lee and my collaborator",
        "start": 51.96,
        "duration": 6.079
    },
    {
        "text": "Clinton at the University of Connecticut",
        "start": 54.6,
        "duration": 7.26
    },
    {
        "text": "so microbiome is an important component",
        "start": 58.039,
        "duration": 6.881
    },
    {
        "text": "of our human body and it consists of",
        "start": 61.86,
        "duration": 7.32
    },
    {
        "text": "archaea bacteria viruses fungi Etc and",
        "start": 64.92,
        "duration": 6.3
    },
    {
        "text": "Studies have actually conjectured that",
        "start": 69.18,
        "duration": 5.1
    },
    {
        "text": "the number of microbial cells or genes",
        "start": 71.22,
        "duration": 5.939
    },
    {
        "text": "would even outnumber the human cells and",
        "start": 74.28,
        "duration": 5.28
    },
    {
        "text": "genes so to some extent we are more of",
        "start": 77.159,
        "duration": 5.221
    },
    {
        "text": "the microbiome Al and in US rather than",
        "start": 79.56,
        "duration": 5.22
    },
    {
        "text": "ourselves and the microbiome is not",
        "start": 82.38,
        "duration": 5.94
    },
    {
        "text": "static it's very Dynamic and it changed",
        "start": 84.78,
        "duration": 5.76
    },
    {
        "text": "with time with different health",
        "start": 88.32,
        "duration": 6.299
    },
    {
        "text": "conditions and as a result it's a good",
        "start": 90.54,
        "duration": 7.38
    },
    {
        "text": "indicator of many health problems for",
        "start": 94.619,
        "duration": 5.521
    },
    {
        "text": "the human body so there has been a lot",
        "start": 97.92,
        "duration": 4.26
    },
    {
        "text": "of study trying to associate the",
        "start": 100.14,
        "duration": 5.04
    },
    {
        "text": "microbiome profile with various health",
        "start": 102.18,
        "duration": 7.439
    },
    {
        "text": "conditions in human and in fact there",
        "start": 105.18,
        "duration": 6.24
    },
    {
        "text": "has been a lot of successful stories",
        "start": 109.619,
        "duration": 5.581
    },
    {
        "text": "there and more recently there has been a",
        "start": 111.42,
        "duration": 5.4
    },
    {
        "text": "lot of studies about how to use",
        "start": 115.2,
        "duration": 4.919
    },
    {
        "text": "microbiome as a treatment Target for",
        "start": 116.82,
        "duration": 5.52
    },
    {
        "text": "various diseases so it's really a very",
        "start": 120.119,
        "duration": 3.741
    },
    {
        "text": "burdening field with a lot of",
        "start": 122.34,
        "duration": 5.699
    },
    {
        "text": "opportunities as well as challenges",
        "start": 123.86,
        "duration": 7.0
    },
    {
        "text": "so I'm a statistician so I'm mostly",
        "start": 128.039,
        "duration": 6.241
    },
    {
        "text": "focused on in analyzing the microbiome",
        "start": 130.86,
        "duration": 5.4
    },
    {
        "text": "data say what the microbiome kind of",
        "start": 134.28,
        "duration": 4.679
    },
    {
        "text": "really tells us so to start with I want",
        "start": 136.26,
        "duration": 5.76
    },
    {
        "text": "to give you a very brief overview of how",
        "start": 138.959,
        "duration": 5.521
    },
    {
        "text": "microbond data are typically acquired so",
        "start": 142.02,
        "duration": 5.52
    },
    {
        "text": "this is a figure stowed from a paper",
        "start": 144.48,
        "duration": 5.759
    },
    {
        "text": "published in 2013 so some information",
        "start": 147.54,
        "duration": 5.04
    },
    {
        "text": "might be a little bit outdated but you",
        "start": 150.239,
        "duration": 5.58
    },
    {
        "text": "get the idea so generally samples were",
        "start": 152.58,
        "duration": 6.299
    },
    {
        "text": "extracted from the human body if you are",
        "start": 155.819,
        "duration": 5.101
    },
    {
        "text": "interested in got microbond typically",
        "start": 158.879,
        "duration": 5.461
    },
    {
        "text": "people take samples from the from fecal",
        "start": 160.92,
        "duration": 5.94
    },
    {
        "text": "samples and if you are interested in low",
        "start": 164.34,
        "duration": 4.14
    },
    {
        "text": "microbiome for example you can take",
        "start": 166.86,
        "duration": 4.68
    },
    {
        "text": "samples from flung Etc once the samples",
        "start": 168.48,
        "duration": 6.06
    },
    {
        "text": "are extracted it's gone through this PCR",
        "start": 171.54,
        "duration": 5.82
    },
    {
        "text": "procedures again magnified and then",
        "start": 174.54,
        "duration": 6.96
    },
    {
        "text": "people use sequencing technology to",
        "start": 177.36,
        "duration": 7.32
    },
    {
        "text": "sequence the micro the microbes in these",
        "start": 181.5,
        "duration": 6.18
    },
    {
        "text": "samples there are two main Technologies",
        "start": 184.68,
        "duration": 5.76
    },
    {
        "text": "one one is the apple consequencing or",
        "start": 187.68,
        "duration": 5.639
    },
    {
        "text": "16s rra which is the most commonly used",
        "start": 190.44,
        "duration": 5.46
    },
    {
        "text": "one and pretty cheap and the other one",
        "start": 193.319,
        "duration": 4.081
    },
    {
        "text": "is the shotgun sequencing or",
        "start": 195.9,
        "duration": 4.08
    },
    {
        "text": "metagenomics which give you more",
        "start": 197.4,
        "duration": 4.919
    },
    {
        "text": "granularity but rather than speaking",
        "start": 199.98,
        "duration": 4.619
    },
    {
        "text": "more expensive and once you get the",
        "start": 202.319,
        "duration": 6.42
    },
    {
        "text": "sequences you can apply some existing",
        "start": 204.599,
        "duration": 7.261
    },
    {
        "text": "analytic pipelines in by by informatics",
        "start": 208.739,
        "duration": 6.061
    },
    {
        "text": "such as the mother pipeline which is I",
        "start": 211.86,
        "duration": 6.48
    },
    {
        "text": "believe developed in Michigan by the uh",
        "start": 214.8,
        "duration": 6.299
    },
    {
        "text": "by by a research group in Michigan and",
        "start": 218.34,
        "duration": 5.459
    },
    {
        "text": "also there are other pipelines that I",
        "start": 221.099,
        "duration": 5.581
    },
    {
        "text": "can use to pre-process the data so you",
        "start": 223.799,
        "duration": 4.281
    },
    {
        "text": "can get some",
        "start": 226.68,
        "duration": 4.559
    },
    {
        "text": "more well pre-processed data that can be",
        "start": 228.08,
        "duration": 6.219
    },
    {
        "text": "directly used for statistical analysis",
        "start": 231.239,
        "duration": 7.08
    },
    {
        "text": "and after this bioinformatics procedure",
        "start": 234.299,
        "duration": 6.421
    },
    {
        "text": "we got what we call the otu data table",
        "start": 238.319,
        "duration": 5.161
    },
    {
        "text": "so essentially you can consider that as",
        "start": 240.72,
        "duration": 5.46
    },
    {
        "text": "a data Matrix where",
        "start": 243.48,
        "duration": 6.259
    },
    {
        "text": "um rows are otus or in other words",
        "start": 246.18,
        "duration": 6.779
    },
    {
        "text": "microbes at different species uh",
        "start": 249.739,
        "duration": 5.441
    },
    {
        "text": "different taxonomic levels and the",
        "start": 252.959,
        "duration": 4.74
    },
    {
        "text": "columns are different samples",
        "start": 255.18,
        "duration": 4.2
    },
    {
        "text": "and typically we also have some",
        "start": 257.699,
        "duration": 3.6
    },
    {
        "text": "additional information such as the",
        "start": 259.38,
        "duration": 4.98
    },
    {
        "text": "taxonomy and the phylogeny of this",
        "start": 261.299,
        "duration": 4.221
    },
    {
        "text": "different",
        "start": 264.36,
        "duration": 4.98
    },
    {
        "text": "microbes and those can be used for",
        "start": 265.52,
        "duration": 6.88
    },
    {
        "text": "further analysis you can collect",
        "start": 269.34,
        "duration": 4.22
    },
    {
        "text": "additional",
        "start": 272.4,
        "duration": 3.78
    },
    {
        "text": "clinical variables trying to associate",
        "start": 273.56,
        "duration": 5.46
    },
    {
        "text": "it with the Oto table and do various",
        "start": 276.18,
        "duration": 5.94
    },
    {
        "text": "statistical analysis so as a",
        "start": 279.02,
        "duration": 6.28
    },
    {
        "text": "statistician we basically take data from",
        "start": 282.12,
        "duration": 6.72
    },
    {
        "text": "this otu table and conduct a further",
        "start": 285.3,
        "duration": 5.52
    },
    {
        "text": "analysis from there so that's also going",
        "start": 288.84,
        "duration": 4.82
    },
    {
        "text": "to be in the focus of uh today's talk",
        "start": 290.82,
        "duration": 6.9
    },
    {
        "text": "but I would like to acknowledge that",
        "start": 293.66,
        "duration": 5.56
    },
    {
        "text": "there are definitely a lot of uh",
        "start": 297.72,
        "duration": 3.479
    },
    {
        "text": "interesting and important statistical",
        "start": 299.22,
        "duration": 4.44
    },
    {
        "text": "questions in this pre-processing of the",
        "start": 301.199,
        "duration": 5.361
    },
    {
        "text": "microbiome data so that's something that",
        "start": 303.66,
        "duration": 6.979
    },
    {
        "text": "needs to be further looked into",
        "start": 306.56,
        "duration": 4.079
    },
    {
        "text": "so once the Oto table is available there",
        "start": 310.68,
        "duration": 5.22
    },
    {
        "text": "are various statistical analysis that",
        "start": 313.56,
        "duration": 5.699
    },
    {
        "text": "can be conducted on this data set to",
        "start": 315.9,
        "duration": 5.46
    },
    {
        "text": "name a few you can quantify the",
        "start": 319.259,
        "duration": 5.28
    },
    {
        "text": "diversity of different samples of a",
        "start": 321.36,
        "duration": 5.76
    },
    {
        "text": "diversity beta diversity Etc we can also",
        "start": 324.539,
        "duration": 5.1
    },
    {
        "text": "visualize the data try to say particular",
        "start": 327.12,
        "duration": 5.46
    },
    {
        "text": "patterns in your data set or you can",
        "start": 329.639,
        "duration": 5.601
    },
    {
        "text": "conduct a differential balance analysis",
        "start": 332.58,
        "duration": 4.8
    },
    {
        "text": "assuming that you have several different",
        "start": 335.24,
        "duration": 4.54
    },
    {
        "text": "conditions you want to really identify",
        "start": 337.38,
        "duration": 6.539
    },
    {
        "text": "which tax or which microbes really is",
        "start": 339.78,
        "duration": 6.6
    },
    {
        "text": "differentially abundant between its",
        "start": 343.919,
        "duration": 4.381
    },
    {
        "text": "different conditions for example house",
        "start": 346.38,
        "duration": 6.12
    },
    {
        "text": "healthy versus disease what is the",
        "start": 348.3,
        "duration": 6.119
    },
    {
        "text": "driving factor or what is associated",
        "start": 352.5,
        "duration": 4.08
    },
    {
        "text": "with that differentiate between the two",
        "start": 354.419,
        "duration": 4.201
    },
    {
        "text": "groups you can conduct this differential",
        "start": 356.58,
        "duration": 4.8
    },
    {
        "text": "abundance analysis or you may be",
        "start": 358.62,
        "duration": 4.74
    },
    {
        "text": "interested in performing network",
        "start": 361.38,
        "duration": 4.56
    },
    {
        "text": "analysis or regression analysis so there",
        "start": 363.36,
        "duration": 4.38
    },
    {
        "text": "are all kinds of analysis that can be",
        "start": 365.94,
        "duration": 4.319
    },
    {
        "text": "performed on the Oto data table",
        "start": 367.74,
        "duration": 5.1
    },
    {
        "text": "so you may Wonder then what's the big",
        "start": 370.259,
        "duration": 4.44
    },
    {
        "text": "fuss about microbiome data why don't we",
        "start": 372.84,
        "duration": 3.78
    },
    {
        "text": "just use the existing statistical method",
        "start": 374.699,
        "duration": 5.101
    },
    {
        "text": "to achieve this goals well they're not",
        "start": 376.62,
        "duration": 5.1
    },
    {
        "text": "so straightforward in the sense that",
        "start": 379.8,
        "duration": 4.38
    },
    {
        "text": "microbiome data has its own unique",
        "start": 381.72,
        "duration": 5.58
    },
    {
        "text": "features so that's why",
        "start": 384.18,
        "duration": 6.299
    },
    {
        "text": "um in many cases the existing method may",
        "start": 387.3,
        "duration": 6.239
    },
    {
        "text": "not be appropriate or sufficient to",
        "start": 390.479,
        "duration": 5.821
    },
    {
        "text": "analyze this type of data to be more",
        "start": 393.539,
        "duration": 5.66
    },
    {
        "text": "specific due to the technology",
        "start": 396.3,
        "duration": 6.48
    },
    {
        "text": "limitation microbiome data although we",
        "start": 399.199,
        "duration": 6.641
    },
    {
        "text": "want to get the absolute abundance of",
        "start": 402.78,
        "duration": 5.22
    },
    {
        "text": "different microbes but in reality",
        "start": 405.84,
        "duration": 5.82
    },
    {
        "text": "typically we cannot obtain that and what",
        "start": 408.0,
        "duration": 6.12
    },
    {
        "text": "we can obtain is really the propulsion",
        "start": 411.66,
        "duration": 5.28
    },
    {
        "text": "of different microbes in the sample or",
        "start": 414.12,
        "duration": 6.359
    },
    {
        "text": "in other words the data is compositional",
        "start": 416.94,
        "duration": 6.479
    },
    {
        "text": "and so on the right figure for each",
        "start": 420.479,
        "duration": 5.28
    },
    {
        "text": "sample you may get a composition of",
        "start": 423.419,
        "duration": 3.9
    },
    {
        "text": "different microbes",
        "start": 425.759,
        "duration": 5.841
    },
    {
        "text": "at a particular level and the the actual",
        "start": 427.319,
        "duration": 7.32
    },
    {
        "text": "value for different microbes is just the",
        "start": 431.6,
        "duration": 5.68
    },
    {
        "text": "propulsion of that microbe in the sample",
        "start": 434.639,
        "duration": 5.641
    },
    {
        "text": "so it's sum up to one then that we call",
        "start": 437.28,
        "duration": 4.979
    },
    {
        "text": "it the compositional data and this",
        "start": 440.28,
        "duration": 3.72
    },
    {
        "text": "compositional feature creates a lot of",
        "start": 442.259,
        "duration": 3.601
    },
    {
        "text": "challenges for statistical analysis",
        "start": 444.0,
        "duration": 4.08
    },
    {
        "text": "because most existing methods is only",
        "start": 445.86,
        "duration": 3.66
    },
    {
        "text": "developed for",
        "start": 448.08,
        "duration": 3.899
    },
    {
        "text": "um you know continuous regular data in",
        "start": 449.52,
        "duration": 3.959
    },
    {
        "text": "the including space but this",
        "start": 451.979,
        "duration": 3.301
    },
    {
        "text": "compositional data does not reside in",
        "start": 453.479,
        "duration": 4.741
    },
    {
        "text": "the euclidean space it's in a Simplex so",
        "start": 455.28,
        "duration": 6.96
    },
    {
        "text": "many methods or Notions do not directly",
        "start": 458.22,
        "duration": 6.36
    },
    {
        "text": "extend to this type of data so that's",
        "start": 462.24,
        "duration": 4.92
    },
    {
        "text": "one major challenge another challenge is",
        "start": 464.58,
        "duration": 5.399
    },
    {
        "text": "that the microbiome data typically they",
        "start": 467.16,
        "duration": 5.099
    },
    {
        "text": "have this additional information",
        "start": 469.979,
        "duration": 2.881
    },
    {
        "text": "um",
        "start": 472.259,
        "duration": 4.261
    },
    {
        "text": "that it can be leveraged in analysis for",
        "start": 472.86,
        "duration": 6.899
    },
    {
        "text": "example we do know the taxonomy of",
        "start": 476.52,
        "duration": 6.239
    },
    {
        "text": "different microbes and sometimes we also",
        "start": 479.759,
        "duration": 5.761
    },
    {
        "text": "know the phylogeny of different microbes",
        "start": 482.759,
        "duration": 5.461
    },
    {
        "text": "so those are all tree structure that",
        "start": 485.52,
        "duration": 4.38
    },
    {
        "text": "capture the relationship between",
        "start": 488.22,
        "duration": 4.14
    },
    {
        "text": "different microbes so how to take into",
        "start": 489.9,
        "duration": 4.62
    },
    {
        "text": "account that additional information in",
        "start": 492.36,
        "duration": 3.6
    },
    {
        "text": "your analysis",
        "start": 494.52,
        "duration": 3.48
    },
    {
        "text": "to make the results more interpretable",
        "start": 495.96,
        "duration": 5.519
    },
    {
        "text": "and more scientifically reasonable is a",
        "start": 498.0,
        "duration": 4.62
    },
    {
        "text": "challenge",
        "start": 501.479,
        "duration": 4.201
    },
    {
        "text": "and in addition the data is typically",
        "start": 502.62,
        "duration": 6.06
    },
    {
        "text": "zero inflated meaning there are a lot of",
        "start": 505.68,
        "duration": 5.4
    },
    {
        "text": "zeros in the data and it depends on",
        "start": 508.68,
        "duration": 4.52
    },
    {
        "text": "which level that you analyze your",
        "start": 511.08,
        "duration": 4.44
    },
    {
        "text": "microbiome's ad",
        "start": 513.2,
        "duration": 5.199
    },
    {
        "text": "um if you look at the spacious level you",
        "start": 515.52,
        "duration": 5.879
    },
    {
        "text": "may get excessive zeros in your data set",
        "start": 518.399,
        "duration": 5.58
    },
    {
        "text": "meaning a lot of species actually do not",
        "start": 521.399,
        "duration": 5.88
    },
    {
        "text": "exist or maybe just their bonus is just",
        "start": 523.979,
        "duration": 5.761
    },
    {
        "text": "too too low to be detected in a",
        "start": 527.279,
        "duration": 4.441
    },
    {
        "text": "particular sample resulting in a bunch",
        "start": 529.74,
        "duration": 4.8
    },
    {
        "text": "of zeros again those zeros also going to",
        "start": 531.72,
        "duration": 6.059
    },
    {
        "text": "create a lot of challenges for using",
        "start": 534.54,
        "duration": 5.34
    },
    {
        "text": "existing statistical methods",
        "start": 537.779,
        "duration": 3.901
    },
    {
        "text": "and on top of that we also have the",
        "start": 539.88,
        "duration": 4.62
    },
    {
        "text": "measurement errors these propulsions or",
        "start": 541.68,
        "duration": 5.339
    },
    {
        "text": "this relative bonuses they are not",
        "start": 544.5,
        "duration": 4.44
    },
    {
        "text": "measured very accurately so there are a",
        "start": 547.019,
        "duration": 4.681
    },
    {
        "text": "bunch of measurement error and also the",
        "start": 548.94,
        "duration": 4.92
    },
    {
        "text": "data is typically of high dimension so",
        "start": 551.7,
        "duration": 4.98
    },
    {
        "text": "these are all challenging features for",
        "start": 553.86,
        "duration": 6.479
    },
    {
        "text": "statistical analysis of microbiome data",
        "start": 556.68,
        "duration": 6.06
    },
    {
        "text": "to address this challenge the most",
        "start": 560.339,
        "duration": 4.62
    },
    {
        "text": "common approach is",
        "start": 562.74,
        "duration": 3.539
    },
    {
        "text": "first",
        "start": 564.959,
        "duration": 4.621
    },
    {
        "text": "transform the data try to leave the data",
        "start": 566.279,
        "duration": 5.521
    },
    {
        "text": "from the Simplex to the Ukrainian space",
        "start": 569.58,
        "duration": 5.22
    },
    {
        "text": "using some transformation and then apply",
        "start": 571.8,
        "duration": 5.64
    },
    {
        "text": "existing methods that's still the most",
        "start": 574.8,
        "duration": 5.219
    },
    {
        "text": "common approach in the literature for",
        "start": 577.44,
        "duration": 5.1
    },
    {
        "text": "microbiome analysis and the most",
        "start": 580.019,
        "duration": 4.561
    },
    {
        "text": "commonly used transformation is called",
        "start": 582.54,
        "duration": 5.52
    },
    {
        "text": "the log ratio Transformations for",
        "start": 584.58,
        "duration": 5.52
    },
    {
        "text": "example you can use the center log ratio",
        "start": 588.06,
        "duration": 4.38
    },
    {
        "text": "transformation once you log transform",
        "start": 590.1,
        "duration": 4.88
    },
    {
        "text": "this composition divided by the",
        "start": 592.44,
        "duration": 4.74
    },
    {
        "text": "geometric mean of this log",
        "start": 594.98,
        "duration": 7.539
    },
    {
        "text": "Transformations then the data is gonna",
        "start": 597.18,
        "duration": 7.92
    },
    {
        "text": "is going to take in the range from",
        "start": 602.519,
        "duration": 4.741
    },
    {
        "text": "negative Infinity to infinity and you do",
        "start": 605.1,
        "duration": 4.62
    },
    {
        "text": "not have this uh sum to one constraint",
        "start": 607.26,
        "duration": 3.32
    },
    {
        "text": "anymore",
        "start": 609.72,
        "duration": 3.48
    },
    {
        "text": "and the log transformation cannot",
        "start": 610.58,
        "duration": 4.36
    },
    {
        "text": "directly deal with zero so what people",
        "start": 613.2,
        "duration": 4.62
    },
    {
        "text": "do is to add some pseudo count to these",
        "start": 614.94,
        "duration": 6.36
    },
    {
        "text": "zero counts so to make it non-zero but",
        "start": 617.82,
        "duration": 5.84
    },
    {
        "text": "those pseudo counts as sort of arbitrary",
        "start": 621.3,
        "duration": 5.94
    },
    {
        "text": "and it definitely introduced bias and",
        "start": 623.66,
        "duration": 6.58
    },
    {
        "text": "noise in the subsequent analysis but",
        "start": 627.24,
        "duration": 5.34
    },
    {
        "text": "that's sort of the state of the art uh",
        "start": 630.24,
        "duration": 4.44
    },
    {
        "text": "methods for dealing with microbiome data",
        "start": 632.58,
        "duration": 4.62
    },
    {
        "text": "namely first adding serial counter deal",
        "start": 634.68,
        "duration": 5.64
    },
    {
        "text": "with zeros and then apply this uh log",
        "start": 637.2,
        "duration": 6.06
    },
    {
        "text": "ratio transformation and then apply",
        "start": 640.32,
        "duration": 5.639
    },
    {
        "text": "existing statistical methods",
        "start": 643.26,
        "duration": 6.0
    },
    {
        "text": "so we thought we thought that this",
        "start": 645.959,
        "duration": 5.221
    },
    {
        "text": "transformation based methods although",
        "start": 649.26,
        "duration": 4.38
    },
    {
        "text": "they are common but may not be most",
        "start": 651.18,
        "duration": 5.159
    },
    {
        "text": "appropriate for analyzing microbiome",
        "start": 653.64,
        "duration": 5.28
    },
    {
        "text": "data especially given the dominant",
        "start": 656.339,
        "duration": 4.5
    },
    {
        "text": "features of conversationality zero",
        "start": 658.92,
        "duration": 3.78
    },
    {
        "text": "inflation as well as this additional",
        "start": 660.839,
        "duration": 4.44
    },
    {
        "text": "tree structure that govern the relation",
        "start": 662.7,
        "duration": 5.16
    },
    {
        "text": "between different microbes maybe there",
        "start": 665.279,
        "duration": 6.381
    },
    {
        "text": "are some other uh there's a room for",
        "start": 667.86,
        "duration": 6.36
    },
    {
        "text": "method development that can be better",
        "start": 671.66,
        "duration": 4.9
    },
    {
        "text": "tailored towards the analysis of this",
        "start": 674.22,
        "duration": 4.32
    },
    {
        "text": "microbiome data so that's sort of the",
        "start": 676.56,
        "duration": 4.8
    },
    {
        "text": "motivation for our analysis or our",
        "start": 678.54,
        "duration": 4.38
    },
    {
        "text": "method development",
        "start": 681.36,
        "duration": 5.7
    },
    {
        "text": "so next I'm gonna focus on two aspects",
        "start": 682.92,
        "duration": 6.599
    },
    {
        "text": "um one is dimension reduction and one is",
        "start": 687.06,
        "duration": 6.06
    },
    {
        "text": "regression analysis so demonstrating how",
        "start": 689.519,
        "duration": 6.781
    },
    {
        "text": "we can further uh libraries in this",
        "start": 693.12,
        "duration": 5.219
    },
    {
        "text": "compositionality of the data to come up",
        "start": 696.3,
        "duration": 3.659
    },
    {
        "text": "with more appropriate statistical",
        "start": 698.339,
        "duration": 4.44
    },
    {
        "text": "methods for analysis",
        "start": 699.959,
        "duration": 5.781
    },
    {
        "text": "so if you have any question feel free to",
        "start": 702.779,
        "duration": 5.641
    },
    {
        "text": "interrupt and happy to take any",
        "start": 705.74,
        "duration": 5.339
    },
    {
        "text": "questions along the way",
        "start": 708.42,
        "duration": 6.24
    },
    {
        "text": "so to start with uh we",
        "start": 711.079,
        "duration": 5.861
    },
    {
        "text": "first look at this very fundamental",
        "start": 714.66,
        "duration": 4.799
    },
    {
        "text": "question of dementia reduction and come",
        "start": 716.94,
        "duration": 4.68
    },
    {
        "text": "up with a new amalgamation based",
        "start": 719.459,
        "duration": 3.961
    },
    {
        "text": "reduction method called principal",
        "start": 721.62,
        "duration": 5.52
    },
    {
        "text": "amalgamation analysis or PA for short",
        "start": 723.42,
        "duration": 5.78
    },
    {
        "text": "so the dimension reduction",
        "start": 727.14,
        "duration": 7.5
    },
    {
        "text": "is a very common commonly used tool as a",
        "start": 729.2,
        "duration": 7.72
    },
    {
        "text": "preliminary analysis of the of the data",
        "start": 734.64,
        "duration": 4.439
    },
    {
        "text": "set it facilities visualization",
        "start": 736.92,
        "duration": 4.62
    },
    {
        "text": "interpretation and downstream analysis",
        "start": 739.079,
        "duration": 5.581
    },
    {
        "text": "so the main idea is we want to reduce",
        "start": 741.54,
        "duration": 5.34
    },
    {
        "text": "the dimension of the data while still",
        "start": 744.66,
        "duration": 3.78
    },
    {
        "text": "being able to capture the main",
        "start": 746.88,
        "duration": 3.959
    },
    {
        "text": "information or major information in the",
        "start": 748.44,
        "duration": 5.339
    },
    {
        "text": "data set and in for microbiome data",
        "start": 750.839,
        "duration": 6.601
    },
    {
        "text": "there are several uh ideas for",
        "start": 753.779,
        "duration": 7.62
    },
    {
        "text": "dimensional reduction uh one is the uh",
        "start": 757.44,
        "duration": 7.38
    },
    {
        "text": "you know extreme reduction using some",
        "start": 761.399,
        "duration": 5.88
    },
    {
        "text": "indexing method for example we can use",
        "start": 764.82,
        "duration": 5.94
    },
    {
        "text": "the diversity or complexity indices to",
        "start": 767.279,
        "duration": 7.581
    },
    {
        "text": "quantify each sample and we can",
        "start": 770.76,
        "duration": 6.6
    },
    {
        "text": "Summarize each sample using just the",
        "start": 774.86,
        "duration": 5.44
    },
    {
        "text": "alpha diversity or some other complex",
        "start": 777.36,
        "duration": 5.7
    },
    {
        "text": "complexity indices that's an extreme",
        "start": 780.3,
        "duration": 4.92
    },
    {
        "text": "reduction of the data right you can",
        "start": 783.06,
        "duration": 3.779
    },
    {
        "text": "reduce the original High dimensional",
        "start": 785.22,
        "duration": 4.559
    },
    {
        "text": "data to just a single digit summary so",
        "start": 786.839,
        "duration": 7.56
    },
    {
        "text": "that's one that is one reduction method",
        "start": 789.779,
        "duration": 8.401
    },
    {
        "text": "for microbond data and it's it's",
        "start": 794.399,
        "duration": 7.56
    },
    {
        "text": "commonly used but it also have apparent",
        "start": 798.18,
        "duration": 5.88
    },
    {
        "text": "limitation so you just reduce the",
        "start": 801.959,
        "duration": 4.32
    },
    {
        "text": "information too much and only give you a",
        "start": 804.06,
        "duration": 3.3
    },
    {
        "text": "little",
        "start": 806.279,
        "duration": 5.941
    },
    {
        "text": "um a limited perspective of the data",
        "start": 807.36,
        "duration": 7.68
    },
    {
        "text": "so another way of doing dimensional",
        "start": 812.22,
        "duration": 5.94
    },
    {
        "text": "reduction for microbond data is using",
        "start": 815.04,
        "duration": 5.64
    },
    {
        "text": "selection namely we only restrict",
        "start": 818.16,
        "duration": 5.22
    },
    {
        "text": "ourselves to a subset of the microbes",
        "start": 820.68,
        "duration": 6.599
    },
    {
        "text": "and a subset of dominant compositions",
        "start": 823.38,
        "duration": 7.5
    },
    {
        "text": "and that is also very common in real",
        "start": 827.279,
        "duration": 7.56
    },
    {
        "text": "analysis so people tend to ignore taxa",
        "start": 830.88,
        "duration": 7.079
    },
    {
        "text": "with lower balance levels some places to",
        "start": 834.839,
        "duration": 5.581
    },
    {
        "text": "drop them and then just focus on the",
        "start": 837.959,
        "duration": 5.461
    },
    {
        "text": "small side of textile with sufficient",
        "start": 840.42,
        "duration": 4.38
    },
    {
        "text": "abundance",
        "start": 843.42,
        "duration": 3.12
    },
    {
        "text": "so that is another way of doing",
        "start": 844.8,
        "duration": 4.5
    },
    {
        "text": "reduction and finally there are",
        "start": 846.54,
        "duration": 4.919
    },
    {
        "text": "transformation based methods namely your",
        "start": 849.3,
        "duration": 4.38
    },
    {
        "text": "first transforming the data using this",
        "start": 851.459,
        "duration": 4.38
    },
    {
        "text": "logarithm transformation and then using",
        "start": 853.68,
        "duration": 3.959
    },
    {
        "text": "existing dimensional reduction methods",
        "start": 855.839,
        "duration": 4.381
    },
    {
        "text": "such as principal component analysis or",
        "start": 857.639,
        "duration": 5.64
    },
    {
        "text": "principal coordinate analysis to get a",
        "start": 860.22,
        "duration": 5.58
    },
    {
        "text": "low low dimensional representation of",
        "start": 863.279,
        "duration": 6.421
    },
    {
        "text": "the original data so the third method",
        "start": 865.8,
        "duration": 5.96
    },
    {
        "text": "this transformation path based method",
        "start": 869.7,
        "duration": 4.8
    },
    {
        "text": "suffered the same limitation as other",
        "start": 871.76,
        "duration": 5.079
    },
    {
        "text": "transformation-based methods right so it",
        "start": 874.5,
        "duration": 5.459
    },
    {
        "text": "doesn't really accommodate this special",
        "start": 876.839,
        "duration": 5.701
    },
    {
        "text": "feature of the data uh including the",
        "start": 879.959,
        "duration": 4.981
    },
    {
        "text": "compositionality and zero inflation",
        "start": 882.54,
        "duration": 4.919
    },
    {
        "text": "so looking at looking at all these",
        "start": 884.94,
        "duration": 4.259
    },
    {
        "text": "existing methods",
        "start": 887.459,
        "duration": 3.961
    },
    {
        "text": "um we sort of felt like it's not",
        "start": 889.199,
        "duration": 5.161
    },
    {
        "text": "sufficient to really capture the what is",
        "start": 891.42,
        "duration": 4.32
    },
    {
        "text": "uh",
        "start": 894.36,
        "duration": 4.32
    },
    {
        "text": "what is needed for this field so we can",
        "start": 895.74,
        "duration": 5.88
    },
    {
        "text": "we ask the question of what constitutes",
        "start": 898.68,
        "duration": 5.64
    },
    {
        "text": "an interpretable and in fact a reduction",
        "start": 901.62,
        "duration": 5.519
    },
    {
        "text": "of this microbiome compositional data",
        "start": 904.32,
        "duration": 7.04
    },
    {
        "text": "and after some thoughts we feel like the",
        "start": 907.139,
        "duration": 7.56
    },
    {
        "text": "amalgamation may be the right way to go",
        "start": 911.36,
        "duration": 6.0
    },
    {
        "text": "for reducing the dimension of",
        "start": 914.699,
        "duration": 5.101
    },
    {
        "text": "compositional data in particular",
        "start": 917.36,
        "duration": 4.599
    },
    {
        "text": "amalgamation means aggregate",
        "start": 919.8,
        "duration": 4.62
    },
    {
        "text": "compositional components for example",
        "start": 921.959,
        "duration": 4.801
    },
    {
        "text": "here is a toy example assuming that it",
        "start": 924.42,
        "duration": 4.14
    },
    {
        "text": "starts with a five-dimensional data",
        "start": 926.76,
        "duration": 3.72
    },
    {
        "text": "Vector of compositional data meaning",
        "start": 928.56,
        "duration": 5.16
    },
    {
        "text": "that X1 plus X2 plus all the way to X5",
        "start": 930.48,
        "duration": 6.12
    },
    {
        "text": "equal to one okay so amalgamation",
        "start": 933.72,
        "duration": 5.88
    },
    {
        "text": "basically is simply means you combine",
        "start": 936.6,
        "duration": 6.06
    },
    {
        "text": "some of these components together lower",
        "start": 939.6,
        "duration": 5.22
    },
    {
        "text": "dimensional data Vector for example we",
        "start": 942.66,
        "duration": 4.32
    },
    {
        "text": "can combine the first two and combine",
        "start": 944.82,
        "duration": 3.78
    },
    {
        "text": "the last two then you reduce the",
        "start": 946.98,
        "duration": 3.719
    },
    {
        "text": "original five-dimensional Vector to a",
        "start": 948.6,
        "duration": 3.72
    },
    {
        "text": "three-dimensional vector",
        "start": 950.699,
        "duration": 5.221
    },
    {
        "text": "but the the the good thing is this",
        "start": 952.32,
        "duration": 5.34
    },
    {
        "text": "three-dimensional Vector is still a",
        "start": 955.92,
        "duration": 3.479
    },
    {
        "text": "compositional vector it's still sum up",
        "start": 957.66,
        "duration": 5.82
    },
    {
        "text": "to one so that's uh what amalgamation is",
        "start": 959.399,
        "duration": 4.861
    },
    {
        "text": "about",
        "start": 963.48,
        "duration": 4.5
    },
    {
        "text": "and we can extend this idea to high",
        "start": 964.26,
        "duration": 6.24
    },
    {
        "text": "dimensional compositional data under",
        "start": 967.98,
        "duration": 4.08
    },
    {
        "text": "some constraints",
        "start": 970.5,
        "duration": 4.92
    },
    {
        "text": "to basically what we want to do is to",
        "start": 972.06,
        "duration": 5.82
    },
    {
        "text": "reduce the data and maintain the",
        "start": 975.42,
        "duration": 4.44
    },
    {
        "text": "information in the data set as much as",
        "start": 977.88,
        "duration": 3.48
    },
    {
        "text": "possible",
        "start": 979.86,
        "duration": 4.2
    },
    {
        "text": "so that's the fundamental idea so that",
        "start": 981.36,
        "duration": 4.86
    },
    {
        "text": "leads to this uh principal malformation",
        "start": 984.06,
        "duration": 4.86
    },
    {
        "text": "analysis idea which essentially is a",
        "start": 986.22,
        "duration": 4.919
    },
    {
        "text": "optimization framework",
        "start": 988.92,
        "duration": 4.14
    },
    {
        "text": "um if you think about this amalgamation",
        "start": 991.139,
        "duration": 4.681
    },
    {
        "text": "procedure",
        "start": 993.06,
        "duration": 5.339
    },
    {
        "text": "let's say if we start from P dimensional",
        "start": 995.82,
        "duration": 4.8
    },
    {
        "text": "data we want to reduce this to a much",
        "start": 998.399,
        "duration": 4.86
    },
    {
        "text": "lower K dimensional space",
        "start": 1000.62,
        "duration": 5.339
    },
    {
        "text": "then each amalgamation operation",
        "start": 1003.259,
        "duration": 5.94
    },
    {
        "text": "essentially can be represented as a K by",
        "start": 1005.959,
        "duration": 4.74
    },
    {
        "text": "P Matrix",
        "start": 1009.199,
        "duration": 4.26
    },
    {
        "text": "where the Matrix is a binary Matrix",
        "start": 1010.699,
        "duration": 5.481
    },
    {
        "text": "which each row being",
        "start": 1013.459,
        "duration": 6.781
    },
    {
        "text": "with each column essentially only having",
        "start": 1016.18,
        "duration": 6.7
    },
    {
        "text": "one entry being one and all the other",
        "start": 1020.24,
        "duration": 5.04
    },
    {
        "text": "entries being zero as long as the Matrix",
        "start": 1022.88,
        "duration": 5.1
    },
    {
        "text": "satisfied that con condition it is a",
        "start": 1025.28,
        "duration": 6.24
    },
    {
        "text": "valid amalgamation Matrix then what we",
        "start": 1027.98,
        "duration": 5.939
    },
    {
        "text": "can do is we can search over all",
        "start": 1031.52,
        "duration": 5.52
    },
    {
        "text": "possible amalgamation operations from P",
        "start": 1033.919,
        "duration": 5.52
    },
    {
        "text": "Dimension to K Dimension that minimize",
        "start": 1037.04,
        "duration": 5.159
    },
    {
        "text": "some loss criteria",
        "start": 1039.439,
        "duration": 5.581
    },
    {
        "text": "and in particular this loss function can",
        "start": 1042.199,
        "duration": 5.161
    },
    {
        "text": "be very general it can be user defined",
        "start": 1045.02,
        "duration": 6.6
    },
    {
        "text": "it can be for example it can be the",
        "start": 1047.36,
        "duration": 4.92
    },
    {
        "text": "um",
        "start": 1051.62,
        "duration": 2.64
    },
    {
        "text": "it can be defined based on the alpha",
        "start": 1052.28,
        "duration": 4.139
    },
    {
        "text": "diversity in particular we have shown",
        "start": 1054.26,
        "duration": 4.919
    },
    {
        "text": "that if you use the Simpsons diversity",
        "start": 1056.419,
        "duration": 6.181
    },
    {
        "text": "index as your loss function then with",
        "start": 1059.179,
        "duration": 6.181
    },
    {
        "text": "any type of amalgamation The Simpsons",
        "start": 1062.6,
        "duration": 5.939
    },
    {
        "text": "index will always decrease so that is to",
        "start": 1065.36,
        "duration": 6.36
    },
    {
        "text": "say we can Define the loss based on the",
        "start": 1068.539,
        "duration": 5.76
    },
    {
        "text": "decrease of The Simpsons index",
        "start": 1071.72,
        "duration": 4.92
    },
    {
        "text": "so what we want to do is we want to find",
        "start": 1074.299,
        "duration": 4.26
    },
    {
        "text": "a low dimensional representation of the",
        "start": 1076.64,
        "duration": 4.56
    },
    {
        "text": "data that minimize the diff the decrease",
        "start": 1078.559,
        "duration": 5.341
    },
    {
        "text": "in The Simpsons index so that could be",
        "start": 1081.2,
        "duration": 4.979
    },
    {
        "text": "your loss function and once we have a",
        "start": 1083.9,
        "duration": 4.8
    },
    {
        "text": "loss function defined we can search over",
        "start": 1086.179,
        "duration": 6.36
    },
    {
        "text": "all this automation operation space and",
        "start": 1088.7,
        "duration": 5.94
    },
    {
        "text": "find the best one that gave us the",
        "start": 1092.539,
        "duration": 4.081
    },
    {
        "text": "smallest loss",
        "start": 1094.64,
        "duration": 4.32
    },
    {
        "text": "and that's going to be the the",
        "start": 1096.62,
        "duration": 4.22
    },
    {
        "text": "amalgamation that we're going to",
        "start": 1098.96,
        "duration": 5.7
    },
    {
        "text": "use in the end to reduce the data",
        "start": 1100.84,
        "duration": 6.4
    },
    {
        "text": "as I mentioned this loss function can be",
        "start": 1104.66,
        "duration": 5.1
    },
    {
        "text": "quite General it could be based on this",
        "start": 1107.24,
        "duration": 5.34
    },
    {
        "text": "decrease in the alpha diversity or it",
        "start": 1109.76,
        "duration": 5.1
    },
    {
        "text": "could be based on the difference in the",
        "start": 1112.58,
        "duration": 4.32
    },
    {
        "text": "beta diversity or based on the change in",
        "start": 1114.86,
        "duration": 4.14
    },
    {
        "text": "the beta diversity you can quantify the",
        "start": 1116.9,
        "duration": 4.32
    },
    {
        "text": "beta diversity for the original data",
        "start": 1119.0,
        "duration": 4.14
    },
    {
        "text": "right you can also quantify the better",
        "start": 1121.22,
        "duration": 5.52
    },
    {
        "text": "diversity for this reduced data so you",
        "start": 1123.14,
        "duration": 5.52
    },
    {
        "text": "can use the difference between these two",
        "start": 1126.74,
        "duration": 5.939
    },
    {
        "text": "as your loss function and the idea is to",
        "start": 1128.66,
        "duration": 5.759
    },
    {
        "text": "minimize the difference as much as",
        "start": 1132.679,
        "duration": 4.021
    },
    {
        "text": "possible while reducing the dimension so",
        "start": 1134.419,
        "duration": 4.38
    },
    {
        "text": "that could also be a valid loss function",
        "start": 1136.7,
        "duration": 4.74
    },
    {
        "text": "or more generally you can use some",
        "start": 1138.799,
        "duration": 4.561
    },
    {
        "text": "entropy based or model base or even",
        "start": 1141.44,
        "duration": 3.72
    },
    {
        "text": "transformation based measures to",
        "start": 1143.36,
        "duration": 4.14
    },
    {
        "text": "quantify the loss at the end of the day",
        "start": 1145.16,
        "duration": 4.68
    },
    {
        "text": "this loss can be user defined once you",
        "start": 1147.5,
        "duration": 4.88
    },
    {
        "text": "have a loss you can always refer to this",
        "start": 1149.84,
        "duration": 5.52
    },
    {
        "text": "optimization framework to find the best",
        "start": 1152.38,
        "duration": 5.08
    },
    {
        "text": "amalgamation operation that reduce the",
        "start": 1155.36,
        "duration": 4.86
    },
    {
        "text": "data from P Dimension to K Dimension so",
        "start": 1157.46,
        "duration": 5.219
    },
    {
        "text": "that's the fundamental idea behind this",
        "start": 1160.22,
        "duration": 5.16
    },
    {
        "text": "uh this proposal",
        "start": 1162.679,
        "duration": 6.0
    },
    {
        "text": "so I want to go into the detail of how",
        "start": 1165.38,
        "duration": 6.06
    },
    {
        "text": "to actually choose the loss function and",
        "start": 1168.679,
        "duration": 5.101
    },
    {
        "text": "and solve this optimization but just",
        "start": 1171.44,
        "duration": 5.4
    },
    {
        "text": "want to give you a highlight overview of",
        "start": 1173.78,
        "duration": 4.74
    },
    {
        "text": "of",
        "start": 1176.84,
        "duration": 4.14
    },
    {
        "text": "how we actually solve this and how it",
        "start": 1178.52,
        "duration": 6.06
    },
    {
        "text": "performs in practice",
        "start": 1180.98,
        "duration": 5.939
    },
    {
        "text": "so as you can imagine searching over",
        "start": 1184.58,
        "duration": 4.7
    },
    {
        "text": "this space could be an MP heart problem",
        "start": 1186.919,
        "duration": 5.101
    },
    {
        "text": "so for most",
        "start": 1189.28,
        "duration": 4.96
    },
    {
        "text": "for some loss function you maybe will",
        "start": 1192.02,
        "duration": 4.68
    },
    {
        "text": "able to explicitly solve this",
        "start": 1194.24,
        "duration": 5.04
    },
    {
        "text": "optimization but in most cases it won't",
        "start": 1196.7,
        "duration": 6.66
    },
    {
        "text": "be solved in the in a reasonable time so",
        "start": 1199.28,
        "duration": 6.68
    },
    {
        "text": "what we propose is a heuristic approach",
        "start": 1203.36,
        "duration": 5.84
    },
    {
        "text": "to approximately solve this optimization",
        "start": 1205.96,
        "duration": 7.18
    },
    {
        "text": "uh problem",
        "start": 1209.2,
        "duration": 6.099
    },
    {
        "text": "in particular we consider three",
        "start": 1213.14,
        "duration": 4.14
    },
    {
        "text": "different scenarios or three different",
        "start": 1215.299,
        "duration": 5.221
    },
    {
        "text": "uh variants of this heuristic one is",
        "start": 1217.28,
        "duration": 6.139
    },
    {
        "text": "unconstrained one is the weak taxonomic",
        "start": 1220.52,
        "duration": 5.88
    },
    {
        "text": "taxonomic hierarchy and one is a strong",
        "start": 1223.419,
        "duration": 5.981
    },
    {
        "text": "taxonomic hierarchy so the latter two",
        "start": 1226.4,
        "duration": 4.92
    },
    {
        "text": "will take advantage of this tree",
        "start": 1229.4,
        "duration": 5.58
    },
    {
        "text": "structure among different taxes to guide",
        "start": 1231.32,
        "duration": 6.479
    },
    {
        "text": "this search and the first one does not",
        "start": 1234.98,
        "duration": 5.28
    },
    {
        "text": "use any additional information so to",
        "start": 1237.799,
        "duration": 3.781
    },
    {
        "text": "start with the first one the",
        "start": 1240.26,
        "duration": 4.5
    },
    {
        "text": "unconstrained approach the basic idea is",
        "start": 1241.58,
        "duration": 5.54
    },
    {
        "text": "instead of directly finding the optimal",
        "start": 1244.76,
        "duration": 5.159
    },
    {
        "text": "amalgamation we can search it step by",
        "start": 1247.12,
        "duration": 5.62
    },
    {
        "text": "step each time we just search over all",
        "start": 1249.919,
        "duration": 7.021
    },
    {
        "text": "possible Pairs and decide which pair if",
        "start": 1252.74,
        "duration": 6.059
    },
    {
        "text": "you combine them will give you the",
        "start": 1256.94,
        "duration": 4.38
    },
    {
        "text": "smallest information loss and then you",
        "start": 1258.799,
        "duration": 5.341
    },
    {
        "text": "can keep doing this procedure until you",
        "start": 1261.32,
        "duration": 7.859
    },
    {
        "text": "reach the desired dimension or desired",
        "start": 1264.14,
        "duration": 6.779
    },
    {
        "text": "information loss",
        "start": 1269.179,
        "duration": 5.541
    },
    {
        "text": "so that's the unconstrained approach",
        "start": 1270.919,
        "duration": 6.601
    },
    {
        "text": "alternatively if you have this tree",
        "start": 1274.72,
        "duration": 5.74
    },
    {
        "text": "structure between different taxes you",
        "start": 1277.52,
        "duration": 5.519
    },
    {
        "text": "can further enhance that by leveraging",
        "start": 1280.46,
        "duration": 6.32
    },
    {
        "text": "the trade structure for this uh",
        "start": 1283.039,
        "duration": 6.181
    },
    {
        "text": "amalgamation procedure",
        "start": 1286.78,
        "duration": 4.899
    },
    {
        "text": "in particular the weak taxonomic",
        "start": 1289.22,
        "duration": 5.04
    },
    {
        "text": "hierarchy means given this additional",
        "start": 1291.679,
        "duration": 5.161
    },
    {
        "text": "tree structure also we call it taxonomic",
        "start": 1294.26,
        "duration": 3.96
    },
    {
        "text": "tree but it doesn't have to be a",
        "start": 1296.84,
        "duration": 3.54
    },
    {
        "text": "taxonomic tree it can be a thousand NX",
        "start": 1298.22,
        "duration": 4.56
    },
    {
        "text": "tray as well so given the tree structure",
        "start": 1300.38,
        "duration": 4.86
    },
    {
        "text": "each step we do not search over all",
        "start": 1302.78,
        "duration": 4.8
    },
    {
        "text": "pairs but only search over the pairs",
        "start": 1305.24,
        "duration": 4.74
    },
    {
        "text": "with the same parent",
        "start": 1307.58,
        "duration": 5.16
    },
    {
        "text": "that way once we combine them we can",
        "start": 1309.98,
        "duration": 5.28
    },
    {
        "text": "still maintain this tree structure so",
        "start": 1312.74,
        "duration": 5.4
    },
    {
        "text": "that along the way we can gradually",
        "start": 1315.26,
        "duration": 5.64
    },
    {
        "text": "reduce the dimension but still maintain",
        "start": 1318.14,
        "duration": 4.98
    },
    {
        "text": "the same tree structure so that's the",
        "start": 1320.9,
        "duration": 6.96
    },
    {
        "text": "way taxonom taxonomic hierarchy approach",
        "start": 1323.12,
        "duration": 6.84
    },
    {
        "text": "in comparison the strong taxonomic",
        "start": 1327.86,
        "duration": 3.9
    },
    {
        "text": "hierarchy further an additional",
        "start": 1329.96,
        "duration": 4.32
    },
    {
        "text": "constraint that is each step we only",
        "start": 1331.76,
        "duration": 5.34
    },
    {
        "text": "search the leaf nodes at the bottom",
        "start": 1334.28,
        "duration": 4.86
    },
    {
        "text": "level of the tree",
        "start": 1337.1,
        "duration": 4.8
    },
    {
        "text": "we only proceed to the next level of the",
        "start": 1339.14,
        "duration": 6.3
    },
    {
        "text": "tree if all the lowest level nodes has",
        "start": 1341.9,
        "duration": 5.639
    },
    {
        "text": "been combined so that's the strong",
        "start": 1345.44,
        "duration": 5.4
    },
    {
        "text": "version of this taxonomic hierarchy so",
        "start": 1347.539,
        "duration": 6.601
    },
    {
        "text": "to give you a example so here is",
        "start": 1350.84,
        "duration": 5.699
    },
    {
        "text": "actually a tree from a real data example",
        "start": 1354.14,
        "duration": 4.86
    },
    {
        "text": "so as you can see this is the tree",
        "start": 1356.539,
        "duration": 6.12
    },
    {
        "text": "structure among the 62 different taxa so",
        "start": 1359.0,
        "duration": 6.6
    },
    {
        "text": "the unconstrained approach basically in",
        "start": 1362.659,
        "duration": 4.621
    },
    {
        "text": "the first step we search over all",
        "start": 1365.6,
        "duration": 3.54
    },
    {
        "text": "possible Pairs and say whether we should",
        "start": 1367.28,
        "duration": 3.96
    },
    {
        "text": "combine them or not based on whether",
        "start": 1369.14,
        "duration": 4.68
    },
    {
        "text": "that combination gave us the smallest",
        "start": 1371.24,
        "duration": 5.46
    },
    {
        "text": "information loss and in that case 2 and",
        "start": 1373.82,
        "duration": 6.06
    },
    {
        "text": "3 is a possible it's an eligible pair 12",
        "start": 1376.7,
        "duration": 5.94
    },
    {
        "text": "and 13 is also an eligible pair 26 and",
        "start": 1379.88,
        "duration": 5.94
    },
    {
        "text": "27 is also algebra pair basically any",
        "start": 1382.64,
        "duration": 5.519
    },
    {
        "text": "pair is an eligible pair for that",
        "start": 1385.82,
        "duration": 4.68
    },
    {
        "text": "unconstrained approach and you just",
        "start": 1388.159,
        "duration": 4.5
    },
    {
        "text": "search over all possible Pairs and say",
        "start": 1390.5,
        "duration": 4.32
    },
    {
        "text": "which one give you the smallest loss",
        "start": 1392.659,
        "duration": 3.681
    },
    {
        "text": "smallest",
        "start": 1394.82,
        "duration": 4.38
    },
    {
        "text": "loss in the information and then you",
        "start": 1396.34,
        "duration": 4.66
    },
    {
        "text": "proceed with the combination and proceed",
        "start": 1399.2,
        "duration": 4.26
    },
    {
        "text": "to the to the next step",
        "start": 1401.0,
        "duration": 6.48
    },
    {
        "text": "in comparison the weight hierarchy",
        "start": 1403.46,
        "duration": 6.66
    },
    {
        "text": "um two and three since they shared the",
        "start": 1407.48,
        "duration": 6.3
    },
    {
        "text": "same parent they are still a valid pair",
        "start": 1410.12,
        "duration": 6.48
    },
    {
        "text": "to be considered in the first step and",
        "start": 1413.78,
        "duration": 4.8
    },
    {
        "text": "12 and 13 they also share the same",
        "start": 1416.6,
        "duration": 4.559
    },
    {
        "text": "parent so it's still a valid pair but",
        "start": 1418.58,
        "duration": 5.219
    },
    {
        "text": "now 26 and 27 since they belongs to",
        "start": 1421.159,
        "duration": 4.561
    },
    {
        "text": "different they have different parents",
        "start": 1423.799,
        "duration": 3.961
    },
    {
        "text": "they are not on eligible player anymore",
        "start": 1425.72,
        "duration": 5.579
    },
    {
        "text": "so if you go with the weak hierarchy",
        "start": 1427.76,
        "duration": 8.039
    },
    {
        "text": "then 26 and 27 is not as popular to be",
        "start": 1431.299,
        "duration": 6.901
    },
    {
        "text": "considered in the first step maybe after",
        "start": 1435.799,
        "duration": 4.38
    },
    {
        "text": "some combination there's they will",
        "start": 1438.2,
        "duration": 4.08
    },
    {
        "text": "become an eligible pair but at least in",
        "start": 1440.179,
        "duration": 4.141
    },
    {
        "text": "the first step they are not",
        "start": 1442.28,
        "duration": 5.94
    },
    {
        "text": "and the strong hierarchy approach uh",
        "start": 1444.32,
        "duration": 6.9
    },
    {
        "text": "only two and three five and six Etc",
        "start": 1448.22,
        "duration": 5.939
    },
    {
        "text": "these are eligible pairs 12 and 13 are",
        "start": 1451.22,
        "duration": 5.339
    },
    {
        "text": "no longer agriculture because they are",
        "start": 1454.159,
        "duration": 4.981
    },
    {
        "text": "not both on the lowest level so we only",
        "start": 1456.559,
        "duration": 4.62
    },
    {
        "text": "proceed to the next level",
        "start": 1459.14,
        "duration": 5.64
    },
    {
        "text": "once we can uh finish the combination on",
        "start": 1461.179,
        "duration": 5.961
    },
    {
        "text": "the lowest level so that's the strongest",
        "start": 1464.78,
        "duration": 3.92
    },
    {
        "text": "uh",
        "start": 1467.14,
        "duration": 4.539
    },
    {
        "text": "strongest version of this uh",
        "start": 1468.7,
        "duration": 6.219
    },
    {
        "text": "amalgamation procedure",
        "start": 1471.679,
        "duration": 7.74
    },
    {
        "text": "so here are some uh potential outputs",
        "start": 1474.919,
        "duration": 7.14
    },
    {
        "text": "that we can we can draw from this",
        "start": 1479.419,
        "duration": 5.101
    },
    {
        "text": "procedure and in particular this is a",
        "start": 1482.059,
        "duration": 7.021
    },
    {
        "text": "real data example of 62 taxa and one",
        "start": 1484.52,
        "duration": 6.659
    },
    {
        "text": "thing that we can do is we can draw this",
        "start": 1489.08,
        "duration": 4.92
    },
    {
        "text": "dendrogram to show how the amalgamation",
        "start": 1491.179,
        "duration": 6.36
    },
    {
        "text": "actually happens in this data set in",
        "start": 1494.0,
        "duration": 6.059
    },
    {
        "text": "particular this example we use the",
        "start": 1497.539,
        "duration": 5.341
    },
    {
        "text": "Simpsons index with strong taxonomic",
        "start": 1500.059,
        "duration": 5.281
    },
    {
        "text": "hierarchy so as you can see the top part",
        "start": 1502.88,
        "duration": 5.279
    },
    {
        "text": "of this figure is a dendrogram which",
        "start": 1505.34,
        "duration": 5.819
    },
    {
        "text": "shows you how this uh different texts",
        "start": 1508.159,
        "duration": 5.581
    },
    {
        "text": "are actually combined along the way so",
        "start": 1511.159,
        "duration": 5.821
    },
    {
        "text": "for example the 20 33 and 35 they are",
        "start": 1513.74,
        "duration": 5.72
    },
    {
        "text": "first combined and the next one",
        "start": 1516.98,
        "duration": 7.199
    },
    {
        "text": "is probably this 52 and 53 and then so",
        "start": 1519.46,
        "duration": 7.62
    },
    {
        "text": "on so forth since we use the strong",
        "start": 1524.179,
        "duration": 6.48
    },
    {
        "text": "taxonomic hierarchy so we won't touch",
        "start": 1527.08,
        "duration": 7.18
    },
    {
        "text": "any family level nodes until we have",
        "start": 1530.659,
        "duration": 6.601
    },
    {
        "text": "aggregated all the genus level nose so",
        "start": 1534.26,
        "duration": 5.76
    },
    {
        "text": "that the this uh the height of the tree",
        "start": 1537.26,
        "duration": 5.399
    },
    {
        "text": "actually gave us the percentage change",
        "start": 1540.02,
        "duration": 4.92
    },
    {
        "text": "in the loss function in The Simpsons",
        "start": 1542.659,
        "duration": 5.161
    },
    {
        "text": "index as you can see once we finish",
        "start": 1544.94,
        "duration": 5.04
    },
    {
        "text": "combination of all the bottom levels the",
        "start": 1547.82,
        "duration": 4.82
    },
    {
        "text": "genus level that will lead to 12",
        "start": 1549.98,
        "duration": 6.179
    },
    {
        "text": "decrease in The Simpsons index",
        "start": 1552.64,
        "duration": 6.06
    },
    {
        "text": "so namely if we aggregate the original",
        "start": 1556.159,
        "duration": 8.101
    },
    {
        "text": "62 genus Genera to 41 families then it",
        "start": 1558.7,
        "duration": 8.32
    },
    {
        "text": "resulted in the 12 decrease in The",
        "start": 1564.26,
        "duration": 5.039
    },
    {
        "text": "Simpsons index and we can further",
        "start": 1567.02,
        "duration": 4.08
    },
    {
        "text": "proceed to the next level to the other",
        "start": 1569.299,
        "duration": 6.48
    },
    {
        "text": "level which only end up with 22 taxa and",
        "start": 1571.1,
        "duration": 8.16
    },
    {
        "text": "that leads to 21.1 percent decrease in",
        "start": 1575.779,
        "duration": 6.361
    },
    {
        "text": "The Simpsons index and so on so forth",
        "start": 1579.26,
        "duration": 4.74
    },
    {
        "text": "and the bottom part is it says color",
        "start": 1582.14,
        "duration": 4.8
    },
    {
        "text": "coding of the taxonomy taxonomic tree",
        "start": 1584.0,
        "duration": 7.62
    },
    {
        "text": "for the 62 taxa so since we use this",
        "start": 1586.94,
        "duration": 6.839
    },
    {
        "text": "strong taxonomic hierarchy so you can",
        "start": 1591.62,
        "duration": 5.76
    },
    {
        "text": "say the aggregation actually followed",
        "start": 1593.779,
        "duration": 7.561
    },
    {
        "text": "quite closely with this uh taxonomic uh",
        "start": 1597.38,
        "duration": 7.679
    },
    {
        "text": "tree structure for the 6a2 taxa",
        "start": 1601.34,
        "duration": 5.939
    },
    {
        "text": "we can also use the same information",
        "start": 1605.059,
        "duration": 5.401
    },
    {
        "text": "loss function by using different",
        "start": 1607.279,
        "duration": 6.9
    },
    {
        "text": "taxonomic constraints and as you can",
        "start": 1610.46,
        "duration": 5.4
    },
    {
        "text": "imagine it would lead to different",
        "start": 1614.179,
        "duration": 4.681
    },
    {
        "text": "amalgamation",
        "start": 1615.86,
        "duration": 3.0
    },
    {
        "text": "path",
        "start": 1619.159,
        "duration": 3.661
    },
    {
        "text": "so the last one is the unconstrained one",
        "start": 1620.48,
        "duration": 4.799
    },
    {
        "text": "the middle one is the weak constraint",
        "start": 1622.82,
        "duration": 5.099
    },
    {
        "text": "and the right panel is what we just saw",
        "start": 1625.279,
        "duration": 6.061
    },
    {
        "text": "the strong constraint and they",
        "start": 1627.919,
        "duration": 5.221
    },
    {
        "text": "corresponds to different type of",
        "start": 1631.34,
        "duration": 5.219
    },
    {
        "text": "amalgamation depending on which one you",
        "start": 1633.14,
        "duration": 5.419
    },
    {
        "text": "believe is the most reasonable",
        "start": 1636.559,
        "duration": 5.1
    },
    {
        "text": "dimensional reduction to proceed",
        "start": 1638.559,
        "duration": 5.561
    },
    {
        "text": "another way to visualize the the outcome",
        "start": 1641.659,
        "duration": 6.781
    },
    {
        "text": "is by drawing this information loss",
        "start": 1644.12,
        "duration": 6.84
    },
    {
        "text": "along with the info the dimension",
        "start": 1648.44,
        "duration": 3.479
    },
    {
        "text": "reduction",
        "start": 1650.96,
        "duration": 4.079
    },
    {
        "text": "so here the three panels corresponds to",
        "start": 1651.919,
        "duration": 5.461
    },
    {
        "text": "diff three different information loss",
        "start": 1655.039,
        "duration": 4.74
    },
    {
        "text": "criteria and The Simpsons index is what",
        "start": 1657.38,
        "duration": 5.88
    },
    {
        "text": "we saw before and the y-axis is the",
        "start": 1659.779,
        "duration": 5.701
    },
    {
        "text": "percentage difference the percentage",
        "start": 1663.26,
        "duration": 4.799
    },
    {
        "text": "change in the sentence index along",
        "start": 1665.48,
        "duration": 5.4
    },
    {
        "text": "Dimension reduction and x-axis is the",
        "start": 1668.059,
        "duration": 5.821
    },
    {
        "text": "number of uh president",
        "start": 1670.88,
        "duration": 6.539
    },
    {
        "text": "dimension of the reduced data so we",
        "start": 1673.88,
        "duration": 6.36
    },
    {
        "text": "start from here where without any",
        "start": 1677.419,
        "duration": 4.74
    },
    {
        "text": "reduction then of course there's no",
        "start": 1680.24,
        "duration": 4.38
    },
    {
        "text": "reduction in The Simpsons index and",
        "start": 1682.159,
        "duration": 5.281
    },
    {
        "text": "along the way as we gradually reduce the",
        "start": 1684.62,
        "duration": 6.0
    },
    {
        "text": "the dimension of the data we still we",
        "start": 1687.44,
        "duration": 7.14
    },
    {
        "text": "start to have information loss and the",
        "start": 1690.62,
        "duration": 5.7
    },
    {
        "text": "three different line types corresponds",
        "start": 1694.58,
        "duration": 4.8
    },
    {
        "text": "to the three different constraints this",
        "start": 1696.32,
        "duration": 5.94
    },
    {
        "text": "black curve is the unconstrained one and",
        "start": 1699.38,
        "duration": 5.1
    },
    {
        "text": "that's the lowest since you don't have",
        "start": 1702.26,
        "duration": 4.019
    },
    {
        "text": "any constraints on how you combine the",
        "start": 1704.48,
        "duration": 5.34
    },
    {
        "text": "data so uh conceptually it will give you",
        "start": 1706.279,
        "duration": 4.76
    },
    {
        "text": "them",
        "start": 1709.82,
        "duration": 4.26
    },
    {
        "text": "it would be able to maintain this",
        "start": 1711.039,
        "duration": 5.14
    },
    {
        "text": "information as much as possible",
        "start": 1714.08,
        "duration": 5.52
    },
    {
        "text": "and this uh grain curve this grain curve",
        "start": 1716.179,
        "duration": 6.301
    },
    {
        "text": "corresponds to the strongest constraint",
        "start": 1719.6,
        "duration": 5.22
    },
    {
        "text": "a strong hierarchy so you can see the",
        "start": 1722.48,
        "duration": 5.64
    },
    {
        "text": "step change right so that happens when",
        "start": 1724.82,
        "duration": 6.359
    },
    {
        "text": "you end up with one level of the",
        "start": 1728.12,
        "duration": 6.96
    },
    {
        "text": "taxonomy and jump to the other level and",
        "start": 1731.179,
        "duration": 6.061
    },
    {
        "text": "then you all of a sudden you have a big",
        "start": 1735.08,
        "duration": 4.979
    },
    {
        "text": "jump you have a big decrease in the",
        "start": 1737.24,
        "duration": 3.96
    },
    {
        "text": "information",
        "start": 1740.059,
        "duration": 4.081
    },
    {
        "text": "and that's the green line and the red",
        "start": 1741.2,
        "duration": 6.18
    },
    {
        "text": "curve uh is sort of in between that's",
        "start": 1744.14,
        "duration": 5.7
    },
    {
        "text": "the weak constraint it's sort of have",
        "start": 1747.38,
        "duration": 5.46
    },
    {
        "text": "this uh nice property uh with the",
        "start": 1749.84,
        "duration": 4.68
    },
    {
        "text": "unconstrained while at the same time",
        "start": 1752.84,
        "duration": 3.78
    },
    {
        "text": "still use the information from the tree",
        "start": 1754.52,
        "duration": 4.379
    },
    {
        "text": "structure so that gave you how the",
        "start": 1756.62,
        "duration": 5.82
    },
    {
        "text": "information is uh is decreased in this",
        "start": 1758.899,
        "duration": 7.02
    },
    {
        "text": "awake constraint amalgamation procedure",
        "start": 1762.44,
        "duration": 5.219
    },
    {
        "text": "and the middle panel corresponds to",
        "start": 1765.919,
        "duration": 4.14
    },
    {
        "text": "another information loss criteria which",
        "start": 1767.659,
        "duration": 4.561
    },
    {
        "text": "is the Shannon index have very similar",
        "start": 1770.059,
        "duration": 4.321
    },
    {
        "text": "patterns and the last one is using the",
        "start": 1772.22,
        "duration": 5.22
    },
    {
        "text": "beta diversity the brake Curtis index so",
        "start": 1774.38,
        "duration": 5.399
    },
    {
        "text": "we measure the information Lost based on",
        "start": 1777.44,
        "duration": 4.739
    },
    {
        "text": "the difference in the beta diversity",
        "start": 1779.779,
        "duration": 5.52
    },
    {
        "text": "from the original data and this reduced",
        "start": 1782.179,
        "duration": 6.541
    },
    {
        "text": "data again the three lines corresponds",
        "start": 1785.299,
        "duration": 7.38
    },
    {
        "text": "to the three different uh procedures",
        "start": 1788.72,
        "duration": 6.24
    },
    {
        "text": "so that way you can also use these",
        "start": 1792.679,
        "duration": 5.581
    },
    {
        "text": "figures if you have a desired cutoff for",
        "start": 1794.96,
        "duration": 4.86
    },
    {
        "text": "the percentage change in the information",
        "start": 1798.26,
        "duration": 4.32
    },
    {
        "text": "that can also give you a way to select",
        "start": 1799.82,
        "duration": 5.4
    },
    {
        "text": "the number of dimensions for the reduced",
        "start": 1802.58,
        "duration": 5.28
    },
    {
        "text": "data for example you want to keep keep",
        "start": 1805.22,
        "duration": 5.04
    },
    {
        "text": "your uh if you care about the symptoms",
        "start": 1807.86,
        "duration": 4.74
    },
    {
        "text": "index and you want to make sure that the",
        "start": 1810.26,
        "duration": 5.72
    },
    {
        "text": "the information loss is not Beyond 20",
        "start": 1812.6,
        "duration": 5.819
    },
    {
        "text": "then you can",
        "start": 1815.98,
        "duration": 5.26
    },
    {
        "text": "you know use the 20 as our cutoff and",
        "start": 1818.419,
        "duration": 5.461
    },
    {
        "text": "decide what what is the smallest",
        "start": 1821.24,
        "duration": 5.52
    },
    {
        "text": "Dimension that it can reduce to",
        "start": 1823.88,
        "duration": 5.039
    },
    {
        "text": "um but still maintain the data with the",
        "start": 1826.76,
        "duration": 5.22
    },
    {
        "text": "reasonable amount of symptoms index so",
        "start": 1828.919,
        "duration": 5.161
    },
    {
        "text": "this script Cloud could be used for",
        "start": 1831.98,
        "duration": 4.86
    },
    {
        "text": "selecting the num uh the dimension for",
        "start": 1834.08,
        "duration": 6.319
    },
    {
        "text": "uh this reduction",
        "start": 1836.84,
        "duration": 3.559
    },
    {
        "text": "here's another visualization uh using",
        "start": 1840.44,
        "duration": 5.88
    },
    {
        "text": "this brake Curtis as the information",
        "start": 1843.2,
        "duration": 7.62
    },
    {
        "text": "loss criteria so again here uh we",
        "start": 1846.32,
        "duration": 6.719
    },
    {
        "text": "actually use brick Curtis as our",
        "start": 1850.82,
        "duration": 4.32
    },
    {
        "text": "information loss criteria and conduct",
        "start": 1853.039,
        "duration": 5.161
    },
    {
        "text": "this weak taxonomic hierarchy and the",
        "start": 1855.14,
        "duration": 4.68
    },
    {
        "text": "three panels corresponds to three",
        "start": 1858.2,
        "duration": 4.32
    },
    {
        "text": "different reduced data the first panel",
        "start": 1859.82,
        "duration": 5.04
    },
    {
        "text": "corresponds to the reduced to the",
        "start": 1862.52,
        "duration": 4.62
    },
    {
        "text": "dimension of 40 second panel reduced to",
        "start": 1864.86,
        "duration": 4.559
    },
    {
        "text": "the dimension of 20 and last one reduced",
        "start": 1867.14,
        "duration": 6.56
    },
    {
        "text": "to the dimension of 10. and here is the",
        "start": 1869.419,
        "duration": 7.74
    },
    {
        "text": "pcoe plot for the original for the",
        "start": 1873.7,
        "duration": 5.38
    },
    {
        "text": "original data as well as the reduced",
        "start": 1877.159,
        "duration": 4.02
    },
    {
        "text": "data while the remain points are the",
        "start": 1879.08,
        "duration": 5.339
    },
    {
        "text": "original data the blue points are the uh",
        "start": 1881.179,
        "duration": 7.38
    },
    {
        "text": "reduce data and we use a circle to to",
        "start": 1884.419,
        "duration": 7.5
    },
    {
        "text": "just Mark which one corresponds to which",
        "start": 1888.559,
        "duration": 8.281
    },
    {
        "text": "in this uh pcoa plot as you can say when",
        "start": 1891.919,
        "duration": 7.26
    },
    {
        "text": "we reduce the data from 60 Dimension to",
        "start": 1896.84,
        "duration": 5.4
    },
    {
        "text": "40 Dimension really there's minimal",
        "start": 1899.179,
        "duration": 6.061
    },
    {
        "text": "difference in this uh two-dimensional",
        "start": 1902.24,
        "duration": 5.64
    },
    {
        "text": "plot in terms of how the samples are",
        "start": 1905.24,
        "duration": 5.46
    },
    {
        "text": "scattered how the samples are how their",
        "start": 1907.88,
        "duration": 6.24
    },
    {
        "text": "Mutual relations uh change in this",
        "start": 1910.7,
        "duration": 5.04
    },
    {
        "text": "two-dimensional space",
        "start": 1914.12,
        "duration": 4.799
    },
    {
        "text": "once we reduced it to 20 Dimension we",
        "start": 1915.74,
        "duration": 5.7
    },
    {
        "text": "start to see some some difference in",
        "start": 1918.919,
        "duration": 3.661
    },
    {
        "text": "their layout",
        "start": 1921.44,
        "duration": 4.099
    },
    {
        "text": "so some data points may start to move",
        "start": 1922.58,
        "duration": 6.06
    },
    {
        "text": "and only when we reduce to the 10",
        "start": 1925.539,
        "duration": 7.0
    },
    {
        "text": "Dimension we can say uh more dramatic",
        "start": 1928.64,
        "duration": 5.759
    },
    {
        "text": "difference in the layout in this",
        "start": 1932.539,
        "duration": 4.02
    },
    {
        "text": "two-dimensional space that is to say",
        "start": 1934.399,
        "duration": 4.861
    },
    {
        "text": "this procedure maintained the beta",
        "start": 1936.559,
        "duration": 4.62
    },
    {
        "text": "diversity of this data set pretty well",
        "start": 1939.26,
        "duration": 4.44
    },
    {
        "text": "if you just reduce it you know even",
        "start": 1941.179,
        "duration": 5.581
    },
    {
        "text": "reduces to 20 Dimension so which is a",
        "start": 1943.7,
        "duration": 5.339
    },
    {
        "text": "quite promising result from this",
        "start": 1946.76,
        "duration": 3.659
    },
    {
        "text": "analysis",
        "start": 1949.039,
        "duration": 5.581
    },
    {
        "text": "so that's uh that's pretty much it for",
        "start": 1950.419,
        "duration": 7.201
    },
    {
        "text": "the dimensional reduction and",
        "start": 1954.62,
        "duration": 5.46
    },
    {
        "text": "for dimensional reduction again it's a",
        "start": 1957.62,
        "duration": 5.4
    },
    {
        "text": "it's a tool for preliminary analysis or",
        "start": 1960.08,
        "duration": 5.459
    },
    {
        "text": "exposure analysis of the microbiome data",
        "start": 1963.02,
        "duration": 6.539
    },
    {
        "text": "and these new procedure basically just",
        "start": 1965.539,
        "duration": 6.421
    },
    {
        "text": "provides a more flexible way of reducing",
        "start": 1969.559,
        "duration": 4.74
    },
    {
        "text": "the microbiome compositional data and",
        "start": 1971.96,
        "duration": 6.12
    },
    {
        "text": "you can flexibly decide what your",
        "start": 1974.299,
        "duration": 6.661
    },
    {
        "text": "information loss function is and how you",
        "start": 1978.08,
        "duration": 4.44
    },
    {
        "text": "want to proceed whether you want to use",
        "start": 1980.96,
        "duration": 3.36
    },
    {
        "text": "the tree information to guide the",
        "start": 1982.52,
        "duration": 3.72
    },
    {
        "text": "dimensional reduction or not so it's in",
        "start": 1984.32,
        "duration": 3.54
    },
    {
        "text": "general it's a very flexible approach",
        "start": 1986.24,
        "duration": 4.319
    },
    {
        "text": "that can be uh",
        "start": 1987.86,
        "duration": 6.96
    },
    {
        "text": "can be can be useful in reducing the",
        "start": 1990.559,
        "duration": 6.301
    },
    {
        "text": "complexity of the microbiome data to",
        "start": 1994.82,
        "duration": 4.459
    },
    {
        "text": "start with",
        "start": 1996.86,
        "duration": 2.419
    },
    {
        "text": "so next I'm gonna shift here and talk",
        "start": 1999.74,
        "duration": 5.58
    },
    {
        "text": "about the regression analysis uh and say",
        "start": 2002.38,
        "duration": 6.12
    },
    {
        "text": "how this idea this amalgamation idea can",
        "start": 2005.32,
        "duration": 5.699
    },
    {
        "text": "also help us with",
        "start": 2008.5,
        "duration": 5.34
    },
    {
        "text": "regression with the association of",
        "start": 2011.019,
        "duration": 4.861
    },
    {
        "text": "clinical outcomes and the microbiome",
        "start": 2013.84,
        "duration": 4.319
    },
    {
        "text": "data as well as selecting important",
        "start": 2015.88,
        "duration": 4.08
    },
    {
        "text": "microbiome features at different",
        "start": 2018.159,
        "duration": 3.9
    },
    {
        "text": "taxonomic levels",
        "start": 2019.96,
        "duration": 3.9
    },
    {
        "text": "so we call our method in the relative",
        "start": 2022.059,
        "duration": 4.561
    },
    {
        "text": "shift and I'll explain a second why we",
        "start": 2023.86,
        "duration": 4.74
    },
    {
        "text": "give it that name",
        "start": 2026.62,
        "duration": 4.919
    },
    {
        "text": "so to start with I just want to give a",
        "start": 2028.6,
        "duration": 5.459
    },
    {
        "text": "very brief background about the",
        "start": 2031.539,
        "duration": 4.5
    },
    {
        "text": "regression analysis for microbiome data",
        "start": 2034.059,
        "duration": 4.201
    },
    {
        "text": "in the literature the most commonly used",
        "start": 2036.039,
        "duration": 4.98
    },
    {
        "text": "approach for a regression of microbiome",
        "start": 2038.26,
        "duration": 4.98
    },
    {
        "text": "compositional data is called the log",
        "start": 2041.019,
        "duration": 4.561
    },
    {
        "text": "contrast model it's a model developed",
        "start": 2043.24,
        "duration": 5.34
    },
    {
        "text": "back in the 80s to associate the",
        "start": 2045.58,
        "duration": 4.98
    },
    {
        "text": "response a universal response with this",
        "start": 2048.58,
        "duration": 3.839
    },
    {
        "text": "compositional predictors",
        "start": 2050.56,
        "duration": 4.92
    },
    {
        "text": "and the idea is instead of directly",
        "start": 2052.419,
        "duration": 4.801
    },
    {
        "text": "associating the response with the",
        "start": 2055.48,
        "duration": 4.679
    },
    {
        "text": "compositions you first transform the",
        "start": 2057.22,
        "duration": 6.48
    },
    {
        "text": "conversation taking one taxa as your",
        "start": 2060.159,
        "duration": 6.781
    },
    {
        "text": "reference and then take all this log",
        "start": 2063.7,
        "duration": 7.679
    },
    {
        "text": "contrast uh as your true predictors and",
        "start": 2066.94,
        "duration": 6.84
    },
    {
        "text": "then fit the standard linear regression",
        "start": 2071.379,
        "duration": 3.361
    },
    {
        "text": "model",
        "start": 2073.78,
        "duration": 3.18
    },
    {
        "text": "so this logarithial transformation again",
        "start": 2074.74,
        "duration": 4.32
    },
    {
        "text": "the main purpose is to leave the",
        "start": 2076.96,
        "duration": 4.199
    },
    {
        "text": "composition from the Simplex to the",
        "start": 2079.06,
        "duration": 5.279
    },
    {
        "text": "euclidean space later on",
        "start": 2081.159,
        "duration": 5.041
    },
    {
        "text": "um people find that it also has a",
        "start": 2084.339,
        "duration": 3.78
    },
    {
        "text": "symmetric form which is essentially",
        "start": 2086.2,
        "duration": 3.959
    },
    {
        "text": "regressing why on all this log",
        "start": 2088.119,
        "duration": 4.861
    },
    {
        "text": "transformed compositional data with",
        "start": 2090.159,
        "duration": 5.341
    },
    {
        "text": "additional linear constraint that the",
        "start": 2092.98,
        "duration": 5.22
    },
    {
        "text": "sum of this coefficient is equal to zero",
        "start": 2095.5,
        "duration": 4.92
    },
    {
        "text": "so these two models are exactly",
        "start": 2098.2,
        "duration": 5.22
    },
    {
        "text": "equivalent and of course uh in practice",
        "start": 2100.42,
        "duration": 6.3
    },
    {
        "text": "you can also use other Transformations",
        "start": 2103.42,
        "duration": 5.16
    },
    {
        "text": "such as the center log original",
        "start": 2106.72,
        "duration": 4.2
    },
    {
        "text": "transformation instead of this um you",
        "start": 2108.58,
        "duration": 3.96
    },
    {
        "text": "know particular",
        "start": 2110.92,
        "duration": 3.6
    },
    {
        "text": "taking one particular text on as a",
        "start": 2112.54,
        "duration": 3.9
    },
    {
        "text": "reference you can use the geometric mean",
        "start": 2114.52,
        "duration": 5.099
    },
    {
        "text": "of this text as the as the reference",
        "start": 2116.44,
        "duration": 4.86
    },
    {
        "text": "then that corresponds to the center of",
        "start": 2119.619,
        "duration": 3.72
    },
    {
        "text": "operational transformation but still it",
        "start": 2121.3,
        "duration": 4.94
    },
    {
        "text": "has this equivalent form",
        "start": 2123.339,
        "duration": 7.441
    },
    {
        "text": "so this model is fine but it has",
        "start": 2126.24,
        "duration": 6.94
    },
    {
        "text": "definitely has some limitations but one",
        "start": 2130.78,
        "duration": 6.36
    },
    {
        "text": "thing it cannot accommodate zeros in the",
        "start": 2133.18,
        "duration": 6.12
    },
    {
        "text": "data we call that you have to do this",
        "start": 2137.14,
        "duration": 4.199
    },
    {
        "text": "loud transformation if you have zero",
        "start": 2139.3,
        "duration": 3.66
    },
    {
        "text": "then it's definitely not going to work",
        "start": 2141.339,
        "duration": 5.041
    },
    {
        "text": "so what you do is you increase or you",
        "start": 2142.96,
        "duration": 5.52
    },
    {
        "text": "you change the zero values by adding",
        "start": 2146.38,
        "duration": 4.199
    },
    {
        "text": "some small pseudo account to change it",
        "start": 2148.48,
        "duration": 4.74
    },
    {
        "text": "but as you can imagine once you change",
        "start": 2150.579,
        "duration": 5.76
    },
    {
        "text": "the value you introduce bias to the",
        "start": 2153.22,
        "duration": 6.78
    },
    {
        "text": "analysis so that is one big drawback of",
        "start": 2156.339,
        "duration": 5.881
    },
    {
        "text": "that and also it lacks straightforward",
        "start": 2160.0,
        "duration": 4.38
    },
    {
        "text": "biological interpretation if you think",
        "start": 2162.22,
        "duration": 5.52
    },
    {
        "text": "about this uh coefficient in this model",
        "start": 2164.38,
        "duration": 4.26
    },
    {
        "text": "um",
        "start": 2167.74,
        "duration": 3.9
    },
    {
        "text": "since this XJ this compositional data",
        "start": 2168.64,
        "duration": 6.959
    },
    {
        "text": "they are not individually they are not",
        "start": 2171.64,
        "duration": 6.479
    },
    {
        "text": "independent meaning if you change the",
        "start": 2175.599,
        "duration": 5.221
    },
    {
        "text": "value of one XJ you know for sure some",
        "start": 2178.119,
        "duration": 5.101
    },
    {
        "text": "other xjs would also change accordingly",
        "start": 2180.82,
        "duration": 5.34
    },
    {
        "text": "because they are compositions so the",
        "start": 2183.22,
        "duration": 5.34
    },
    {
        "text": "betas cannot be interpreted in the same",
        "start": 2186.16,
        "duration": 4.199
    },
    {
        "text": "way as in the standard linear regression",
        "start": 2188.56,
        "duration": 4.26
    },
    {
        "text": "model namely you cannot interpret beta J",
        "start": 2190.359,
        "duration": 5.641
    },
    {
        "text": "as how does change increasing one unit",
        "start": 2192.82,
        "duration": 6.24
    },
    {
        "text": "of this predictor affect the response so",
        "start": 2196.0,
        "duration": 4.68
    },
    {
        "text": "there's no straightforward",
        "start": 2199.06,
        "duration": 3.48
    },
    {
        "text": "interpretation of what this beta Gene",
        "start": 2200.68,
        "duration": 4.64
    },
    {
        "text": "really means in this uh log contrast",
        "start": 2202.54,
        "duration": 5.64
    },
    {
        "text": "model especially given that you also",
        "start": 2205.32,
        "duration": 4.06
    },
    {
        "text": "have to",
        "start": 2208.18,
        "duration": 3.54
    },
    {
        "text": "um you know acknowledge that the betas",
        "start": 2209.38,
        "duration": 4.26
    },
    {
        "text": "actually sum to zero this additional",
        "start": 2211.72,
        "duration": 3.359
    },
    {
        "text": "constraint",
        "start": 2213.64,
        "duration": 3.78
    },
    {
        "text": "and also it's not a very straightforward",
        "start": 2215.079,
        "duration": 3.78
    },
    {
        "text": "how to incorporate additional",
        "start": 2217.42,
        "duration": 3.179
    },
    {
        "text": "information such as the tree structure",
        "start": 2218.859,
        "duration": 4.941
    },
    {
        "text": "among the microbes so that is another",
        "start": 2220.599,
        "duration": 6.721
    },
    {
        "text": "limitation and finally if you conduct an",
        "start": 2223.8,
        "duration": 5.2
    },
    {
        "text": "analysis at different level of the",
        "start": 2227.32,
        "duration": 4.62
    },
    {
        "text": "taxonomy taxonomic tree you may get a",
        "start": 2229.0,
        "duration": 5.94
    },
    {
        "text": "very different result you can consider",
        "start": 2231.94,
        "duration": 5.88
    },
    {
        "text": "if you do the analysis on the species",
        "start": 2234.94,
        "duration": 5.639
    },
    {
        "text": "level maybe you can find a couple of",
        "start": 2237.82,
        "duration": 5.34
    },
    {
        "text": "spaces to be imported but once you start",
        "start": 2240.579,
        "duration": 4.321
    },
    {
        "text": "aggregating the data to the next level",
        "start": 2243.16,
        "duration": 4.199
    },
    {
        "text": "to the genus level then you may find a",
        "start": 2244.9,
        "duration": 5.1
    },
    {
        "text": "totally different setup Janus General to",
        "start": 2247.359,
        "duration": 5.161
    },
    {
        "text": "be important so there is no way to to",
        "start": 2250.0,
        "duration": 5.099
    },
    {
        "text": "guarantee that the analysis conducted at",
        "start": 2252.52,
        "duration": 4.319
    },
    {
        "text": "different levels are actually consistent",
        "start": 2255.099,
        "duration": 5.041
    },
    {
        "text": "so that's another big limitation which",
        "start": 2256.839,
        "duration": 6.0
    },
    {
        "text": "uh really constraints the",
        "start": 2260.14,
        "duration": 6.42
    },
    {
        "text": "reproducibility of this uh analysis",
        "start": 2262.839,
        "duration": 6.121
    },
    {
        "text": "so then we ask a question can we",
        "start": 2266.56,
        "duration": 4.38
    },
    {
        "text": "directly model compositions without",
        "start": 2268.96,
        "duration": 4.379
    },
    {
        "text": "transformation and use that in the",
        "start": 2270.94,
        "duration": 4.76
    },
    {
        "text": "regression model so that's sort of the",
        "start": 2273.339,
        "duration": 6.981
    },
    {
        "text": "motivation for this work",
        "start": 2275.7,
        "duration": 4.62
    },
    {
        "text": "and the answer is yes and the way to do",
        "start": 2280.48,
        "duration": 6.42
    },
    {
        "text": "it is actually surprisingly simple and",
        "start": 2283.78,
        "duration": 6.48
    },
    {
        "text": "we just know it's a particular fact that",
        "start": 2286.9,
        "duration": 6.36
    },
    {
        "text": "if you directly regress this response y",
        "start": 2290.26,
        "duration": 6.48
    },
    {
        "text": "on this compositional predictor X1 to XP",
        "start": 2293.26,
        "duration": 5.579
    },
    {
        "text": "the model itself is not going to be",
        "start": 2296.74,
        "duration": 4.56
    },
    {
        "text": "identifiable because you have this X1",
        "start": 2298.839,
        "duration": 3.421
    },
    {
        "text": "Plus",
        "start": 2301.3,
        "duration": 3.059
    },
    {
        "text": "all the way to XP equal to one",
        "start": 2302.26,
        "duration": 3.42
    },
    {
        "text": "constraint so the model is not",
        "start": 2304.359,
        "duration": 3.661
    },
    {
        "text": "identifiable but if you reduce the",
        "start": 2305.68,
        "duration": 4.32
    },
    {
        "text": "degree of freedom for this regression",
        "start": 2308.02,
        "duration": 4.559
    },
    {
        "text": "model by one the model will become",
        "start": 2310.0,
        "duration": 5.28
    },
    {
        "text": "identifiable and to reduce the degree of",
        "start": 2312.579,
        "duration": 5.101
    },
    {
        "text": "Freedom by one you can simply get rid of",
        "start": 2315.28,
        "duration": 4.44
    },
    {
        "text": "this intercept term forget about the",
        "start": 2317.68,
        "duration": 5.399
    },
    {
        "text": "intercept and only focus on this this",
        "start": 2319.72,
        "duration": 5.399
    },
    {
        "text": "regression without the intercept the",
        "start": 2323.079,
        "duration": 4.26
    },
    {
        "text": "model is fully identifiable meaning all",
        "start": 2325.119,
        "duration": 5.101
    },
    {
        "text": "this beta 1 to Beta P they are uniquely",
        "start": 2327.339,
        "duration": 6.961
    },
    {
        "text": "defined once we have the data y X1 to XP",
        "start": 2330.22,
        "duration": 6.78
    },
    {
        "text": "and I'm moreover we have Superior",
        "start": 2334.3,
        "duration": 5.1
    },
    {
        "text": "interpretabilities for this regression",
        "start": 2337.0,
        "duration": 5.16
    },
    {
        "text": "coefficient by noticing the the relation",
        "start": 2339.4,
        "duration": 6.3
    },
    {
        "text": "that for any pair beta J X G Plus beta k",
        "start": 2342.16,
        "duration": 7.14
    },
    {
        "text": "x k you can always re uh rewrite this",
        "start": 2345.7,
        "duration": 6.12
    },
    {
        "text": "relation in the right hand side which is",
        "start": 2349.3,
        "duration": 5.1
    },
    {
        "text": "beta K times the sum of these two",
        "start": 2351.82,
        "duration": 5.64
    },
    {
        "text": "compositions plus the difference of the",
        "start": 2354.4,
        "duration": 6.36
    },
    {
        "text": "coefficient times x j so what that means",
        "start": 2357.46,
        "duration": 6.119
    },
    {
        "text": "is that if you can if you maintain this",
        "start": 2360.76,
        "duration": 6.12
    },
    {
        "text": "x j plus x k constant this difference",
        "start": 2363.579,
        "duration": 6.961
    },
    {
        "text": "will tell you how moving concentration",
        "start": 2366.88,
        "duration": 8.94
    },
    {
        "text": "from x k to x j would affect",
        "start": 2370.54,
        "duration": 7.319
    },
    {
        "text": "the response",
        "start": 2375.82,
        "duration": 4.38
    },
    {
        "text": "namely this difference of the",
        "start": 2377.859,
        "duration": 4.801
    },
    {
        "text": "coefficient carry very important meaning",
        "start": 2380.2,
        "duration": 5.639
    },
    {
        "text": "that is how shifting concentration",
        "start": 2382.66,
        "duration": 7.02
    },
    {
        "text": "between taxa would affect the response",
        "start": 2385.839,
        "duration": 6.361
    },
    {
        "text": "so that actually gave us give it its",
        "start": 2389.68,
        "duration": 5.1
    },
    {
        "text": "name the relative shift because the sh",
        "start": 2392.2,
        "duration": 4.86
    },
    {
        "text": "this uh this difference in the",
        "start": 2394.78,
        "duration": 4.44
    },
    {
        "text": "coefficient really capture the shift",
        "start": 2397.06,
        "duration": 4.62
    },
    {
        "text": "effect of the concentration",
        "start": 2399.22,
        "duration": 4.379
    },
    {
        "text": "and that also leads to a nice",
        "start": 2401.68,
        "duration": 4.5
    },
    {
        "text": "combinatorial property of the model that",
        "start": 2403.599,
        "duration": 5.281
    },
    {
        "text": "is if two coefficients are equal then",
        "start": 2406.18,
        "duration": 4.98
    },
    {
        "text": "what we know is that you can arbitrarily",
        "start": 2408.88,
        "duration": 4.199
    },
    {
        "text": "shift concentrations between these two",
        "start": 2411.16,
        "duration": 5.939
    },
    {
        "text": "taxes without really changing the model",
        "start": 2413.079,
        "duration": 8.401
    },
    {
        "text": "so that just gave us another way of uh",
        "start": 2417.099,
        "duration": 7.201
    },
    {
        "text": "connecting to this amalgamation idea if",
        "start": 2421.48,
        "duration": 4.92
    },
    {
        "text": "the coefficients are equal then it just",
        "start": 2424.3,
        "duration": 4.26
    },
    {
        "text": "means these two texts are from a",
        "start": 2426.4,
        "duration": 3.959
    },
    {
        "text": "prediction perspective they can be",
        "start": 2428.56,
        "duration": 4.68
    },
    {
        "text": "treated at the same entity and all we",
        "start": 2430.359,
        "duration": 5.821
    },
    {
        "text": "care about is the total composition of",
        "start": 2433.24,
        "duration": 5.22
    },
    {
        "text": "these two taxa we don't care about each",
        "start": 2436.18,
        "duration": 4.56
    },
    {
        "text": "individual composition you can",
        "start": 2438.46,
        "duration": 4.74
    },
    {
        "text": "arbitrullate change the composition",
        "start": 2440.74,
        "duration": 4.56
    },
    {
        "text": "change the composition between these two",
        "start": 2443.2,
        "duration": 4.2
    },
    {
        "text": "taxes as long as the total composition",
        "start": 2445.3,
        "duration": 4.02
    },
    {
        "text": "is the same that would have the same",
        "start": 2447.4,
        "duration": 4.86
    },
    {
        "text": "prediction effect on the response and",
        "start": 2449.32,
        "duration": 4.92
    },
    {
        "text": "moreover the model is a scale and shift",
        "start": 2452.26,
        "duration": 4.44
    },
    {
        "text": "in Balance meaning that you can you can",
        "start": 2454.24,
        "duration": 6.839
    },
    {
        "text": "change your response to the scale and",
        "start": 2456.7,
        "duration": 6.72
    },
    {
        "text": "um and you can change the scale and me",
        "start": 2461.079,
        "duration": 4.26
    },
    {
        "text": "of the response all you need to do is to",
        "start": 2463.42,
        "duration": 4.32
    },
    {
        "text": "change this beta 1 to Beta P by the same",
        "start": 2465.339,
        "duration": 6.061
    },
    {
        "text": "uh scale and shift uh uh",
        "start": 2467.74,
        "duration": 5.82
    },
    {
        "text": "skimming and shifting",
        "start": 2471.4,
        "duration": 5.04
    },
    {
        "text": "so I won't go into detail so a quick how",
        "start": 2473.56,
        "duration": 5.4
    },
    {
        "text": "to add a comparison with the standard",
        "start": 2476.44,
        "duration": 4.679
    },
    {
        "text": "law contrast model we can say there are",
        "start": 2478.96,
        "duration": 4.28
    },
    {
        "text": "some major differences between these two",
        "start": 2481.119,
        "duration": 6.0
    },
    {
        "text": "two ideas first in terms of predictors",
        "start": 2483.24,
        "duration": 5.98
    },
    {
        "text": "the relative ship model do not need to",
        "start": 2487.119,
        "duration": 5.101
    },
    {
        "text": "conduct any transformation and in terms",
        "start": 2489.22,
        "duration": 5.1
    },
    {
        "text": "of coefficient there is no constraint",
        "start": 2492.22,
        "duration": 6.119
    },
    {
        "text": "well well only one constraint you do not",
        "start": 2494.32,
        "duration": 5.94
    },
    {
        "text": "add The Intercept term in this",
        "start": 2498.339,
        "duration": 4.081
    },
    {
        "text": "regression model and in terms of the",
        "start": 2500.26,
        "duration": 4.26
    },
    {
        "text": "interpretation the relative shape model",
        "start": 2502.42,
        "duration": 4.32
    },
    {
        "text": "has nice interpretation where the",
        "start": 2504.52,
        "duration": 4.02
    },
    {
        "text": "difference of coefficient of",
        "start": 2506.74,
        "duration": 3.48
    },
    {
        "text": "coefficients can be interpreted as a",
        "start": 2508.54,
        "duration": 4.079
    },
    {
        "text": "random effect of Shifting concentration",
        "start": 2510.22,
        "duration": 4.379
    },
    {
        "text": "between taxes and that can also be",
        "start": 2512.619,
        "duration": 3.72
    },
    {
        "text": "generalized to more than",
        "start": 2514.599,
        "duration": 5.101
    },
    {
        "text": "two taxa for any number of taxes you can",
        "start": 2516.339,
        "duration": 5.581
    },
    {
        "text": "always construct a contrast of this",
        "start": 2519.7,
        "duration": 4.62
    },
    {
        "text": "coefficient as long as this contrast the",
        "start": 2521.92,
        "duration": 4.08
    },
    {
        "text": "coefficient they can always be",
        "start": 2524.32,
        "duration": 3.84
    },
    {
        "text": "interpreted as how shifting",
        "start": 2526.0,
        "duration": 4.68
    },
    {
        "text": "concentration between this subset of",
        "start": 2528.16,
        "duration": 5.76
    },
    {
        "text": "taxa would affect to our outcome",
        "start": 2530.68,
        "duration": 6.3
    },
    {
        "text": "and in addition if we are dealing with",
        "start": 2533.92,
        "duration": 6.72
    },
    {
        "text": "high dimensional data uh we can use this",
        "start": 2536.98,
        "duration": 7.02
    },
    {
        "text": "uh this combinatorial property to",
        "start": 2540.64,
        "duration": 6.12
    },
    {
        "text": "achieve feature aggregation in relative",
        "start": 2544.0,
        "duration": 5.28
    },
    {
        "text": "shift model we can combine some text",
        "start": 2546.76,
        "duration": 4.98
    },
    {
        "text": "because there are individual composition",
        "start": 2549.28,
        "duration": 4.2
    },
    {
        "text": "does not really matter in prediction we",
        "start": 2551.74,
        "duration": 3.72
    },
    {
        "text": "can combine them to reduce the dimension",
        "start": 2553.48,
        "duration": 4.2
    },
    {
        "text": "of the predictor while the law contrast",
        "start": 2555.46,
        "duration": 3.899
    },
    {
        "text": "you may need to refer to the feature",
        "start": 2557.68,
        "duration": 2.58
    },
    {
        "text": "selection",
        "start": 2559.359,
        "duration": 3.601
    },
    {
        "text": "and recall that we argue the aggregation",
        "start": 2560.26,
        "duration": 5.16
    },
    {
        "text": "or amalgamation is more appropriate for",
        "start": 2562.96,
        "duration": 5.46
    },
    {
        "text": "compositional data in addition if we",
        "start": 2565.42,
        "duration": 5.04
    },
    {
        "text": "have additional tree structure that can",
        "start": 2568.42,
        "duration": 4.62
    },
    {
        "text": "be easily Incorporated which I'm going",
        "start": 2570.46,
        "duration": 5.52
    },
    {
        "text": "to talk about in a second and it's also",
        "start": 2573.04,
        "duration": 5.4
    },
    {
        "text": "quite robust against measurement error",
        "start": 2575.98,
        "duration": 4.8
    },
    {
        "text": "because you can combine taxa to higher",
        "start": 2578.44,
        "duration": 5.04
    },
    {
        "text": "levels and the higher the level is the",
        "start": 2580.78,
        "duration": 4.86
    },
    {
        "text": "lower the measurement error going to be",
        "start": 2583.48,
        "duration": 4.2
    },
    {
        "text": "effective",
        "start": 2585.64,
        "duration": 3.959
    },
    {
        "text": "so that's just the nature of the",
        "start": 2587.68,
        "duration": 4.38
    },
    {
        "text": "microbiome data",
        "start": 2589.599,
        "duration": 6.061
    },
    {
        "text": "so to incorporate this additional tree",
        "start": 2592.06,
        "duration": 6.539
    },
    {
        "text": "structure here is a toy example of how",
        "start": 2595.66,
        "duration": 5.82
    },
    {
        "text": "we're going to do it uh essentially the",
        "start": 2598.599,
        "duration": 5.701
    },
    {
        "text": "basic idea is we we want to aggregate",
        "start": 2601.48,
        "duration": 5.46
    },
    {
        "text": "taxa with similar taxonomic path",
        "start": 2604.3,
        "duration": 5.22
    },
    {
        "text": "so assume this is the your taxonomic",
        "start": 2606.94,
        "duration": 4.1
    },
    {
        "text": "tree structure",
        "start": 2609.52,
        "duration": 4.079
    },
    {
        "text": "these two nodes comma one and comma two",
        "start": 2611.04,
        "duration": 6.279
    },
    {
        "text": "they share a lot of this uh taxonomy",
        "start": 2613.599,
        "duration": 5.821
    },
    {
        "text": "along the way from the root node all the",
        "start": 2617.319,
        "duration": 4.441
    },
    {
        "text": "way to the leaf node the only differ at",
        "start": 2619.42,
        "duration": 4.98
    },
    {
        "text": "the bottom level and starting from their",
        "start": 2621.76,
        "duration": 5.579
    },
    {
        "text": "parent they become the same node so they",
        "start": 2624.4,
        "duration": 6.36
    },
    {
        "text": "share a lot of a taxonomic path in that",
        "start": 2627.339,
        "duration": 5.581
    },
    {
        "text": "way they are more likely to be combined",
        "start": 2630.76,
        "duration": 6.18
    },
    {
        "text": "compared to say node comma 1 versus no",
        "start": 2632.92,
        "duration": 7.399
    },
    {
        "text": "comma four which only share between uh",
        "start": 2636.94,
        "duration": 6.78
    },
    {
        "text": "from from the root node to the second",
        "start": 2640.319,
        "duration": 7.54
    },
    {
        "text": "level so comma 1 and Gamma 4 are less",
        "start": 2643.72,
        "duration": 6.0
    },
    {
        "text": "likely to be combined compared to Gamma",
        "start": 2647.859,
        "duration": 3.901
    },
    {
        "text": "1 and Gamma 2. so that's sort of the",
        "start": 2649.72,
        "duration": 4.92
    },
    {
        "text": "fundamental idea and in order to",
        "start": 2651.76,
        "duration": 5.46
    },
    {
        "text": "um realize that idea where it can",
        "start": 2654.64,
        "duration": 6.06
    },
    {
        "text": "actually use some technical um some",
        "start": 2657.22,
        "duration": 6.18
    },
    {
        "text": "technical tricks to convert the original",
        "start": 2660.7,
        "duration": 4.919
    },
    {
        "text": "regression coefficient beta 1 to Beta 7",
        "start": 2663.4,
        "duration": 4.679
    },
    {
        "text": "to this intermediate coefficient and",
        "start": 2665.619,
        "duration": 5.401
    },
    {
        "text": "leverage the existing methods of zero",
        "start": 2668.079,
        "duration": 5.161
    },
    {
        "text": "sparsity in the statistical literature",
        "start": 2671.02,
        "duration": 5.22
    },
    {
        "text": "to encourage this aggregation of the",
        "start": 2673.24,
        "duration": 5.52
    },
    {
        "text": "coefficient because recall that in the",
        "start": 2676.24,
        "duration": 5.339
    },
    {
        "text": "proposed model equating the coefficients",
        "start": 2678.76,
        "duration": 6.48
    },
    {
        "text": "is the same as combining taxon once the",
        "start": 2681.579,
        "duration": 6.061
    },
    {
        "text": "coefficient of this two taxes are the",
        "start": 2685.24,
        "duration": 4.68
    },
    {
        "text": "same naturally they will be combined",
        "start": 2687.64,
        "duration": 4.38
    },
    {
        "text": "because individual conversation does not",
        "start": 2689.92,
        "duration": 6.0
    },
    {
        "text": "matter anymore so that's the idea and",
        "start": 2692.02,
        "duration": 6.96
    },
    {
        "text": "with some technical technicalities we",
        "start": 2695.92,
        "duration": 5.399
    },
    {
        "text": "can essentially rewrite the original",
        "start": 2698.98,
        "duration": 4.98
    },
    {
        "text": "problem at this optimization problem",
        "start": 2701.319,
        "duration": 4.921
    },
    {
        "text": "where the loss function is just a",
        "start": 2703.96,
        "duration": 5.22
    },
    {
        "text": "standard release Square loss and with",
        "start": 2706.24,
        "duration": 6.18
    },
    {
        "text": "the penalty of zero sparsity penalty on",
        "start": 2709.18,
        "duration": 4.98
    },
    {
        "text": "this intermediate coefficient that we",
        "start": 2712.42,
        "duration": 4.08
    },
    {
        "text": "introduce on the tree and subject to",
        "start": 2714.16,
        "duration": 3.959
    },
    {
        "text": "this constraint that the original",
        "start": 2716.5,
        "duration": 3.54
    },
    {
        "text": "coefficient is a linear transformation",
        "start": 2718.119,
        "duration": 5.581
    },
    {
        "text": "of the is intermediate coefficient so I",
        "start": 2720.04,
        "duration": 6.84
    },
    {
        "text": "won't go into the details of this uh",
        "start": 2723.7,
        "duration": 6.54
    },
    {
        "text": "um of this approach so you can log into",
        "start": 2726.88,
        "duration": 5.88
    },
    {
        "text": "our paper if you are interested so just",
        "start": 2730.24,
        "duration": 4.98
    },
    {
        "text": "want to use the last couple minutes to",
        "start": 2732.76,
        "duration": 5.22
    },
    {
        "text": "quickly talk through a real data example",
        "start": 2735.22,
        "duration": 6.24
    },
    {
        "text": "to show you what would be the output of",
        "start": 2737.98,
        "duration": 7.32
    },
    {
        "text": "this uh new approach so we apply this",
        "start": 2741.46,
        "duration": 7.56
    },
    {
        "text": "method to this Origins study the oral",
        "start": 2745.3,
        "duration": 6.12
    },
    {
        "text": "microbiome study trying to study the",
        "start": 2749.02,
        "duration": 4.319
    },
    {
        "text": "association between our microbial and",
        "start": 2751.42,
        "duration": 4.86
    },
    {
        "text": "biota and",
        "start": 2753.339,
        "duration": 4.101
    },
    {
        "text": "um",
        "start": 2756.28,
        "duration": 4.74
    },
    {
        "text": "some diabetes as well as periodontal",
        "start": 2757.44,
        "duration": 6.46
    },
    {
        "text": "diseases so in in the first attempt we",
        "start": 2761.02,
        "duration": 4.98
    },
    {
        "text": "try to associate this r microbiota with",
        "start": 2763.9,
        "duration": 4.439
    },
    {
        "text": "periodontal disease and we have over a",
        "start": 2766.0,
        "duration": 4.8
    },
    {
        "text": "thousand diabetes free individuals we",
        "start": 2768.339,
        "duration": 4.381
    },
    {
        "text": "collect the microbiome data from their",
        "start": 2770.8,
        "duration": 5.22
    },
    {
        "text": "sub changeable plug samples uh using the",
        "start": 2772.72,
        "duration": 5.639
    },
    {
        "text": "16s ra sequencing and after",
        "start": 2776.02,
        "duration": 4.799
    },
    {
        "text": "pre-processing we end up with over 500",
        "start": 2778.359,
        "duration": 4.801
    },
    {
        "text": "taxa at the spacious level with known",
        "start": 2780.819,
        "duration": 4.8
    },
    {
        "text": "taxonomic structure the response we use",
        "start": 2783.16,
        "duration": 5.22
    },
    {
        "text": "here is the periodontal status which is",
        "start": 2785.619,
        "duration": 5.281
    },
    {
        "text": "essentially a ordinal categorical",
        "start": 2788.38,
        "duration": 5.64
    },
    {
        "text": "outcome but here for Simplicity we just",
        "start": 2790.9,
        "duration": 5.04
    },
    {
        "text": "treat it as a continuous outcome and use",
        "start": 2794.02,
        "duration": 4.26
    },
    {
        "text": "this approach so zero represented",
        "start": 2795.94,
        "duration": 5.54
    },
    {
        "text": "healthy one represented moderate",
        "start": 2798.28,
        "duration": 6.12
    },
    {
        "text": "paranormal status and two means that we",
        "start": 2801.48,
        "duration": 5.92
    },
    {
        "text": "are severe periodontal status and we",
        "start": 2804.4,
        "duration": 4.919
    },
    {
        "text": "also adjust for additional covaries such",
        "start": 2807.4,
        "duration": 3.78
    },
    {
        "text": "as sex age race",
        "start": 2809.319,
        "duration": 5.641
    },
    {
        "text": "Etc so that's the basic setup so the",
        "start": 2811.18,
        "duration": 6.3
    },
    {
        "text": "Paranormal status is the outcome tax is",
        "start": 2814.96,
        "duration": 4.98
    },
    {
        "text": "raised as covaries and microbiome is the",
        "start": 2817.48,
        "duration": 5.22
    },
    {
        "text": "mem High dimensional predictor",
        "start": 2819.94,
        "duration": 4.98
    },
    {
        "text": "so we fit the model uh use the cross",
        "start": 2822.7,
        "duration": 3.72
    },
    {
        "text": "validation to select the tuning",
        "start": 2824.92,
        "duration": 7.32
    },
    {
        "text": "parameter and this is a major result of",
        "start": 2826.42,
        "duration": 8.1
    },
    {
        "text": "the model fitting so in particular the",
        "start": 2832.24,
        "duration": 4.859
    },
    {
        "text": "out circle is the spacious level of the",
        "start": 2834.52,
        "duration": 6.059
    },
    {
        "text": "original input data of five over 500",
        "start": 2837.099,
        "duration": 6.72
    },
    {
        "text": "taxes at the spacious level and this",
        "start": 2840.579,
        "duration": 6.721
    },
    {
        "text": "solid dots this black dots are the",
        "start": 2843.819,
        "duration": 5.76
    },
    {
        "text": "feature aggregation result",
        "start": 2847.3,
        "duration": 5.22
    },
    {
        "text": "as you can see some texts they are",
        "start": 2849.579,
        "duration": 6.361
    },
    {
        "text": "aggregated to their immediate parent",
        "start": 2852.52,
        "duration": 5.819
    },
    {
        "text": "these bunch of species are aggregated to",
        "start": 2855.94,
        "duration": 4.98
    },
    {
        "text": "the genus meaning individual composition",
        "start": 2858.339,
        "duration": 4.441
    },
    {
        "text": "of the species does not really matter in",
        "start": 2860.92,
        "duration": 4.74
    },
    {
        "text": "prediction but rather their genus the",
        "start": 2862.78,
        "duration": 5.22
    },
    {
        "text": "composition of the genus for these",
        "start": 2865.66,
        "duration": 5.04
    },
    {
        "text": "species actually matters and some other",
        "start": 2868.0,
        "duration": 5.579
    },
    {
        "text": "attacks are maybe aggregated to uh to",
        "start": 2870.7,
        "duration": 5.639
    },
    {
        "text": "higher levels so at the end of the day",
        "start": 2873.579,
        "duration": 4.681
    },
    {
        "text": "we can aggregate the data at different",
        "start": 2876.339,
        "duration": 5.401
    },
    {
        "text": "levels adaptively we do not need to",
        "start": 2878.26,
        "duration": 5.76
    },
    {
        "text": "um to restrict which level we want to",
        "start": 2881.74,
        "duration": 4.68
    },
    {
        "text": "aggregate the data but the model will",
        "start": 2884.02,
        "duration": 4.44
    },
    {
        "text": "adapt limit aggregate the data to a",
        "start": 2886.42,
        "duration": 3.3
    },
    {
        "text": "property levels",
        "start": 2888.46,
        "duration": 5.94
    },
    {
        "text": "and here eventually we end up with a",
        "start": 2889.72,
        "duration": 7.859
    },
    {
        "text": "from the original 530 taxa at the",
        "start": 2894.4,
        "duration": 5.64
    },
    {
        "text": "specialist level the model essentially",
        "start": 2897.579,
        "duration": 6.24
    },
    {
        "text": "speed out 31 groups to be significantly",
        "start": 2900.04,
        "duration": 6.96
    },
    {
        "text": "meaningful in prediction that includes",
        "start": 2903.819,
        "duration": 6.661
    },
    {
        "text": "five spaces for General 11 families or",
        "start": 2907.0,
        "duration": 6.42
    },
    {
        "text": "others four classes and a three file",
        "start": 2910.48,
        "duration": 5.22
    },
    {
        "text": "and moreover we can look at the",
        "start": 2913.42,
        "duration": 4.679
    },
    {
        "text": "coefficient estimated for these 31",
        "start": 2915.7,
        "duration": 5.879
    },
    {
        "text": "groups and try to interpret how does the",
        "start": 2918.099,
        "duration": 8.781
    },
    {
        "text": "composition actually matters in this uh",
        "start": 2921.579,
        "duration": 5.301
    },
    {
        "text": "in the prediction of the this",
        "start": 2926.98,
        "duration": 5.46
    },
    {
        "text": "periodontal outcome in particular we can",
        "start": 2929.8,
        "duration": 6.48
    },
    {
        "text": "look at the coefficient and uh these",
        "start": 2932.44,
        "duration": 6.12
    },
    {
        "text": "here are a few examples",
        "start": 2936.28,
        "duration": 5.539
    },
    {
        "text": "the trypanogenous has a coefficient of",
        "start": 2938.56,
        "duration": 6.42
    },
    {
        "text": "0.7455 which if you look at all the",
        "start": 2941.819,
        "duration": 5.5
    },
    {
        "text": "coefficient estimate is relatively High",
        "start": 2944.98,
        "duration": 4.8
    },
    {
        "text": "compared to other coefficients which",
        "start": 2947.319,
        "duration": 5.461
    },
    {
        "text": "means if you shift concentration from",
        "start": 2949.78,
        "duration": 6.78
    },
    {
        "text": "other taxa to trepanoma that would",
        "start": 2952.78,
        "duration": 6.059
    },
    {
        "text": "increase the outcome",
        "start": 2956.56,
        "duration": 5.58
    },
    {
        "text": "and recall in practice uh in this",
        "start": 2958.839,
        "duration": 5.881
    },
    {
        "text": "setting a higher value of the outcome",
        "start": 2962.14,
        "duration": 5.76
    },
    {
        "text": "means worse periodontal status so that",
        "start": 2964.72,
        "duration": 5.16
    },
    {
        "text": "is to say a higher concentration of",
        "start": 2967.9,
        "duration": 6.54
    },
    {
        "text": "trapnoma essentially is uh is is harmful",
        "start": 2969.88,
        "duration": 7.62
    },
    {
        "text": "for the periodontal status similarly for",
        "start": 2974.44,
        "duration": 5.22
    },
    {
        "text": "the peptococcus you also have a pretty",
        "start": 2977.5,
        "duration": 4.319
    },
    {
        "text": "large coefficient that also explains",
        "start": 2979.66,
        "duration": 5.159
    },
    {
        "text": "higher concentration of this uh of this",
        "start": 2981.819,
        "duration": 5.221
    },
    {
        "text": "texture linked with worst periodontal",
        "start": 2984.819,
        "duration": 4.381
    },
    {
        "text": "status which is consistent with what",
        "start": 2987.04,
        "duration": 4.799
    },
    {
        "text": "people have found in the literature and",
        "start": 2989.2,
        "duration": 5.04
    },
    {
        "text": "on the other hand we can also look at",
        "start": 2991.839,
        "duration": 5.161
    },
    {
        "text": "tax how is specifically low coefficient",
        "start": 2994.24,
        "duration": 6.32
    },
    {
        "text": "values for example this uh acting actino",
        "start": 2997.0,
        "duration": 7.02
    },
    {
        "text": "Messiah tallies so which have a negative",
        "start": 3000.56,
        "duration": 6.42
    },
    {
        "text": "coefficient and that one essentially",
        "start": 3004.02,
        "duration": 5.4
    },
    {
        "text": "there has been studies in the literature",
        "start": 3006.98,
        "duration": 4.66
    },
    {
        "text": "showing the high concentration is linked",
        "start": 3009.42,
        "duration": 4.74
    },
    {
        "text": "with health with our health",
        "start": 3011.64,
        "duration": 5.16
    },
    {
        "text": "so we cannot have actually some nice",
        "start": 3014.16,
        "duration": 4.98
    },
    {
        "text": "interpretation of the coefficient so",
        "start": 3016.8,
        "duration": 3.22
    },
    {
        "text": "more",
        "start": 3019.14,
        "duration": 2.34
    },
    {
        "text": "[Music]",
        "start": 3020.02,
        "duration": 4.22
    },
    {
        "text": "more in-depth analysis can be conducted",
        "start": 3021.48,
        "duration": 5.52
    },
    {
        "text": "on this coefficient as well which is",
        "start": 3024.24,
        "duration": 4.98
    },
    {
        "text": "ongoing work",
        "start": 3027.0,
        "duration": 5.579
    },
    {
        "text": "so just want to Briefly summarize uh",
        "start": 3029.22,
        "duration": 6.599
    },
    {
        "text": "what I've talked about today so we",
        "start": 3032.579,
        "duration": 5.341
    },
    {
        "text": "proposed this amalgamation based methods",
        "start": 3035.819,
        "duration": 4.381
    },
    {
        "text": "for microbiome compositional data in the",
        "start": 3037.92,
        "duration": 4.62
    },
    {
        "text": "first part well I introduce a new",
        "start": 3040.2,
        "duration": 3.78
    },
    {
        "text": "dimensional reduction approach called",
        "start": 3042.54,
        "duration": 4.319
    },
    {
        "text": "principal malformation analysis the idea",
        "start": 3043.98,
        "duration": 5.04
    },
    {
        "text": "is really trying to get a interpretable",
        "start": 3046.859,
        "duration": 4.621
    },
    {
        "text": "dimensional reduction at the same time",
        "start": 3049.02,
        "duration": 4.5
    },
    {
        "text": "being flexible to accommodate different",
        "start": 3051.48,
        "duration": 6.06
    },
    {
        "text": "needs from the practitioners so the idea",
        "start": 3053.52,
        "duration": 6.72
    },
    {
        "text": "you can minimize some user-defined laws",
        "start": 3057.54,
        "duration": 4.2
    },
    {
        "text": "to get a lower dimensional",
        "start": 3060.24,
        "duration": 3.54
    },
    {
        "text": "representation of the data while still",
        "start": 3061.74,
        "duration": 4.8
    },
    {
        "text": "maintain the uh the information in the",
        "start": 3063.78,
        "duration": 5.16
    },
    {
        "text": "data set it's suitable for visualization",
        "start": 3066.54,
        "duration": 4.14
    },
    {
        "text": "and subsequent analysis of this",
        "start": 3068.94,
        "duration": 4.139
    },
    {
        "text": "microbiome data and for the second part",
        "start": 3070.68,
        "duration": 4.74
    },
    {
        "text": "I introduce a relative shift regression",
        "start": 3073.079,
        "duration": 4.26
    },
    {
        "text": "which is a multiple regression framework",
        "start": 3075.42,
        "duration": 4.62
    },
    {
        "text": "that Associates the universe unitary",
        "start": 3077.339,
        "duration": 4.74
    },
    {
        "text": "response with high dimensional zero",
        "start": 3080.04,
        "duration": 4.62
    },
    {
        "text": "inflated compositions and",
        "start": 3082.079,
        "duration": 5.04
    },
    {
        "text": "because of the the way the model is set",
        "start": 3084.66,
        "duration": 4.919
    },
    {
        "text": "up the coefficient actually capture the",
        "start": 3087.119,
        "duration": 4.321
    },
    {
        "text": "effect of Shifting concentration on the",
        "start": 3089.579,
        "duration": 4.861
    },
    {
        "text": "outcome and it naturally both methods",
        "start": 3091.44,
        "duration": 5.7
    },
    {
        "text": "can accommodate guidance from the",
        "start": 3094.44,
        "duration": 6.179
    },
    {
        "text": "taxonomic tree structure so it could be",
        "start": 3097.14,
        "duration": 6.479
    },
    {
        "text": "made more General in practice",
        "start": 3100.619,
        "duration": 6.0
    },
    {
        "text": "so with that I'd like to thank you and",
        "start": 3103.619,
        "duration": 5.041
    },
    {
        "text": "also happy to take any questions if you",
        "start": 3106.619,
        "duration": 4.5
    },
    {
        "text": "have and then the tools for both Masters",
        "start": 3108.66,
        "duration": 5.1
    },
    {
        "text": "are posted on GitHub so if you are",
        "start": 3111.119,
        "duration": 5.581
    },
    {
        "text": "interested you can try it out or uh if",
        "start": 3113.76,
        "duration": 4.68
    },
    {
        "text": "you have any questions or interested in",
        "start": 3116.7,
        "duration": 3.419
    },
    {
        "text": "collaboration",
        "start": 3118.44,
        "duration": 4.44
    },
    {
        "text": "um definitely feel free to email me so",
        "start": 3120.119,
        "duration": 4.98
    },
    {
        "text": "I'll be happy to explore",
        "start": 3122.88,
        "duration": 5.28
    },
    {
        "text": "um all various applications using this",
        "start": 3125.099,
        "duration": 4.921
    },
    {
        "text": "uh this approach",
        "start": 3128.16,
        "duration": 4.58
    },
    {
        "text": "thank you",
        "start": 3130.02,
        "duration": 2.72
    },
    {
        "text": "so I think we only have a few minutes",
        "start": 3135.42,
        "duration": 3.72
    },
    {
        "text": "for questions because I know that needs",
        "start": 3137.28,
        "duration": 4.26
    },
    {
        "text": "to be in pretty soon to go teach but if",
        "start": 3139.14,
        "duration": 4.199
    },
    {
        "text": "anyone has a question online you can put",
        "start": 3141.54,
        "duration": 4.14
    },
    {
        "text": "it in chat or either Zoom hand if anyone",
        "start": 3143.339,
        "duration": 3.841
    },
    {
        "text": "in the root another question feel free",
        "start": 3145.68,
        "duration": 3.86
    },
    {
        "text": "to ask",
        "start": 3147.18,
        "duration": 2.36
    },
    {
        "text": "therefore there are no questions but",
        "start": 3163.8,
        "duration": 3.12
    },
    {
        "text": "let's give it a couple minutes in case",
        "start": 3165.54,
        "duration": 4.86
    },
    {
        "text": "yeah I'm just interested uh you know is",
        "start": 3166.92,
        "duration": 5.939
    },
    {
        "text": "there do you have a way to detect and",
        "start": 3170.4,
        "duration": 4.38
    },
    {
        "text": "see different populations of different",
        "start": 3172.859,
        "duration": 3.96
    },
    {
        "text": "microbiometrics",
        "start": 3174.78,
        "duration": 4.26
    },
    {
        "text": "uh constituents with different",
        "start": 3176.819,
        "duration": 5.641
    },
    {
        "text": "severities of the periodontal disease",
        "start": 3179.04,
        "duration": 5.94
    },
    {
        "text": "I mean this is pretty pretty important",
        "start": 3182.46,
        "duration": 4.859
    },
    {
        "text": "stuff I mean you know it my",
        "start": 3184.98,
        "duration": 4.139
    },
    {
        "text": "understanding is that you know the",
        "start": 3187.319,
        "duration": 4.981
    },
    {
        "text": "microbiome even like varies depending on",
        "start": 3189.119,
        "duration": 5.581
    },
    {
        "text": "what tube it is so you know it's just",
        "start": 3192.3,
        "duration": 4.799
    },
    {
        "text": "really pretty amazing thing that's",
        "start": 3194.7,
        "duration": 5.58
    },
    {
        "text": "that's true so uh again this is only the",
        "start": 3197.099,
        "duration": 5.041
    },
    {
        "text": "first attempt and I believe a more",
        "start": 3200.28,
        "duration": 4.819
    },
    {
        "text": "granular study you know the",
        "start": 3202.14,
        "duration": 5.64
    },
    {
        "text": "definitely can reveal more information",
        "start": 3205.099,
        "duration": 5.681
    },
    {
        "text": "about that and so far the method we only",
        "start": 3207.78,
        "duration": 5.88
    },
    {
        "text": "use uh you know the cross-sectional data",
        "start": 3210.78,
        "duration": 4.74
    },
    {
        "text": "at a single tooth",
        "start": 3213.66,
        "duration": 3.72
    },
    {
        "text": "um to study this relation since the",
        "start": 3215.52,
        "duration": 4.02
    },
    {
        "text": "original goal of this study is really",
        "start": 3217.38,
        "duration": 4.32
    },
    {
        "text": "trying to study the r microbiome the",
        "start": 3219.54,
        "duration": 3.779
    },
    {
        "text": "association of our microbiome with",
        "start": 3221.7,
        "duration": 3.899
    },
    {
        "text": "diabetes so this is sort of a a",
        "start": 3223.319,
        "duration": 6.3
    },
    {
        "text": "secondary outcome that people uh use in",
        "start": 3225.599,
        "duration": 7.26
    },
    {
        "text": "this in the study but I agree that you",
        "start": 3229.619,
        "duration": 5.641
    },
    {
        "text": "know a more granular study would reveal",
        "start": 3232.859,
        "duration": 4.98
    },
    {
        "text": "more interesting information from it but",
        "start": 3235.26,
        "duration": 4.079
    },
    {
        "text": "potentially this method can also be",
        "start": 3237.839,
        "duration": 4.861
    },
    {
        "text": "generalized to accommodate that goal",
        "start": 3239.339,
        "duration": 5.76
    },
    {
        "text": "yeah I can definitely see that it's a",
        "start": 3242.7,
        "duration": 4.68
    },
    {
        "text": "very promising area thanks so it's very",
        "start": 3245.099,
        "duration": 4.52
    },
    {
        "text": "interesting",
        "start": 3247.38,
        "duration": 2.239
    },
    {
        "text": "um I actually have a question about um",
        "start": 3254.88,
        "duration": 3.66
    },
    {
        "text": "when you end up posting the results for",
        "start": 3256.619,
        "duration": 4.321
    },
    {
        "text": "different economic levels uh can you",
        "start": 3258.54,
        "duration": 4.019
    },
    {
        "text": "speak a little louder so I have a",
        "start": 3260.94,
        "duration": 4.34
    },
    {
        "text": "trouble here",
        "start": 3262.559,
        "duration": 5.341
    },
    {
        "text": "yeah it will hurt yeah",
        "start": 3265.28,
        "duration": 4.059
    },
    {
        "text": "okay",
        "start": 3267.9,
        "duration": 3.48
    },
    {
        "text": "um can you hear me clearly now very good",
        "start": 3269.339,
        "duration": 3.0
    },
    {
        "text": "yeah",
        "start": 3271.38,
        "duration": 4.26
    },
    {
        "text": "okay I had a question about",
        "start": 3272.339,
        "duration": 4.5
    },
    {
        "text": "um the",
        "start": 3275.64,
        "duration": 3.66
    },
    {
        "text": "um pineal aggregation example were there",
        "start": 3276.839,
        "duration": 4.381
    },
    {
        "text": "any um predictors or repentance you",
        "start": 3279.3,
        "duration": 4.5
    },
    {
        "text": "found for what determines um for your",
        "start": 3281.22,
        "duration": 4.2
    },
    {
        "text": "principal components will be at the",
        "start": 3283.8,
        "duration": 3.24
    },
    {
        "text": "species level versus The Genius level",
        "start": 3285.42,
        "duration": 5.54
    },
    {
        "text": "versus family level the",
        "start": 3287.04,
        "duration": 3.92
    },
    {
        "text": "um so you mean the dimensional reduction",
        "start": 3291.54,
        "duration": 7.079
    },
    {
        "text": "part right yes uh can you repeat your",
        "start": 3294.48,
        "duration": 7.56
    },
    {
        "text": "question I don't quite got your question",
        "start": 3298.619,
        "duration": 5.22
    },
    {
        "text": "um when you were going to the final real",
        "start": 3302.04,
        "duration": 4.14
    },
    {
        "text": "example and showing when you further",
        "start": 3303.839,
        "duration": 3.901
    },
    {
        "text": "dimensional reduction steps for which",
        "start": 3306.18,
        "duration": 3.6
    },
    {
        "text": "one you select so can you go to the",
        "start": 3307.74,
        "duration": 3.599
    },
    {
        "text": "regression analysis",
        "start": 3309.78,
        "duration": 5.72
    },
    {
        "text": "um like slide 22 I think",
        "start": 3311.339,
        "duration": 4.161
    },
    {
        "text": "okay 21.",
        "start": 3316.16,
        "duration": 5.199
    },
    {
        "text": "this one this one yes",
        "start": 3318.78,
        "duration": 4.02
    },
    {
        "text": "um I was curious",
        "start": 3321.359,
        "duration": 3.541
    },
    {
        "text": "um if you found it there were any",
        "start": 3322.8,
        "duration": 5.46
    },
    {
        "text": "patterns or predictors which um",
        "start": 3324.9,
        "duration": 5.4
    },
    {
        "text": "um after you did the computations for",
        "start": 3328.26,
        "duration": 3.839
    },
    {
        "text": "minimizing the loss functions which you",
        "start": 3330.3,
        "duration": 5.46
    },
    {
        "text": "could use to figure out um the patterns",
        "start": 3332.099,
        "duration": 5.52
    },
    {
        "text": "for if this is genius level family level",
        "start": 3335.76,
        "duration": 4.079
    },
    {
        "text": "or domain level which ends up as the",
        "start": 3337.619,
        "duration": 5.101
    },
    {
        "text": "final dimensional component yeah that's",
        "start": 3339.839,
        "duration": 5.881
    },
    {
        "text": "a very good question so we have actually",
        "start": 3342.72,
        "duration": 6.3
    },
    {
        "text": "haven't died for this example uh trying",
        "start": 3345.72,
        "duration": 5.399
    },
    {
        "text": "the the paas the dimensional reduction",
        "start": 3349.02,
        "duration": 4.14
    },
    {
        "text": "approach the the main difference between",
        "start": 3351.119,
        "duration": 3.96
    },
    {
        "text": "these two is one is supervised one is",
        "start": 3353.16,
        "duration": 4.02
    },
    {
        "text": "unsupervised right so",
        "start": 3355.079,
        "duration": 3.54
    },
    {
        "text": "um the dimension reduction if you you",
        "start": 3357.18,
        "duration": 3.06
    },
    {
        "text": "can also apply the dimensional reaction",
        "start": 3358.619,
        "duration": 4.5
    },
    {
        "text": "today and say you know whether you can",
        "start": 3360.24,
        "duration": 6.18
    },
    {
        "text": "replicate to some extent this reduction",
        "start": 3363.119,
        "duration": 5.181
    },
    {
        "text": "uh",
        "start": 3366.42,
        "duration": 4.98
    },
    {
        "text": "structure right without using the",
        "start": 3368.3,
        "duration": 4.96
    },
    {
        "text": "response that would also give you some",
        "start": 3371.4,
        "duration": 4.86
    },
    {
        "text": "alternative perspective of whether you",
        "start": 3373.26,
        "duration": 6.54
    },
    {
        "text": "know the the supervised reduction result",
        "start": 3376.26,
        "duration": 6.24
    },
    {
        "text": "is mainly because of the data structure",
        "start": 3379.8,
        "duration": 5.1
    },
    {
        "text": "or because they have association with",
        "start": 3382.5,
        "duration": 5.4
    },
    {
        "text": "the outcome but uh that we haven't done",
        "start": 3384.9,
        "duration": 3.84
    },
    {
        "text": "yet",
        "start": 3387.9,
        "duration": 3.959
    },
    {
        "text": "but that's a good point yes",
        "start": 3388.74,
        "duration": 5.94
    },
    {
        "text": "we do have a question online uh I know",
        "start": 3391.859,
        "duration": 4.561
    },
    {
        "text": "we're about out of time Nick if you want",
        "start": 3394.68,
        "duration": 2.939
    },
    {
        "text": "to unmute yourself and ask your",
        "start": 3396.42,
        "duration": 2.939
    },
    {
        "text": "questions and then we can decide if",
        "start": 3397.619,
        "duration": 3.121
    },
    {
        "text": "you've got time to answer it or if you",
        "start": 3399.359,
        "duration": 3.48
    },
    {
        "text": "want to take it out there well yeah I",
        "start": 3400.74,
        "duration": 3.24
    },
    {
        "text": "was sort of asking the same question I",
        "start": 3402.839,
        "duration": 2.701
    },
    {
        "text": "guess like what what influenced your",
        "start": 3403.98,
        "duration": 3.359
    },
    {
        "text": "choice to uh",
        "start": 3405.54,
        "duration": 3.299
    },
    {
        "text": "uh or what should influence your choice",
        "start": 3407.339,
        "duration": 4.02
    },
    {
        "text": "between doing the uh pre-aggregation or",
        "start": 3408.839,
        "duration": 4.441
    },
    {
        "text": "using regularization to do to do the",
        "start": 3411.359,
        "duration": 3.061
    },
    {
        "text": "aggregation",
        "start": 3413.28,
        "duration": 3.9
    },
    {
        "text": "yeah so it really depends on your goal",
        "start": 3414.42,
        "duration": 4.62
    },
    {
        "text": "right so if you know you have a",
        "start": 3417.18,
        "duration": 3.24
    },
    {
        "text": "particular response that you want to",
        "start": 3419.04,
        "duration": 2.7
    },
    {
        "text": "associate with definitely you can",
        "start": 3420.42,
        "duration": 3.24
    },
    {
        "text": "directly go with this uh you know",
        "start": 3421.74,
        "duration": 4.98
    },
    {
        "text": "supervised approach there's no need to",
        "start": 3423.66,
        "duration": 5.699
    },
    {
        "text": "do this uh dimensional reduction in the",
        "start": 3426.72,
        "duration": 4.44
    },
    {
        "text": "first place but the dimensional",
        "start": 3429.359,
        "duration": 3.901
    },
    {
        "text": "reduction is sort of a more General tool",
        "start": 3431.16,
        "duration": 4.74
    },
    {
        "text": "that it can use to simplify the data so",
        "start": 3433.26,
        "duration": 5.099
    },
    {
        "text": "you may be able you may be interested in",
        "start": 3435.9,
        "duration": 4.26
    },
    {
        "text": "learning this uh you know Network",
        "start": 3438.359,
        "duration": 4.2
    },
    {
        "text": "structure among the taxa but the the",
        "start": 3440.16,
        "duration": 4.8
    },
    {
        "text": "data is just a way too high dimensional",
        "start": 3442.559,
        "duration": 5.421
    },
    {
        "text": "to directly be applied so then you can",
        "start": 3444.96,
        "duration": 5.879
    },
    {
        "text": "try this dimensional reduction tool",
        "start": 3447.98,
        "duration": 5.32
    },
    {
        "text": "first right to simplify our data while",
        "start": 3450.839,
        "duration": 4.081
    },
    {
        "text": "still maintaining the majority of the",
        "start": 3453.3,
        "duration": 3.779
    },
    {
        "text": "information in the data and then apply",
        "start": 3454.92,
        "duration": 4.439
    },
    {
        "text": "the network analysis so it's really two",
        "start": 3457.079,
        "duration": 5.221
    },
    {
        "text": "different tools that it can be can be",
        "start": 3459.359,
        "duration": 5.581
    },
    {
        "text": "used in practice but short short answer",
        "start": 3462.3,
        "duration": 4.559
    },
    {
        "text": "is if you are interested in regression",
        "start": 3464.94,
        "duration": 3.899
    },
    {
        "text": "then you can directly use this without",
        "start": 3466.859,
        "duration": 3.72
    },
    {
        "text": "using the dimensional reduction because",
        "start": 3468.839,
        "duration": 4.74
    },
    {
        "text": "it does build into the official",
        "start": 3470.579,
        "duration": 5.54
    },
    {
        "text": "aggregation you in it",
        "start": 3473.579,
        "duration": 7.201
    },
    {
        "text": "is that a question yes okay thank you",
        "start": 3476.119,
        "duration": 6.761
    },
    {
        "text": "I think we probably need to wrap up yeah",
        "start": 3480.78,
        "duration": 3.66
    },
    {
        "text": "so I probably have to run but thank",
        "start": 3482.88,
        "duration": 4.5
    },
    {
        "text": "everyone for your interest and if you",
        "start": 3484.44,
        "duration": 4.32
    },
    {
        "text": "have any further questions feel free to",
        "start": 3487.38,
        "duration": 4.26
    },
    {
        "text": "email me and I'm happy to discuss in",
        "start": 3488.76,
        "duration": 4.5
    },
    {
        "text": "more depth",
        "start": 3491.64,
        "duration": 5.12
    },
    {
        "text": "great all right thank you",
        "start": 3493.26,
        "duration": 3.5
    }
]