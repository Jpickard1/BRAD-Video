issues that are kind of happening right now in quantitative biology or are you know resurging in in new ways i mean one thing that's been arising in recent years is of course electronic medical records um and you know the issues that go along with those their usage their you know standardization and things like this so what we try and do in these topics is give a wide view and particularly try and give views that maybe we don't get when we're in the lab doing our research and so we have a variety of panelists today and we've changed the order slightly so first we're going to have dr adler milstein who's from uh you know public health talk about kind of a broader bigger picture view of this we'll then have dr huela talk about the regulatory issues um and then we'll have dr hanauer talk more about the research and technical issues that he deals with his research so first i would like to welcome dr adler milstein uh dr adler milstein is an associate professor in the school of information in the school of public health um and as i understand that you've been you've worked with congressional uh groups for this kind of work right yeah all right so let me just bring up her i got a promotion i'm an assistant professor so oh i'm sorry no no well i know thank you so much okay okay wonderful well i'm so happy to be here today and um my voice is i just came off of three hours of teaching so i think my voice will hold out for another 10 or 15 minutes um but uh this is um you know as as your introduction alluded to this has been an area of incredible change and um the piece is i think almost uh breathtaking and it's been a really interesting set of issues to study for someone whose background is really in health policy that that's what my degree is in that's what my passion is and um and have sort of gotten sucked into uh electronic health records and health i.t because it's been one of the areas in which we've had the most active uh policy efforts um over the past few years so i'm gonna just try to set the stage we thought it made sense for me to go first to sort of you know give you some big picture sense of what's been happening across the nation and then dive into some of the more specific issues um so that's what i want to spend the next 10 to 15 minutes doing so uh as i said i'll just sort of do very brief policy context i'm going to talk about this uh really transformative piece of legislation uh in the world of electronic health records and then just try to give you a brief sense of where we've ended up now um about seven years after the the passage of that legislation so i'm going to give a report card uh on on sort of what's transpired since uh since this was passed so why electronic health records i mean i almost don't think we need to have this discussion anymore but it is i think a helpful starting point and it really came from the recognition that sort of almost anything that we were trying to do in the health care system and even including sort of public health and research was just not feasible in a world in which health information was stored in paper-based medical records if you want to do sort of any information management task and i showed you that room and said have fun you would say i think i'm going to pick a new job and so it just i think became really clear that this was not a sustainable path forward for uh for the u.s healthcare system and so you know really key domains such as just being sure that information can follow patients across care delivery settings to ensure that they're getting safe and effective care right you just can't do that effectively or efficiently in a paper-based world so i think there were sort of so many reasons that were really pointing to the need to uh to help the healthcare industry catch up to other major industries uh all of which had computerized you know in the 80s and 90s in the sense that like health care had to be next um and so i think there was just sort of not really a uh you know a policy debate about uh whether or not we should do this the question was really how what's the sort of right tool uh and and particular sort of should we use policy as something to drive electronic health record adoption in the healthcare system so the first question as we started to sort of recognize the importance of moving towards electronic health records was well where does the country stand what are adoption rates today and so i'm showing you here at the data that was available uh that sort of tracked where the country stood with electronic health records and this is data from from sort of a u.s physician and what we realized in sort of the early days uh uh was that you know adoption rates looked pretty low right i mean it was not you know we were nowhere even near the halfway mark uh but also that this data was coming from surveys of physicians who were asked do you have an electronic health record or not and the question was when someone says yes do they even know what they're saying yes to right and they could have very different definitions in their head of what it meant to have an electronic health record so pretty quickly it became clear that we needed to collect better data to really have a picture of where the country stood and the first step with that was sort of defining what is an electronic health record and the approach that was taken was to basically define a set of electronic functionalities and say if you have these electronic functionalities in your practice or in your hospital then you at least have a basic electronic health record and then sort of this more comprehensive list of functionalities with considered a comprehensive um so what you can see is these are things just you know do you have electronic uh patient demographics recorded uh do you have problem with medication lists can you order medications electronically so functions that you would not expect a lot of variation if i asked a physician do you enter your prescriptions electronically or not but there's not a lot of sort of user bias that's likely to enter into whether they say say yes or no so this essentially became the national standard for how to think about do physicians and hospitals have electronic health systems using these definitions of basic and comprehensive and then we went back to the data and for the first time as you can see in 2006 we asked those more detailed questions and the rates dropped off pretty substantially right so what you saw is that there was a lot of difference in what people were thinking constituted an electronic health record um and when we said what percent of u.s physicians have a comprehensive health record we were at three percent right and so this was pretty staggering to think like you know in you know midway through uh the the 2000s these rates were really low and i will tell you on the hospital side they were even lower so really created that i think this sense of urgency uh that you know we need to do something right these these rates are low and they don't appear to be going up very quickly um and so it's really a case that seems like a policy intervention is needed i'm flexible maybe if is it going to count against my 10 or 15 minutes i'm sorry i forgot to mention this but at the end of the the three presentations we're actually going to have a panel uh for all questions to be asked so yeah i think there's quick clarifying questions yeah so what did it it was the survey sort of agnostic to like who the vendor was and it was just really about do you have this functionality in your practice yes or no um and so that could be four different systems that when pieced together gave you all those functions or not it was actually one of the criticisms of that definition was that it doesn't tell you how well integrated those functions are or not but it you know the sense when they're that low we shouldn't even you know be that critical about what's going on um so uh so these same surveys then asked about barriers right so if you haven't adopted what are the key challenges and again the sort of national data made it clear that there were a few set of really high priority issues and the biggest was was sort of money uh the sense that both uh these systems are expensive and i don't have the capital to invest in them as well as uncertain return on investment if i invest in one of these systems am i gonna benefit or are these benefits gonna accrue to patients payers sort of other third parties um there was also a set of issues around how do i pick a system that is gonna meet my needs that a vendor that's still going to be around a year or two from now as well as you can see some concern about do i have the capacity to implement do i know how to go through this very disruptive change and what's going to be the impact on my productivity so a range of barriers to address but i think it was pretty clear from the start that we had to start with addressing uh the financial barriers uh these questions were also asked in terms of what uh facilitators what would encourage you to adopt electronic health records and then you know the data was very consistent right it was uh monetary incentives for purchase or some kind of additional payment so i think the signal to policymakers was quite clear uh that if you want the country to uh increase adoption of electronic health records there needs to be some kind of financial incentive type intervention so this sort of all culminated uh in the passage of the hi-tech act this was part of ara american recovery and reinvestment act which if you'll recall was all about sort of shovel-ready projects how can we stimulate the us economy with things that were sort of ready to go uh today um and this was just i think a relatively non-controversial part of high tech excuse me a part of ara which was to say you know if let's we think electronic health records and health care are good um and the data is pretty clear that we need to uh stimulate their adoption using financial incentives and so this sort of opportunity for aura just i think created the perfect forum to uh to specifically target financial incentives for electronic health records so this sort of shows you all the pieces that were in high tech but really at the center of it was this idea of meaningful use of electronic health records from a policy perspective what they didn't want to do was give doctors a lot of money to have computers and unopened boxes on their desks and so the question was how do we give doctors money to not just adopt the system but use them in ways that we think will really improve care right those are the outcomes that we ultimately cared about um so the policy challenge was sort of how do we how do we give them money for something that will ensure that they're actually doing what we care about and what we think is valuable so that was sort of the core policy challenge of high tech was how to do that how do you structure this uh policy intervention in that way and then there were sort of again a much longer talk you talked about all these other pieces that went into it um but that was really you know the the heart of it but they also wanted to be sure that for example health information exchange could happen that the systems could share information with each other um as well as uh make sure that there was some sort of support for physicians who were going through this adoption process so they set up at the very top box there something called the regional extension centers these are essentially geek squads for doctors who can go to their offices and help them adopt so they you know they try to i think really approach this in a comprehensive way uh that address the various barriers so just sort of a little bit more detail on this meaningful use piece um so again as i said these are financial incentives um and uh they are structured they they flow through medicare and medicaid so they're extra payments that doctors get from medicare and medicaid um and there was a lot of sort of design decisions and you know the factors that went into uh the specifics of the regulations uh but in short uh if you are a provider who sees a lot of medicare patients you can get up to forty four thousand dollars uh for adopting an electronic health record system and meeting these meaningful use criteria and if on the medicaid side they were a little more generous because they were concerned that medicaid providers uh may need a little bit more money and health in order to keep up um and they did not want to sort of have these policies result in some kind of digital divide where medicaid providers got left behind um they they sort of did this trick where they front loaded the incentive so the earlier you started the program the more money you got and then for the medicare side it actually converts to penalties and so last year was the first year that providers that did not participate in this program actually got paid less because of it um so it's often described as a carrot and stick program so they got some of the money uh some upside incentives and then it converted to penalties and as far as we know for the near future that will continue um so just what are these meaningful use criteria uh just to give you a sense i mean they are very specific about how you have to use electronic health records to sort of capture data and manage care so these are things like you have to submit 30 of your prescriptions electronically and you have to capture you know basic patient demographics in a structured format so you can go and find the specific criteria that that basically say how electronic health records have to be used and then providers attest that they did that and then they get these uh these incentive payments um and it's i think you know if we step back it's sort of a really remarkable program it's hard to think about other policy efforts that have come into an industry and really dictated how to use technology to do their job right most other industries adopted technology on their own and has had a much lighter sort of regulatory framework around it so it's really in some ways i think a one-of-a-kind program in terms of how you know precise this was in terms of you know how to use technology to support healthcare delivery the other sort of interesting thing in the program was that there are these stages that roll out over time it actually was in the original legislation uh from congress that said uh you put in these criteria and they have to get progressively harder over time so that and i think they may have been progressively more valuable over time which also means progressively harder and so what we're seeing is that every few years a new stage of the program comes out that asks doctors and hospitals to use electronic health records in more advanced ways and so that's been i think both you know a good thing in the sense that you do want to make the criteria more valuable over time um but there's also i think been a lot of frustration with how uh fast uh they're moving and whether they're actually getting the criteria right at all foreign yeah yeah and i think the problem is is that change of mind is corresponding with when the incentives are converting to penalties and i think it's actually making it tricky to detect whether this is truly not valuable or whether just now that there's no free dollars and so i mean i personally agree yeah absolutely so that is i mean again this is a much longer than a 15-minute discussion but there's been i think a lot of pushback given how sort of a top-down and specific this program has been and really sort of dictating the providers like this is how you have to use this to manage care okay um so again i think you know thinking about this is like you know what was the policy challenge in getting this right i really had to do with sort of what level of incentive and how to define these criteria in ways that were going to be valuable and we didn't really have a lot of you know guidance to know how to get this right and so i really think this is an area in which policymakers had to take a guess at how much the pay providers and how to structure these criteria and again i think they you know they probably got some of it right but not all of it so let me just spend a minute on on that uh so i think the first question is so did it drive adoption have we seen an increase in electronic health record adoption since the meaningful youth program came online um so i'm going to start with hospital data uh so in 2008 which was the first year we had really good data we saw uh that nine percent of hospitals had at least a basic electronic health record and it was sort of creeping up each year the incentives start and it's almost been you know sort of a classic hockey stick a huge increase in hospital ehr adoption uh in the most recent numbers three quarters of hospitals had at least a basic system and those that didn't were very close right they were usually just missing one or two of those functionalities it's been a little bit less of a success story on the sort of physician outpatient physician side um you can see they started a little bit higher again we're sort of creeping up a little bit year over year the incentives start and again just have not seen that same hockey stick growth it's been a lot more sluggish i think the sense is that you know small physician practices have really had a harder time sort of keeping up with uh with the program uh as well as just adopting electronic health workers to begin with okay so now i'm going to this is my last slide which is sort of a high tech report card where i can just i just want to sort of preview some of both what's gone well as well as some of the the challenges um so uh so i just showed you data on adoption of ehrs if we're gonna say sort of one thing has worked well with these policies i think it's that on the hospital side i give them an a i mean i really think that we've seen a big increase in adoption of electronic health records there's some question of whether that would have happened anyway uh had uh had there not been an incentive so sort of what's the counter factual um and i actually think we have a pretty good counter factual in the sense that there were hospitals were not eligible for meaningful use incentive payments and they really have not adopted um and so i i'm actually convinced uh that um that you know if we're going to give high tech an a on anything it's really driving adoption among hospitals and again i think now there's some questioning about whether it's worth sticking with the program but there was over the last five years i think it's really driven a lot of adoption uh i give them a b plus on physician adoption as i said i think we didn't quite get the program right to convince um you know the majority of physicians to adopt but we're over 50 percent and i think we're really going to have to hope that from here on out uh that you know that there's going to be there's not going to be more you know incentive payments but that they're going to be sort of other forces health reform etc that help pick up the physicians that haven't yet adopted almost everything else oh sorry this is not you know i'm just gonna go back and talk to you so my red doesn't get in the way uh i have to say that the rest of the report card is gonna start to get pretty depressing um i think oh absolutely so i will just um say that i think sort of almost everything else we really have struggled with this includes things like getting physicians uh getting uh like long-term care providers sort of all of the providers who are not uh part of the financial incentives to be sure that they're keeping up i feel like we built great highways and then we didn't pave any of the roads off the highways and so you can get great hospital care now and then you transition to a long-term care facility and it's just you know very you know going back 10 years into the dark ages i think we have not done a great job of engaging patients to interact with their data i think we have really not done a good job of interoperability moving data around the healthcare system between different provider organizations usability david is an expert in this i'm not sure he's going to talk about it but i think the providers hate these systems by and large and they are not what we consider to be very usable and i think there's some real questions about data quality so we have a lot more electronic data that's now captured in these systems but particularly for folks like you who might want to access and use that data for research and other purposes i think there's real questions about whether it's good data that's actually going to tell us something meaningful so i think uh lo and behold uh we've come a long way but uh we are nowhere near uh the peak or the end of this story so next we're going to have uh dr julia enrolled to jd and i believe that you know euros doctors i'll use the honorary there she is the director for regulatory compliance in the medical school um and she's going to talk to us about talk to us about the related issues there in the hospital you make a complaint oh i'm sorry um it's a sign i can't tell okay yeah these are my slides that's hard but while we're waiting for my slides to come up i'm here to talk about the use of electronic records and provide a legal and an ethical perspective for you to contemplate as we think about how we can use some of these data so first of all large data sets are very important to research and they're driven by a lot of the meaningful use efforts that have been going on in the collection of large data sets and in our electronic medical records the important thing to think about though is what are the risks to the individuals who are the subjects of those data and we have to think about that because it's a very important concept so we're concerned about basically three things we're concerned about harm to the individuals perhaps maybe someone being able to re-identify the information or perhaps maybe there's there's direct identifiers in these databases that can identify who they are and perhaps um cause them any kind of harm like perhaps financial harm identity theft is quite um a big industry right now and so being able to identify a patient and use their identity to use it their medical record for something perhaps maybe um purchasing cells oxycontin as an example that's a great big market for oxycontin so there's a lot of impetus for us to try and keep the data private as much as we can there's also the reputational harm for the institution as well as the individual and i will say that medical records out on the market today runs about fifty to ninety dollars a record for exceeding a credit card record so this is a hot commodity right now and we need to do everything that we can to protect it and also because medical records have a longer shelf life today than a credit card does there's a lot of institutional processes that are in place in the commercial world that will um alert us right away when someone's using our cards uh erroneously but not so much if the medical breakfast being used that that takes a little bit more time so there's more opportunity so what i wanted to do is set a baseline of health law so health information privacy is federal law and what it is is called hipaa how many are familiar with what hipaa is and what it does marvelous i've saw nearly every hand go up and that's wonderful we'll get into a little bit of detail though just to refresh your memories so um the u.s department of health and human services issued privacy rules to implement requirements that were part of the health insurance portability accountability act which is hippa and those rules establish standards of privacy of individually identified identifiable health information privacy standards also talked about when we can use information and how further we can disclose that information and specifically the information we're talking about is what's identifiable which has a name of protected health information and that would be something that could identify us directly our name social security number medical record number but also indirectly which a lot of us don't really think about but indirect could be our um you know a treatment date or something like that that's within the data elements considered by hipaa to be regulated as protected health information privacy the privacy rule also establishes conditions under which um hit that point but the last point here i wanted to make stress and then what goals for us is that the privacy rule really tries to balance patients privacy rights with the need to use this information for other purposes and one of those major purposes here in the academic world at the university of michigan is for research and also for clinical quality improvement we need to have this information so that we can conduct our research and also do our clinical quality work which is really related to how the hospital can improve its delivery of care system what is protected under hipaa um individually identified information and let's go over the definition of what that means that means that it's any information that's collected in the course of treatment billing or operations that a covered entity would collect you know the university of michigan hospital system is a covered entity by definition under hipaa and it's about an individual's past present future physical or our mental health or condition information the prison of provision of health care to the individual so when we provide that care we collect that information it goes into our electronic medical record it is protected health information to the extent that it is identifiable there's other this is more into the research realm there's other laws that help protect the the privacy and the um preventing harm to study subjects and that's the common rule it's a federal program federal policy as well and the common rule establishes standards of ethics for government-funded research in and that is primarily if it is government-funded research so not if it's something that's privately sponsored but we do try to apply the common rule commonly across our different research applications here at the institution because it becomes too difficult to try to say oh well this is government-funded their footfalls are these rules versus being a privately sponsored image too but the requirements for assuming compliance what it provides is requirements for assuming compliance for research institutions it provides requirements for researchers obtaining and documenting informed consent which is very important when we're conducting a research as well as authorization to use protected health information which are two separate things um requirements for institutional review boards you know what how do they staff them who's the members and and really basically what their processes of reviews are so it provides all the guidance that we need for those applications and um also this is an interesting thing um i think it'd be important to know is that the notice of proposal mccain went into effect to take a look at this regulation and um it hasn't really been looked at seriously since 1981 and as you learned from the the talk that came before mine that there's just been a explosion of electronic data an explosion of the need to have people who want to have that information and do good things with it so um rules aren't keeping up and so what they're looking at doing is perhaps maybe um creating better protections if they can um of course you know when people have rules and they they get concerned about maybe interfering with their ability to conduct research so they get worried about things like that happening so there's going to be a lot of give and take that's going to challenge how the rule ends up but what they would like to do is make changes that will improve transparency in the informed consent process they'd like to generally require informed consent for secondary use of biospecimens and this is very key because often we will have biospecimens that are left over from a procedure that people want to use for secondary purposes and so there's a lot of conversation about how we can protect those individuals and the biospecies itself also looking at how to right side the review process that the institutional review boards are required to do putting perhaps less oversight on things that are less risky or harm to an individual subject and more process into research that would be a little bit more sensitive and then also too which which is really brings joy to me is better harmonization with the hipaa privacy rules uh right now we are we struggle with two different rules and we try and figure out when one applies really hipaa is is universally should universally be applied but i think that there's some confusion among irbs as to when in how it should be applied so so i'm happy to see that this is something they're going to be doing the the published uh those public rulemaking was published in september of 2015 the comment period has closed already i believe it closed on january 6 2016. so we've had our opportunity to comment and we'll just have to wait and see what the regulators end up with um part of the harmonization that's being proposed is to start using some of the hipaa definitions so here i have the three major types of data sets and defined as typically defined then we have data sets where there's no identifiers so those are considered de-identified data sets and hipaa does not regulate them any further than once they've you've appropriately de-identified that data set but that's not to say there's not a probability that you could this or re-identify a person because it is possible but there's a low probability of it happening at least from from hipaa's regulatory perspective data sets with indirect identifiers are called limited data sets those are available for research purposes and they don't require that we ask our patients to use their information a limited data set does not require authorization um it has you can include dates and unlimited data sets so with that there's a moderate based on hipaa's perspective probability of reidentification there's datasets which have direct identifiers and those are the most concerning and when we use those sometimes it's necessary in research it's not that they can't be used in research but we have to take great care in how those are used because they directly identify who that person is the identification standards there's two method methodologies that can be used there's the expert determination methodology and then there's a safe harbor i think here at the institution we primarily use safe harbor um you know and that's really basically stripping out the 18 different identifiers that that hipaa regulations have identified as being protected health information and then using that in combination with that not having knowledge of the possibility or probability of re-identifying individuals in that data set so with that um we say that if we have depending on the dataset we consider what is the risk of re-identification so it's always difficult to achieve the balance of protecting the privacy of the individuals who are subject of that information with the need to use that information so this diagram is just trying to show that with each bit of information you have about a person you really run the the probability of re-identification increases so you start with an anonymized data set an anonymized data set is something that contains absolutely no identifiers in there whether it is a date that would not be there be basically stripped all of anything that we could possibly think of as being an identifier then there is the identified safe harbor or of course the other methodology all the way up to identifiability so um but you think about that and you're just thinking about these in singular data sets we think well we've anonymized the data set then we can't identify who it is but when we talk about big data sets and we start linking these data sets the probability of identifying individuals increases and with that there's been a couple of instances where people have shown that you can take anonymized data sets and actually re-identify individuals so the first instance is um there's an individual who used de-identified data that was released by a insurance group and they combined that with voting lists and they were able to identify that a former massachusetts governor was part of that data set and his name was william weld quite famous yes and what that study did lead to is trying to improve the hipaa regulations and the identification identification provisions and guidance also there's the netflix example where we've had um there was a public data set of about 50 000 netflix users um who were netflix thought it was an anonymous database or de-identified database it was about a bunch of ratings and they released that data set and there was an individual who was able to figure out who those individuals were there's a paper on it i can get you the link if you'd like to review that but they identified users and uncovered potentially sensitive information about them um this resulted in well part of the fact that they were able to be re-identified did end up being part of a lawsuit a class-action lawsuit was filed against netflix and um it was invited what it was was that they said that netflix violated the federal video privacy protection act and i gotta get my statistics on what actually ended up happening there so netflix uh paid nine million dollars to resolve the class action privacy lawsuit in addition to paying 6.5 million to 20 non-profit institutions and 2.5 billion lawyers i think i picked the wrong job but also they um required netflix to stop linking former subscriber names with their movie viewing history they um but it also interestingly and we do move slow a little bit in the law but interestingly there was an amendment that was fought that was approved for um amending the privacy protection law and that was the law states that you can't disclose information about an individual without their consent it was amended to require and not only just not disclose but also to destroy it but it was amended in 2013 to allow customers to give consent on an ongoing basis the amendment now allows netflix to integrate with facebook by sharing users movie selections with their social networking friends so there's a lot of things that had to take place so that you guys could do that in your facebook accounts um the other thing is um really that one of the other challenges of balancing privacy when we're talking about genomic data or dna sequencing data because our our data is unique to uh individuals so this was another an instance where using a computer and that the internet and public data um this team of researchers were able to identify 50 individuals who had submitted um personal genetic material to um as part of a research study so they're able to identify those individuals so you know keeping in mind that dna samples never can be truly anonymized so we have to figure out how do we work with these data sets and a lot of it involves a trust model a lot of involves doing what we can to put policies and procedures in place so there's a lot of things that come together and it really takes a village for all of us to maintain privacy and security of our research subjects but there's other laws there's the um that that govern genetics and there's the genetic information non-discrimination act which is gina and basically basically that is it protects the genetic privacy of public of the public by including research participants and makes it legal for health insurance or employers to request that information to be used in any other in any purpose which could cause them to any kind of harm or discriminate against them then there's also the nih genomic data sharing policy there's a lot of data sets that the nih has curated that they have a lot that have strong policies in place for access and use of that data hipaa does not apply to genetic information by the way if there's no way to to identify them by name or anything like that the only thing that hipaa says about genomic data is it can't be used in in or shared with insurance companies so um i think there's still a lot of that we can do to help protect subjects of research and and um individuals who want to participate in research and and with their privacy and this i think this this is one of my uh last couple of slides here but this is i think is interesting um done by the pew research center so a poll or about americans attitudes about privacy security and surveillance it's done in 2015 so it's fairly recent i looked at another one that was done about 10 years ago but it seems to be fairly consistent to what we are showing here and i just point out a couple of things the first is that there was 93 percent of adults who wanted to be in control about who had access to their information we know that we use our our patients information for research as researchers we know that a patient's not so much we tell our patients in their notice of privacy practice that we will use their information for health care operational purposes for treatment and for billing purposes we tell them that we'll use their information in research under two conditions we say we'll use their information with their consent or under a waiver um i don't know if they really quite understand what all of that means in terms of their privacy so we have a long way to to go to educate our our population of patients and the other thing too is when you're talking about health information exchanges a lot of our information all of our patient information goes into a health information exchange mine goes into that health information exchange yours goes into the health information exchange you can't stop um for that going forward into those large databases and then that could be further shared for other purposes so with that i ask you the question do you know where your data is [Music] you're talking about this particular one right here right this one well how they managed to do it i can't tell you i couldn't even begin to tell you but they were able to do that and they use they use um the internet so they had to have some information that was attached to that sample so it didn't have to be something that identified me directly but it was something that provided them enough information to make some guesses and and then of course statistically showing that they're able to actually directly identify the individuals well they had certainly they had information that they were able to use it was not identifiable but they were able to create the links to make it identifiable through their re-identification techniques all right thank you very much um so now we're going to have dr david uh hanauer director of the cancer center informatics corps right and an associate professor in pediatrics i give his talk okay so this is a slightly different topic than the others this is not really so much about ehrs but more about some of the things that you can do with data from ehrs i thought that might be a little bit more interesting to people in this audience just to understand the kind of things that you can do with the data i can certainly talk about ehrs or usability with ehrs another time if you wanted to do that so i thought i should just say you know we collect a lot of data as part of routine care that would be called the primary use of clinical data when we use it for other purposes that's called the secondary use of data and really what i'm talking about here is all the secondary use of data not for clinical care but really for all those other things like research and interestingly about 25 years ago someone had come up with what they call the first law of medical informatics where they said that data shall be used only for the purpose for which they were collected and we have obviously discarded that law because we use it for just about anything else that we can think of around the same time someone else came up with some other laws where they said that data always will be used for purposes other than originally intended and that's kind of really what we do around here so what i thought i would do is just take you through a pathway of research that i had done at one point that i thought would be of interest to all of you and it really started out with uh your uh group when i say your group i mean like i am a clinical informatics person i don't do omit stuff but this originally started with some uh someone who did so this so dan road yes a graduate from here and a rule tonight and they had this uh uh paper about uh how they were doing what they called molecular concept mapping and they were looking for associations among gene expression signatures and it was kind of an interesting uh work that they were doing and and basically they were looking at different genes that are expressing gene signatures and doing some chi-square tests and or fischer's exact tests to look to see which uh which genes were sort of being co-expressed together and they came up with these very interesting network diagrams to show the relationships of things that were being co-expressed together and i thought that was really fascinating and we were talking at one point we said well you know instead of sort of g you know the gene expressions expressing different genes what if we actually just said well what if these are patients expressing diagnosis is it a similar kind of thing and we actually just took their software through some of our patient data to see what we would get and so this is the paper that we had uh written based on that work we basically took uh one and a half million free text sort of at the time was free text diagnosis from our problem list from about three hundred thousand patients we use a tool they had built and just put it in there just to see what we would get and we got in we basically did an association analysis found almost 800 000 associations in this data set and we started exploring some of these manually and of course we can come up with our own interesting network diagrams uh if we sort of zoom in just to show you the kind of things that we found and these are color-coded based on kind of disease types just to show you that a lot of things clustered together i'm not going to go into too much detail here but we could find things that really kind of showed it work so that that green circle in the middle uh non-insulin dependent diabetes which is type two diabetes he sort of said well what did it find that was associated with it and really everything it found were things that we knew about and that kind of gave us some confidence that this thing may really be working and doing something real we found some things we didn't really know or couldn't explain like shingles and hypothyroidism but we could use these network diagrams to help us find out why that field might be related so when you look at the network diagrams we can see that well maybe it's because someone was being treated for cancer and through chemotherapy these things might be related because you can get your immune system suppressed through chemotherapy et cetera and and be hypothyroid as well we also found this very unusual one cat fighting depression couldn't really figure out what that was about at all it was really interesting i'll get back to that later uh so there's of course limitations of this right you can find these associations but there's no causation we had no temporal information so we didn't know what was happening first or second so we thought well you know maybe we can explore this further so then later on i had another attempt where i was actually trying to look for maybe some uh temporal associations between things and this was yet another paper and you can share the slides and you can look up the papers if you want but so what i used here was i used instead of these free text uh diagnosis these are icd codes these are basically diagnosis code views for billing um most institutions have these they're used heavily for research they weren't designed for research they were designed for billing uh they're often inaccurate i think uh julia had mentioned uh how lots of the stuff we have is inaccurate but you know you sort of take what you can get there's strange icd codes right we've got icd-10 codes they're struck by chicken injury due to legal intervention by explosive action involved in spacecraft burn due to water skis on fire there are so many codes out there i have no idea why or how they're there those are not the ones i focus on so we got this is data from our own health system here oh those are real code yeah i don't know why uh 1.6 million patients we had about 41 million time stamped icd codes we didn't actually have real data times we just got relative times this was really a de-identified data set it was just codes times and just a non-patient identifier to link them together and to show you kind of what we did here we could basically take a single code let's say chronic fatigue syndrome and that's what this uh that's what this middle line is here and then we could take other codes that were paired with it so basically if you look at this top line here each dot represents a patient who had both an intracranial injury and the code for chronic fatigue syndrome and then we could plot when they happened on a on a timeline and you can see here that almost every single patient who had both intracranial injury and chronic fatigue syndrome the intracranial injury happened before their diagnosis of chronic fatigue syndrome whereas if they had dysphagia almost every patient and again every dot is a patient had both of those codes it happened afterwards so that really suggested some temporal thing going on between those codes what's that what what what is it oh dysphagia sorry basically difficulty what they swallow and um sometimes speaking but usually uh and then voice and resonance disorder you can see that uh um this is sort of kind of on both sides to suggest that there's basically no temporal relationship it's sort of randomly communicated that's kind of what we did there and uh and of course we can come up with our diagrams here uh this time with arrows basically showing sort of the passage of time what came first and what came second we could look at this a different time scale the one that i circled here was a one that was 10 years apart basically just to show you that the first one was a pregnancy the second one was a delivery basically um but but at 10 years apart this is not the same pregnancy and delivery so you can get things that have really no meaning at all and you'll still get results of course you have to be careful with that so back to the cap fights in this data set here we had about 800 animal bites we had about 193 patients of the animal bites with depression 24 of those with the bite had depression um compared to 6.7 percent of the general population and the bite depression usually preceded the bite so it was of interest but you know again didn't really know uh what to make of that and of course there are lots of challenges and open questions to this the coding as i mentioned is often wrong and the big question which i think is still a huge open question is how do you identify interesting or novel findings and filter out what's already known and that's a really hard problem to do and part of this is because there's no data that you can download of this is what we know in medicine especially things are already in a pre-coded format like you can get a textbook but that's not the same as a nice clean data set that said yes we know these two diseases are related but there is medline so maybe that could be a source of this kind of data so this is this uh this study here where we actually try to do that just to explain what we had here we had our 1.6 million patients with 41 million codes from our own health system we had 20 and a half or 21 or so million abstracts from medline or pubmed which is the literature of um you know biomedical literature it was basically every single abstract ever published like you hope that there's a lot of information in there so what did we do here basically we took these uh um abstracts these citations the full text of the abstract not the full paper uh we ran a natural language processing tool that some of you may be familiar with called metamath uh we got umls codes which are basically codes that um can be it's sort of like a standard coding system for for biomedicine in general we took that mapped them back to icd-9 code which was basically the same language of our diagnosis codes we ran chi-square tests on both of these basically looking for what two diagnoses are mentioned in any single abstract what two diagnoses appear for any single patient to say well now we can compare them and see what we get and the hope was that we would have our big volume of clinical data these associations we found and the hope was that if we overlapped the ones that we found in the literature in medline we would maybe have this little bit of sliver left of things that did not overlap which would be these new interesting discoveries that we could find so that was what we hoped for the reality was sort of what you can see here in this diagram uh in the upper left hand corner which is that almost nothing overlapped at all so instead of discovering lots of new things we just basically had two different data sets that really didn't even overlap at all and that was kind of sad so i'll just get back to the cat thing right now for just a little bit because that i thought was interesting we actually did a paper about this um because i was really intrigued like what could possibly be going on here is this real and part of it was because the code for catfight is a very non-specific code there is at least at the time there was a code for dog bites but not one specific to cat fight so cat fights could have been uh any other kind of squirrels or other stuff so we thought we should look into this a little bit more so we went back to our data warehouse and pulled out um 1.3 million patients just adults we found every single patient with depression based on an icv code and then we did a manual chart review so we actually went through the clinical notes of these patients with cat fights and depression to figure out like did they really have a bite did they really have um was it a cat fight was a dog bite or something else so to really kind of just get to the point what we found here was that the overall probability of depression in our patient population here at michigan was nine percent uh seven percent of all males had depression eleven percent of all uh females had depression if they had a dog bite that really jumped up considerably um twenty one percent of males and thirty six percent of uh a women had depression in the patients who had dog bites and in cat fights for the men it was 24 which is still pretty high but not too much different but for women strangely 47 so basically in our 1.3 million patients among the people uh women who came into our health system to get cared for for a cat fight half of them had depression either before or afterwards and you know this does kind of raise issues about this kind of crazy cat baby sort of a stereotype of course there are other people out there who will say no there's no such thing as like this person writing in the new york times there uh this guy here uh he's a czech researcher he thinks your cat can make you crazy and there's actually been lots of uh research that has at least linked this toxoplasma gandhi um parasite to things like self-inflicted violence prenatal depression suicide rates in women obsessive-compulsive disorder refractory depression until they treated this parasite so there is some evidence there to suggest that maybe there could be something real going on um so the question of course really are cassie's nice benign creatures that everybody has are they actually causing lots of problems with people we don't really so this was a complicated journey we started with these association analyses delve into the data a little bit further found this strange relationship between cats and depression don't know really what it's about but you know it's just of interest so i thought that i would share that with you and that's all i have to say [Applause] all right so we've heard as promised you know a very wide field for this topic from you know uh usage rates throughout the nation to the regulatory difficulties and and things with emrs and also an example of their use and so at this point we opened the floor to questions um because these presentations were all very information dense hopefully you've got a few questions to ask our panelists um and for you know as much as a half an hour we'll be doing this um since i i've got the mic first i'm going to go ahead and steal my opportunity here something i noticed in your presentation was that for the incentives for using these uh emrs one thing that was listed is that if you don't use then you're legally liable and 55 percent of people said that that would be you know an incentive but 45 i guess didn't um now do i understand correctly that legally liable means that they would be in violation of the law and therefore subject to prosecution so i think it really has to do with what the standard of care is and so it's an interesting question of as these systems get more adopted does using them become the standard of care such that if you're not using them you're actually you know engaging in malpractice right and so that you know i may think that's something that's evolved over time we are not at the point now where people who don't use electronic health records are getting sued for malpractice but there are certain you can probably speak to this too right there are certainly cases in which uh you know whether or not things go right and in some cases go wrong in electronic health records or leading to new types of malpractice so it's it's an active uh area of intersection okay well and i guess that's where i was leading it it just kind of struck me as surprising that 45 of doctors said yeah i'll go ahead and just malpractice if this is uh if this is the law because i don't want to deal with emrs um and i guess that where i was going with that is for for you given that you're the director of regulatory compliance is this a an accurate window into how doctors generally will view legal liability um and say well you know if it makes my job too difficult okay fine i was kind of shocked by that finding was all well i think you need to consider too that sometimes the electronic medical record incorporates a lot of information and you have to again look at standard of care and see whether whether that physician practices care there's a wealth of information in there but some of it is not accurate some of it might be pulled in from a patient that's not even the patient that has that um that condition so um there's a lot of like a lot of legal i think contemplation we have to put to this because it's almost unfair to say that because you have not scanned every single record in the patient's record that you could be found to be emailed in malpractice so there's a lot more conversations take place um the question that i have is about permissions granularity one of the things that's going on right now in the world of smartphones is that almost every app that you install has some permissions and at least at the beginning of both android and ios they were very messed up there was a permission called telethon that covered everything from getting access to your telephone number to actually making calls directly without your permission and so just recently updates for both of those operating systems have been have been tearing the permissions down into smaller pieces partly as a way of addressing a consumer backlash against apps that ask for every permission under the fund and is that kind of thinking going on in the emr space in terms of making more granular the access that researchers and even medical providers might have to these records is that problem is that kind of thinking applicable to this would it be useful in increasing anonymity for research purposes how much would it inhibit research and broadly how applicable is that well we try to like we have to under triple law to use only what we minimally need to accomplish our research objectives and so we have to use that as our principal guidance whenever we ask for request information we have robust irb processes that are in place that will review the project and they'll review whether there's going to be harm to subjects based on information or whatever that's going to be the you know result of research so or for the participation in the research so um is it perfect no we have a long way to go and the trouble that we the um or the challenges that we face is that the research community wants more information they want more granularity in the research data and so we have to try to always balance that with trying to make sure that research can go forward but putting it in as many protections as we can both from a legal perspective and from a policy perspective and i think i mean i feel that uh you know informed consent is an area in which it's been the the path forward has been very much and i think that people who argue what we need to move forward is a highly granular you know making decisions about who can access each piece of our data and personally i just don't think it's feasible like it's just a non-starter to me so then you think about okay well what did the other end look like could you articulate a set of principles for which you would like some kind of algorithm to operationalize those principles for you and ideally after you die as well because then how do we manage consent once patients are no longer living but their data continues to live on um so i think it's very unclear they're people who are arguing for a lot of different approaches to consent and uh you know i think it's um you know we are going to learn a lot from what we're doing outside of healthcare but i think the reality is we just you know really don't know how to do this well yet correct and part of the changes that are going to be made to the common rule is going to address trying to put more transparency in the consent process making sure that people understand what their information is going to be used how that information is going to be used and the best that we can do is to educate it as much as we can the of the part that i think is a little bit more challenging is when we use the information without their authorization they have no idea that the information is being used and that's more challenging and so there's a lot of rigor that we try to put around research projects like that where we make sure that there's appropriate security measures that are in place as best as we can and um that there's a lot of understanding by the research team about what it is that they're working with their sensitivity training hipaa compliance training that goes into their understanding and so we try to put all these administrative measures in place because we always above all want to be respectful for the information in which we use it so my question is for julia but i want to make a comment first and just follow on what you said there are people here at michigan and elsewhere that are actually looking into computable models of consent to automate that process and of course also looking at patterns of behavior and desires of large populations of people with regard to the application of some of those models my question is actually about the health information exchanges and meaningful use um so my question is that that in previous research published a few years back there's a lot of evidence that even when health information is available in electronic health information exchange it's not being used to impact care and i wondered if you could comment on that is meaningful use been effective in that regard were we simply putting lots of information in the health information exchange and not actually impacting care with it sure um i think uh that uh the answer today is still largely no uh that even when that information is we've sort of solved the information sharing problem it's still not getting to the point of care to the point of clinical decision and i think that that has a lot to do with clunky technology and poor workflows um and uh and i think there are cases in which we're getting this right so for people who practice uh here in our healthcare system they've probably seen that now epic has care everywhere um which really is sort of the most seamless that's out there and it's still not great but it at least sort of is as accessible as sort of any other piece of data in the record and so i pulled data from our health system to study does it seem to be impacting ed care and what you find is that when information is coming back through care everywhere there's a lower likelihood that the patients admitted they're getting out of the ed quicker so i think when done well we're starting to see that the information is used and is impacting care but it's unfortunately the minority of cases where i think we've really built uh these exchanges in ways that make it easy for the providers to use and access information and if not they're just too busy frankly uh to you know to take the time to go search out this information i i would like to correct myself so i looked it up what my question was earlier so they did identify 50 individuals without having a sample there wasn't a split sample to compare with what they did is they went through some y chromosomal database found last names with that and had enough non-identifiable so-called information about them to find the location the birth they knew the age i guess and so after that you know age and last name of whatever that so even they were if they weren't in a y chromosomal database someone else with that last name was and that's how they they were linked because i couldn't figure out from what you're saying there had to be something and the something is the y chromosome and the last name from someone else but to make it so it is a bit scary but on the other hand my one of my questions is in the uh genetic counseling and genetic test testing ethics community there are some really good papers that show that all these scare things you know in the end very very little harm has been done to any particular individual but because of participating in genetic studies or because of some leaks so do are these 50 people actually harmed by someone knowing it or did this i mean was this particular participant in a let's say stigmatizing database like a bipolar database and he might not want everyone to know that he's suffering from bipolar disorder or how good is the evidence that there were actually with all these leaks and things that have or could have happened that actual damage was done so i think harm is something that we have to consider and and you hit the nail on the head when you talk about the sensitivity of the data the sensitivity of the diagnosis so we part of what we do when we're looking at whether there's a potential for harm when from the irb's perspective and studies going forward as we look at those pieces and make determinations of how the data should be protected and whether informed consent would be necessary before they even went forth with the the research project so there's a lot of things that come into play with the data and sensitivity is certainly an important factor and also rare conditions too so someone might have a rare condition it may not be sensitive necessarily but because of the rarity of that condition we can identify who those individuals are i think it remains to be seen from larger databases of what what the harm can be certainly the harm would be your information being used inappropriately calm to you financially if they're using it to um purchase things you know out on the marketplace so that you're dealing with credit card companies and so on and so forth so there's there's a financial harm there's a reputational harm which you bring forward um it could be very embarrassing for somebody to have um information let out that perhaps maybe um you know i have gone through substance abuse um treatment i wouldn't want my colleagues to know that um making this up but you know there's things that are very sensitive to people that we have to be always vigilant and making sure that that information is kept as private as we possibly can and a lot of that is is within a trust model and so those are things that are outside of policy and um respiratory control we have to trust people in which they have given access to that information to treat it properly there's also i think the psychological harm of knowing your information is out there i mean that's increasingly what we're seeing that last slide you showed that showed that people want control of their data and therefore when they know that it is then out of their control that there is this psychological harm and uh you know that's i think a real thing even though if it doesn't often feel like real harm there has been cases that have gone to court systems and there the people have to show harm so you have to show that you've been harmed whether it's a financial harm or otherwise so i think in the court systems you're going to have to do that in order to recover any sort of monies to become what you would consider yourself to be full financially or even emotionally whole through the court system so you might be part of a suit but so far what i have heard is most of them have been tossed out because we have the people have not been able to show that they've been harmed but that's not to say that it couldn't happen um i'm interested in the secondary use of biospecimens um and i was wondering if there's a sense of um how like with the new changes to the common rule if all biospecimens are going to be treated equally like would a microbiological specimen be treated with the same protections as a tissue specimen where maybe the risk to the patient is greater well i don't know to that granularity but i do know that there's a lot of conversation that would be improving the informed consent process when it is a bile specimen involved so that the people who that they are that's their specimen that they will be able to actually given informed consent rather than it being a waiver of consent flash authorization so um i don't know just answer your question directly perhaps you know the difference between those those types of samples but for bio specimen that's collected we want to make sure that we get one percent now informed consent could mean that we consent for future research unspecified future research so you can consent to the research project that is at hand and then to future research for that use of that sample and the common rules targeting those both of those areas for informed consent david so fun little examples there so i guess i'm sort of following on your example so you know fantastic opportunity to find false discoveries by mining the data here so what's what safeguards are in place and methods of validating what you can find i mean the literature biomedical literature is riddled with false reproducible results and so what what's how are we going to move forward to make sure it's real i i think it's an open question you know i think the problem is that all we have are just the data that we have and i i think all we can do is really just say we have found this and then other people may have to take it on and do more right so a prospective trial if somebody wants to of course some things may not be important enough to to bother with but i don't think we know i mean um when we when we did even that work with the uh the meta-map tool and we looked at medline there's typographic errors that it'll find mistakes it'll find diseases that don't exist because of a typographic error or misinterpretations of of how these automated tools work and there is no good way i mean i sort of got stuck i stopped going down that line because i couldn't find any good automated way to filter out the real from the non-real um the thing i'm going to try next is a crowdsourcing thing so i've got a europe student i'm going to be working with uh where we're going to try to put some of this stuff online and let people look up pairs of associations and figure out that they think it's real or it's not probably more for clinicians and this is partly because i i still read papers all the time or someone's come up with some new association to make the news we go back to our data set it's there um so we thought that this might be useful just to have out there so people can sort of look up and annotate on their own i think you need some clinical judgment basically you need someone who actually understands to say that i know this disease domain and i know that this is strange or unusual versus oh no we've known that for a long time they may not be in a textbook but this is well known i don't know if i answered your question yeah it's also bleeding into treatment decisions right and i think that you just talked about associations between diseases but increasingly now we're using these data sets to look at you know what do we know about when treatment a versus treatment b has been applied and you know the sort of green button paper and so i mean i think it even goes beyond understanding two diseases but also now into informing treatment decisions which is perhaps both exciting and scary so i have a first i want to thank all three of you i think a pretty interesting afternoon especially like this model where the students figure out a topic invite the speakers and [Music] get educated about an area that's a little different from our usual seminar topics and socially a important observations first of all on the original legislation 2009 era of legislation i am still aggrieved that people who knew better fail to take the opportunity to require at least significant progress for an interoperability it was left out completely they just shoveled out 19 billion dollars of taxpayers monies to make the worst possible combination of incompatible systems permanent and it's getting worse instead of better as far as i can tell nearly every company operates on the model that if they can sell you the system they own you and after that it's your problem and all the special systems you need for ophthalmology or for longitudinal data or other stuff that doesn't fit in the system you just paid a few hundred million dollars to install um good luck and of course we need upgrades from compounds this is highly unacceptable and regrettable the other side i think people have become very much more comfortable using technology and computers and smartphones and all and it is astonishing to me how many people are eager to put their data out there you look to a site like patients like me there's a lot of mindable information and some very interesting associations of family and there's opportunity for follow-up people volunteer to share their private information they're psychological and all kinds of information it's not saying everybody shares this attitude of course not but far more i would say than most of us expected finally i have another grievance which is about the attitude toward research in our society and it's reflected severely in hipaa legislation it's also reflected in our own legal colleagues here and around the country in academic medical centers it turns out that all this data all these data that are so tightly protected and if there should be an accidental release trigger potential fines of enormous amounts um can be plowed for as much as you like as long as you call it anything but research if it's for patient care covering almost anything if it's for billing the most important use of all or if it's for safety investigation quality of care it's all permitted under exceptions so long as you don't learn anything from it or share what you've learned if you share what you've learned in the form of a publication you've now committed a crime and retroactively what was a quality investigation or a safety investigation is reclassified as research because after all it's only those researchers who do things like publish in journals and help to educate their colleagues and the public are you as uh concerned about this as i seem to be we probably disagree worse than they have to be my interpretation what's happened with the hipaa situation is that we've done a workaround we've learned to get waivers for relatively expeditious approvals from our overburdened irbs so that we can actually do some of these studies but the activation energy for that is such that most people don't bother there's a lot of unfinalized data here and everywhere and the lawyers who typically can be described in one of two camps those who tell you how to get things done and also tell you don't dare do anything are mostly in the second camp because the fear of litigation is greatest among institutional awareness of not doing research of being too scared of all of this stuff and and that i think is the way i would put it i i completely agree nobody in the ethics and legal community seems to think that not doing things that could help a lot of people is in any way an ethical violation there's always the okay if if there's a risk then uh uh yeah well my only comment to your grievances would be that's uh i think that what the legal community would um say that we're looking to make sure that the rules are followed research is something that we promote um at the university of michigan and of course at other academic institutions as well and we want to be able to collaborate with other institutions it's just there's there's a legal way to do it that will keep us out of murky waters and that's i think really all that we would from a compliance perspective and from a legal perspective like to see happen i i see from my job working with different researchers and on different projects the data accessibility is wide here we have a large risk appetite and so um what we just tried to do is balance that risk appetite with trying to put in guard rails to keep researchers out of trouble and to keep the institution out of trouble i i would say that i i agree with your statement especially when you talked about the irb my i love the people in the rb they're very nice but i do think that my personal experience is that people like me we gum up the irb with all these retrospective studies where we never interact with patients we're really the only heart the harm is always the same the harm is the data could be lost somehow or stolen but these get they have to get reviewed they ask very nitpicky questions it takes months for them to be approved and really my my view is that those should really be fast track worry about the integrity you know the protection of the data but fast track doesn't really focus on those trials where harm could actually happen to somebody but right now they're almost treated equally and they go through these very long processes yeah that i under i understand that perspective and i think that part of the rule changes for the common rule is to look at those types of studies to say which ones are really high risk and put more process there and ones that are lower risk less process so you know those things are being looked at from a regulatory perspective today thanks so the so i was just going to ask a question based on would you answer about the uh research risk so uh know uh most of your uh suggestions or your comments are focusing on you know the research within the institute but i would say you know from a perspective let's say a layman researcher or like some people they're starting doing their things and it's very frustrating when you say you know we want to find data to learn say you know the people's purchase preference or you know those things it's very easy to get those data from let's say kaggle or you know a lot of online data sets and when people are starting to get into let's say you know medical research or you know there's you know this health related information and we started facing all kinds of regulation and all kinds of barriers and so in that case isn't that the regulation to some extent is like hindering the uh you know studying in this area and also uh when talking to other people you know when people started thinking about big data one of the problem coming out is like every time when we discuss about this topic we thought you know we we go go on to youtube and i click two episodes of uh daily show in the starting point beyond all donald trump stupid talk and when we really get to medical study and they think okay people are studying these data and cancer's still not cured and my disease do not help is you know helpful for my disease so is it giving a bad impression about this area and is there any like a policy coming on like to address this issue thanks so we have to be reminded that the information that we are using from the medical record is personal and private to that patient and so there we ha and we have to be respectful for the regulations that try to balance research with the the privacy of an individual and um hipaa i don't see as changing the way it's written anytime in the future so we have to try to figure out how do we best apply the rules and work within the rules um i'm not sure if i'm answering your question or your concern but um understanding that the data that we're we're working with is very private to people and we have to be respectful of that um like my question is why can't you just have a simple program takes out of a big data set just takes out the you know the identifiers like the name and things like that and then you'd have uh the data without the you know the identifiers and i mean it's a pretty simple program i think does anybody else hear a programmer i can address that to some degree so i would say there's there's two kinds of data sets one would be unstructured data where everything is already you know or one is the structured data where everything is already clearly defined in columns and and that you can do a pretty reasonable job of removing uh the identifiers because they're they're in easily removable columns remove the name remove the address column and you can you can give more or less clinical data i think that the truth is that a lot of that structure data is only a small part of the actual picture of a patient most of the data in my opinion is in the free text unstructured clinical note that clinicians made well that even that could there you could even have a program that removed some of that so the answer is yes you can and i've actually worked on some of that and they work pretty well but they always make mistakes because that's really a natural language processing program and no nlp is ever perfect and and the question of course is really how much can you allow to pass through before you can um really make it available to just about anybody the it sort of really reduce that in identification as opposed to de-identification and and there's always going to be things in there that aren't really the clear identifiers right so you can have name you could have dates and remove all that but if it said head coach of the u of m football team uh you'll know who that person is um and and things like that like i mean like for career or whatever or uh it's almost infinite how you can describe something and identify who somebody is so that that's the problem with that we the software is out there we haven't implemented here we probably should just to help reduce the risk of releasing this kind of information but it things will still slip through the way i heard the question it's why can't we just remove coded data identifiers and you know wouldn't that be sufficient and why is that such a problem and i think even using coded identifiers there's been plenty of work by latonya sweeney brad malen and others on taking discrete data that's fully coded and linking it with publicly available data sets and re-identifying the actual data so the the problem is that the statistical distributions of the actual data elements can essentially when you multiply them to the probability of them together you can you wind up with very small probability that it's anyone other than particular people and and that's the real risk it has really little to do with the actual identification of the you know what you remove the problem still becomes a statistical distribution issue so i think that this might have been one of the most engaged question and answer sessions throughout this series that we do so i want to thank you all for your questions and of course one more time thank our speakers who have done a great job today thank you