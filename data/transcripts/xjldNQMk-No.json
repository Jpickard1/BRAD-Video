[
    {
        "text": "a pretty good crowd so i'm going to go",
        "start": 0.08,
        "duration": 3.52
    },
    {
        "text": "ahead and get started",
        "start": 1.68,
        "duration": 4.96
    },
    {
        "text": "welcome everybody to the dcmv",
        "start": 3.6,
        "duration": 6.16
    },
    {
        "text": "seminar series today we've got uh",
        "start": 6.64,
        "duration": 6.079
    },
    {
        "text": "dr magnus rattray speaking with us from",
        "start": 9.76,
        "duration": 5.839
    },
    {
        "text": "the university of manchester",
        "start": 12.719,
        "duration": 5.121
    },
    {
        "text": "it's uh one uh one good thing about",
        "start": 15.599,
        "duration": 3.201
    },
    {
        "text": "covet is um",
        "start": 17.84,
        "duration": 2.16
    },
    {
        "text": "since we're having these virtual",
        "start": 18.8,
        "duration": 3.12
    },
    {
        "text": "seminars we can uh we can bring people",
        "start": 20.0,
        "duration": 4.08
    },
    {
        "text": "in from europe very easily so",
        "start": 21.92,
        "duration": 5.199
    },
    {
        "text": "we're excited to have dr ratri here",
        "start": 24.08,
        "duration": 5.439
    },
    {
        "text": "he uh graduated with his bachelor's in",
        "start": 27.119,
        "duration": 3.92
    },
    {
        "text": "math and physics",
        "start": 29.519,
        "duration": 3.441
    },
    {
        "text": "and and then ultimately his phd in",
        "start": 31.039,
        "duration": 3.281
    },
    {
        "text": "computer science from the university of",
        "start": 32.96,
        "duration": 2.72
    },
    {
        "text": "manchester",
        "start": 34.32,
        "duration": 3.919
    },
    {
        "text": "and then he did postdoctoral work on the",
        "start": 35.68,
        "duration": 5.52
    },
    {
        "text": "statistical mechanics of neural networks",
        "start": 38.239,
        "duration": 4.561
    },
    {
        "text": "at the neural computing research group",
        "start": 41.2,
        "duration": 3.76
    },
    {
        "text": "at aston university",
        "start": 42.8,
        "duration": 3.919
    },
    {
        "text": "and he was professor of machine learning",
        "start": 44.96,
        "duration": 3.439
    },
    {
        "text": "and statistical bioinformatics at",
        "start": 46.719,
        "duration": 4.081
    },
    {
        "text": "sheffield university",
        "start": 48.399,
        "duration": 4.961
    },
    {
        "text": "before returning to manchester in 2012",
        "start": 50.8,
        "duration": 3.52
    },
    {
        "text": "where he currently",
        "start": 53.36,
        "duration": 3.199
    },
    {
        "text": "is the director of the university of",
        "start": 54.32,
        "duration": 5.6
    },
    {
        "text": "manchester data science institute",
        "start": 56.559,
        "duration": 5.52
    },
    {
        "text": "and dr rattray uses probabilistic",
        "start": 59.92,
        "duration": 3.52
    },
    {
        "text": "modeling and bayesian inference",
        "start": 62.079,
        "duration": 4.08
    },
    {
        "text": "techniques to study biological systems",
        "start": 63.44,
        "duration": 4.719
    },
    {
        "text": "across a range of temporal and spatial",
        "start": 66.159,
        "duration": 3.121
    },
    {
        "text": "scales",
        "start": 68.159,
        "duration": 2.96
    },
    {
        "text": "from gene expression in single cells to",
        "start": 69.28,
        "duration": 5.04
    },
    {
        "text": "longitudinal population health data",
        "start": 71.119,
        "duration": 4.961
    },
    {
        "text": "and what's particularly impressive to me",
        "start": 74.32,
        "duration": 3.76
    },
    {
        "text": "about his work is his deep knowledge of",
        "start": 76.08,
        "duration": 3.52
    },
    {
        "text": "both statistical machine learning and",
        "start": 78.08,
        "duration": 3.52
    },
    {
        "text": "biological applications",
        "start": 79.6,
        "duration": 4.0
    },
    {
        "text": "he's a world-class expert in gaussian",
        "start": 81.6,
        "duration": 3.04
    },
    {
        "text": "processes and",
        "start": 83.6,
        "duration": 2.24
    },
    {
        "text": "he's been working on genomic",
        "start": 84.64,
        "duration": 3.36
    },
    {
        "text": "applications since the days of",
        "start": 85.84,
        "duration": 4.72
    },
    {
        "text": "microarrays",
        "start": 88.0,
        "duration": 4.24
    },
    {
        "text": "and more recently he's he's developing",
        "start": 90.56,
        "duration": 3.199
    },
    {
        "text": "gaussian process methods",
        "start": 92.24,
        "duration": 3.68
    },
    {
        "text": "um to uncover oscillations in single",
        "start": 93.759,
        "duration": 4.481
    },
    {
        "text": "cell imaging time course data and in",
        "start": 95.92,
        "duration": 4.239
    },
    {
        "text": "first pseudo time from single cell rna",
        "start": 98.24,
        "duration": 3.04
    },
    {
        "text": "seq data",
        "start": 100.159,
        "duration": 2.96
    },
    {
        "text": "which i believe he's going to talk about",
        "start": 101.28,
        "duration": 3.36
    },
    {
        "text": "today so",
        "start": 103.119,
        "duration": 3.04
    },
    {
        "text": "magnus thanks very much for speaking",
        "start": 104.64,
        "duration": 4.4
    },
    {
        "text": "with us and we're excited for your talk",
        "start": 106.159,
        "duration": 5.701
    },
    {
        "text": "ms joshua thanks for the nice",
        "start": 109.04,
        "duration": 4.24
    },
    {
        "text": "[Music]",
        "start": 111.86,
        "duration": 3.82
    },
    {
        "text": "bio and uh you made me feel old now",
        "start": 113.28,
        "duration": 3.839
    },
    {
        "text": "talking about microarrays",
        "start": 115.68,
        "duration": 5.92
    },
    {
        "text": "uh so um okay let me share my screen and",
        "start": 117.119,
        "duration": 6.241
    },
    {
        "text": "i hope that works",
        "start": 121.6,
        "duration": 4.96
    },
    {
        "text": "uh is that okay yep looks good",
        "start": 123.36,
        "duration": 5.84
    },
    {
        "text": "brilliant okay so thanks so much for",
        "start": 126.56,
        "duration": 3.36
    },
    {
        "text": "inviting me",
        "start": 129.2,
        "duration": 3.84
    },
    {
        "text": "uh it's sad that i can't actually",
        "start": 129.92,
        "duration": 6.56
    },
    {
        "text": "visit uh ann arbor um",
        "start": 133.04,
        "duration": 5.6
    },
    {
        "text": "but i did have a look at it on wikipedia",
        "start": 136.48,
        "duration": 3.839
    },
    {
        "text": "so that i felt like i was actually in",
        "start": 138.64,
        "duration": 2.319
    },
    {
        "text": "the place",
        "start": 140.319,
        "duration": 4.081
    },
    {
        "text": "you know um and uh",
        "start": 140.959,
        "duration": 6.321
    },
    {
        "text": "it's also unusual for me to give a talk",
        "start": 144.4,
        "duration": 4.64
    },
    {
        "text": "just after putting the kids to bed",
        "start": 147.28,
        "duration": 4.8
    },
    {
        "text": "so uh that's also but",
        "start": 149.04,
        "duration": 4.72
    },
    {
        "text": "luckily they've gone okay so so",
        "start": 152.08,
        "duration": 3.519
    },
    {
        "text": "hopefully they won't interrupt us",
        "start": 153.76,
        "duration": 5.36
    },
    {
        "text": "um okay so um",
        "start": 155.599,
        "duration": 6.081
    },
    {
        "text": "i am gonna talk about um guys and",
        "start": 159.12,
        "duration": 3.36
    },
    {
        "text": "processes",
        "start": 161.68,
        "duration": 3.44
    },
    {
        "text": "as joshua says i've been working on that",
        "start": 162.48,
        "duration": 4.08
    },
    {
        "text": "for quite a long time",
        "start": 165.12,
        "duration": 5.52
    },
    {
        "text": "um so",
        "start": 166.56,
        "duration": 7.759
    },
    {
        "text": "just see if i can just move forward",
        "start": 170.64,
        "duration": 6.48
    },
    {
        "text": "so i'm going to give a quick tutorial",
        "start": 174.319,
        "duration": 4.401
    },
    {
        "text": "about gaussian processes",
        "start": 177.12,
        "duration": 4.16
    },
    {
        "text": "um so i think they're a useful",
        "start": 178.72,
        "duration": 4.4
    },
    {
        "text": "statistical model",
        "start": 181.28,
        "duration": 5.36
    },
    {
        "text": "um that you know it's useful to know",
        "start": 183.12,
        "duration": 4.479
    },
    {
        "text": "about in general",
        "start": 186.64,
        "duration": 2.959
    },
    {
        "text": "so hopefully that intro will give people",
        "start": 187.599,
        "duration": 3.681
    },
    {
        "text": "a bit of a flavor about what they're",
        "start": 189.599,
        "duration": 2.72
    },
    {
        "text": "about",
        "start": 191.28,
        "duration": 3.76
    },
    {
        "text": "um and then i'm gonna talk about three",
        "start": 192.319,
        "duration": 4.161
    },
    {
        "text": "different ways that",
        "start": 195.04,
        "duration": 4.24
    },
    {
        "text": "we've applied them recently i'll start",
        "start": 196.48,
        "duration": 4.399
    },
    {
        "text": "off talking about pseudotemporal",
        "start": 199.28,
        "duration": 2.239
    },
    {
        "text": "inference",
        "start": 200.879,
        "duration": 4.321
    },
    {
        "text": "in the specific case where we have some",
        "start": 201.519,
        "duration": 7.601
    },
    {
        "text": "um capture time information from a",
        "start": 205.2,
        "duration": 7.599
    },
    {
        "text": "single cell time series data",
        "start": 209.12,
        "duration": 6.399
    },
    {
        "text": "and the bayesian nature of the gaussian",
        "start": 212.799,
        "duration": 4.241
    },
    {
        "text": "process method",
        "start": 215.519,
        "duration": 3.521
    },
    {
        "text": "is useful to encode that prior",
        "start": 217.04,
        "duration": 3.919
    },
    {
        "text": "information about capture times of the",
        "start": 219.04,
        "duration": 3.68
    },
    {
        "text": "cells",
        "start": 220.959,
        "duration": 5.041
    },
    {
        "text": "and that's really building on",
        "start": 222.72,
        "duration": 5.439
    },
    {
        "text": "other people's works but our extension",
        "start": 226.0,
        "duration": 4.56
    },
    {
        "text": "was to introduce some extra latent",
        "start": 228.159,
        "duration": 5.28
    },
    {
        "text": "dimensions into that model to capture",
        "start": 230.56,
        "duration": 5.039
    },
    {
        "text": "other variation",
        "start": 233.439,
        "duration": 5.681
    },
    {
        "text": "such as differentiation and branching",
        "start": 235.599,
        "duration": 6.161
    },
    {
        "text": "so then uh after talking about branching",
        "start": 239.12,
        "duration": 3.199
    },
    {
        "text": "in",
        "start": 241.76,
        "duration": 2.8
    },
    {
        "text": "high dimensional data i'll go down to",
        "start": 242.319,
        "duration": 3.2
    },
    {
        "text": "the gene",
        "start": 244.56,
        "duration": 4.319
    },
    {
        "text": "level and talk about modeling branching",
        "start": 245.519,
        "duration": 7.321
    },
    {
        "text": "individual genes from single cell",
        "start": 248.879,
        "duration": 5.36
    },
    {
        "text": "pseudotemporal",
        "start": 252.84,
        "duration": 4.44
    },
    {
        "text": "or pseudotime course data",
        "start": 254.239,
        "duration": 6.4
    },
    {
        "text": "and finally i'll just talk about a new",
        "start": 257.28,
        "duration": 5.04
    },
    {
        "text": "extension",
        "start": 260.639,
        "duration": 4.321
    },
    {
        "text": "where we've introduced a negative",
        "start": 262.32,
        "duration": 4.72
    },
    {
        "text": "binomial likelihood into gaussian",
        "start": 264.96,
        "duration": 3.04
    },
    {
        "text": "process framework",
        "start": 267.04,
        "duration": 3.76
    },
    {
        "text": "which allows us to model count data a",
        "start": 268.0,
        "duration": 4.32
    },
    {
        "text": "little bit better",
        "start": 270.8,
        "duration": 4.56
    },
    {
        "text": "and i'll talk about spatial",
        "start": 272.32,
        "duration": 6.879
    },
    {
        "text": "inference with that type of model",
        "start": 275.36,
        "duration": 8.8
    },
    {
        "text": "so first guessing processes 101",
        "start": 279.199,
        "duration": 4.961
    },
    {
        "text": "and uh you know if people want to ask a",
        "start": 285.12,
        "duration": 4.16
    },
    {
        "text": "question you can just unmute and",
        "start": 287.04,
        "duration": 5.76
    },
    {
        "text": "uh go ahead or put things in the chat",
        "start": 289.28,
        "duration": 5.12
    },
    {
        "text": "whatever i don't mind",
        "start": 292.8,
        "duration": 4.16
    },
    {
        "text": "um if there's something in the chat that",
        "start": 294.4,
        "duration": 4.72
    },
    {
        "text": "i miss maybe josh can alert me",
        "start": 296.96,
        "duration": 5.519
    },
    {
        "text": "um so um",
        "start": 299.12,
        "duration": 6.48
    },
    {
        "text": "what's gaussian process so it's",
        "start": 302.479,
        "duration": 5.361
    },
    {
        "text": "it's a probability distribution but it's",
        "start": 305.6,
        "duration": 3.92
    },
    {
        "text": "a probability distribution over",
        "start": 307.84,
        "duration": 3.84
    },
    {
        "text": "functions rather than numbers",
        "start": 309.52,
        "duration": 5.119
    },
    {
        "text": "so a gaussian distribution is a",
        "start": 311.68,
        "duration": 4.48
    },
    {
        "text": "distribution over numbers",
        "start": 314.639,
        "duration": 3.441
    },
    {
        "text": "a gaussian process is a distribution",
        "start": 316.16,
        "duration": 4.08
    },
    {
        "text": "over functions",
        "start": 318.08,
        "duration": 5.44
    },
    {
        "text": "and the functions",
        "start": 320.24,
        "duration": 7.28
    },
    {
        "text": "in code are sort of prior beliefs or",
        "start": 323.52,
        "duration": 7.679
    },
    {
        "text": "or they model structure and data so",
        "start": 327.52,
        "duration": 5.519
    },
    {
        "text": "for instance they might model the fact",
        "start": 331.199,
        "duration": 4.881
    },
    {
        "text": "that time series is very dynamic",
        "start": 333.039,
        "duration": 5.921
    },
    {
        "text": "um or they could model the fact that",
        "start": 336.08,
        "duration": 5.04
    },
    {
        "text": "your time series could be stochastic",
        "start": 338.96,
        "duration": 5.519
    },
    {
        "text": "like from uh single cell",
        "start": 341.12,
        "duration": 6.4
    },
    {
        "text": "life cell imaging traces for instance",
        "start": 344.479,
        "duration": 4.881
    },
    {
        "text": "or it could be smooth because you're",
        "start": 347.52,
        "duration": 4.72
    },
    {
        "text": "averaging over millions of cells",
        "start": 349.36,
        "duration": 5.44
    },
    {
        "text": "it could be stationary so it looks the",
        "start": 352.24,
        "duration": 4.959
    },
    {
        "text": "same at different places",
        "start": 354.8,
        "duration": 5.519
    },
    {
        "text": "or it could be non-stationary and the",
        "start": 357.199,
        "duration": 4.56
    },
    {
        "text": "covariance function",
        "start": 360.319,
        "duration": 4.641
    },
    {
        "text": "encodes the type of functions that we",
        "start": 361.759,
        "duration": 4.241
    },
    {
        "text": "can draw from",
        "start": 364.96,
        "duration": 4.239
    },
    {
        "text": "this probability distribution so the",
        "start": 366.0,
        "duration": 5.12
    },
    {
        "text": "covariance function really",
        "start": 369.199,
        "duration": 4.321
    },
    {
        "text": "contains the the sort of modeling",
        "start": 371.12,
        "duration": 3.12
    },
    {
        "text": "strength",
        "start": 373.52,
        "duration": 4.48
    },
    {
        "text": "of gaussian processes",
        "start": 374.24,
        "duration": 3.76
    },
    {
        "text": "so um what why the gaussian processors",
        "start": 379.039,
        "duration": 3.841
    },
    {
        "text": "what's the link to gaussian",
        "start": 381.68,
        "duration": 2.959
    },
    {
        "text": "distributions well",
        "start": 382.88,
        "duration": 4.159
    },
    {
        "text": "i'm going to try and explain that here",
        "start": 384.639,
        "duration": 3.84
    },
    {
        "text": "so",
        "start": 387.039,
        "duration": 4.72
    },
    {
        "text": "the dots here are um",
        "start": 388.479,
        "duration": 8.0
    },
    {
        "text": "numbers from a 25-dimensional vector",
        "start": 391.759,
        "duration": 7.361
    },
    {
        "text": "which has been drawn from a multivariate",
        "start": 396.479,
        "duration": 3.84
    },
    {
        "text": "normal",
        "start": 399.12,
        "duration": 4.32
    },
    {
        "text": "so you take your you know",
        "start": 400.319,
        "duration": 6.16
    },
    {
        "text": "multivariate normal random number",
        "start": 403.44,
        "duration": 6.96
    },
    {
        "text": "generator from r or python or whatever",
        "start": 406.479,
        "duration": 7.361
    },
    {
        "text": "and you draw a 25-dimensional vector",
        "start": 410.4,
        "duration": 5.44
    },
    {
        "text": "and then you plot the data and the",
        "start": 413.84,
        "duration": 3.359
    },
    {
        "text": "indices in the",
        "start": 415.84,
        "duration": 4.479
    },
    {
        "text": "vector are along the x-axis and the",
        "start": 417.199,
        "duration": 4.481
    },
    {
        "text": "values in the",
        "start": 420.319,
        "duration": 4.641
    },
    {
        "text": "vector are on the y-axis here",
        "start": 421.68,
        "duration": 6.4
    },
    {
        "text": "and um i've",
        "start": 424.96,
        "duration": 6.48
    },
    {
        "text": "i've chosen the covariance matrix",
        "start": 428.08,
        "duration": 6.76
    },
    {
        "text": "this normal distribution to have a",
        "start": 431.44,
        "duration": 5.199
    },
    {
        "text": "specific um",
        "start": 434.84,
        "duration": 5.32
    },
    {
        "text": "structure where so white is top here and",
        "start": 436.639,
        "duration": 4.801
    },
    {
        "text": "it means that",
        "start": 440.16,
        "duration": 4.0
    },
    {
        "text": "indices that are close together are",
        "start": 441.44,
        "duration": 4.0
    },
    {
        "text": "highly correlated",
        "start": 444.16,
        "duration": 4.0
    },
    {
        "text": "so this covariance matrix or the",
        "start": 445.44,
        "duration": 4.159
    },
    {
        "text": "variance is one so you can think of it",
        "start": 448.16,
        "duration": 3.52
    },
    {
        "text": "as a correlation matrix",
        "start": 449.599,
        "duration": 4.081
    },
    {
        "text": "so things where the indices are close",
        "start": 451.68,
        "duration": 4.799
    },
    {
        "text": "together so if we take the 10th element",
        "start": 453.68,
        "duration": 6.079
    },
    {
        "text": "and the 11th element in this",
        "start": 456.479,
        "duration": 5.84
    },
    {
        "text": "vector then if we go along and look at",
        "start": 459.759,
        "duration": 4.241
    },
    {
        "text": "that box it's high and that means",
        "start": 462.319,
        "duration": 4.32
    },
    {
        "text": "those two things are highly correlated",
        "start": 464.0,
        "duration": 4.24
    },
    {
        "text": "so if we draw that vector",
        "start": 466.639,
        "duration": 6.081
    },
    {
        "text": "it looks a little bit during those dots",
        "start": 468.24,
        "duration": 7.92
    },
    {
        "text": "it's a smooth curve okay",
        "start": 472.72,
        "duration": 5.84
    },
    {
        "text": "um but it's not a function it's it's a",
        "start": 476.16,
        "duration": 3.28
    },
    {
        "text": "vector",
        "start": 478.56,
        "duration": 2.24
    },
    {
        "text": "but we because we've chosen the",
        "start": 479.44,
        "duration": 3.92
    },
    {
        "text": "covariance matrix in a particular way",
        "start": 480.8,
        "duration": 6.079
    },
    {
        "text": "it looks good",
        "start": 483.36,
        "duration": 3.519
    },
    {
        "text": "so gaussian process is just where you",
        "start": 487.12,
        "duration": 4.88
    },
    {
        "text": "take instead of having n equals 25",
        "start": 489.28,
        "duration": 5.84
    },
    {
        "text": "you have n equals infinity so if i",
        "start": 492.0,
        "duration": 5.36
    },
    {
        "text": "and actually these curves here aren't",
        "start": 495.12,
        "duration": 3.12
    },
    {
        "text": "really",
        "start": 497.36,
        "duration": 3.519
    },
    {
        "text": "drawn with infinite number of points i",
        "start": 498.24,
        "duration": 4.399
    },
    {
        "text": "think i chose 400",
        "start": 500.879,
        "duration": 4.481
    },
    {
        "text": "you know so actually this is now a 400",
        "start": 502.639,
        "duration": 3.361
    },
    {
        "text": "dimensional",
        "start": 505.36,
        "duration": 3.2
    },
    {
        "text": "vector but it just looks like a function",
        "start": 506.0,
        "duration": 3.599
    },
    {
        "text": "because everything is so",
        "start": 508.56,
        "duration": 4.399
    },
    {
        "text": "smooth and close together and now the",
        "start": 509.599,
        "duration": 5.521
    },
    {
        "text": "covariance matrix or the correlation",
        "start": 512.959,
        "duration": 2.88
    },
    {
        "text": "matrix",
        "start": 515.12,
        "duration": 3.2
    },
    {
        "text": "is no longer a matrix it's actually a",
        "start": 515.839,
        "duration": 5.44
    },
    {
        "text": "function so it's this thing here",
        "start": 518.32,
        "duration": 6.4
    },
    {
        "text": "and it's got the same form as",
        "start": 521.279,
        "duration": 6.401
    },
    {
        "text": "this guy it's high in the middle along",
        "start": 524.72,
        "duration": 4.239
    },
    {
        "text": "this diagonal",
        "start": 527.68,
        "duration": 5.2
    },
    {
        "text": "and falls off on the off diagonal",
        "start": 528.959,
        "duration": 6.081
    },
    {
        "text": "so that means this function here takes",
        "start": 532.88,
        "duration": 4.0
    },
    {
        "text": "its maximum value when",
        "start": 535.04,
        "duration": 3.84
    },
    {
        "text": "two points are right on top of each",
        "start": 536.88,
        "duration": 3.2
    },
    {
        "text": "other t equals t",
        "start": 538.88,
        "duration": 4.399
    },
    {
        "text": "prime and then it falls off otherwise",
        "start": 540.08,
        "duration": 7.52
    },
    {
        "text": "and if you um draw functions from this",
        "start": 543.279,
        "duration": 5.201
    },
    {
        "text": "particular",
        "start": 547.6,
        "duration": 3.919
    },
    {
        "text": "covariance function then they're going",
        "start": 548.48,
        "duration": 5.2
    },
    {
        "text": "to look smooth",
        "start": 551.519,
        "duration": 4.88
    },
    {
        "text": "and there's a parameter of this which is",
        "start": 553.68,
        "duration": 4.56
    },
    {
        "text": "a length scale here",
        "start": 556.399,
        "duration": 4.401
    },
    {
        "text": "so it's t minus t prime over this length",
        "start": 558.24,
        "duration": 4.56
    },
    {
        "text": "scale squared",
        "start": 560.8,
        "duration": 5.44
    },
    {
        "text": "if i make that large then the functions",
        "start": 562.8,
        "duration": 6.0
    },
    {
        "text": "cross the zero line less often and they",
        "start": 566.24,
        "duration": 4.56
    },
    {
        "text": "have a longer length scale",
        "start": 568.8,
        "duration": 3.92
    },
    {
        "text": "if i make that small then they're going",
        "start": 570.8,
        "duration": 3.76
    },
    {
        "text": "to be more wiggly",
        "start": 572.72,
        "duration": 3.84
    },
    {
        "text": "and things are going to cross the zero",
        "start": 574.56,
        "duration": 4.399
    },
    {
        "text": "line a lot so that parameter",
        "start": 576.56,
        "duration": 5.279
    },
    {
        "text": "we call it hyperparameter it tunes how",
        "start": 578.959,
        "duration": 4.961
    },
    {
        "text": "wiggly these curves are",
        "start": 581.839,
        "duration": 4.321
    },
    {
        "text": "so gaussian process is a probability",
        "start": 583.92,
        "duration": 5.12
    },
    {
        "text": "distribution over wiggly curves",
        "start": 586.16,
        "duration": 4.799
    },
    {
        "text": "and the parameters of the covariance",
        "start": 589.04,
        "duration": 3.04
    },
    {
        "text": "function they tune",
        "start": 590.959,
        "duration": 4.32
    },
    {
        "text": "how wiggly they are and uh here at the",
        "start": 592.08,
        "duration": 4.08
    },
    {
        "text": "beginning there's an",
        "start": 595.279,
        "duration": 5.12
    },
    {
        "text": "amplitude outside this exponent",
        "start": 596.16,
        "duration": 6.48
    },
    {
        "text": "which says how much amplitude there is",
        "start": 600.399,
        "duration": 3.841
    },
    {
        "text": "in these functions so they're wiggly and",
        "start": 602.64,
        "duration": 2.639
    },
    {
        "text": "they go up and down",
        "start": 604.24,
        "duration": 3.92
    },
    {
        "text": "alpha tunes how high they go up and down",
        "start": 605.279,
        "duration": 3.201
    },
    {
        "text": "and",
        "start": 608.16,
        "duration": 3.76
    },
    {
        "text": "l tunes their length scale",
        "start": 608.48,
        "duration": 3.44
    },
    {
        "text": "so that squared exponential covariance",
        "start": 613.12,
        "duration": 4.959
    },
    {
        "text": "that's one choice",
        "start": 616.72,
        "duration": 3.6
    },
    {
        "text": "this is what one sample from that looks",
        "start": 618.079,
        "duration": 3.361
    },
    {
        "text": "like",
        "start": 620.32,
        "duration": 3.32
    },
    {
        "text": "sometimes you call it an rbf which is",
        "start": 621.44,
        "duration": 4.48
    },
    {
        "text": "historically",
        "start": 623.64,
        "duration": 3.96
    },
    {
        "text": "because it's related to radio basis",
        "start": 625.92,
        "duration": 5.28
    },
    {
        "text": "functions so that's one choice",
        "start": 627.6,
        "duration": 3.6
    },
    {
        "text": "if we change the function instead of",
        "start": 631.36,
        "duration": 3.36
    },
    {
        "text": "having an",
        "start": 634.079,
        "duration": 3.361
    },
    {
        "text": "l2 norm here an exponent but we have a",
        "start": 634.72,
        "duration": 3.44
    },
    {
        "text": "um",
        "start": 637.44,
        "duration": 4.88
    },
    {
        "text": "l1 then we get stochastic",
        "start": 638.16,
        "duration": 8.239
    },
    {
        "text": "sats and that's actually like a brown",
        "start": 642.32,
        "duration": 7.6
    },
    {
        "text": "in a potential so that's called an",
        "start": 646.399,
        "duration": 6.961
    },
    {
        "text": "einstein um back process",
        "start": 649.92,
        "duration": 3.44
    },
    {
        "text": "also sort of make more complex variance",
        "start": 655.44,
        "duration": 3.44
    },
    {
        "text": "functions",
        "start": 658.24,
        "duration": 2.8
    },
    {
        "text": "so here i've one of these einstein",
        "start": 658.88,
        "duration": 3.84
    },
    {
        "text": "illinois processes",
        "start": 661.04,
        "duration": 5.44
    },
    {
        "text": "i've multiplied by a",
        "start": 662.72,
        "duration": 9.119
    },
    {
        "text": "cosine and that's induced these kind of",
        "start": 666.48,
        "duration": 10.56
    },
    {
        "text": "stochastic pseudo periodic kind of",
        "start": 671.839,
        "duration": 8.161
    },
    {
        "text": "shapes here so it's um what you could",
        "start": 677.04,
        "duration": 3.76
    },
    {
        "text": "call kind of",
        "start": 680.0,
        "duration": 4.959
    },
    {
        "text": "it's not completely uh periodic",
        "start": 680.8,
        "duration": 7.92
    },
    {
        "text": "but it's kind of stochastically periodic",
        "start": 684.959,
        "duration": 5.521
    },
    {
        "text": "and actually in the past we've used that",
        "start": 688.72,
        "duration": 3.44
    },
    {
        "text": "to model",
        "start": 690.48,
        "duration": 4.96
    },
    {
        "text": "oscillations in a single",
        "start": 692.16,
        "duration": 5.679
    },
    {
        "text": "cell data time course data so",
        "start": 695.44,
        "duration": 4.639
    },
    {
        "text": "longitudinal microscopy",
        "start": 697.839,
        "duration": 5.041
    },
    {
        "text": "type data i'm not going to talk about",
        "start": 700.079,
        "duration": 4.481
    },
    {
        "text": "that today but if you're interested",
        "start": 702.88,
        "duration": 4.48
    },
    {
        "text": "that's the paper",
        "start": 704.56,
        "duration": 2.8
    },
    {
        "text": "okay so gaussian processes are",
        "start": 708.88,
        "duration": 3.6
    },
    {
        "text": "distributions over",
        "start": 710.88,
        "duration": 4.0
    },
    {
        "text": "functions and the reason people in",
        "start": 712.48,
        "duration": 4.64
    },
    {
        "text": "machine learning are interested in them",
        "start": 714.88,
        "duration": 5.28
    },
    {
        "text": "is because they're",
        "start": 717.12,
        "duration": 6.399
    },
    {
        "text": "very preference over data so",
        "start": 720.16,
        "duration": 6.16
    },
    {
        "text": "uh on the left here i'm showing samples",
        "start": 723.519,
        "duration": 3.841
    },
    {
        "text": "from",
        "start": 726.32,
        "duration": 4.72
    },
    {
        "text": "uh our squared exponential distributions",
        "start": 727.36,
        "duration": 5.84
    },
    {
        "text": "so that means that these are smooth",
        "start": 731.04,
        "duration": 5.599
    },
    {
        "text": "samples and if we're doing bayesian",
        "start": 733.2,
        "duration": 5.04
    },
    {
        "text": "inference we can think of these",
        "start": 736.639,
        "duration": 4.561
    },
    {
        "text": "as our prior belief for what some time",
        "start": 738.24,
        "duration": 4.719
    },
    {
        "text": "series is going to look like before we",
        "start": 741.2,
        "duration": 3.6
    },
    {
        "text": "see data",
        "start": 742.959,
        "duration": 4.641
    },
    {
        "text": "so i haven't seen any data but i know",
        "start": 744.8,
        "duration": 3.44
    },
    {
        "text": "that",
        "start": 747.6,
        "duration": 4.56
    },
    {
        "text": "you know it's a bulk rna sequence a",
        "start": 748.24,
        "duration": 5.839
    },
    {
        "text": "so i'm expecting things to be smooth",
        "start": 752.16,
        "duration": 3.2
    },
    {
        "text": "because it's averaged",
        "start": 754.079,
        "duration": 4.961
    },
    {
        "text": "over tissue and um",
        "start": 755.36,
        "duration": 5.12
    },
    {
        "text": "i don't really know what's going to",
        "start": 759.04,
        "duration": 2.799
    },
    {
        "text": "happen but i've seen lots of time of",
        "start": 760.48,
        "duration": 3.039
    },
    {
        "text": "course in the past and they always look",
        "start": 761.839,
        "duration": 3.761
    },
    {
        "text": "like wiggly kind of curves like this",
        "start": 763.519,
        "duration": 4.641
    },
    {
        "text": "so that's my prior belief and then i do",
        "start": 765.6,
        "duration": 6.88
    },
    {
        "text": "four experiments",
        "start": 768.16,
        "duration": 7.52
    },
    {
        "text": "and those have to be passed closer data",
        "start": 772.48,
        "duration": 5.039
    },
    {
        "text": "in this case i've done a super clean",
        "start": 775.68,
        "duration": 5.12
    },
    {
        "text": "experiment so these are really low noise",
        "start": 777.519,
        "duration": 5.281
    },
    {
        "text": "uh but in between the data i don't",
        "start": 780.8,
        "duration": 3.52
    },
    {
        "text": "really know what's happened so the guys",
        "start": 782.8,
        "duration": 4.4
    },
    {
        "text": "in process allows me to",
        "start": 784.32,
        "duration": 6.319
    },
    {
        "text": "say you know the prior tells me what the",
        "start": 787.2,
        "duration": 5.28
    },
    {
        "text": "functions look like they're smooth",
        "start": 790.639,
        "duration": 4.161
    },
    {
        "text": "the data tells me constrains me to have",
        "start": 792.48,
        "duration": 4.08
    },
    {
        "text": "functions that pass closer data and",
        "start": 794.8,
        "duration": 4.32
    },
    {
        "text": "in between the functions are allowed to",
        "start": 796.56,
        "duration": 4.24
    },
    {
        "text": "vary and that gives me my",
        "start": 799.12,
        "duration": 5.68
    },
    {
        "text": "uncertainty in what the inferred",
        "start": 800.8,
        "duration": 7.039
    },
    {
        "text": "functions should look like so the",
        "start": 804.8,
        "duration": 6.159
    },
    {
        "text": "kind of posterior distribution after",
        "start": 807.839,
        "duration": 4.8
    },
    {
        "text": "seeing data",
        "start": 810.959,
        "duration": 4.88
    },
    {
        "text": "is this kind of uh sample of functions",
        "start": 812.639,
        "duration": 4.0
    },
    {
        "text": "that all pass",
        "start": 815.839,
        "duration": 4.401
    },
    {
        "text": "close to the data and that's uh",
        "start": 816.639,
        "duration": 6.081
    },
    {
        "text": "that allows and you can do all this",
        "start": 820.24,
        "duration": 3.599
    },
    {
        "text": "analytically",
        "start": 822.72,
        "duration": 3.04
    },
    {
        "text": "it's fully tractable and that's the nice",
        "start": 823.839,
        "duration": 3.521
    },
    {
        "text": "thing about gaussian processors so you",
        "start": 825.76,
        "duration": 3.439
    },
    {
        "text": "can do bayesian inference",
        "start": 827.36,
        "duration": 6.719
    },
    {
        "text": "for nonlinear regression exactly",
        "start": 829.199,
        "duration": 4.88
    },
    {
        "text": "and josh was asking about",
        "start": 836.48,
        "duration": 6.56
    },
    {
        "text": "neil lawrence actually so this is uh",
        "start": 841.04,
        "duration": 4.0
    },
    {
        "text": "example of the simplest thing you can do",
        "start": 843.04,
        "duration": 3.52
    },
    {
        "text": "with gaussian processors",
        "start": 845.04,
        "duration": 3.28
    },
    {
        "text": "you have some time series gene",
        "start": 846.56,
        "duration": 3.519
    },
    {
        "text": "expression data",
        "start": 848.32,
        "duration": 4.16
    },
    {
        "text": "and you just want to ask is it changing",
        "start": 850.079,
        "duration": 3.921
    },
    {
        "text": "in time",
        "start": 852.48,
        "duration": 3.2
    },
    {
        "text": "or later on i'm going to talk about",
        "start": 854.0,
        "duration": 4.48
    },
    {
        "text": "space is it changing in some spatial",
        "start": 855.68,
        "duration": 5.279
    },
    {
        "text": "dimensions and the simplest thing you",
        "start": 858.48,
        "duration": 4.32
    },
    {
        "text": "can do is just work out the probability",
        "start": 860.959,
        "duration": 3.761
    },
    {
        "text": "under a dynamic model so under gaussian",
        "start": 862.8,
        "duration": 3.92
    },
    {
        "text": "process",
        "start": 864.72,
        "duration": 5.28
    },
    {
        "text": "take away the probability under a",
        "start": 866.72,
        "duration": 5.52
    },
    {
        "text": "constant model and that gives you a log",
        "start": 870.0,
        "duration": 3.199
    },
    {
        "text": "likelihood ratio",
        "start": 872.24,
        "duration": 4.399
    },
    {
        "text": "score for whether the gene is",
        "start": 873.199,
        "duration": 6.801
    },
    {
        "text": "dynamic and you can just use",
        "start": 876.639,
        "duration": 6.161
    },
    {
        "text": "data find the dynamic genes and then",
        "start": 880.0,
        "duration": 4.72
    },
    {
        "text": "push them into the next",
        "start": 882.8,
        "duration": 6.08
    },
    {
        "text": "sort of stage of phase analysis",
        "start": 884.72,
        "duration": 4.16
    },
    {
        "text": "now um gaussian processes",
        "start": 891.04,
        "duration": 8.08
    },
    {
        "text": "if you just apply naively are slow",
        "start": 895.92,
        "duration": 6.0
    },
    {
        "text": "because they involve a big fixing verb",
        "start": 899.12,
        "duration": 5.76
    },
    {
        "text": "and that's cubicking complexity with the",
        "start": 901.92,
        "duration": 4.719
    },
    {
        "text": "number of time points or the number of",
        "start": 904.88,
        "duration": 3.84
    },
    {
        "text": "space you'll look at",
        "start": 906.639,
        "duration": 6.081
    },
    {
        "text": "so that's completely impractical but",
        "start": 908.72,
        "duration": 5.84
    },
    {
        "text": "there's lots of ways of getting around",
        "start": 912.72,
        "duration": 3.919
    },
    {
        "text": "that so we use something called sparse",
        "start": 914.56,
        "duration": 2.88
    },
    {
        "text": "inference",
        "start": 916.639,
        "duration": 4.0
    },
    {
        "text": "with inducing points and um",
        "start": 917.44,
        "duration": 7.399
    },
    {
        "text": "that scales linearly in the dimension of",
        "start": 920.639,
        "duration": 6.481
    },
    {
        "text": "data quadratically in the number of",
        "start": 924.839,
        "duration": 3.56
    },
    {
        "text": "inducing points",
        "start": 927.12,
        "duration": 3.04
    },
    {
        "text": "but the inducing points only need to",
        "start": 928.399,
        "duration": 4.8
    },
    {
        "text": "really be um",
        "start": 930.16,
        "duration": 3.039
    },
    {
        "text": "sort of logarithmic in the dimensions so",
        "start": 933.36,
        "duration": 5.2
    },
    {
        "text": "k there can scale logarithmically",
        "start": 936.399,
        "duration": 3.601
    },
    {
        "text": "usually i think",
        "start": 938.56,
        "duration": 3.92
    },
    {
        "text": "and the whole thing is just a little bit",
        "start": 940.0,
        "duration": 4.0
    },
    {
        "text": "slower than uh linear",
        "start": 942.48,
        "duration": 4.719
    },
    {
        "text": "so that's not bad times",
        "start": 944.0,
        "duration": 6.24
    },
    {
        "text": "we have a model that has some",
        "start": 947.199,
        "duration": 6.481
    },
    {
        "text": "time to talk about models with",
        "start": 950.24,
        "duration": 7.279
    },
    {
        "text": "i must talk about gaussian data",
        "start": 953.68,
        "duration": 7.839
    },
    {
        "text": "uh you can no longer do everything atlas",
        "start": 957.519,
        "duration": 7.041
    },
    {
        "text": "and you have to use something uh like",
        "start": 961.519,
        "duration": 6.88
    },
    {
        "text": "mcmc or variational inference and we use",
        "start": 964.56,
        "duration": 6.88
    },
    {
        "text": "variational inference",
        "start": 968.399,
        "duration": 3.041
    },
    {
        "text": "and finally you can also benefit from",
        "start": 971.68,
        "duration": 4.0
    },
    {
        "text": "all the advances",
        "start": 974.32,
        "duration": 4.24
    },
    {
        "text": "in software engineering from the deep",
        "start": 975.68,
        "duration": 4.719
    },
    {
        "text": "learning community so they've",
        "start": 978.56,
        "duration": 3.519
    },
    {
        "text": "got these really nice methods like",
        "start": 980.399,
        "duration": 3.201
    },
    {
        "text": "tensorflow",
        "start": 982.079,
        "duration": 4.801
    },
    {
        "text": "and pi torch these methods allow you to",
        "start": 983.6,
        "duration": 5.52
    },
    {
        "text": "make really good use of processors",
        "start": 986.88,
        "duration": 5.04
    },
    {
        "text": "so you can use all your cpus and gpus to",
        "start": 989.12,
        "duration": 4.24
    },
    {
        "text": "full effect",
        "start": 991.92,
        "duration": 5.12
    },
    {
        "text": "um and really these things have",
        "start": 993.36,
        "duration": 7.039
    },
    {
        "text": "matured tremendously in the last",
        "start": 997.04,
        "duration": 7.44
    },
    {
        "text": "five to ten years so i think that",
        "start": 1000.399,
        "duration": 6.081
    },
    {
        "text": "getting process inference is a lot more",
        "start": 1004.48,
        "duration": 3.919
    },
    {
        "text": "practical for big data than it was",
        "start": 1006.48,
        "duration": 4.24
    },
    {
        "text": "in the past so i think it's it's really",
        "start": 1008.399,
        "duration": 5.68
    },
    {
        "text": "become a very practical tool",
        "start": 1010.72,
        "duration": 3.359
    },
    {
        "text": "okay so that was kind of uh",
        "start": 1018.639,
        "duration": 7.121
    },
    {
        "text": "you know in processes 101 world wind",
        "start": 1022.24,
        "duration": 7.12
    },
    {
        "text": "uh tour uh so now talk about a few",
        "start": 1025.76,
        "duration": 4.64
    },
    {
        "text": "applications",
        "start": 1029.36,
        "duration": 4.959
    },
    {
        "text": "uh bioinformatics app okay",
        "start": 1030.4,
        "duration": 3.919
    },
    {
        "text": "so first i'm going to talk a bit about",
        "start": 1035.439,
        "duration": 3.281
    },
    {
        "text": "dimensionality reduction and super time",
        "start": 1036.88,
        "duration": 3.76
    },
    {
        "text": "inference",
        "start": 1038.72,
        "duration": 5.68
    },
    {
        "text": "um so people are probably very familiar",
        "start": 1040.64,
        "duration": 7.439
    },
    {
        "text": "with pseudotime is well established now",
        "start": 1044.4,
        "duration": 4.32
    },
    {
        "text": "and there's",
        "start": 1048.079,
        "duration": 4.48
    },
    {
        "text": "there's tens of packages uh",
        "start": 1048.72,
        "duration": 6.959
    },
    {
        "text": "doing this um so the idea",
        "start": 1052.559,
        "duration": 6.641
    },
    {
        "text": "is if we're doing single cell genomics",
        "start": 1055.679,
        "duration": 6.401
    },
    {
        "text": "we typically destroy the cell and",
        "start": 1059.2,
        "duration": 3.92
    },
    {
        "text": "enrichment",
        "start": 1062.08,
        "duration": 4.24
    },
    {
        "text": "we can't follow in time and",
        "start": 1063.12,
        "duration": 7.04
    },
    {
        "text": "if we're interested in something that's",
        "start": 1066.32,
        "duration": 5.359
    },
    {
        "text": "going on in this song",
        "start": 1070.16,
        "duration": 3.759
    },
    {
        "text": "we might want to infer where the cells",
        "start": 1071.679,
        "duration": 4.161
    },
    {
        "text": "are in that dynamic process",
        "start": 1073.919,
        "duration": 4.561
    },
    {
        "text": "so it's a bit like rediscovering time",
        "start": 1075.84,
        "duration": 4.88
    },
    {
        "text": "from high dimensional time series data",
        "start": 1078.48,
        "duration": 3.92
    },
    {
        "text": "and having a sort of pseudo-temporal",
        "start": 1080.72,
        "duration": 3.44
    },
    {
        "text": "ordering of cells and here's a picture",
        "start": 1082.4,
        "duration": 3.76
    },
    {
        "text": "from the nice slingshot method",
        "start": 1084.16,
        "duration": 4.96
    },
    {
        "text": "where first you reduce the",
        "start": 1086.16,
        "duration": 4.08
    },
    {
        "text": "dimensionality",
        "start": 1089.12,
        "duration": 3.2
    },
    {
        "text": "of the data into some low dimensional",
        "start": 1090.24,
        "duration": 3.76
    },
    {
        "text": "space not really three",
        "start": 1092.32,
        "duration": 3.599
    },
    {
        "text": "i think a bit higher than three but just",
        "start": 1094.0,
        "duration": 4.16
    },
    {
        "text": "this is just a picture",
        "start": 1095.919,
        "duration": 4.321
    },
    {
        "text": "uh they do some clustering and then they",
        "start": 1098.16,
        "duration": 4.08
    },
    {
        "text": "join the clusters together with a",
        "start": 1100.24,
        "duration": 5.28
    },
    {
        "text": "minimum spanning tree and then do some",
        "start": 1102.24,
        "duration": 4.16
    },
    {
        "text": "smoothing",
        "start": 1105.52,
        "duration": 2.56
    },
    {
        "text": "doing some sort of principle curves",
        "start": 1106.4,
        "duration": 3.6
    },
    {
        "text": "modeling through that space",
        "start": 1108.08,
        "duration": 6.959
    },
    {
        "text": "and to work out pseudotime profiles",
        "start": 1110.0,
        "duration": 5.039
    },
    {
        "text": "so there was a nice paper from john reed",
        "start": 1118.24,
        "duration": 4.16
    },
    {
        "text": "and lawrence varnish",
        "start": 1121.12,
        "duration": 3.36
    },
    {
        "text": "a few years ago introducing something",
        "start": 1122.4,
        "duration": 4.159
    },
    {
        "text": "called the delorean package",
        "start": 1124.48,
        "duration": 4.559
    },
    {
        "text": "which did sue the time using a bayesian",
        "start": 1126.559,
        "duration": 3.601
    },
    {
        "text": "gprvm",
        "start": 1129.039,
        "duration": 4.321
    },
    {
        "text": "which is a type of geysing process",
        "start": 1130.16,
        "duration": 6.16
    },
    {
        "text": "um but it's a gaussian process where you",
        "start": 1133.36,
        "duration": 3.84
    },
    {
        "text": "infer",
        "start": 1136.32,
        "duration": 5.28
    },
    {
        "text": "the um time variable as well",
        "start": 1137.2,
        "duration": 8.16
    },
    {
        "text": "as the um data",
        "start": 1141.6,
        "duration": 10.24
    },
    {
        "text": "y so you're inferring one e",
        "start": 1145.36,
        "duration": 6.48
    },
    {
        "text": "um the nice thing about this",
        "start": 1153.28,
        "duration": 6.88
    },
    {
        "text": "is that if you have some private about",
        "start": 1156.72,
        "duration": 5.6
    },
    {
        "text": "where the cells are and dynamic process",
        "start": 1160.16,
        "duration": 3.92
    },
    {
        "text": "you're interested in",
        "start": 1162.32,
        "duration": 4.0
    },
    {
        "text": "so maybe you've captured them at some",
        "start": 1164.08,
        "duration": 4.16
    },
    {
        "text": "particular point",
        "start": 1166.32,
        "duration": 5.84
    },
    {
        "text": "in the process then you can introduce",
        "start": 1168.24,
        "duration": 4.319
    },
    {
        "text": "that",
        "start": 1172.16,
        "duration": 3.92
    },
    {
        "text": "model as a prior",
        "start": 1172.559,
        "duration": 6.801
    },
    {
        "text": "and that information about and helps you",
        "start": 1176.08,
        "duration": 4.479
    },
    {
        "text": "infer",
        "start": 1179.36,
        "duration": 4.24
    },
    {
        "text": "pseudo time so you can't apply this to",
        "start": 1180.559,
        "duration": 4.801
    },
    {
        "text": "every data set but if you have a data",
        "start": 1183.6,
        "duration": 3.199
    },
    {
        "text": "set where you have some capture time",
        "start": 1185.36,
        "duration": 2.72
    },
    {
        "text": "information",
        "start": 1186.799,
        "duration": 4.481
    },
    {
        "text": "um then this is a useful approach but",
        "start": 1188.08,
        "duration": 3.92
    },
    {
        "text": "this was a nice",
        "start": 1191.28,
        "duration": 2.24
    },
    {
        "text": "paper but it didn't really scale very",
        "start": 1192.0,
        "duration": 4.16
    },
    {
        "text": "well and in 2016 the data sets weren't",
        "start": 1193.52,
        "duration": 5.76
    },
    {
        "text": "so huge um and",
        "start": 1196.16,
        "duration": 7.2
    },
    {
        "text": "um they used i think stan to implement",
        "start": 1199.28,
        "duration": 5.04
    },
    {
        "text": "this",
        "start": 1203.36,
        "duration": 4.88
    },
    {
        "text": "and every um cell was a variable that",
        "start": 1204.32,
        "duration": 4.96
    },
    {
        "text": "you had to do",
        "start": 1208.24,
        "duration": 3.679
    },
    {
        "text": "mcmc over and stan so it stands really",
        "start": 1209.28,
        "duration": 3.44
    },
    {
        "text": "nice but",
        "start": 1211.919,
        "duration": 2.321
    },
    {
        "text": "it doesn't really it's not going to",
        "start": 1212.72,
        "duration": 4.16
    },
    {
        "text": "scale you up to millions of cells",
        "start": 1214.24,
        "duration": 4.72
    },
    {
        "text": "so we re-implemented this using a more",
        "start": 1216.88,
        "duration": 3.279
    },
    {
        "text": "scalable architecture",
        "start": 1218.96,
        "duration": 4.32
    },
    {
        "text": "using gp flow and",
        "start": 1220.159,
        "duration": 6.961
    },
    {
        "text": "we introduced a new or a modified",
        "start": 1223.28,
        "duration": 6.08
    },
    {
        "text": "variational inference algorithm and",
        "start": 1227.12,
        "duration": 3.439
    },
    {
        "text": "another thing we did was",
        "start": 1229.36,
        "duration": 3.52
    },
    {
        "text": "as well as inferring pseudotime we also",
        "start": 1230.559,
        "duration": 4.641
    },
    {
        "text": "introduced other dimensions",
        "start": 1232.88,
        "duration": 5.44
    },
    {
        "text": "into the laying space and we found that",
        "start": 1235.2,
        "duration": 4.88
    },
    {
        "text": "be quite useful so as well as",
        "start": 1238.32,
        "duration": 4.32
    },
    {
        "text": "having time we also had some additional",
        "start": 1240.08,
        "duration": 4.0
    },
    {
        "text": "lane variable",
        "start": 1242.64,
        "duration": 4.8
    },
    {
        "text": "color x and x could model other types of",
        "start": 1244.08,
        "duration": 3.92
    },
    {
        "text": "variation",
        "start": 1247.44,
        "duration": 2.08
    },
    {
        "text": "that might reflect for instance",
        "start": 1248.0,
        "duration": 3.12
    },
    {
        "text": "branching that's going on",
        "start": 1249.52,
        "duration": 4.72
    },
    {
        "text": "as you go through time and we publish",
        "start": 1251.12,
        "duration": 3.919
    },
    {
        "text": "this as the",
        "start": 1254.24,
        "duration": 4.0
    },
    {
        "text": "grand prix package",
        "start": 1255.039,
        "duration": 3.201
    },
    {
        "text": "so just to explain the branching",
        "start": 1259.36,
        "duration": 6.72
    },
    {
        "text": "i'm going to show results from uh it's",
        "start": 1263.12,
        "duration": 3.36
    },
    {
        "text": "it's",
        "start": 1266.08,
        "duration": 1.92
    },
    {
        "text": "it's not a very big data set but it's a",
        "start": 1266.48,
        "duration": 2.8
    },
    {
        "text": "very nice data set for sort of",
        "start": 1268.0,
        "duration": 2.799
    },
    {
        "text": "explaining the idea",
        "start": 1269.28,
        "duration": 5.759
    },
    {
        "text": "so it's an old data set or using qpcr",
        "start": 1270.799,
        "duration": 7.281
    },
    {
        "text": "on early very early",
        "start": 1275.039,
        "duration": 6.721
    },
    {
        "text": "embryonic development in mouse",
        "start": 1278.08,
        "duration": 6.959
    },
    {
        "text": "and the idea is that you go from",
        "start": 1281.76,
        "duration": 4.88
    },
    {
        "text": "really the earliest stage where you have",
        "start": 1285.039,
        "duration": 3.76
    },
    {
        "text": "a single cell and then it goes into",
        "start": 1286.64,
        "duration": 4.399
    },
    {
        "text": "doubles into two cells and four cells",
        "start": 1288.799,
        "duration": 4.401
    },
    {
        "text": "eight cells and so on",
        "start": 1291.039,
        "duration": 4.081
    },
    {
        "text": "into the inner cell mass and then the",
        "start": 1293.2,
        "duration": 3.04
    },
    {
        "text": "trifecta derm",
        "start": 1295.12,
        "duration": 4.32
    },
    {
        "text": "epiblast and primitive endotherm and so",
        "start": 1296.24,
        "duration": 5.919
    },
    {
        "text": "by the time you're at the 64 cell stage",
        "start": 1299.44,
        "duration": 6.8
    },
    {
        "text": "you've got three different cell types um",
        "start": 1302.159,
        "duration": 7.281
    },
    {
        "text": "and um so",
        "start": 1306.24,
        "duration": 5.84
    },
    {
        "text": "if if if you can capture the cells at",
        "start": 1309.44,
        "duration": 4.719
    },
    {
        "text": "all these different stages",
        "start": 1312.08,
        "duration": 3.52
    },
    {
        "text": "then you've got a lot of information",
        "start": 1314.159,
        "duration": 3.041
    },
    {
        "text": "about time but then you can use",
        "start": 1315.6,
        "duration": 3.36
    },
    {
        "text": "pseudotime to kind of model the fact",
        "start": 1317.2,
        "duration": 2.959
    },
    {
        "text": "that the cells are",
        "start": 1318.96,
        "duration": 3.36
    },
    {
        "text": "differentiating into different cell",
        "start": 1320.159,
        "duration": 3.841
    },
    {
        "text": "types over time",
        "start": 1322.32,
        "duration": 4.88
    },
    {
        "text": "now if you just do pca um it doesn't",
        "start": 1324.0,
        "duration": 3.919
    },
    {
        "text": "really work",
        "start": 1327.2,
        "duration": 4.16
    },
    {
        "text": "it's clearly a non-linear data set",
        "start": 1327.919,
        "duration": 7.921
    },
    {
        "text": "um and so um pca is not not going to do",
        "start": 1331.36,
        "duration": 5.52
    },
    {
        "text": "it",
        "start": 1335.84,
        "duration": 2.48
    },
    {
        "text": "everything's going to be kind of mixed",
        "start": 1336.88,
        "duration": 4.64
    },
    {
        "text": "up the standard gpr vm",
        "start": 1338.32,
        "duration": 6.8
    },
    {
        "text": "is a typical kind of non-linear",
        "start": 1341.52,
        "duration": 6.96
    },
    {
        "text": "um dimensionality reduction algorithm",
        "start": 1345.12,
        "duration": 5.12
    },
    {
        "text": "and so you can think of that as just",
        "start": 1348.48,
        "duration": 3.36
    },
    {
        "text": "doing t-sne or umap",
        "start": 1350.24,
        "duration": 4.08
    },
    {
        "text": "or one of these kind of methods and it's",
        "start": 1351.84,
        "duration": 4.079
    },
    {
        "text": "non-linear so it's much better",
        "start": 1354.32,
        "duration": 5.12
    },
    {
        "text": "separating out the different stages",
        "start": 1355.919,
        "duration": 5.361
    },
    {
        "text": "so here i've used colors for each",
        "start": 1359.44,
        "duration": 3.92
    },
    {
        "text": "different stage and then",
        "start": 1361.28,
        "duration": 5.519
    },
    {
        "text": "those also for different cell types",
        "start": 1363.36,
        "duration": 6.64
    },
    {
        "text": "um but what you can see is that the time",
        "start": 1366.799,
        "duration": 6.24
    },
    {
        "text": "order of the process so so these",
        "start": 1370.0,
        "duration": 7.039
    },
    {
        "text": "differentiation times uh",
        "start": 1373.039,
        "duration": 5.841
    },
    {
        "text": "they aren't really reflected in the",
        "start": 1377.039,
        "duration": 3.681
    },
    {
        "text": "latent space so this low dimensional",
        "start": 1378.88,
        "duration": 2.48
    },
    {
        "text": "space here",
        "start": 1380.72,
        "duration": 2.4
    },
    {
        "text": "doesn't really capture the fact that you",
        "start": 1381.36,
        "duration": 5.84
    },
    {
        "text": "go from 8 16 to 32 to 64.",
        "start": 1383.12,
        "duration": 7.679
    },
    {
        "text": "the 32 inner cell mass is",
        "start": 1387.2,
        "duration": 7.2
    },
    {
        "text": "um away from the trifecta dome of 32",
        "start": 1390.799,
        "duration": 5.441
    },
    {
        "text": "and it's separated by these other cells",
        "start": 1394.4,
        "duration": 4.0
    },
    {
        "text": "at 64 stage",
        "start": 1396.24,
        "duration": 3.84
    },
    {
        "text": "so the latent space doesn't really",
        "start": 1398.4,
        "duration": 4.08
    },
    {
        "text": "reflect reflect the temporal",
        "start": 1400.08,
        "duration": 6.16
    },
    {
        "text": "um nature of the data",
        "start": 1402.48,
        "duration": 3.76
    },
    {
        "text": "so on the left showing the same",
        "start": 1407.84,
        "duration": 6.24
    },
    {
        "text": "standard gprvm picture on the right i've",
        "start": 1410.96,
        "duration": 6.079
    },
    {
        "text": "shown the result of using grand prix",
        "start": 1414.08,
        "duration": 5.52
    },
    {
        "text": "so we're growing we put some prior",
        "start": 1417.039,
        "duration": 3.041
    },
    {
        "text": "knowledge",
        "start": 1419.6,
        "duration": 4.48
    },
    {
        "text": "that we know which cells around",
        "start": 1420.08,
        "duration": 6.88
    },
    {
        "text": "so we know uh the one two four eight",
        "start": 1424.08,
        "duration": 5.28
    },
    {
        "text": "sixteen a two sixty four",
        "start": 1426.96,
        "duration": 5.44
    },
    {
        "text": "and then we just use gpm to add in the",
        "start": 1429.36,
        "duration": 6.319
    },
    {
        "text": "additional variation in the um",
        "start": 1432.4,
        "duration": 6.56
    },
    {
        "text": "hearer's y-axis",
        "start": 1435.679,
        "duration": 6.401
    },
    {
        "text": "and really captures the",
        "start": 1438.96,
        "duration": 6.24
    },
    {
        "text": "differentiation into cell types at",
        "start": 1442.08,
        "duration": 6.479
    },
    {
        "text": "time to time 64.",
        "start": 1445.2,
        "duration": 7.16
    },
    {
        "text": "so it gives us a much kind of clearer",
        "start": 1448.559,
        "duration": 7.041
    },
    {
        "text": "representation of this uh developmental",
        "start": 1452.36,
        "duration": 4.36
    },
    {
        "text": "process",
        "start": 1455.6,
        "duration": 4.959
    },
    {
        "text": "over time than the standard",
        "start": 1456.72,
        "duration": 6.72
    },
    {
        "text": "representation",
        "start": 1460.559,
        "duration": 2.881
    },
    {
        "text": "another advantage of adding in that",
        "start": 1465.919,
        "duration": 4.561
    },
    {
        "text": "extra dimension so you can",
        "start": 1468.48,
        "duration": 4.88
    },
    {
        "text": "you can go back and look at how good",
        "start": 1470.48,
        "duration": 4.16
    },
    {
        "text": "your latent",
        "start": 1473.36,
        "duration": 3.199
    },
    {
        "text": "representation of data really",
        "start": 1474.64,
        "duration": 4.24
    },
    {
        "text": "corresponds to the known",
        "start": 1476.559,
        "duration": 4.881
    },
    {
        "text": "times for the cells so the capture",
        "start": 1478.88,
        "duration": 3.919
    },
    {
        "text": "stages",
        "start": 1481.44,
        "duration": 3.52
    },
    {
        "text": "and if you use the original approach of",
        "start": 1482.799,
        "duration": 3.921
    },
    {
        "text": "just inferring time",
        "start": 1484.96,
        "duration": 3.199
    },
    {
        "text": "only having time as your latent",
        "start": 1486.72,
        "duration": 4.0
    },
    {
        "text": "dimension and no other variation",
        "start": 1488.159,
        "duration": 5.12
    },
    {
        "text": "you actually get a much poorer solution",
        "start": 1490.72,
        "duration": 3.28
    },
    {
        "text": "you find",
        "start": 1493.279,
        "duration": 2.961
    },
    {
        "text": "you find you get stuck in local optima",
        "start": 1494.0,
        "duration": 3.2
    },
    {
        "text": "basically",
        "start": 1496.24,
        "duration": 3.919
    },
    {
        "text": "which don't really reflect the temporal",
        "start": 1497.2,
        "duration": 3.68
    },
    {
        "text": "progression",
        "start": 1500.159,
        "duration": 3.12
    },
    {
        "text": "through those stages but if you do the",
        "start": 1500.88,
        "duration": 4.799
    },
    {
        "text": "2d optimization where you also allow for",
        "start": 1503.279,
        "duration": 3.921
    },
    {
        "text": "the branching",
        "start": 1505.679,
        "duration": 4.24
    },
    {
        "text": "then the times are much better reflected",
        "start": 1507.2,
        "duration": 4.56
    },
    {
        "text": "in the",
        "start": 1509.919,
        "duration": 4.24
    },
    {
        "text": "latent space so it seems like having",
        "start": 1511.76,
        "duration": 3.68
    },
    {
        "text": "this 2d",
        "start": 1514.159,
        "duration": 3.361
    },
    {
        "text": "approach rather than just learning a 1d",
        "start": 1515.44,
        "duration": 3.599
    },
    {
        "text": "space",
        "start": 1517.52,
        "duration": 4.48
    },
    {
        "text": "also improves the 1d inference improve",
        "start": 1519.039,
        "duration": 5.12
    },
    {
        "text": "improves the time inference",
        "start": 1522.0,
        "duration": 4.08
    },
    {
        "text": "and then once you've inferred sudo time",
        "start": 1524.159,
        "duration": 3.921
    },
    {
        "text": "you can go back to individual genes and",
        "start": 1526.08,
        "duration": 3.12
    },
    {
        "text": "see how they behave",
        "start": 1528.08,
        "duration": 3.76
    },
    {
        "text": "so you know in this case we can see that",
        "start": 1529.2,
        "duration": 4.88
    },
    {
        "text": "id2 here is already looking like it's",
        "start": 1531.84,
        "duration": 3.6
    },
    {
        "text": "differentiating at the",
        "start": 1534.08,
        "duration": 5.04
    },
    {
        "text": "16 cell stage even though that wasn't",
        "start": 1535.44,
        "duration": 7.2
    },
    {
        "text": "apparent in the kind of global",
        "start": 1539.12,
        "duration": 3.52
    },
    {
        "text": "reduced dimension picture um but it's",
        "start": 1543.12,
        "duration": 5.679
    },
    {
        "text": "probably not involved here in the",
        "start": 1546.08,
        "duration": 6.16
    },
    {
        "text": "epiblast differentiation later",
        "start": 1548.799,
        "duration": 6.081
    },
    {
        "text": "whereas sox2 is involved in the epiblast",
        "start": 1552.24,
        "duration": 4.08
    },
    {
        "text": "later",
        "start": 1554.88,
        "duration": 3.679
    },
    {
        "text": "so now that kind of links me to the next",
        "start": 1556.32,
        "duration": 3.839
    },
    {
        "text": "part because",
        "start": 1558.559,
        "duration": 4.48
    },
    {
        "text": "if we look at individual genes as we are",
        "start": 1560.159,
        "duration": 4.801
    },
    {
        "text": "here in the bottom",
        "start": 1563.039,
        "duration": 4.481
    },
    {
        "text": "then we might ask the question which",
        "start": 1564.96,
        "duration": 4.56
    },
    {
        "text": "genes are associated with branching",
        "start": 1567.52,
        "duration": 3.44
    },
    {
        "text": "events",
        "start": 1569.52,
        "duration": 3.759
    },
    {
        "text": "and so we can see here that sox2 is",
        "start": 1570.96,
        "duration": 5.28
    },
    {
        "text": "clearly involved in",
        "start": 1573.279,
        "duration": 4.88
    },
    {
        "text": "that transition from the inner cell mass",
        "start": 1576.24,
        "duration": 4.16
    },
    {
        "text": "to the epiblast",
        "start": 1578.159,
        "duration": 5.281
    },
    {
        "text": "um and",
        "start": 1580.4,
        "duration": 5.92
    },
    {
        "text": "so in order to do that we have to go",
        "start": 1583.44,
        "duration": 4.479
    },
    {
        "text": "down and kind of model things at",
        "start": 1586.32,
        "duration": 2.8
    },
    {
        "text": "individual genes",
        "start": 1587.919,
        "duration": 2.721
    },
    {
        "text": "and that's what i'm going to talk about",
        "start": 1589.12,
        "duration": 3.84
    },
    {
        "text": "next",
        "start": 1590.64,
        "duration": 2.32
    },
    {
        "text": "um just before i finish",
        "start": 1593.279,
        "duration": 6.241
    },
    {
        "text": "scalability so that was a very small",
        "start": 1597.6,
        "duration": 3.76
    },
    {
        "text": "example as i said",
        "start": 1599.52,
        "duration": 5.039
    },
    {
        "text": "introducing this implementation in gp",
        "start": 1601.36,
        "duration": 4.88
    },
    {
        "text": "flow right allows us to really scale",
        "start": 1604.559,
        "duration": 2.961
    },
    {
        "text": "this up to big",
        "start": 1606.24,
        "duration": 4.4
    },
    {
        "text": "data sets this is not a pseudo time one",
        "start": 1607.52,
        "duration": 5.44
    },
    {
        "text": "this is just a dimensionality reduction",
        "start": 1610.64,
        "duration": 4.8
    },
    {
        "text": "problem so this is a standard gpu vm",
        "start": 1612.96,
        "duration": 5.36
    },
    {
        "text": "which shows it's very kind of scalable",
        "start": 1615.44,
        "duration": 4.0
    },
    {
        "text": "um",
        "start": 1618.32,
        "duration": 5.599
    },
    {
        "text": "and this data",
        "start": 1619.44,
        "duration": 4.479
    },
    {
        "text": "i think we initialized using t-sne and",
        "start": 1624.799,
        "duration": 3.441
    },
    {
        "text": "what we found that",
        "start": 1626.96,
        "duration": 4.4
    },
    {
        "text": "was that the gprvm latent space actually",
        "start": 1628.24,
        "duration": 3.76
    },
    {
        "text": "ended up",
        "start": 1631.36,
        "duration": 2.799
    },
    {
        "text": "more consistent with the clusters in",
        "start": 1632.0,
        "duration": 3.6
    },
    {
        "text": "this data than the",
        "start": 1634.159,
        "duration": 4.721
    },
    {
        "text": "uh this one where the clusters were",
        "start": 1635.6,
        "duration": 5.12
    },
    {
        "text": "found not not in low dimensional space",
        "start": 1638.88,
        "duration": 2.24
    },
    {
        "text": "but",
        "start": 1640.72,
        "duration": 3.839
    },
    {
        "text": "in the higher dimensional space",
        "start": 1641.12,
        "duration": 3.439
    },
    {
        "text": "um one nice thing we found was the",
        "start": 1644.799,
        "duration": 8.24
    },
    {
        "text": "uh so so uber developed",
        "start": 1649.279,
        "duration": 7.28
    },
    {
        "text": "this package called pyro for um",
        "start": 1653.039,
        "duration": 6.64
    },
    {
        "text": "probabilistic programming uh it's a bit",
        "start": 1656.559,
        "duration": 4.081
    },
    {
        "text": "like stan",
        "start": 1659.679,
        "duration": 3.041
    },
    {
        "text": "but it uses different inference",
        "start": 1660.64,
        "duration": 3.6
    },
    {
        "text": "techniques",
        "start": 1662.72,
        "duration": 5.839
    },
    {
        "text": "so you can just write model and",
        "start": 1664.24,
        "duration": 6.48
    },
    {
        "text": "the ornates all the different spots",
        "start": 1668.559,
        "duration": 4.48
    },
    {
        "text": "really nice",
        "start": 1670.72,
        "duration": 5.36
    },
    {
        "text": "and um we just used",
        "start": 1673.039,
        "duration": 4.801
    },
    {
        "text": "our paper to make the sample for the",
        "start": 1676.08,
        "duration": 3.199
    },
    {
        "text": "gprvm so those",
        "start": 1677.84,
        "duration": 4.079
    },
    {
        "text": "can be independent we just noticed",
        "start": 1679.279,
        "duration": 4.64
    },
    {
        "text": "they've done this",
        "start": 1681.919,
        "duration": 3.76
    },
    {
        "text": "and they've implemented it in both from",
        "start": 1683.919,
        "duration": 4.24
    },
    {
        "text": "scratch and they get exactly the same",
        "start": 1685.679,
        "duration": 3.12
    },
    {
        "text": "results",
        "start": 1688.159,
        "duration": 3.841
    },
    {
        "text": "so it's quite nice because it you know",
        "start": 1688.799,
        "duration": 5.041
    },
    {
        "text": "we're very much into repo",
        "start": 1692.0,
        "duration": 5.279
    },
    {
        "text": "research and reproducing results um",
        "start": 1693.84,
        "duration": 6.719
    },
    {
        "text": "but reproducing something including",
        "start": 1697.279,
        "duration": 4.88
    },
    {
        "text": "implementing in a different framework",
        "start": 1700.559,
        "duration": 3.36
    },
    {
        "text": "and getting the same results very nice",
        "start": 1702.159,
        "duration": 4.321
    },
    {
        "text": "so so that gave us so it shows actually",
        "start": 1703.919,
        "duration": 4.961
    },
    {
        "text": "the model isn't quite",
        "start": 1706.48,
        "duration": 4.96
    },
    {
        "text": "simple and can be implemented in many",
        "start": 1708.88,
        "duration": 3.44
    },
    {
        "text": "different ways",
        "start": 1711.44,
        "duration": 3.2
    },
    {
        "text": "and you know there's lots of practical",
        "start": 1712.32,
        "duration": 3.76
    },
    {
        "text": "tools out there for doing this type of",
        "start": 1714.64,
        "duration": 1.919
    },
    {
        "text": "modeling",
        "start": 1716.08,
        "duration": 4.16
    },
    {
        "text": "and pyro looks actually really nice",
        "start": 1716.559,
        "duration": 3.681
    },
    {
        "text": "um recently uh verma and barbara",
        "start": 1721.36,
        "duration": 4.16
    },
    {
        "text": "engelhardt",
        "start": 1724.64,
        "duration": 3.6
    },
    {
        "text": "um have a really nice version of the",
        "start": 1725.52,
        "duration": 4.24
    },
    {
        "text": "gprvm",
        "start": 1728.24,
        "duration": 4.64
    },
    {
        "text": "which is a bit more robust um than the",
        "start": 1729.76,
        "duration": 6.24
    },
    {
        "text": "standard gaussian that we use so",
        "start": 1732.88,
        "duration": 6.96
    },
    {
        "text": "they're using a student t",
        "start": 1736.0,
        "duration": 6.399
    },
    {
        "text": "likelihood so it's a bit more robust to",
        "start": 1739.84,
        "duration": 3.68
    },
    {
        "text": "heavy tailed",
        "start": 1742.399,
        "duration": 4.4
    },
    {
        "text": "kind of noise they use a slightly more",
        "start": 1743.52,
        "duration": 6.56
    },
    {
        "text": "general set of covariance functions",
        "start": 1746.799,
        "duration": 5.201
    },
    {
        "text": "and it looks really nice and if you look",
        "start": 1750.08,
        "duration": 3.92
    },
    {
        "text": "at this paper it actually shows that",
        "start": 1752.0,
        "duration": 3.84
    },
    {
        "text": "this scale is better than",
        "start": 1754.0,
        "duration": 5.039
    },
    {
        "text": "things like umap and t-sne actually",
        "start": 1755.84,
        "duration": 6.48
    },
    {
        "text": "so i think people are probably thinking",
        "start": 1759.039,
        "duration": 5.52
    },
    {
        "text": "gaussian processes are slow thing",
        "start": 1762.32,
        "duration": 4.959
    },
    {
        "text": "and maybe avoid them for that reason but",
        "start": 1764.559,
        "duration": 4.561
    },
    {
        "text": "if you look at this paper",
        "start": 1767.279,
        "duration": 3.441
    },
    {
        "text": "you can see actually that when you",
        "start": 1769.12,
        "duration": 3.039
    },
    {
        "text": "implement them",
        "start": 1770.72,
        "duration": 2.88
    },
    {
        "text": "in a modern framework they're pretty",
        "start": 1772.159,
        "duration": 3.52
    },
    {
        "text": "scalable so i like this paper i thought",
        "start": 1773.6,
        "duration": 7.6
    },
    {
        "text": "it was really nice",
        "start": 1775.679,
        "duration": 9.041
    },
    {
        "text": "okay so um that was",
        "start": 1781.2,
        "duration": 6.24
    },
    {
        "text": "that was kind of looking at gps for",
        "start": 1784.72,
        "duration": 4.24
    },
    {
        "text": "modeling high dimensional data and",
        "start": 1787.44,
        "duration": 3.04
    },
    {
        "text": "inferring a low dimensional",
        "start": 1788.96,
        "duration": 6.0
    },
    {
        "text": "lane space um",
        "start": 1790.48,
        "duration": 7.919
    },
    {
        "text": "i'm gonna go back to dimensional data",
        "start": 1794.96,
        "duration": 4.48
    },
    {
        "text": "modeling actual",
        "start": 1798.399,
        "duration": 3.601
    },
    {
        "text": "individual genes and looking a bit more",
        "start": 1799.44,
        "duration": 4.08
    },
    {
        "text": "of that branching question",
        "start": 1802.0,
        "duration": 4.48
    },
    {
        "text": "you know uh seeing if there's evidence",
        "start": 1803.52,
        "duration": 4.08
    },
    {
        "text": "for genes branching",
        "start": 1806.48,
        "duration": 5.52
    },
    {
        "text": "and whether they branch early or not",
        "start": 1807.6,
        "duration": 4.4
    },
    {
        "text": "so originally we had a model for",
        "start": 1813.76,
        "duration": 4.24
    },
    {
        "text": "branching gain processes which we used",
        "start": 1816.0,
        "duration": 4.08
    },
    {
        "text": "for time series data and",
        "start": 1818.0,
        "duration": 5.44
    },
    {
        "text": "it's for what's called a two-sample",
        "start": 1820.08,
        "duration": 6.0
    },
    {
        "text": "inference problem where you have two",
        "start": 1823.44,
        "duration": 3.28
    },
    {
        "text": "different time",
        "start": 1826.08,
        "duration": 2.959
    },
    {
        "text": "series data and you want to understand",
        "start": 1826.72,
        "duration": 4.4
    },
    {
        "text": "the differences between those two time",
        "start": 1829.039,
        "duration": 3.681
    },
    {
        "text": "series so",
        "start": 1831.12,
        "duration": 5.439
    },
    {
        "text": "for example you might have a time series",
        "start": 1832.72,
        "duration": 6.24
    },
    {
        "text": "for a wild type and a time series for a",
        "start": 1836.559,
        "duration": 3.441
    },
    {
        "text": "mutant",
        "start": 1838.96,
        "duration": 4.079
    },
    {
        "text": "uh organism and you",
        "start": 1840.0,
        "duration": 5.2
    },
    {
        "text": "follow the genes over time and you ask",
        "start": 1843.039,
        "duration": 3.12
    },
    {
        "text": "you know",
        "start": 1845.2,
        "duration": 3.44
    },
    {
        "text": "which genes are changing in the mutant",
        "start": 1846.159,
        "duration": 3.12
    },
    {
        "text": "and",
        "start": 1848.64,
        "duration": 3.84
    },
    {
        "text": "when are the changes happening um and",
        "start": 1849.279,
        "duration": 4.721
    },
    {
        "text": "and that's the question we addressed",
        "start": 1852.48,
        "duration": 3.76
    },
    {
        "text": "originally with this work from a few",
        "start": 1854.0,
        "duration": 4.159
    },
    {
        "text": "years ago",
        "start": 1856.24,
        "duration": 5.2
    },
    {
        "text": "but um we can also apply this to",
        "start": 1858.159,
        "duration": 7.681
    },
    {
        "text": "single cell pseudotemporal data",
        "start": 1861.44,
        "duration": 4.4
    },
    {
        "text": "so a gaussian process as i said is a",
        "start": 1866.799,
        "duration": 5.36
    },
    {
        "text": "distribution over functions",
        "start": 1869.919,
        "duration": 3.76
    },
    {
        "text": "um but now i'm going to talk about",
        "start": 1872.159,
        "duration": 3.76
    },
    {
        "text": "branching functions so",
        "start": 1873.679,
        "duration": 5.201
    },
    {
        "text": "here the red function is a standard",
        "start": 1875.919,
        "duration": 3.521
    },
    {
        "text": "sample",
        "start": 1878.88,
        "duration": 3.6
    },
    {
        "text": "from a smooth gaussian process",
        "start": 1879.44,
        "duration": 5.119
    },
    {
        "text": "and the blue one is a gaussian process",
        "start": 1882.48,
        "duration": 4.079
    },
    {
        "text": "that touches the red one",
        "start": 1884.559,
        "duration": 5.12
    },
    {
        "text": "at a particular time point and then goes",
        "start": 1886.559,
        "duration": 4.801
    },
    {
        "text": "off and does its own thing",
        "start": 1889.679,
        "duration": 3.441
    },
    {
        "text": "so here's one sample from that",
        "start": 1891.36,
        "duration": 4.4
    },
    {
        "text": "distribution here's another",
        "start": 1893.12,
        "duration": 4.08
    },
    {
        "text": "here's another these are just all",
        "start": 1895.76,
        "duration": 3.44
    },
    {
        "text": "samples from the same coherence",
        "start": 1897.2,
        "duration": 6.0
    },
    {
        "text": "uh function and",
        "start": 1899.2,
        "duration": 6.479
    },
    {
        "text": "you know so that's that's the the",
        "start": 1903.2,
        "duration": 4.4
    },
    {
        "text": "samples from that distribution and then",
        "start": 1905.679,
        "duration": 3.84
    },
    {
        "text": "you want to do some inference over that",
        "start": 1907.6,
        "duration": 3.199
    },
    {
        "text": "so you plug that",
        "start": 1909.519,
        "duration": 4.081
    },
    {
        "text": "covariance function into your gaussian",
        "start": 1910.799,
        "duration": 4.561
    },
    {
        "text": "process inference tool",
        "start": 1913.6,
        "duration": 4.959
    },
    {
        "text": "and you can make inferences about where",
        "start": 1915.36,
        "duration": 5.76
    },
    {
        "text": "uh when you have real data where does",
        "start": 1918.559,
        "duration": 5.441
    },
    {
        "text": "the branching happen",
        "start": 1921.12,
        "duration": 6.72
    },
    {
        "text": "so two things you can do you can say um",
        "start": 1924.0,
        "duration": 6.48
    },
    {
        "text": "what's the probability of branching at",
        "start": 1927.84,
        "duration": 4.0
    },
    {
        "text": "each time",
        "start": 1930.48,
        "duration": 4.96
    },
    {
        "text": "in that time course and the second thing",
        "start": 1931.84,
        "duration": 4.24
    },
    {
        "text": "you get",
        "start": 1935.44,
        "duration": 2.64
    },
    {
        "text": "is what's the probability of branching",
        "start": 1936.08,
        "duration": 3.52
    },
    {
        "text": "at all you know what's probability of",
        "start": 1938.08,
        "duration": 3.36
    },
    {
        "text": "branching versus non-branching",
        "start": 1939.6,
        "duration": 3.919
    },
    {
        "text": "and we can work out that using a bayes",
        "start": 1941.44,
        "duration": 4.479
    },
    {
        "text": "factor",
        "start": 1943.519,
        "duration": 2.4
    },
    {
        "text": "so if i look at time series so um this",
        "start": 1947.2,
        "duration": 4.56
    },
    {
        "text": "is some time series data",
        "start": 1949.919,
        "duration": 4.961
    },
    {
        "text": "uh then at the top i'm showing the",
        "start": 1951.76,
        "duration": 4.72
    },
    {
        "text": "probability of where the",
        "start": 1954.88,
        "duration": 2.96
    },
    {
        "text": "branching is so the posterior",
        "start": 1956.48,
        "duration": 3.52
    },
    {
        "text": "probability of where those two things",
        "start": 1957.84,
        "duration": 7.36
    },
    {
        "text": "are beginning to diverge um",
        "start": 1960.0,
        "duration": 5.2
    },
    {
        "text": "there's an evidence so and the there's",
        "start": 1969.12,
        "duration": 3.6
    },
    {
        "text": "there's",
        "start": 1972.08,
        "duration": 3.439
    },
    {
        "text": "there's very low evidence for those two",
        "start": 1972.72,
        "duration": 5.52
    },
    {
        "text": "things not branching",
        "start": 1975.519,
        "duration": 5.361
    },
    {
        "text": "here's an example where there's strong",
        "start": 1978.24,
        "duration": 4.159
    },
    {
        "text": "evidence for these things",
        "start": 1980.88,
        "duration": 4.24
    },
    {
        "text": "not branching so they look identical",
        "start": 1982.399,
        "duration": 3.361
    },
    {
        "text": "over time",
        "start": 1985.12,
        "duration": 4.32
    },
    {
        "text": "statistically at the top is a posterior",
        "start": 1985.76,
        "duration": 5.2
    },
    {
        "text": "probability of where the branching is",
        "start": 1989.44,
        "duration": 3.119
    },
    {
        "text": "but the highest value",
        "start": 1990.96,
        "duration": 4.959
    },
    {
        "text": "is at the end and",
        "start": 1992.559,
        "duration": 6.161
    },
    {
        "text": "the the base factor for whether it's",
        "start": 1995.919,
        "duration": 4.801
    },
    {
        "text": "branching or not branching is basically",
        "start": 1998.72,
        "duration": 3.839
    },
    {
        "text": "it's worked out as the height of the",
        "start": 2000.72,
        "duration": 4.88
    },
    {
        "text": "last bar divided by the average height",
        "start": 2002.559,
        "duration": 4.081
    },
    {
        "text": "of all the bars",
        "start": 2005.6,
        "duration": 2.959
    },
    {
        "text": "so if the last bar is higher than all",
        "start": 2006.64,
        "duration": 3.6
    },
    {
        "text": "the other ones it means that",
        "start": 2008.559,
        "duration": 3.441
    },
    {
        "text": "the most likely thing is that there's no",
        "start": 2010.24,
        "duration": 4.24
    },
    {
        "text": "branching",
        "start": 2012.0,
        "duration": 2.48
    },
    {
        "text": "so that was for time series that's kind",
        "start": 2016.32,
        "duration": 3.12
    },
    {
        "text": "of old work",
        "start": 2018.48,
        "duration": 4.96
    },
    {
        "text": "um then when we have uh",
        "start": 2019.44,
        "duration": 6.4
    },
    {
        "text": "pseudo-temporal data we have some",
        "start": 2023.44,
        "duration": 3.68
    },
    {
        "text": "additional",
        "start": 2025.84,
        "duration": 5.199
    },
    {
        "text": "so we have to work as time to talk about",
        "start": 2027.12,
        "duration": 6.32
    },
    {
        "text": "then we have to work out you know which",
        "start": 2031.039,
        "duration": 5.52
    },
    {
        "text": "branch does the cell actually belong to",
        "start": 2033.44,
        "duration": 6.0
    },
    {
        "text": "um we have to work out which genes are",
        "start": 2036.559,
        "duration": 4.081
    },
    {
        "text": "involved in the branching",
        "start": 2039.44,
        "duration": 3.44
    },
    {
        "text": "and when they change so the last two are",
        "start": 2040.64,
        "duration": 3.759
    },
    {
        "text": "the same as for time series but the",
        "start": 2042.88,
        "duration": 3.12
    },
    {
        "text": "question of where",
        "start": 2044.399,
        "duration": 3.441
    },
    {
        "text": "the cell lies on the branch is actually",
        "start": 2046.0,
        "duration": 3.76
    },
    {
        "text": "a new problem and we address that",
        "start": 2047.84,
        "duration": 5.839
    },
    {
        "text": "in this bp package",
        "start": 2049.76,
        "duration": 3.919
    },
    {
        "text": "so um method that did something like",
        "start": 2054.56,
        "duration": 5.359
    },
    {
        "text": "this was called beam which is based on",
        "start": 2058.159,
        "duration": 2.881
    },
    {
        "text": "splines",
        "start": 2059.919,
        "duration": 4.72
    },
    {
        "text": "and beam was uh it was implemented in",
        "start": 2061.04,
        "duration": 6.319
    },
    {
        "text": "earlier versions of monocle but i don't",
        "start": 2064.639,
        "duration": 3.76
    },
    {
        "text": "think it's in the",
        "start": 2067.359,
        "duration": 4.161
    },
    {
        "text": "current version um so",
        "start": 2068.399,
        "duration": 6.641
    },
    {
        "text": "if the data is low noise",
        "start": 2071.52,
        "duration": 7.04
    },
    {
        "text": "and um and",
        "start": 2075.04,
        "duration": 6.24
    },
    {
        "text": "you can see that the so beam here is on",
        "start": 2078.56,
        "duration": 3.839
    },
    {
        "text": "the left",
        "start": 2081.28,
        "duration": 5.04
    },
    {
        "text": "and we have uh we've done pseudotime",
        "start": 2082.399,
        "duration": 6.401
    },
    {
        "text": "inference there's some global branching",
        "start": 2086.32,
        "duration": 4.0
    },
    {
        "text": "which is the dashed",
        "start": 2088.8,
        "duration": 5.279
    },
    {
        "text": "the black line here",
        "start": 2090.32,
        "duration": 6.079
    },
    {
        "text": "and then the actual branching for this",
        "start": 2094.079,
        "duration": 3.921
    },
    {
        "text": "gene is a bit later than the global",
        "start": 2096.399,
        "duration": 3.281
    },
    {
        "text": "branching and we want to infer where",
        "start": 2098.0,
        "duration": 3.04
    },
    {
        "text": "that is",
        "start": 2099.68,
        "duration": 3.52
    },
    {
        "text": "beam fits these splines it looks where",
        "start": 2101.04,
        "duration": 4.0
    },
    {
        "text": "they cross and it finds that they branch",
        "start": 2103.2,
        "duration": 2.879
    },
    {
        "text": "late",
        "start": 2105.04,
        "duration": 2.96
    },
    {
        "text": "this is synthetic data so we know that",
        "start": 2106.079,
        "duration": 5.52
    },
    {
        "text": "this is is close to the truth",
        "start": 2108.0,
        "duration": 6.88
    },
    {
        "text": "um bgp does something similar works out",
        "start": 2111.599,
        "duration": 5.281
    },
    {
        "text": "that the branching is here",
        "start": 2114.88,
        "duration": 5.28
    },
    {
        "text": "um has some uncertainty but generally",
        "start": 2116.88,
        "duration": 3.84
    },
    {
        "text": "the two",
        "start": 2120.16,
        "duration": 4.24
    },
    {
        "text": "methods agree however if there's a lot",
        "start": 2120.72,
        "duration": 5.44
    },
    {
        "text": "of noise which is more typical with",
        "start": 2124.4,
        "duration": 3.84
    },
    {
        "text": "single cell data",
        "start": 2126.16,
        "duration": 5.199
    },
    {
        "text": "then the gaussian process says well",
        "start": 2128.24,
        "duration": 5.599
    },
    {
        "text": "you know the most likely branching is",
        "start": 2131.359,
        "duration": 3.841
    },
    {
        "text": "still late",
        "start": 2133.839,
        "duration": 4.721
    },
    {
        "text": "um but i'm super unconfident about it so",
        "start": 2135.2,
        "duration": 4.48
    },
    {
        "text": "i'm going to put big",
        "start": 2138.56,
        "duration": 4.96
    },
    {
        "text": "error bars or credible regions",
        "start": 2139.68,
        "duration": 6.56
    },
    {
        "text": "whereas the spline doesn't have any uh",
        "start": 2143.52,
        "duration": 4.48
    },
    {
        "text": "concept of uncertainty",
        "start": 2146.24,
        "duration": 3.76
    },
    {
        "text": "and it tends to be highly biased towards",
        "start": 2148.0,
        "duration": 4.24
    },
    {
        "text": "this global branching this black line so",
        "start": 2150.0,
        "duration": 3.04
    },
    {
        "text": "it becomes",
        "start": 2152.24,
        "duration": 3.44
    },
    {
        "text": "very conservative and says ah i think",
        "start": 2153.04,
        "duration": 4.559
    },
    {
        "text": "this gene just branches where the global",
        "start": 2155.68,
        "duration": 3.439
    },
    {
        "text": "branching of all the other",
        "start": 2157.599,
        "duration": 4.401
    },
    {
        "text": "genes is",
        "start": 2159.119,
        "duration": 2.881
    },
    {
        "text": "the other thing that the gaussian",
        "start": 2165.2,
        "duration": 3.919
    },
    {
        "text": "process allows us to do is it allows us",
        "start": 2167.2,
        "duration": 3.2
    },
    {
        "text": "to deal with the",
        "start": 2169.119,
        "duration": 4.641
    },
    {
        "text": "situation where branching is actually",
        "start": 2170.4,
        "duration": 5.199
    },
    {
        "text": "earlier than the global branching in the",
        "start": 2173.76,
        "duration": 3.2
    },
    {
        "text": "single in the",
        "start": 2175.599,
        "duration": 4.961
    },
    {
        "text": "um in the data so if we use",
        "start": 2176.96,
        "duration": 6.56
    },
    {
        "text": "some um",
        "start": 2180.56,
        "duration": 2.96
    },
    {
        "text": "sort of method like uh slingshot on",
        "start": 2184.48,
        "duration": 4.32
    },
    {
        "text": "monaco and we work out where the",
        "start": 2186.96,
        "duration": 4.72
    },
    {
        "text": "global branching of the cells is if we",
        "start": 2188.8,
        "duration": 5.52
    },
    {
        "text": "have a gene that branches very early",
        "start": 2191.68,
        "duration": 5.919
    },
    {
        "text": "then uh often it will branch before that",
        "start": 2194.32,
        "duration": 6.16
    },
    {
        "text": "global branching in pseudotime and we",
        "start": 2197.599,
        "duration": 4.321
    },
    {
        "text": "can see here that the",
        "start": 2200.48,
        "duration": 4.24
    },
    {
        "text": "purple dots aren't labeled to which",
        "start": 2201.92,
        "duration": 4.48
    },
    {
        "text": "branch they belong to",
        "start": 2204.72,
        "duration": 4.96
    },
    {
        "text": "and the gp allows us to make inferences",
        "start": 2206.4,
        "duration": 5.28
    },
    {
        "text": "about which of these branches the purple",
        "start": 2209.68,
        "duration": 3.84
    },
    {
        "text": "dots belong to",
        "start": 2211.68,
        "duration": 3.2
    },
    {
        "text": "whereas the kind of beam approach",
        "start": 2213.52,
        "duration": 3.12
    },
    {
        "text": "doesn't allow us to do that it it",
        "start": 2214.88,
        "duration": 2.4
    },
    {
        "text": "actually just",
        "start": 2216.64,
        "duration": 2.56
    },
    {
        "text": "randomly assigns the purple ones to",
        "start": 2217.28,
        "duration": 5.04
    },
    {
        "text": "either branch and fits the spine",
        "start": 2219.2,
        "duration": 6.96
    },
    {
        "text": "um so in that case so the red pluses tri",
        "start": 2222.32,
        "duration": 5.68
    },
    {
        "text": "beam they're kind of biased towards this",
        "start": 2226.16,
        "duration": 4.32
    },
    {
        "text": "global branching in this example",
        "start": 2228.0,
        "duration": 5.119
    },
    {
        "text": "um whereas the blue and black ones are",
        "start": 2230.48,
        "duration": 4.0
    },
    {
        "text": "the black is the grand truth and the",
        "start": 2233.119,
        "duration": 3.281
    },
    {
        "text": "blue is the btp result",
        "start": 2234.48,
        "duration": 5.04
    },
    {
        "text": "and the the blue and black don't match",
        "start": 2236.4,
        "duration": 4.439
    },
    {
        "text": "here because",
        "start": 2239.52,
        "duration": 4.8
    },
    {
        "text": "um sudo time can be a kind of non-linear",
        "start": 2240.839,
        "duration": 5.081
    },
    {
        "text": "function of actual time and",
        "start": 2244.32,
        "duration": 3.039
    },
    {
        "text": "and there's always a risk that you can",
        "start": 2245.92,
        "duration": 3.6
    },
    {
        "text": "be a bit biased so so i think what's",
        "start": 2247.359,
        "duration": 3.681
    },
    {
        "text": "happened here is pseudo time is a bit",
        "start": 2249.52,
        "duration": 2.559
    },
    {
        "text": "warped relative",
        "start": 2251.04,
        "duration": 4.559
    },
    {
        "text": "to um actual time but the kind of rank",
        "start": 2252.079,
        "duration": 5.201
    },
    {
        "text": "order of the cells in pseudotime is",
        "start": 2255.599,
        "duration": 4.401
    },
    {
        "text": "probably okay",
        "start": 2257.28,
        "duration": 2.72
    },
    {
        "text": "so looking at some real data um",
        "start": 2260.88,
        "duration": 6.32
    },
    {
        "text": "sort of um from bone marrow myeloid",
        "start": 2264.24,
        "duration": 7.599
    },
    {
        "text": "progenitor populations",
        "start": 2267.2,
        "duration": 4.639
    },
    {
        "text": "we kind of so the way you do this you",
        "start": 2272.24,
        "duration": 3.599
    },
    {
        "text": "apply",
        "start": 2275.28,
        "duration": 3.36
    },
    {
        "text": "some general approach for pseudotime and",
        "start": 2275.839,
        "duration": 5.441
    },
    {
        "text": "branching inference for the cells",
        "start": 2278.64,
        "duration": 3.92
    },
    {
        "text": "and then you can look at individual",
        "start": 2281.28,
        "duration": 3.44
    },
    {
        "text": "cells and you can score them",
        "start": 2282.56,
        "duration": 4.16
    },
    {
        "text": "in terms of their evidence of branching",
        "start": 2284.72,
        "duration": 3.52
    },
    {
        "text": "a particular branching",
        "start": 2286.72,
        "duration": 4.639
    },
    {
        "text": "in the sort of global tree",
        "start": 2288.24,
        "duration": 4.879
    },
    {
        "text": "um and then you can look at the",
        "start": 2291.359,
        "duration": 4.72
    },
    {
        "text": "locations",
        "start": 2293.119,
        "duration": 2.96
    },
    {
        "text": "so here's some examples in real data",
        "start": 2296.72,
        "duration": 5.92
    },
    {
        "text": "these are kind of genes with strong",
        "start": 2300.0,
        "duration": 5.2
    },
    {
        "text": "evidence of branching in that data",
        "start": 2302.64,
        "duration": 4.56
    },
    {
        "text": "and bgp the posterior for where the",
        "start": 2305.2,
        "duration": 3.6
    },
    {
        "text": "branching is is at the bottom here so",
        "start": 2307.2,
        "duration": 3.04
    },
    {
        "text": "most of these are early branches",
        "start": 2308.8,
        "duration": 3.36
    },
    {
        "text": "but we can see that car 2 and car 1 are",
        "start": 2310.24,
        "duration": 5.44
    },
    {
        "text": "kind of branching a bit later here",
        "start": 2312.16,
        "duration": 3.52
    },
    {
        "text": "and then we can get a confident gene",
        "start": 2316.32,
        "duration": 3.6
    },
    {
        "text": "ordering um",
        "start": 2318.32,
        "duration": 3.6
    },
    {
        "text": "so where things here are connected by",
        "start": 2319.92,
        "duration": 3.52
    },
    {
        "text": "line that means that they're",
        "start": 2321.92,
        "duration": 4.64
    },
    {
        "text": "confidently branching",
        "start": 2323.44,
        "duration": 5.44
    },
    {
        "text": "later or earlier than the gene they're",
        "start": 2326.56,
        "duration": 3.36
    },
    {
        "text": "connected to",
        "start": 2328.88,
        "duration": 3.28
    },
    {
        "text": "so it allows you to kind of rank order",
        "start": 2329.92,
        "duration": 4.8
    },
    {
        "text": "the genes",
        "start": 2332.16,
        "duration": 2.56
    },
    {
        "text": "okay so um finally",
        "start": 2338.16,
        "duration": 5.199
    },
    {
        "text": "i'm just going to talk a bit a little",
        "start": 2341.52,
        "duration": 4.079
    },
    {
        "text": "bit about some recent work where we've",
        "start": 2343.359,
        "duration": 4.321
    },
    {
        "text": "extended these types of gaussian process",
        "start": 2345.599,
        "duration": 3.441
    },
    {
        "text": "models",
        "start": 2347.68,
        "duration": 5.2
    },
    {
        "text": "to modeling cans data",
        "start": 2349.04,
        "duration": 3.84
    },
    {
        "text": "so here's an example where gaussian",
        "start": 2353.119,
        "duration": 4.561
    },
    {
        "text": "processors have gone wrong a little bit",
        "start": 2355.68,
        "duration": 3.76
    },
    {
        "text": "using a standard gaussian likelihood so",
        "start": 2357.68,
        "duration": 3.28
    },
    {
        "text": "in the bottom",
        "start": 2359.44,
        "duration": 3.44
    },
    {
        "text": "here i've done this thing of",
        "start": 2360.96,
        "duration": 3.36
    },
    {
        "text": "transforming log",
        "start": 2362.88,
        "duration": 5.04
    },
    {
        "text": "counts plus a constant and modeling that",
        "start": 2364.32,
        "duration": 4.32
    },
    {
        "text": "using",
        "start": 2367.92,
        "duration": 4.4
    },
    {
        "text": "uh gp um",
        "start": 2368.64,
        "duration": 5.68
    },
    {
        "text": "and then i'm trying to do a two sample",
        "start": 2372.32,
        "duration": 3.84
    },
    {
        "text": "test to work out whether these two time",
        "start": 2374.32,
        "duration": 3.039
    },
    {
        "text": "series are different",
        "start": 2376.16,
        "duration": 4.08
    },
    {
        "text": "um and they are different i mean or",
        "start": 2377.359,
        "duration": 3.521
    },
    {
        "text": "there's",
        "start": 2380.24,
        "duration": 2.56
    },
    {
        "text": "strong evidence in the top here when we",
        "start": 2380.88,
        "duration": 4.239
    },
    {
        "text": "use a negative binomial likelihood",
        "start": 2382.8,
        "duration": 5.36
    },
    {
        "text": "a proper kind of cancer likelihood but",
        "start": 2385.119,
        "duration": 4.081
    },
    {
        "text": "in the bottom here",
        "start": 2388.16,
        "duration": 3.76
    },
    {
        "text": "we find that the gaussian is not fitting",
        "start": 2389.2,
        "duration": 3.52
    },
    {
        "text": "one of the time",
        "start": 2391.92,
        "duration": 3.439
    },
    {
        "text": "series very well and it's probably",
        "start": 2392.72,
        "duration": 3.28
    },
    {
        "text": "confused",
        "start": 2395.359,
        "duration": 2.161
    },
    {
        "text": "by the fact that we don't have a lot of",
        "start": 2396.0,
        "duration": 4.32
    },
    {
        "text": "replicates here and the replicates",
        "start": 2397.52,
        "duration": 5.28
    },
    {
        "text": "just happen to be very close together in",
        "start": 2400.32,
        "duration": 4.24
    },
    {
        "text": "this example",
        "start": 2402.8,
        "duration": 5.039
    },
    {
        "text": "and so the gp is somewhat confused and",
        "start": 2404.56,
        "duration": 6.64
    },
    {
        "text": "it's kind of wiggling through this data",
        "start": 2407.839,
        "duration": 6.161
    },
    {
        "text": "and just not fitting well so if we're",
        "start": 2411.2,
        "duration": 5.119
    },
    {
        "text": "doing a two sample test this is actually",
        "start": 2414.0,
        "duration": 5.68
    },
    {
        "text": "this model because the fit the green fit",
        "start": 2416.319,
        "duration": 4.8
    },
    {
        "text": "for the bottom right there",
        "start": 2419.68,
        "duration": 3.76
    },
    {
        "text": "is not good it means the model is going",
        "start": 2421.119,
        "duration": 3.841
    },
    {
        "text": "to prefer to say that there's no",
        "start": 2423.44,
        "duration": 3.04
    },
    {
        "text": "difference between green blue",
        "start": 2424.96,
        "duration": 3.68
    },
    {
        "text": "green and blue in that case so the the",
        "start": 2426.48,
        "duration": 4.8
    },
    {
        "text": "inference is kind of failed i think",
        "start": 2428.64,
        "duration": 5.28
    },
    {
        "text": "whereas in the top the nega binomial fit",
        "start": 2431.28,
        "duration": 4.24
    },
    {
        "text": "to these time series",
        "start": 2433.92,
        "duration": 3.679
    },
    {
        "text": "really captures the fact that these are",
        "start": 2435.52,
        "duration": 3.76
    },
    {
        "text": "two different functions they're both",
        "start": 2437.599,
        "duration": 3.601
    },
    {
        "text": "smooth they both look like they've got",
        "start": 2439.28,
        "duration": 4.799
    },
    {
        "text": "reasonable credible regions and it's",
        "start": 2441.2,
        "duration": 4.56
    },
    {
        "text": "more plausible to say that those two",
        "start": 2444.079,
        "duration": 3.681
    },
    {
        "text": "time series are different",
        "start": 2445.76,
        "duration": 4.16
    },
    {
        "text": "so sometimes the gaussian likely goes",
        "start": 2447.76,
        "duration": 4.16
    },
    {
        "text": "wrong because it doesn't correctly model",
        "start": 2449.92,
        "duration": 5.76
    },
    {
        "text": "the noise distribution in the data",
        "start": 2451.92,
        "duration": 3.76
    },
    {
        "text": "now there's been quite a few papers",
        "start": 2457.359,
        "duration": 5.361
    },
    {
        "text": "suggesting that negative binomial",
        "start": 2460.24,
        "duration": 6.0
    },
    {
        "text": "is quite a good choice for um",
        "start": 2462.72,
        "duration": 8.0
    },
    {
        "text": "single cell rna seq data um",
        "start": 2466.24,
        "duration": 6.72
    },
    {
        "text": "and i'm not going to kind of go into the",
        "start": 2470.72,
        "duration": 3.44
    },
    {
        "text": "the the",
        "start": 2472.96,
        "duration": 3.68
    },
    {
        "text": "details of those discussions um we've",
        "start": 2474.16,
        "duration": 4.24
    },
    {
        "text": "actually implemented negative binomial",
        "start": 2476.64,
        "duration": 3.679
    },
    {
        "text": "and xero inflated",
        "start": 2478.4,
        "duration": 4.0
    },
    {
        "text": "but in practice we find the zero",
        "start": 2480.319,
        "duration": 4.081
    },
    {
        "text": "inflated doesn't add much in most",
        "start": 2482.4,
        "duration": 3.36
    },
    {
        "text": "applications",
        "start": 2484.4,
        "duration": 3.12
    },
    {
        "text": "so the idea of a negative binomial is",
        "start": 2485.76,
        "duration": 3.04
    },
    {
        "text": "that",
        "start": 2487.52,
        "duration": 4.4
    },
    {
        "text": "it models um counts data which",
        "start": 2488.8,
        "duration": 6.88
    },
    {
        "text": "has excessive variance or dispersion",
        "start": 2491.92,
        "duration": 5.679
    },
    {
        "text": "relative to a poisson distribution so",
        "start": 2495.68,
        "duration": 3.12
    },
    {
        "text": "the variance",
        "start": 2497.599,
        "duration": 4.321
    },
    {
        "text": "in the data is equal to the mean plus an",
        "start": 2498.8,
        "duration": 6.559
    },
    {
        "text": "extra term which captures the dispersion",
        "start": 2501.92,
        "duration": 5.76
    },
    {
        "text": "and in the gaussian process what we do",
        "start": 2505.359,
        "duration": 4.24
    },
    {
        "text": "is we model the",
        "start": 2507.68,
        "duration": 4.96
    },
    {
        "text": "log of the mean of the data as a",
        "start": 2509.599,
        "duration": 5.52
    },
    {
        "text": "function from a gaussian process",
        "start": 2512.64,
        "duration": 6.56
    },
    {
        "text": "so the dispersion models the accounts",
        "start": 2515.119,
        "duration": 6.72
    },
    {
        "text": "data and the the mean of that is modeled",
        "start": 2519.2,
        "duration": 6.0
    },
    {
        "text": "using the gaussian process",
        "start": 2521.839,
        "duration": 3.361
    },
    {
        "text": "and if we use synthetic data we can look",
        "start": 2526.88,
        "duration": 3.6
    },
    {
        "text": "at you know is that",
        "start": 2528.8,
        "duration": 5.519
    },
    {
        "text": "is that useful well um",
        "start": 2530.48,
        "duration": 6.4
    },
    {
        "text": "if you have low dispersion then the",
        "start": 2534.319,
        "duration": 3.601
    },
    {
        "text": "gaussian",
        "start": 2536.88,
        "duration": 3.28
    },
    {
        "text": "is pretty good you know so the gaussian",
        "start": 2537.92,
        "duration": 3.6
    },
    {
        "text": "and the negative binomial",
        "start": 2540.16,
        "duration": 4.24
    },
    {
        "text": "are quite comparable for low dispersion",
        "start": 2541.52,
        "duration": 4.079
    },
    {
        "text": "data",
        "start": 2544.4,
        "duration": 4.4
    },
    {
        "text": "um the poisson works reasonably well but",
        "start": 2545.599,
        "duration": 3.681
    },
    {
        "text": "for",
        "start": 2548.8,
        "duration": 3.039
    },
    {
        "text": "high cancer can still break down a bit",
        "start": 2549.28,
        "duration": 6.24
    },
    {
        "text": "even with quite low dispersion",
        "start": 2551.839,
        "duration": 3.681
    },
    {
        "text": "but when you have high dispersion",
        "start": 2556.079,
        "duration": 4.881
    },
    {
        "text": "especially if you have high cancer and",
        "start": 2559.04,
        "duration": 3.6
    },
    {
        "text": "high dispersion you can see quite a big",
        "start": 2560.96,
        "duration": 5.84
    },
    {
        "text": "difference between the nega binomial",
        "start": 2562.64,
        "duration": 4.16
    },
    {
        "text": "and the slime and here what we're doing",
        "start": 2567.52,
        "duration": 3.36
    },
    {
        "text": "is",
        "start": 2570.64,
        "duration": 2.64
    },
    {
        "text": "one of those one sample tests where",
        "start": 2570.88,
        "duration": 3.92
    },
    {
        "text": "we're just testing to see if there's",
        "start": 2573.28,
        "duration": 3.039
    },
    {
        "text": "dynamics in the data",
        "start": 2574.8,
        "duration": 5.12
    },
    {
        "text": "and that's that's kind of the um",
        "start": 2576.319,
        "duration": 5.121
    },
    {
        "text": "type of statistical test that we're",
        "start": 2579.92,
        "duration": 3.76
    },
    {
        "text": "doing in this comparison",
        "start": 2581.44,
        "duration": 4.8
    },
    {
        "text": "so it seems like negative binomial um is",
        "start": 2583.68,
        "duration": 4.0
    },
    {
        "text": "useful in the case where we have high",
        "start": 2586.24,
        "duration": 2.96
    },
    {
        "text": "dispersion data and",
        "start": 2587.68,
        "duration": 3.84
    },
    {
        "text": "if we have this type of single cell",
        "start": 2589.2,
        "duration": 4.159
    },
    {
        "text": "pseudo time series for instance we have",
        "start": 2591.52,
        "duration": 4.0
    },
    {
        "text": "high dispersion but also if we have",
        "start": 2593.359,
        "duration": 4.561
    },
    {
        "text": "spatial transcripts to makes data we",
        "start": 2595.52,
        "duration": 3.12
    },
    {
        "text": "also see",
        "start": 2597.92,
        "duration": 4.48
    },
    {
        "text": "a high dispersion often",
        "start": 2598.64,
        "duration": 3.76
    },
    {
        "text": "supply is to um spatial",
        "start": 2604.48,
        "duration": 6.32
    },
    {
        "text": "data just to a very simple problem of",
        "start": 2608.0,
        "duration": 4.8
    },
    {
        "text": "identifying differentially expressed",
        "start": 2610.8,
        "duration": 5.12
    },
    {
        "text": "genes basically",
        "start": 2612.8,
        "duration": 3.12
    },
    {
        "text": "and um spatial spatial leakage does that",
        "start": 2616.0,
        "duration": 6.0
    },
    {
        "text": "with the standard gaussian process for",
        "start": 2620.24,
        "duration": 4.24
    },
    {
        "text": "the gaussian likelihood function",
        "start": 2622.0,
        "duration": 5.359
    },
    {
        "text": "and we've just plugged in a negative",
        "start": 2624.48,
        "duration": 4.24
    },
    {
        "text": "binomial likelihood",
        "start": 2627.359,
        "duration": 3.841
    },
    {
        "text": "into the same pipeline so everything",
        "start": 2628.72,
        "duration": 4.24
    },
    {
        "text": "else is very similar",
        "start": 2631.2,
        "duration": 5.52
    },
    {
        "text": "so the idea here is that um",
        "start": 2632.96,
        "duration": 6.399
    },
    {
        "text": "if you have spatial variation then those",
        "start": 2636.72,
        "duration": 4.08
    },
    {
        "text": "should have a characteristic length",
        "start": 2639.359,
        "duration": 2.24
    },
    {
        "text": "scale",
        "start": 2640.8,
        "duration": 2.4
    },
    {
        "text": "so you should be able to model them with",
        "start": 2641.599,
        "duration": 3.361
    },
    {
        "text": "a covariance function that has a kind of",
        "start": 2643.2,
        "duration": 3.68
    },
    {
        "text": "length scale parameter",
        "start": 2644.96,
        "duration": 4.56
    },
    {
        "text": "if you have non-spatial variation it",
        "start": 2646.88,
        "duration": 4.239
    },
    {
        "text": "should be better modeled just",
        "start": 2649.52,
        "duration": 4.88
    },
    {
        "text": "as a noise and it won't be",
        "start": 2651.119,
        "duration": 5.521
    },
    {
        "text": "captured by a kind of spatial covariance",
        "start": 2654.4,
        "duration": 3.6
    },
    {
        "text": "function so",
        "start": 2656.64,
        "duration": 3.36
    },
    {
        "text": "you do we're doing a likelihood ratio",
        "start": 2658.0,
        "duration": 4.0
    },
    {
        "text": "test between",
        "start": 2660.0,
        "duration": 5.76
    },
    {
        "text": "a model which is flat and only has um",
        "start": 2662.0,
        "duration": 7.119
    },
    {
        "text": "non-spatial variation versus",
        "start": 2665.76,
        "duration": 6.24
    },
    {
        "text": "a model it has a variation to see um",
        "start": 2669.119,
        "duration": 7.361
    },
    {
        "text": "which is best",
        "start": 2672.0,
        "duration": 8.0
    },
    {
        "text": "and what we find is that um",
        "start": 2676.48,
        "duration": 6.0
    },
    {
        "text": "having this negative binomial likelihood",
        "start": 2680.0,
        "duration": 3.52
    },
    {
        "text": "function",
        "start": 2682.48,
        "duration": 3.599
    },
    {
        "text": "really gives us much better sensitivity",
        "start": 2683.52,
        "duration": 3.52
    },
    {
        "text": "and",
        "start": 2686.079,
        "duration": 5.601
    },
    {
        "text": "uh also avoids some rather implausible",
        "start": 2687.04,
        "duration": 8.24
    },
    {
        "text": "positives so",
        "start": 2691.68,
        "duration": 7.6
    },
    {
        "text": "spatialde in this venn diagram here",
        "start": 2695.28,
        "duration": 7.36
    },
    {
        "text": "is identifying a smaller number of genes",
        "start": 2699.28,
        "duration": 5.039
    },
    {
        "text": "as differentially expressed in this data",
        "start": 2702.64,
        "duration": 3.36
    },
    {
        "text": "set and then",
        "start": 2704.319,
        "duration": 4.961
    },
    {
        "text": "the ones which spatial dc he says",
        "start": 2706.0,
        "duration": 6.48
    },
    {
        "text": "are positive um when we look at them",
        "start": 2709.28,
        "duration": 4.799
    },
    {
        "text": "often they're extremely",
        "start": 2712.48,
        "duration": 3.359
    },
    {
        "text": "they have extremely small numbers of",
        "start": 2714.079,
        "duration": 3.441
    },
    {
        "text": "counts um",
        "start": 2715.839,
        "duration": 4.881
    },
    {
        "text": "so it looks like the fact that if you",
        "start": 2717.52,
        "duration": 4.72
    },
    {
        "text": "have very small numbers accounts and you",
        "start": 2720.72,
        "duration": 2.32
    },
    {
        "text": "use a lot",
        "start": 2722.24,
        "duration": 4.879
    },
    {
        "text": "and use a um gaussian noise model",
        "start": 2723.04,
        "duration": 5.76
    },
    {
        "text": "then you don't have a lot of information",
        "start": 2727.119,
        "duration": 3.601
    },
    {
        "text": "to estimate things like variance when",
        "start": 2728.8,
        "duration": 3.2
    },
    {
        "text": "you have that little data",
        "start": 2730.72,
        "duration": 3.2
    },
    {
        "text": "so it's rather implausible to use a",
        "start": 2732.0,
        "duration": 4.24
    },
    {
        "text": "gaussian noise model in that case",
        "start": 2733.92,
        "duration": 4.24
    },
    {
        "text": "the the counts likely it's quite nice",
        "start": 2736.24,
        "duration": 3.44
    },
    {
        "text": "because",
        "start": 2738.16,
        "duration": 3.919
    },
    {
        "text": "in the case where you have very little",
        "start": 2739.68,
        "duration": 4.08
    },
    {
        "text": "data you're just going to basically",
        "start": 2742.079,
        "duration": 2.401
    },
    {
        "text": "infer",
        "start": 2743.76,
        "duration": 3.12
    },
    {
        "text": "something like a poison or slightly over",
        "start": 2744.48,
        "duration": 3.76
    },
    {
        "text": "dispersed poisson",
        "start": 2746.88,
        "duration": 2.88
    },
    {
        "text": "and then you get a lot of information",
        "start": 2748.24,
        "duration": 3.44
    },
    {
        "text": "about variation in the data that you",
        "start": 2749.76,
        "duration": 4.319
    },
    {
        "text": "wouldn't get from a gaussian model",
        "start": 2751.68,
        "duration": 4.399
    },
    {
        "text": "um and if you look at some of the ones",
        "start": 2754.079,
        "duration": 3.921
    },
    {
        "text": "which are positive you can see that they",
        "start": 2756.079,
        "duration": 2.401
    },
    {
        "text": "kind of",
        "start": 2758.0,
        "duration": 3.359
    },
    {
        "text": "are reflected in images which are",
        "start": 2758.48,
        "duration": 4.32
    },
    {
        "text": "independent from the",
        "start": 2761.359,
        "duration": 5.041
    },
    {
        "text": "spatial transcriptomics data um",
        "start": 2762.8,
        "duration": 6.799
    },
    {
        "text": "we've also scaled this up um",
        "start": 2766.4,
        "duration": 4.959
    },
    {
        "text": "using the sparse inference techniques i",
        "start": 2769.599,
        "duration": 3.681
    },
    {
        "text": "was talking about and",
        "start": 2771.359,
        "duration": 3.841
    },
    {
        "text": "i was hoping to present some results on",
        "start": 2773.28,
        "duration": 3.36
    },
    {
        "text": "slide seek we we've",
        "start": 2775.2,
        "duration": 4.08
    },
    {
        "text": "we've run it on that data um but we",
        "start": 2776.64,
        "duration": 3.36
    },
    {
        "text": "haven't",
        "start": 2779.28,
        "duration": 3.44
    },
    {
        "text": "uh got results ready to present but with",
        "start": 2780.0,
        "duration": 4.079
    },
    {
        "text": "the sparse methods",
        "start": 2782.72,
        "duration": 3.92
    },
    {
        "text": "it scales up to large scale things like",
        "start": 2784.079,
        "duration": 3.201
    },
    {
        "text": "um",
        "start": 2786.64,
        "duration": 5.76
    },
    {
        "text": "slide seek and 10x spatial data",
        "start": 2787.28,
        "duration": 5.12
    },
    {
        "text": "so um i'm done",
        "start": 2793.359,
        "duration": 8.0
    },
    {
        "text": "so so just to summarize gps are",
        "start": 2797.599,
        "duration": 5.441
    },
    {
        "text": "they're very natural for modeling",
        "start": 2801.359,
        "duration": 4.561
    },
    {
        "text": "branching in time series",
        "start": 2803.04,
        "duration": 4.88
    },
    {
        "text": "uncertainty allows you to kind of get a",
        "start": 2805.92,
        "duration": 3.04
    },
    {
        "text": "confidence in",
        "start": 2807.92,
        "duration": 4.32
    },
    {
        "text": "ordering your um",
        "start": 2808.96,
        "duration": 5.119
    },
    {
        "text": "events so if you want to know which",
        "start": 2812.24,
        "duration": 3.68
    },
    {
        "text": "genes are branching early or late you",
        "start": 2814.079,
        "duration": 3.201
    },
    {
        "text": "can order those with",
        "start": 2815.92,
        "duration": 4.88
    },
    {
        "text": "with a level of uncertainty",
        "start": 2817.28,
        "duration": 5.36
    },
    {
        "text": "to be practical for single cell you",
        "start": 2820.8,
        "duration": 3.6
    },
    {
        "text": "really have to use speed up so we use",
        "start": 2822.64,
        "duration": 3.76
    },
    {
        "text": "these kind of variational",
        "start": 2824.4,
        "duration": 3.76
    },
    {
        "text": "inference techniques in the gp flow",
        "start": 2826.4,
        "duration": 4.0
    },
    {
        "text": "package which is very good for that",
        "start": 2828.16,
        "duration": 4.4
    },
    {
        "text": "and and recently we've introduced a",
        "start": 2830.4,
        "duration": 4.08
    },
    {
        "text": "negative binomial likelihood into these",
        "start": 2832.56,
        "duration": 3.519
    },
    {
        "text": "gaussian process methods which",
        "start": 2834.48,
        "duration": 5.28
    },
    {
        "text": "i think gives us a much more realistic",
        "start": 2836.079,
        "duration": 6.0
    },
    {
        "text": "model for counts data and we've been",
        "start": 2839.76,
        "duration": 3.839
    },
    {
        "text": "applying that specifically in this",
        "start": 2842.079,
        "duration": 3.28
    },
    {
        "text": "spatial inference",
        "start": 2843.599,
        "duration": 5.361
    },
    {
        "text": "um challenges well um",
        "start": 2845.359,
        "duration": 5.281
    },
    {
        "text": "i separated out suitable time and",
        "start": 2848.96,
        "duration": 3.44
    },
    {
        "text": "branching it would be nicer to model",
        "start": 2850.64,
        "duration": 2.8
    },
    {
        "text": "them together",
        "start": 2852.4,
        "duration": 2.8
    },
    {
        "text": "and have a kind of joint model which",
        "start": 2853.44,
        "duration": 3.52
    },
    {
        "text": "also has",
        "start": 2855.2,
        "duration": 3.359
    },
    {
        "text": "which has pseudotime and branching at",
        "start": 2856.96,
        "duration": 3.92
    },
    {
        "text": "the same time um",
        "start": 2858.559,
        "duration": 3.921
    },
    {
        "text": "and we'd like to look at more complex",
        "start": 2860.88,
        "duration": 3.6
    },
    {
        "text": "spatial models so we're interested in",
        "start": 2862.48,
        "duration": 4.96
    },
    {
        "text": "point processes",
        "start": 2864.48,
        "duration": 2.96
    },
    {
        "text": "um and also when you're fitting these",
        "start": 2870.88,
        "duration": 4.8
    },
    {
        "text": "models to",
        "start": 2873.839,
        "duration": 3.52
    },
    {
        "text": "you know and sometimes we're fitting",
        "start": 2875.68,
        "duration": 3.28
    },
    {
        "text": "them to all the genes",
        "start": 2877.359,
        "duration": 4.401
    },
    {
        "text": "so so we're fitting ten thousand models",
        "start": 2878.96,
        "duration": 4.32
    },
    {
        "text": "it's really important that the inference",
        "start": 2881.76,
        "duration": 3.12
    },
    {
        "text": "is robust and that hyperprinter",
        "start": 2883.28,
        "duration": 2.96
    },
    {
        "text": "estimation is robust so you have to",
        "start": 2884.88,
        "duration": 2.0
    },
    {
        "text": "catch",
        "start": 2886.24,
        "duration": 2.8
    },
    {
        "text": "numerical issues you have to restart if",
        "start": 2886.88,
        "duration": 3.92
    },
    {
        "text": "you converge at a bad local optima so",
        "start": 2889.04,
        "duration": 3.44
    },
    {
        "text": "those type of things",
        "start": 2890.8,
        "duration": 4.24
    },
    {
        "text": "we're working on but i think we can",
        "start": 2892.48,
        "duration": 4.079
    },
    {
        "text": "always improve so that you don't get",
        "start": 2895.04,
        "duration": 2.0
    },
    {
        "text": "kind of",
        "start": 2896.559,
        "duration": 4.56
    },
    {
        "text": "um bad inference in in some bad cases",
        "start": 2897.04,
        "duration": 7.12
    },
    {
        "text": "and finally i'd like to thank uh people",
        "start": 2901.119,
        "duration": 4.161
    },
    {
        "text": "who did a lot of the work",
        "start": 2904.16,
        "duration": 4.88
    },
    {
        "text": "so um suman ahmed",
        "start": 2905.28,
        "duration": 6.72
    },
    {
        "text": "and alexis buccavales did a lot of work",
        "start": 2909.04,
        "duration": 4.64
    },
    {
        "text": "on grand prix in the bgp",
        "start": 2912.0,
        "duration": 5.76
    },
    {
        "text": "method um jing yang also on the",
        "start": 2913.68,
        "duration": 6.32
    },
    {
        "text": "branching",
        "start": 2917.76,
        "duration": 5.359
    },
    {
        "text": "estee john and sokratia worked on the",
        "start": 2920.0,
        "duration": 3.92
    },
    {
        "text": "spatial",
        "start": 2923.119,
        "duration": 3.841
    },
    {
        "text": "and the nega binomial and",
        "start": 2923.92,
        "duration": 4.96
    },
    {
        "text": "new heart as well who's put the gp cans",
        "start": 2926.96,
        "duration": 3.04
    },
    {
        "text": "package together",
        "start": 2928.88,
        "duration": 3.12
    },
    {
        "text": "and then james hensman is a long time",
        "start": 2930.0,
        "duration": 3.44
    },
    {
        "text": "collaborator and",
        "start": 2932.0,
        "duration": 3.68
    },
    {
        "text": "you have worked with on this work thank",
        "start": 2933.44,
        "duration": 4.48
    },
    {
        "text": "you",
        "start": 2935.68,
        "duration": 2.24
    },
    {
        "text": "great beautiful work uh magnus thank you",
        "start": 2939.359,
        "duration": 6.561
    },
    {
        "text": "um all right so now we have time for for",
        "start": 2943.2,
        "duration": 3.52
    },
    {
        "text": "questions so",
        "start": 2945.92,
        "duration": 2.32
    },
    {
        "text": "um if you have a question feel free to",
        "start": 2946.72,
        "duration": 3.839
    },
    {
        "text": "type it in the chat um or just unmute",
        "start": 2948.24,
        "duration": 5.119
    },
    {
        "text": "yourself and ask",
        "start": 2950.559,
        "duration": 2.8
    },
    {
        "text": "and uh maybe i'll ask a question while",
        "start": 2954.16,
        "duration": 5.28
    },
    {
        "text": "people are are thinking um",
        "start": 2955.839,
        "duration": 3.601
    },
    {
        "text": "so these um these gaussian process",
        "start": 2959.52,
        "duration": 5.2
    },
    {
        "text": "models are",
        "start": 2963.52,
        "duration": 5.52
    },
    {
        "text": "beautiful and elegant um i wonder",
        "start": 2964.72,
        "duration": 7.2
    },
    {
        "text": "so the other sort of technique that",
        "start": 2969.04,
        "duration": 4.48
    },
    {
        "text": "people are using now for a lot of single",
        "start": 2971.92,
        "duration": 2.72
    },
    {
        "text": "cell problems is",
        "start": 2973.52,
        "duration": 3.68
    },
    {
        "text": "deep learning in various forms like um",
        "start": 2974.64,
        "duration": 3.6
    },
    {
        "text": "so i i wonder",
        "start": 2977.2,
        "duration": 2.8
    },
    {
        "text": "what do you think are the pros and cons",
        "start": 2978.24,
        "duration": 5.359
    },
    {
        "text": "of gp regression versus",
        "start": 2980.0,
        "duration": 7.04
    },
    {
        "text": "ml you know multi-layer perceptron or",
        "start": 2983.599,
        "duration": 6.161
    },
    {
        "text": "gplvm versus variational autoencoder for",
        "start": 2987.04,
        "duration": 4.72
    },
    {
        "text": "some of these applications",
        "start": 2989.76,
        "duration": 4.799
    },
    {
        "text": "it's a really good question we i my",
        "start": 2991.76,
        "duration": 4.559
    },
    {
        "text": "group also uses deep learning",
        "start": 2994.559,
        "duration": 3.76
    },
    {
        "text": "and variation shorts encoders and",
        "start": 2996.319,
        "duration": 3.441
    },
    {
        "text": "they're they're",
        "start": 2998.319,
        "duration": 5.04
    },
    {
        "text": "very nice um i think the the",
        "start": 2999.76,
        "duration": 5.44
    },
    {
        "text": "um let me take the variational",
        "start": 3003.359,
        "duration": 4.96
    },
    {
        "text": "autoencoder versus gprvms1",
        "start": 3005.2,
        "duration": 7.52
    },
    {
        "text": "um so um one advantage",
        "start": 3008.319,
        "duration": 8.401
    },
    {
        "text": "i think of the gplvm is that",
        "start": 3012.72,
        "duration": 7.119
    },
    {
        "text": "it has a very explicit",
        "start": 3016.72,
        "duration": 6.32
    },
    {
        "text": "um model um",
        "start": 3019.839,
        "duration": 5.841
    },
    {
        "text": "which allows you to introduce prior",
        "start": 3023.04,
        "duration": 3.519
    },
    {
        "text": "information",
        "start": 3025.68,
        "duration": 3.36
    },
    {
        "text": "if you have it about the lane space so",
        "start": 3026.559,
        "duration": 4.56
    },
    {
        "text": "so i gave a simple example of that but i",
        "start": 3029.04,
        "duration": 2.96
    },
    {
        "text": "think",
        "start": 3031.119,
        "duration": 4.161
    },
    {
        "text": "you can probably think of more complex",
        "start": 3032.0,
        "duration": 4.079
    },
    {
        "text": "models",
        "start": 3035.28,
        "duration": 2.88
    },
    {
        "text": "where you have some prior information",
        "start": 3036.079,
        "duration": 3.921
    },
    {
        "text": "that you want to build into the",
        "start": 3038.16,
        "duration": 4.399
    },
    {
        "text": "lane space and i think the gplvm",
        "start": 3040.0,
        "duration": 3.92
    },
    {
        "text": "provides a really nice",
        "start": 3042.559,
        "duration": 4.401
    },
    {
        "text": "way of doing that um",
        "start": 3043.92,
        "duration": 6.8
    },
    {
        "text": "i think in terms of deep learning",
        "start": 3046.96,
        "duration": 7.28
    },
    {
        "text": "deep learning is um",
        "start": 3050.72,
        "duration": 7.28
    },
    {
        "text": "extremely powerful in terms of uh",
        "start": 3054.24,
        "duration": 6.8
    },
    {
        "text": "you know non-linear function estimation",
        "start": 3058.0,
        "duration": 6.48
    },
    {
        "text": "basically and um has",
        "start": 3061.04,
        "duration": 8.64
    },
    {
        "text": "has great power but i think that um",
        "start": 3064.48,
        "duration": 8.079
    },
    {
        "text": "it's quite hard to build the uncertainty",
        "start": 3069.68,
        "duration": 4.0
    },
    {
        "text": "into deep learning",
        "start": 3072.559,
        "duration": 5.52
    },
    {
        "text": "well and calibrating the uncertainties",
        "start": 3073.68,
        "duration": 6.48
    },
    {
        "text": "in in deep learning models is quite",
        "start": 3078.079,
        "duration": 3.921
    },
    {
        "text": "tricky i mean people will work on it so",
        "start": 3080.16,
        "duration": 3.199
    },
    {
        "text": "i'm not saying it's not",
        "start": 3082.0,
        "duration": 2.72
    },
    {
        "text": "something that you can do it's an",
        "start": 3083.359,
        "duration": 3.441
    },
    {
        "text": "interesting area",
        "start": 3084.72,
        "duration": 5.92
    },
    {
        "text": "um but i think so i think the benefits",
        "start": 3086.8,
        "duration": 6.64
    },
    {
        "text": "of using gps is a very explicit",
        "start": 3090.64,
        "duration": 5.04
    },
    {
        "text": "treatment of uncertainty",
        "start": 3093.44,
        "duration": 4.48
    },
    {
        "text": "and a very explicit treatment of priors",
        "start": 3095.68,
        "duration": 3.52
    },
    {
        "text": "and prior knowledge",
        "start": 3097.92,
        "duration": 4.24
    },
    {
        "text": "but you know you've got to use the right",
        "start": 3099.2,
        "duration": 4.32
    },
    {
        "text": "approach for the right problem",
        "start": 3102.16,
        "duration": 4.56
    },
    {
        "text": "and we use deep learning all the time so",
        "start": 3103.52,
        "duration": 8.319
    },
    {
        "text": "it's also a great set of tools",
        "start": 3106.72,
        "duration": 5.119
    },
    {
        "text": "looks like we've got a question in the",
        "start": 3128.4,
        "duration": 3.84
    },
    {
        "text": "chat",
        "start": 3129.92,
        "duration": 2.32
    },
    {
        "text": "chen lee asks um is gp flow easily",
        "start": 3133.28,
        "duration": 5.44
    },
    {
        "text": "transformed and applied to",
        "start": 3137.2,
        "duration": 3.52
    },
    {
        "text": "other single cell modalities to find",
        "start": 3138.72,
        "duration": 5.44
    },
    {
        "text": "branching and pseudo time ordering",
        "start": 3140.72,
        "duration": 7.119
    },
    {
        "text": "so you uh like an example",
        "start": 3144.16,
        "duration": 5.28
    },
    {
        "text": "single scale attack seek or something",
        "start": 3147.839,
        "duration": 3.041
    },
    {
        "text": "like that perhaps or",
        "start": 3149.44,
        "duration": 5.119
    },
    {
        "text": "other is that the",
        "start": 3150.88,
        "duration": 6.4
    },
    {
        "text": "other type ceromics and so on i think",
        "start": 3154.559,
        "duration": 4.0
    },
    {
        "text": "that's how i would interpret that",
        "start": 3157.28,
        "duration": 2.48
    },
    {
        "text": "question",
        "start": 3158.559,
        "duration": 3.361
    },
    {
        "text": "that's a good question we we we actually",
        "start": 3159.76,
        "duration": 3.92
    },
    {
        "text": "work a lot in single cell attack see",
        "start": 3161.92,
        "duration": 3.199
    },
    {
        "text": "data",
        "start": 3163.68,
        "duration": 6.56
    },
    {
        "text": "often without taxi data",
        "start": 3165.119,
        "duration": 5.511
    },
    {
        "text": "um",
        "start": 3170.24,
        "duration": 3.04
    },
    {
        "text": "[Music]",
        "start": 3170.63,
        "duration": 6.41
    },
    {
        "text": "so one of the challenges there is",
        "start": 3173.28,
        "duration": 7.6
    },
    {
        "text": "um because the data is",
        "start": 3177.04,
        "duration": 5.76
    },
    {
        "text": "it's not quite binary but it's almost",
        "start": 3180.88,
        "duration": 3.12
    },
    {
        "text": "binary you know it's",
        "start": 3182.8,
        "duration": 4.0
    },
    {
        "text": "it's it's got a little bit less dynamic",
        "start": 3184.0,
        "duration": 6.4
    },
    {
        "text": "range than single cell rna-seq data",
        "start": 3186.8,
        "duration": 7.12
    },
    {
        "text": "so um it's a little bit more challenging",
        "start": 3190.4,
        "duration": 5.919
    },
    {
        "text": "to normalize out",
        "start": 3193.92,
        "duration": 5.199
    },
    {
        "text": "library size effects in single-cell",
        "start": 3196.319,
        "duration": 5.52
    },
    {
        "text": "a-taxi data we find",
        "start": 3199.119,
        "duration": 5.601
    },
    {
        "text": "and having a probabilistic model for",
        "start": 3201.839,
        "duration": 4.401
    },
    {
        "text": "modeling the library",
        "start": 3204.72,
        "duration": 4.72
    },
    {
        "text": "depth is is really nice",
        "start": 3206.24,
        "duration": 6.56
    },
    {
        "text": "so you can model the kind of observation",
        "start": 3209.44,
        "duration": 3.919
    },
    {
        "text": "process",
        "start": 3212.8,
        "duration": 3.2
    },
    {
        "text": "like how many reeds you get from the",
        "start": 3213.359,
        "duration": 3.681
    },
    {
        "text": "experiment",
        "start": 3216.0,
        "duration": 4.24
    },
    {
        "text": "on top of the uh kind of",
        "start": 3217.04,
        "duration": 5.2
    },
    {
        "text": "um well you might model the data's",
        "start": 3220.24,
        "duration": 3.92
    },
    {
        "text": "binary or you might model it with some",
        "start": 3222.24,
        "duration": 4.24
    },
    {
        "text": "other model that's not binary we often",
        "start": 3224.16,
        "duration": 5.36
    },
    {
        "text": "just use something binary and you can",
        "start": 3226.48,
        "duration": 4.879
    },
    {
        "text": "put that type of likelihood model",
        "start": 3229.52,
        "duration": 4.88
    },
    {
        "text": "into a gp so um",
        "start": 3231.359,
        "duration": 6.081
    },
    {
        "text": "i think this that that's one of the nice",
        "start": 3234.4,
        "duration": 3.76
    },
    {
        "text": "things",
        "start": 3237.44,
        "duration": 3.44
    },
    {
        "text": "about gps because they have a very",
        "start": 3238.16,
        "duration": 4.32
    },
    {
        "text": "explicit",
        "start": 3240.88,
        "duration": 4.32
    },
    {
        "text": "probabilistic model if you want to plug",
        "start": 3242.48,
        "duration": 3.04
    },
    {
        "text": "in",
        "start": 3245.2,
        "duration": 2.24
    },
    {
        "text": "some other probabilistic model that",
        "start": 3245.52,
        "duration": 3.76
    },
    {
        "text": "models something like the",
        "start": 3247.44,
        "duration": 4.879
    },
    {
        "text": "library depth um",
        "start": 3249.28,
        "duration": 6.079
    },
    {
        "text": "you can you can do that actually and and",
        "start": 3252.319,
        "duration": 5.04
    },
    {
        "text": "i bet the pyro package would be quite",
        "start": 3255.359,
        "duration": 3.441
    },
    {
        "text": "good for that because you could just",
        "start": 3257.359,
        "duration": 4.161
    },
    {
        "text": "write things down like you do in stan",
        "start": 3258.8,
        "duration": 5.039
    },
    {
        "text": "and the inference would just the machine",
        "start": 3261.52,
        "duration": 4.0
    },
    {
        "text": "just turns the handle",
        "start": 3263.839,
        "duration": 4.961
    },
    {
        "text": "um you know so yeah i think i think",
        "start": 3265.52,
        "duration": 5.68
    },
    {
        "text": "definitely",
        "start": 3268.8,
        "duration": 2.4
    },
    {
        "text": "any other questions",
        "start": 3275.839,
        "duration": 4.0
    },
    {
        "text": "one other thing i was thinking about as",
        "start": 3281.599,
        "duration": 3.601
    },
    {
        "text": "sort of a",
        "start": 3283.599,
        "duration": 4.72
    },
    {
        "text": "tool in your set of gaussian process",
        "start": 3285.2,
        "duration": 7.28
    },
    {
        "text": "tools is multi-output gps have you guys",
        "start": 3288.319,
        "duration": 5.921
    },
    {
        "text": "investigated using those for anything",
        "start": 3292.48,
        "duration": 2.72
    },
    {
        "text": "maybe like",
        "start": 3294.24,
        "duration": 3.839
    },
    {
        "text": "covariance relationships among genes",
        "start": 3295.2,
        "duration": 4.56
    },
    {
        "text": "yeah that's a really interesting",
        "start": 3298.079,
        "duration": 5.441
    },
    {
        "text": "question so um exactly um",
        "start": 3299.76,
        "duration": 5.28
    },
    {
        "text": "we're very interested in that in the",
        "start": 3303.52,
        "duration": 3.2
    },
    {
        "text": "spatial case because",
        "start": 3305.04,
        "duration": 5.36
    },
    {
        "text": "um i think discovering",
        "start": 3306.72,
        "duration": 7.44
    },
    {
        "text": "latent lower dimensional gps",
        "start": 3310.4,
        "duration": 5.679
    },
    {
        "text": "and relating them yeah that's a very",
        "start": 3314.16,
        "duration": 3.679
    },
    {
        "text": "good question i didn't talk about that",
        "start": 3316.079,
        "duration": 2.561
    },
    {
        "text": "type of thing",
        "start": 3317.839,
        "duration": 4.401
    },
    {
        "text": "but that's exactly one of the extensions",
        "start": 3318.64,
        "duration": 5.439
    },
    {
        "text": "i mentioned point processes but also",
        "start": 3322.24,
        "duration": 3.119
    },
    {
        "text": "multi-output",
        "start": 3324.079,
        "duration": 5.121
    },
    {
        "text": "actually in the past um in older",
        "start": 3325.359,
        "duration": 7.681
    },
    {
        "text": "work and times periods",
        "start": 3329.2,
        "duration": 6.879
    },
    {
        "text": "we use um",
        "start": 3333.04,
        "duration": 6.16
    },
    {
        "text": "different layers of transcription uh",
        "start": 3336.079,
        "duration": 7.441
    },
    {
        "text": "so you know modeling",
        "start": 3339.2,
        "duration": 8.399
    },
    {
        "text": "um primase a's and proteins",
        "start": 3343.52,
        "duration": 7.36
    },
    {
        "text": "and degradation and and production",
        "start": 3347.599,
        "duration": 5.121
    },
    {
        "text": "models and you can also do that with",
        "start": 3350.88,
        "duration": 3.28
    },
    {
        "text": "multi-output gps",
        "start": 3352.72,
        "duration": 6.48
    },
    {
        "text": "so yeah i think multiple gps have great",
        "start": 3354.16,
        "duration": 5.04
    },
    {
        "text": "potential",
        "start": 3360.839,
        "duration": 3.0
    },
    {
        "text": "great well um it doesn't look like there",
        "start": 3364.0,
        "duration": 4.4
    },
    {
        "text": "are any other questions so",
        "start": 3366.24,
        "duration": 6.0
    },
    {
        "text": "i'll let everybody go thanks again",
        "start": 3368.4,
        "duration": 3.84
    }
]