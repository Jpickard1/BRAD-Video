[
    {
        "start": 0.24,
        "text": "yeah so yeah let's come to the uh outline directly so first i will briefly introduce the background about protein structure prediction based on sequences and also protein contaminant prediction which is uh reduce the representation of protein structure and next i'll introduce the concept of co-evolution and the recent progression in this field deep learning best method that using the future of coherence between two positions of the multiple students alignment data after that the inverse of the conventional matrix precision matrix will be introduced which also can be interrupted as the gaussian approximation with postmodern and the based on the precision matrix and high accuracy protein contentment return raspberry can be obtained by coupling the precision "
    },
    {
        "start": 60.64,
        "text": "matrix with deep breast net and [Music] an extension of raspberry and some applications that are built on it will also be briefly introduced finally we will have a sub summary of the respiratory method so let's first have some background about the protein structure prediction so the purpose of producing structure production is to infer the three-dimensional structure from its amino acid sequence so the task is uh actually more and more emergency because there is a wider gap between the sequence and the determined structures so actually determine the produce structure is usually quite expensive it should be more than like uh 250 000 dollars per sequence but for a protein sequence it is echo actually around 100 because of that the accumulation of "
    },
    {
        "start": 123.04,
        "text": "sequence is certainly faster than protein structures so actually in 2010 the gap is around 200 times but now it's over 1 000 times so sequence based protein structure prediction should be helped to narrow the gap between the sequence and the structures so to summary sorry the input of the protein structure prediction is the sequence and the output of the method or the algorithm is a protein structure and each atom is represented by the coordinates in three dimensional space uh just like this in a pdb format just like this in the pvp format so actually this setup is actually hard to formulate especially for a general machine learning methods but the geometric descriptions between "
    },
    {
        "start": 185.76,
        "text": "atoms for example the distance should be easier to predict because they are rotational and translational in variance so for the simplification we just predict a binary content map and the protein can be represented as a graph usually the the link between two residues is defined if the distance of their c beta items is less than a threshold for example in amsterdam so although the content map is a reduced representation of the structure we can still have some overview of the protein structure so for example uh we can uh some observe some signal structure patterns uh in the content map the the patterns in the blue box here uh represent the helix in the protein structure and those points that are vertical to the diagonal corresponding to the "
    },
    {
        "start": 246.239,
        "text": "interactions between the antiparallel beta sheet and protein and another application of content map or predict content map is to help recovery the three-dimensional coordinates by some contact potentials during the simulation of the protein structure prediction so the potentials look like this can help poor two atoms close to each other if they are predicted as compact so how to predict the content map of course you can simply using the amino acid type or other features to directly predict the map this is fine but a more powerful alternative is using coevolution for contaminant prediction so the assumption of co evolution is that amoled acids at a different positions "
    },
    {
        "start": 306.96,
        "text": "do not evolve independently actually so most single-sided mutations are deleterious and the damage done by the first mutation should be repaired by limitations in the neighboring sites and this is the direction from the contact to the evaluation however from the multiple students alignment to the contents how do we get the direction from the observations to the contact so we can simply measure the correlations between the columns in the two columns in the multi-sensor alignment and such correlations should help reduce the contact structures so for example the basic covariance between two variables and here we want to introduce the work by david jones that predicted the contact using the basic convergence "
    },
    {
        "start": 367.6,
        "text": "between the two columns in this work the convergence between two positions for example i and two positions i and g is represented by a 21 by 21 matrix because each variable that representing a position is categorical so the categorical variable can be expanded into 21 sub-variables here 21 means the 20 types of ammo acids or residues plus an extra state for the gap that may occur in that in one position in a multiple times alignment so for each pair uh we can have uh 21 times 21 descriptors and the uh the problem can be formulated into a like a pixel labeling or pixel classification problem in like computer version the channel size of the input is like 441 "
    },
    {
        "start": 429.199,
        "text": "which is 21 times 21 and the they use the full fully convolutional networks structure here to predict the content map so this i believe actually is an intuitive intuitive formulation so it makes sense and actually the work prevail however the convenience just simply measures some kind of marginal dependency between these two variables without considering other positions of variables in a multiple sense alignment so next i'm going to introduce a global uh model because the current is just can be considered as a local model that in the global model the coupling parameters between variables is called pulse model so we can so here post model is a probabilistic model and each row of the "
    },
    {
        "start": 490.479,
        "text": "multiple sims alignment can be considered as one observation and of the variable because under the post model have two terms the first term is the pairwise complex and the second term is the local fields uh representing like two body and the one body interactions and later some other methods also consider three body terms in the hamiltonian but actually in this case we just simply you know that we believe that these two two terms should be enough in this field and here z is the normalization factor to ensure that the summation of probability for all all possible observations equals to 1 and it contains many terms like this and such large amount of terms is almost impossible to compute so there are many approximations "
    },
    {
        "start": 552.48,
        "text": "and this paper introduced a gaussian approximation to solve this problem and the and finally they find that the solution is just the negative of inverse of convenience matrix just like this so which is also known as precision matrix here and in this work we consider estimation regularized precision matrix because in some cases where only just a few alignments found in the multiple series alignment so the inverse of the conveyors should be like a aero post so we add a regular addition term to try to reduce the number of parameters so i think the most famous one is the graphic lasso which applies the l1 regulation to the "
    },
    {
        "start": 614.399,
        "text": "precision matrix and you can see that the first terms here are the negative log likelihood function of multivariate constant distribution and this term uh is the uh lasso term or the error one local regulation term in this work we find that rich precision estimation have the best performance like this and we are also trying other types for example error l0 realization and also group graphic lasso so before i saw the performance comparison between those precision matrix estimation uh the evaluation of our first have a brief introduction of the evaluation index have been used in this area so the predicted content map is evaluated by top-end precision "
    },
    {
        "start": 675.12,
        "text": "at multiple ranges usually and have four values like this and here here is the protein length indicating another precision at the different threshold levels and the content map can be actually splitted into several ranges for example the sequence separation that for shutter range contact is from 6 to 11 in this area and for medium range it is from 12 to 23 and if the sequence separation of contacts is over 24 then they are considered as long range compacts so actually the long range contacts has more it is more important and determines the overall topology structure so it is mostly used and now we show the performance of different kinds of precision matrix estimation uh the contact is directly "
    },
    {
        "start": 736.72,
        "text": "uh predicted from the precision matrix here the precision matrix has a shape of 21 times error by 21 times air and each sub-matrix with a shape of 21 by 21 can be used by a post-process which is known of the sub-matrix and the norm can be considered as the predicted content map and yeah so the long-range top-end precision shows actually that the rich precision matrix have a better performance for such data and here error one and the cycle have the same loss function but different implementation and cycle is implemented in graphic lasso and l1 is implemented by ourselves with uh admf admin "
    },
    {
        "start": 798.32,
        "text": "strategy or optimization particle so uh and also the rich precision matrix estimation has a close phone solution so it can be very fast we only need an urgent decomposition during the computation so we have funding determine the future extraction strategy and we can show that to the pipeline of our proposed risk-free based on the precision matrix so actually the fixed difference between respiratory and the pressure's previous work tip cough is that a matrix inversion is added here and we also replace the previous convolutional neural networks uh with rest net as a backbone structure "
    },
    {
        "start": 858.8,
        "text": "raspberry is like this and uh first uh the comparison between the convenience feature and the precision battery feature is shown here and here sunderland solid lines are the validation precision during the training epochs and the dashed lines are for the conveyors feature and we can observe actual significant gap between two lines and the previous p-values are shown in the left table actually the improvement is brought by the precision matrix is quite obvious and significant so we can have the conclusion that the performance can be boosted up by simply apply a matrix reversion operation and here we show the performance of risk-free compared with other state of other state-of-the-art methods now raspberry is also proven to be "
    },
    {
        "start": 921.44,
        "text": "compatible with state-of-the-art method in casper 12 and here ccm parade and the cycles here are unsupervised models they just directly refer the contacts from the multiple multiple students alignment without the supervised training so it is reasonable that they have a relatively lower precision and here deep cough is the method based on the conveyance matrix but uh slightly worse have a slightly worse compared with other state about the art methods but if we just using the inverse of the conveyance matrix feature the precision matrix feature we can have the respiratory can achieve the higher precision than other methods with just one feature itself so uh here we also show two examples "
    },
    {
        "start": 982.24,
        "text": "to show the predictive power of respiration the first one only have three aligned sequence in a multiple sequence alignment which means only three samples was used to estimate the precision matrix and there are 200 variables in the system which means the parameter size is 200 times 21 by 210 times 21 and i believe that the precision matrix should be uh just near random you know we can see that the direct prediction using precision matrix uh produce zero positives among top 40 predictions but risk 3 can still have a top air divided 5 precision of 50 which is far better than other methods and this example highlight the power of supervised model in the the rest net structure that i "
    },
    {
        "start": 1042.799,
        "text": "used by respring the second example we can see that the result of red spring have more like immune distribution across a sequence and the diverse contact should help recovery a better protein structure model actually raspberry has already been successfully applied in many tasks especially some structure prediction methods in casper's cast searching and here casp stands for critical assessment of protein structure prediction and is it is held every two years the structure is blind to everyone when they do the prediction or the modeling so the experimental groups we are trying to solve the structure and at the same time and the performance of the computational servers or groups will be evaluated after the "
    },
    {
        "start": 1103.6,
        "text": "server structure is released so there are many tasks or categories in that competition for example the protein structure topology prediction in the form of atomic coordinates and the contaminant prediction is also one of the official tasks of casp and the estimation of motor accuracies tries to assign a predicted quality score to those predictive structures or models from the server groups so raspberry did not directly participate in cash 13 but those methods using raspberry or extending raspberry participate in the protein topology prediction and the the first task and also the residual residue content prediction task hey i'm sorry this is uh mercy real "
    },
    {
        "start": 1164.96,
        "text": "quickly there's a question that was put into the chat box i can read it too if you'd like it's um for benchmarking data sets were these limited to proteins with known structures like case study protein and are there predictions related to contacts mediated by disordered regions of proteins that wouldn't be captured by most structural experimental approaches uh i'm sorry about that i need to check that yeah do i mean can you see the chat or do you want me to read it to you again i don't know whether i can take that i can read it to you again if you want sort of two parts the first part is for benchmarking data sets were these limited to proteins with known structures like case study protein yeah of course they have no instructions but during the prediction we do not know the structure we only have the sequence or the multiple since alignment okay and then the second part is and are there predictions related to contacts mediated by disordered regions of proteins that wouldn't "
    },
    {
        "start": 1225.2,
        "text": "be captured by most structural experimental approaches um but actually that is possible because the disorder regions may have like very different patterns and there could be some noise for the prediction but we did not systematically evaluate the specific type great thank you that's everything in the chat right now and uh they said great thanks yeah thank you so yeah so this is a uh the pipeline of soundlab servers in case13 and the raspberry provides some contact information for protecting structural prediction or simulation programs like cis or c quark in cap 13 as shown in the left finger and the right finger shows the ranking "
    },
    {
        "start": 1286.08,
        "text": "of the prediction structure of protein structure prediction track in cash 13. so where the first course is the ever vote in the john group that used the respiratory also had a quite good ranking in this competition another work which is the extension of raspberry also called triple res participates in the official content map track in casper 13 it is called it is called triple rs because it resembles three co-evolution analyze features the first two are the precision matrix feature and the convenience matrix feature that has been have been mentioned before and the third one called the cd likelihood maximized of pots model it is actually another approximation of port model similar to the precision matrix and "
    },
    {
        "start": 1346.08,
        "text": "this approximation is uh that is representing the probability of the sequence uh by the product of individual positional probabilities so in in such case the partition function for each position only have like 21 terms and it is very easy to compute 21 terms in the partition function and the period matrix at the prm approximation can be considered as a set of multinomial logistic regression tasks and each of those features will go through uh rest net and then concatenate it together and then feed it to another wrist net of like and each of the rest net has like 24 razor blocks and finally we can have the content map or the contact probability map as a "
    },
    {
        "start": 1406.88,
        "text": "final result uh so actually triple res did a quite good job in the content map prediction track and it ranked as first in this track about however effortful didn't participate in this task so next i want to briefly compare our pipeline our through the res pipeline with airflow pipeline so the basic formula is actually quite similar the formula is just coupling the co-evolutionary features with rest net and the main difference is that in tributaries we have like three co-evolutionary features but in alpha fault they only consider one prm feature they're also using by triple res as a map feature and then feed it to the rest net of ffod "
    },
    {
        "start": 1471.12,
        "text": "and also we have a pipeline to generate more multiple service alignments from a metagenomic databases and of course our work is many done by xinjiang in region so uh but the advantage of ever thought i believe is that they have uh extremely deep learning or deep nearly works with like 220 residue blocks but we only have like 48 wrist blocks from the beginning to the prediction and another thing is that they have a training set with 35 000 proteins but at that time we did not realize that the importance of data and we only have like 7000 training protein sequences and after the competition we simply retrain our model with more data and we find that our model should be "
    },
    {
        "start": 1532.159,
        "text": "compatible with effort actually the different part of our phone and here i list several questions yes yeah so that was casp 13. yes how many proteins did they use in casp 14 14 we have like uh 25 000 and alpha phone two ever has like two hundred thousand ten ten times yes okay yeah but yeah and we believe that the data is very important so we want to examine that okay yeah and here i list several tools that use containment predicted by raspberry and here lomits and the c trader are the threading programs by dr region and using content map alignments to find the long distinct structure templates chesser and c quad "
    },
    {
        "start": 1592.24,
        "text": "uses raspberry to predict the contacts as a extra restraints or energy potentials to guide the protein folding simulations the last one fa parade is using content map to split sequence into different structure domains by considering the uh protein as a graph and the the content of the links between nodes yeah of course this work is also done by way and you can uh of course check those servers at the john lab but for raspberry we also have a online server where you need well what we need to do is pass your query sequence in the text box here and then press the submit button and after several hours depending on the condition of our computational clusters you can have the prediction results look like this so that you can have a quick overview of the protein structure for example "
    },
    {
        "start": 1652.799,
        "text": "this map show here can be should be a helix f helix protein with some anti-directional folds at the c terminal and here we have a brief summary of respring the first one is that the inverse of convenience matrix in this problem should have a better performance than the convergence matrix itself and the signal one is that the reach regularization should be a better choice so actually the convenience matrix and its inverse inversion should have to contain the same amount amount of information when they are used as features of deep learning but uh actually in practical there are many limitations of the currency uh for example the limitations of available training data the representation power of deep neural networks so the precision "
    },
    {
        "start": 1714.24,
        "text": "matrix compared to convenience matrix should help the neural network to recognize those contact patterns in easier and more efficient way but if we have uh enough data we may not need such uh i would say inductive knowledge uh just like the the matrix invention of the invention operation of converse matrix but i believe that the current the data size cannot uh help the deep neural networks to figure it out so some parallel information should be added to the system just like the precision matrix you may also see some problems with the current line for protein structure prediction so the first is that the nearly work and the protein folding is not connected so arrows during the folding cannot pass back to the neural network "
    },
    {
        "start": 1775.2,
        "text": "and update the parameters of veneering works and another problem is that the loss uh function is marginal actually so multi uh multiple ranges of compacts they share the same weight but the contribution of them to the structure should be very very different so i think uh one possible solution to this problem is finding figure out uh end-to-end structure of protein structure prediction and which i think the effortful the most recent version of ffoat should be onenose solution and finally i would like to thank uh dr xinjiang way for their very high quality multiple sense alignments which is the basement of the method and other lab members eric sargenzo and "
    },
    {
        "start": 1835.44,
        "text": "of course professor yong jong for the very example discussion and the formula and also some very interesting ideas and i would like to give my uh special thanks to uh and ron xiaomi for their help to understand the concept of post model and some inverse problems and the other materials that are used in slides are also listed here and i think uh that's it thank you so any questions all right i think that that's the that are the other introductions today "
    },
    {
        "start": 1895.6,
        "text": "and thank you okay "
    }
]