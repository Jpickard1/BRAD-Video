okay better yeah okay great great okay okay so today um i'm going to talk about our work on using semantic integration technologies across species for rare disease diagnostics and one of the one of the nice things about this particular body of work is that it really demonstrates a practical usage of ontologies and ontologies you know are often utilized to structure knowledge or for philosophical exploration but more and more we're starting to see how they can be applied in various kinds of ways in order to help clinical and translational research applications and in this case diagnostics so the promise of precision medicine tells us that we should be able to take all the attributes of a given person and then collect all those attributes for each person in whatever cohort and then be able to classify those patients into meaningful ways that help us understand what their diagnosis is what their prognosis is what their treatment regime should be and we can use many different kinds of characteristics in order to think about this and increasingly in the current world these can include lots of e-health applications real-time data social network data all kinds of things that we didn't necessarily even traditionally think about really being reflective of our health so we need to build systems that can grow to accommodate how to meaningful how to sift through all of these data and meaningfully classify patients it's not enough to just say that we can classify patients we actually need to find the useful classifications that help us understand you know how to answer important clinical questions for those patients so in order to do that we also need to leverage all the biological knowledge about the relationships between these types of things so our our fundamental dogma is such that we have our individual genetic endowment we are exposed to our environment over time we have different behaviors and that results in a phenotypic spectrum that also changes over time for the life of an organism but there are many kinds of relationships between all of these three types of entities you know changes in genetic variation over time in a tumor can be responsive to an environment can lead to changes in histological phenotypic outcomes and so it's a dynamic representation between these three fundamental components so when we think about diagnostics for mendelian and especially rare mendelian diseases the prevailing clinical pipelines leverage really only a tiny fraction of those data that we were just talking about let's see i do have a pointer i don't know does it work if i do it here it does look at that um uh so if we think about you know what what happens in the average clinic is you might go in and have your exome or genome sequenced and they would have a bunch of candidate diseases and they would compare that that whole exome against um a genomic reference range which for the most part if you're of white european descent you're probably pretty lucky that your variant might be in that collection and if you're not you're probably less likely although that is rapidly changing fortunately but there's a lot of other kinds of data that we aren't using effectively to classify that information clinical phenotypes which is the main focus of this talk but many other types of information about the patient such as various kinds of omics technologies socioeconomic factors environmental exposure data both from you know personal devices as well as sort of environmental monitoring and the reference population level cohorts that we might be able to compare um against for these types of of data and so we really um really have a loss of discriminatory power when faced with a diagnostic pipeline that might result in 5 000 candidate variants for a given patient and that is way too many for a clinician to be able to sift through throughout the literature in order to be able to determine what is the cause of that patient's rare genetic disease so the talk that i'm going to give is about how do we actually utilize phenotypic information to improve the the picture here so right now oops um so right now we have about 10 to 25 percent diagnostic rate um for rare disease patients that walk into a a clinic who have a rare genetic disease so we can definitely um improve uh upon that and of course that in and of itself is already a success story so i want to talk first about the human phenotype ontology um and so you know how many of you are actually familiar with i mean i'm at this about you know center epicenter of there aren't too many epicenters of ontologies and this is one of them so i'm sure that some of you are are familiar with ontologies how many of you are familiar with ontologies so do i need to give an introduction to ontologies i do okay okay great okay great so um an ontology um is a structured terminology where each term is in a graph structure as you can see here so here we have this term hyposnia in here in the human phenotype ontology which is an ontology that represents abnormal human phenotypic features or symptoms these terms can have multiple parents so you can see there can be multiple ways to get up to the root of the terminology and as you go down in the graph you get to more specific terms and the terms themselves such as hyposmia are defined logically using an language called the web ontology language or owl or l2 for short and you might say okay that acronym doesn't add up melissa and that's exactly right because ontologists are nerdy and they liked owls so um so hyposmia is [Laughter] um so hyposmia this term um is actually defined in terms of other terms from other ontologies in a logical fashion that a software tool called a reasoner can actually leverage so that software tool can can know that for example deeply set eyes are a subtype of abnormality of the globe location which is a subtype of abnormal eye morphology and so if i query on all phenotypes that have to do with abnormal eye morphology i'm going to come back with terms that uh are annotated to you know data that's annotated to deeply set eyes furthermore these terms such as hypothemia over here are defined in terms of the logic with other terminology so here the gene ontology is not really working very well is it the gene ontology term sensory perception of smell so hyposmia is an abnormality in the sensory perception of smell and the really cool thing about this underlying logic is that it's built in data integration so this term in the gene ontology has been annotated to thirty four thousand 34 000 times to a variety of different genes in 22 different species there's a lot of data out there about the gene function sensory perception of smell and if hyposnia is an abnormality in the sensory perception of smell all of a sudden there's a lot of genes that we might be able to associate that information with and so the hpo has over 14 000 terms in it right now it's basically used to provide that terminology content for representing computational models of disease and so what that looks like is we say for every known mendelian disease we can create a phenotypic profile and so this just shows how we can as you go down in the phenotype graph so here abnormality of the orbital region has 2 600 diseases associated with it but abnormality of the globe location has only 1000 diseases associated whereas hypertelorism has 94 diseases associated with it and so you can see that basically each disease the more specific the phenotypic term the less diseases that it would be associated with and each disease has a set of phenotypic features that are associated with it creating a computational model of disease and that's a simplistic description of the model but you get the idea so this is what this actually looks like in practice and this is a real case um where uh two patients um one on the left uh three-year-old girl and a fourteen-year-old boy over there on the right both came into the same clinic within two weeks of each other and the clinician did not recognize either of the two patients as having vitamin steiner syndrome and the patients themselves had you know slightly different phenotypic features than would be expected for vitamin steiner syndrome and in fact some of those features are actually um the opposite so over here on the right the 14 year old boy has a long has long toes and you'll also note that here these are these human phenotype ontology terms these terms are not things that you would have an icd code for in your clinical system doctors don't um diet you know um have uh terms for things like long toes so much these are like characteristics of the organism that are helping us build systems that help diagnose the patient but they're not something that you can bill for necessarily there's no procedure associated with having a long toe you just have a long toe so there's a lot of content like that in the hpo that's simply not in standard clinical terminologies because they're really it's really treating the human patient as an organism and providing descriptors for how we describe features of organisms and i'll get to why that's really important in a bit and so in this case we have a phenotype long toe which is actually the opposite phenotype of what we had curated in our gold standard phenotype profile for vitamin steiner syndrome in some cases there might be a missing phenotype short middle phalanx of the finger is not present in the 14 year old boy but a related phenotype is here in the girl so cone-shaped epiphysis of the phalanges of the hand you know has a phenotypic similarity to the short uh middle finger phallics of the finger and so what this is if i go back briefly is it's saying there's related terms these terms are not exactly the same but they might be nearby in the graph right and so so what the algorithm is going to do is it's going to try to find um for a given profile each for this this three-year-old girl and this 14 year old boy take their phenotypic profile which the clinician has captured using hpo terms and say what is the disease that most closely resembles my patients phenotypic features based upon what we call this fuzzy phenotype phenotype matching algorithm that looks for the the most similar set of nodes in that graph so think about that hpo graph it's like for every disease we have a graph where there's a lit up set of nodes in that graph which graph fits the best and in this case the clinician was quite surprised to find that within these within two weeks both of these patients matched best the vitamin steiner syndrome even though they had quite different phenotypes from both the gold standard and from each other and it turns out that they have different variants in the same in the same gene kmt2a and so you know it also kind of gets after the fact well does that mean it's the same disease or a different disease that clearly have uh different phenotypic features to some extent but there's obviously a lot of similarity and that similarity is in fact what helped diagnose these two patients but we'll come back to this later it's it's a challenge because the more we are able to classify patients as individuals the more we tend towards every patient as their own disease the question becomes what are the useful classifications that help us and so in this case if we're going to provide treatment to these two patients that's the same or they have the same prognosis and that might constitute keeping this as one single vitamin steiner syndrome or if not we might make vitamin steiner syndrome one or a or whatever okay so um as i mentioned the diagnostic efficiency for mendelian diseases can be improved um and so oops so what other data can we use so if you look at um actually i'm just going to skip to this one so if you look at the human coding genome there are 19 218 genes of those roughly um 3 900 of them have causal mutations that cause a phenotypic an abnormal phenotypic outcome do we really only know something about 18 of the human coding genome in terms of disease-causing genes for mendelian disease if we take the orthologs of those 19 000 genes and we look at those orthologs in the five most commonly used model organisms so fruit fly worms yeast mouse and zebrafish and we look at which of those genes do we actually know something about if we mutate those genes which what do we know something about in terms of the phenotypic outcomes of those mutations we end up with 15 000 plus genes that have phenotypic features associated with them and when you take the union of these two you end up with 82 coverage of the human coding genome so all of a sudden we we can have the capacity to leverage these model organism data to help support inference for the human coding genome so remember those clinicians got 5000 genes to sort through when they are trying to figure out which disease their patient has and that's too many we need to get that number down so that they can more effectively evaluate candidate genes and so um so our hypothesis is that we should be able to use these model organism data in order to help improve the diagnostic efficiency of these types of of whole exome and whole genome analysis so other species aren't just relevant it's also important to know that it's not just those five model organisms we actually need all the organisms we need to learn about the phenotypic consequences of mutation in all the organisms because it helps us understand the biology it's it helps us find drug targets it helps us understand the mechanism of of these diseases and so there are many wonderful examples i also really just wanted to put an armadillo on the slide so armadillos are actually a natural host of um the leprosy uh mycobacterium uh and it's the only other organism that causes that that gets leprosy is the armadillo um you probably already know that naked mole rats don't get cancer why is that um silkworms are a model for uric acid metabolism pond snails are models for inflammation mediated memory dysfunction and show evidence of spontaneous neural tissue regeneration after injury there's clearly a never-ending story about every organism so how can we actually like you know tap into this this biological diversity to help inform disease diagnostics and mechanism discovery and drug discovery kind of an overall goal of our program which i forgot to mention is called the monarch initiative for this work so but in order to do that we need to actually help computers understand the phenotypic terms that we're using to describe these phenotypes so here on the left a clinician might use the term homo plant or hyperkeratosis and the computer really has no idea what that means we actually have to tell the computer what does this term actually mean we can place it in a graph like we talked about earlier but we also have different communities that use different languages so we want to relate the palma plantar hyperkeratosis to a term that might be used by a mouse biologist where they might have a phenotype that's similar called ulcerated pause this is not a string matching problem it's a conceptual alignment problem and then furthermore the patient might refer to this particular phenotype as having thick hand skin so even within the same species we have different communities that use different terminological um words to represent the same thing so you think it's bad that there's only a few of these problems but the challenge is really that each data source uses their own terminology and i have to say i've spent much of my career aligning other people's terminologies so a lot of a lot of what we'll talk about is is that process but um so here we have on over there on the right we have the human phenotype ontology on the left we have the mammalian phenotype ontology used by the mouse genome informatics resource but there's literally hundreds and hundreds of different terminological representations for each domain each community and and they're all represented differently it's not just that they're have a different term label for something but the actual structure of the terminologies and how the information is encoded is actually different so there's a computational alignment challenge and there's a whole field of research on ontology alignment in general to you know come up with better methods for aligning different conceptual representations so i'm going to talk about the method that we've been using for this particular problem in the phenotype space and this we call the chasm of semantic despair and this this was a term that was coined by chris chute for those of you who know chris um but made especially pretty by my um uh favorite colleague julie mcmurray and yes that is me at the bottom of the chasm of semantic despair um and what this what the chasm of semantic despair is really talking about is especially in the context of how do we relate clinical phenotypic features and encodings to basic science phenotypic information um and whether it's you know proteomics or mil or cellular models versus lab data or medical imaging it doesn't really matter the that these codings with the basic research pretty much whatsoever at least in the basic research community we have a bit more strategy and overlap in the terminological space but um really we have a terrible chasm of semantic despair but there between the basic and clinical side and so that's part of what we're trying to address here as well so the strategy that we have is to basically build in what we call logical decomposition so palmo plantar hyperkeratosis is just a string to the computer but we can represent it using species neutral terms from other ontologies so if you recall from that human phenotype ontology i talked about representing terms using the gene ontology but we can use many other different kinds of species neutral terms so here homoplantar hyperkeratosis is represented as an increase from the phenotype and trait ontology in the gene ontology term keratinization that's located in the uberon stratum corneum layer of the skin that's part of the autopod and you might say okay well you know clinicians don't use the word autopod that's a sort of evolutionary biology term they don't need to know about all this all they need to do is use the term that has an identifier and the right text definition and the computer can tell us that aha because the term definition logically for ulcerated pause actually matches the logical definition for polyplant or hyperkeratosis these two terms are similar to one another and we don't really say the words exact because they're in different species so they're not really exact anyway but again it's a proxy for representing the specific phenotypes and this logical interoperability using species neutral ontologies and homologous concepts allows us to create this type of interoperability across species in particular for phenotypes so we've also recently been able to use this approach to prospectively harmonize phenotype terminology so that we can start getting more of those different species to participate and share their data in an interoperable way and so basically what this is is it says okay the terms that have stars on them here um you know are terms that have a pattern so you know abnormality of organ function could be a pattern and so anytime we have a subtype of function or a subtype of organ we use that same pattern right and so by aligning these patterns across the different terminologies we can then create what we call the uber pheno ontology we do like our umlauts in the ontology community so this this terminology is the sort of consensus intersection of all those other phenotype terminologies that says these are the design patterns that match across all the different ones and so this just shows you how you can do cross species inference if you have information coming from a human and information coming from zebrafish we can actually know that these terms are essentially implemented with the same design pattern and then automatically be able to infer relationships for example between gene function across those species and transfer across species so we also need um sort of spatiotemporal representations to relate form function and dysfunction in order to interpret the genome for diagnostics or or otherwise and so this is i just put this slide up for the students to really think about the fact that no ontology really exists all by itself it's all about the integration and the purpose that you want to have it serve and so here we might have the gene ontology with respiratory gaseous exchange which might relate to a gene if that's a gene dysfunction might be abnormal blood gas level and these both relate to the anatomical term gas exchange organ and uber on which you know we might have um inhuman and in fish they would be gills here in fish and lungs and humans but the evolutionary ancestor for lungs is actually the swim bladder but it no longer has that same function and these relate to the cell types and the tissue types that are present at different spatial scales and these are represented by the cell ontology and so and then also in the gene ontology we have subcellular anatomy so all these kinds of anatomical pieces in both space and time fit together and then also the other axis is is function and dysfunction so this is what this looks like when you put it all together and so here we have um form from a mouse a term duplex kidney which relates to a human disease phenotype renal hypoplasia where the the intermediate uber pheno term is abnormal kidney morphology and so you can see that this term from this kind of uber phenotype ontology matches neither of the two terms that are used in those two organisms so there's some other examples here abnormal palette morphology here we have cleft palate here we have high palate and this fuzzy matching so now as i showed you before for the the two patients with vitamin steiner syndrome is now also able to be used across species so all of those genes that are annotated to all those phenotypes in the venn diagram slide that i showed are now accessible to this technology for comparison to use as potential features that can help prioritize genes that come back in that list of 5000 g and so this is how you put it all together so traditional variant filtering uses a variety of approaches it looks for rarity of a variant it looks for mendelian inheritance patterns we look for we use a variety of different pathogenicity algorithms and these are always improving all the time i mean this is a fairly standard approach but our special sauce is that over here on the phenotype side we encode the patient's phenotypes using the hpo and then taking data from a variety of sources including human sources such as omim and orphanet and others we can do that fuzzy matching and see if we can find a disease that matches based on that we we match against the model organisms that i showed you earlier and then we also do a guilt by association by bringing in data via orthology and via string db which has a lot of protein-protein interaction data so if a phenotype is associated with the gene but that gene's not on our short list we might prioritize it if it's has a protein-protein interaction with another being that does have a similar phenotype and so then together these prioritized genes and their orthologs come together with the candidate variants that come out of the variant filtering and we have a final prioritization scheme and this tool is called examizer and is developed by my colleague damian smedley at genomics england so this is a story of jessica so this is one of our patients from genomics england and it jessica um and i just wanted to illustrate the power of how the ontologies are actually helping um to improve the diagnostic rate at scale so the genomic england is one of the larger diagnostic programs and genetic diseases worldwide and here in the jessica's case she at age four was indicated with a rare condition with epilepsy she had movement disorder developmental delays and her her tests were negative if you look over here on the left we started with 6 million plus variants in her genome 677 000 of them were rare 2 800 of them were predicted to cause a change in the protein 67 of them were different to her parents and using the phenotypic information and the protein protein interaction information we went from 67 to one candidate which turned out to be the smoking gun and this child is now being treated successfully with a ketogenic low-carb diet so simply getting to that variant now is going to have this child live a healthy life [Applause] always makes me cry so the other thing it can do is it can it can also help us identify new models so as it turns out we actually know a lot about genetic diseases that we don't know what the gene is still even still there's lots and lots of gene diseases in omim for which we don't have the molecular basis and so we've actually recently used the same approach to actually find candidate genes for those diseases so here's an example using the international mouse phenotyping consortium data to find a candidate disease gene for cataracts patients cdkn 2a and so and there's a link to the paper there if you want to read about that so we've actually identified a few hundred new disease genes using this the same approach so i want to talk a little bit about evidence especially because i know we have a lot of students in the audience and we were talking even at lunch about how you know um how do we sort of uh understand our assumptions about the data and how do we include those assumptions in our investigative bioinformatics applications and so i have two kinds of approaches that i want to talk about one of which i want to talk about for two reasons one is what is a disease what's the evidence the disease exists and how do we actually represent diseases and it's also an example of of ontology harmonization that takes years and years but is critically important and the other one is really about ways to in ways in which evidence might be used to help support um conclusion drawing so i'm going to start with an overview of both so um over there on the left we have um an effort that we call the lumping and splitting group that's part of clingen um and clin gen is uh business is really about defining um you know what you know what are does what are the disease gene relationships and what kinds of characteristics for these patients um you know are indicative of a given disease when to define a new disease when to merge diseases um and so um they've we've been working with them to come up with guidelines um which are kind of summarized here you know are there distinct molecular mechanisms are is there a reputable assertion of a difference between the two diseases um is there a distinct clinical management protocol for the two different diseases and do they have different distinct phenotypic profiles and so we developed an ontology called the sepio ontology the scientific evidence and providence information ontology which allows us and i'm going to talk more about that in a second to represent these these differences these changes in these different and these different components and then that information from the lumping and splitting group is used to help inform armando ontology which is an ontology i haven't spoken about yet which is basically an effort to try to take all the different global disease definitions for rare mendelian diseases and bring them together into one harmonious ontology that helps support consensus definitions across the different resources so if we have two different diseases that have the same label from two different resources but one has a completely different genetic basis or a completely different treatment regime how do we decide if that's the same disease or not they have the same label they might even cross-reference each other but if they have different treatment regimes you're a patient you're going to get a different treatment if you're in one country or another so we've got to figure out how to come up with consensus or else patients will not be treated with the same degree of rigor in the different contexts and so we work with the clinton group to work back and forth and going through all the different diseases to try to define what these disease definitions really should look like so first i want to talk about the evidence part and then i'll talk about the mondo part so evaluate so this is an example of how we might apply the sepio model to the ability to evaluate the pathogenicity of a variant for a given condition so here we might have three clinical labs that would interpret different types of evidence in determining whether a variant was pathological for a given disease so uh we might have computational prediction evidence so the path the maybe there's a truncation of the protein or it's going to cause you know malformation of the protein um we have population frequency evidence the variant is absent from population databases well we know what the challenges are there right we have we are missing a lot of popular key populations we have family history evidence the variant fails to segregate with disease phenotypes we have functional evidence that the variant is shown to have um normal activity uh when put in when in vivo and so there's many different kinds of evidence and there's a an organization that has defined what types of evidence are important to decide when a variant is pathological for a given condition but what we find when we look at the data is that the different labs will use different evidence lines and come up with different interpretations so lab one here might say that i've got yes i have computational prediction evidence and population frequency evidence but not the other two kinds and then declare it to be pathogenic whereas lab two might have the first type of evidence but also family history evidence and then lab 3 might have only functional evidence and so it calls it that lab calls it benign and so what to do if you're a clinician saying okay well there's only three labs that have evaluated this variant before the patient's sitting in front of me remember i've gone from maybe 5 000 to 67 if i'm lucky candidate variance how do i decide whether or not this is a candidate for my patient if it's path if the different submitters from the different labs don't agree on whether it's pathogenic or not and so pepio oncology helps support how we represent quantitative metrics of evidence quality quantity diversity and concordance i mean i don't have time to go into all the details here but basically we can make a graph structure of the different types of evidence so here in the middle we might have co-immunoprecipitation evidence here we might have functional complementation evidence here we might have different types of imaging evidence such as microscopy or co-localization and so over there on the left every time i go up there i get the thing you know one claim might be that i'm pathogenic and i've got evidence of type 1 and type 2 and over there on the right i'm saying that the variant is benign for that condition and i've got evidence types 3 4 and 5 in green and so it allows you to sort of create automated systems that can come up with instead of just likely pathogenic or pathogenic we have a five bucket system we can actually have a gradient between zero and one of what does the evidence actually tell us by looking at degree of quality quantity diversity and concordance so here for example i've got lots of imaging evidence that says that it's benign but i've got um you know co-amino precipitation evidence and functional complementation evidence which are two very different kinds of evidence that both say it's pathogenic and so that actually can kind of work together to say okay those two very different types of evidence might be more corroborative that it's pathogenic versus really all very similar types of evidence over there on the right saying that it's it's benign you can also ask the question well did the same lab do the same assays or did it come from different labs which would also corroborate those types of findings okay so moving on a little bit to the problem of evidence for disease so um this is an actual table that shows an actual use case that shows um the evidence and of equivalency between these 11 different records from different rare disease mendelian database resources for ehlers-danlos syndrome and so there's different ontologies or terminologies or resources over there on the left and they have you know mostly the same label but not exactly so you know mostly they say ehlers-danlos syndrome but there are some that have eds and parentheses or one that's all in capital letters which if you're a bioinformatics person you know that any disease label that's all in caps comes from omim um so that one's ehlers-danlos syndrome comma classic type some of them have text definitions some of them have synonyms some of them quite a lot so the ncit the national cancer institute source has 26 different synonyms for ehlers-danlos how can we have so many synonyms for ehlers-danlos syndrome in ncit but not have any synonyms for it in orphanet which is a major rare disease resource if you look at the mapping so um i was saying earlier that i i have one recurring nightmare and it's about mappings um never use anybody else's mappings so these are outgoing mappings so from each one of these terminologies each one maps to the other so it's this giant mess of everybody mapping to everybody else and most of the time these mappings are not well documented they're just a link um at best uh just an identifier tag um and so you don't know who did it or why they did it or when they did it um but you can see that there's this kind of smattering of them you know you we have uh eight mappings in total between the disease ontology and the various other outpouring mappings we have 11 from the mondo ontology which is the one that that we've developed that i'll talk about in a minute and almost all of these resources don't actually have phenotypic information so you can't actually use the phenotype data that might be associated with that disease to actually decide whether or not it's the same disease or not you really have to go on the label and if you're lucky there's a text definition or the synonyms that exist and then if you look at the unique ones we come up with with 20 distinct mappings across this different suite so what are we going to do with this mess if you're if you're a patient and your your clinic uses omin but not orphanet or medgen but not snomed or ncit because you're more of a cancer patient you know you're going to come up with different results as to whether or not this is a candidate disease for you so we needed to harmonize all this mass in order to have our diagnostic pipeline give us adequate results for the clinicians to review for the candidate variants so we needed disease categories that spanned multiple disease classes that span multiple categories so a disease can be both a cardiovascular disease as well as a cancer you know you can we need that multiple classification that so many of our clinical terminologies don't give us and we need a systematic way of relating these concepts to one another so um standards proliferation here we go how do we know we need a new standard um and this is a great um xkdd comic so there's 14 competing standards 14 that's ridiculous we needed a we need to develop one universal standard that covers everyone else's use cases yeah um so the situation is soon there are 15 competing um standards and of course you know cac chargers character encodings and messaging it goes on right uh but here's our situation for diseases there are 15 times 14 which equals 210 sets of mapping so we already have 210 standards so we made a new one so um this is um for those uh bioinformatics folks i maybe forgot to put the link on here but this is a really neat algorithm called kboom which is the bayesian owl ontology merging algorithm which uses both logical and probabilistic inference to understand when are terms in two different terminologies or in all the terminologies equivalent or not what is the evidence of their equivalence and that algorithm basically looks for the most parsimonious equivalence cliques amongst all the different ones so if we go back to the ehlers-danlos example um here it can it can look at all these different terms from the different ontologies and say which ones of these are actually truly equivalent versus which ones might be children classes or sibling classes based upon a variety of features which might include those mappings and synonyms placement in the graph text definitions priors because we like some terminologies better than others and these sorts of things that can all kind of work together and then the algorithm spits out these equivalence creeks that we then look at the ones that have low probability and curate them and figure out what's going on and in many cases what we found is that they're mostly errors somewhere upstream in one of the sources so for example we found in mesh that there were a lot of terms that had that were essentially the same but were in two parts of the graph where one used roman numerals and the other used alpha numeric numerals for the for the terms right but they were otherwise the same term and so the algorithm told us you know this is not parsimonious these must be um equivalent but you're telling me that they're two different terms and so how do we reconcile that so then we fed all that information back to mesh it's all been fixed so it's also really helping improve upstream resources as well so i just wanted to talk a little bit about how so if you are interested in disease modeling we have a new new kind of community effort on this project that aims to help define the disease models as well as their text and logical definitions as a community effort and hopefully get all these other resources even if they keep their own terminologies to align with this process in a community-oriented way it'll be a long haul but it'll be worth it but i did want to spend just a little bit of time talking about the relationship between terminologies and data models because especially for folks just starting off in bioinformatics it's really important to understand how these two things relate and we don't have too much time to talk about data models today but it's really important to think about how we use these two together so if we think about patient encounters we generate bunch of data that data goes into clinical databases that those subsets of that information can go into registries we have various kinds of inference that that give us medical knowledge that helps clinical decision makers develop clinical guidelines and manage that knowledge and feed that knowledge to clinicians as they're doing going about their work and those clinical guidelines then feed into expert decision support systems within our ehrs and clinical settings which then leads to better patient care in our patient encounters and the terminologies and the data models really have to work together at all steps in this process so the terminologies are really the vocabulary that we use to describe these features so for phenotypes it's the symptoms and features um but the models are the structure the content the the context so if we if we say ehlers-danlos we might mean that the patient was diagnosed on x-date with ehlers-danlos or we might mean that the patient's mother was had ehlers-danlos um and so we need to be able to distinguish between those two contexts and that's where the modeling comes in we really have to have the terminologies are useless without a model in which to place them it's all about how they're used in context our hpo ontology is useless without the gold standard models for how we represent the diseases that they're associated with and so it's really important to keep in mind that the ontology is not going to solve your problems all by itself if you have a terminology problem you really have to have a robust model that goes along with that for the computability and to support this sort of cycle of evidence-based practice so i wanted to kind of follow up on the craziness of of that and why we need a model so this is the real example and what the mondo community is going to be working on different communities annotate different relationships at different levels of granularity using different vocabularies because there is no model of disease so clinvar annotates diseases to variants the national cancer institute annotates diseases to genes we annotate diseases to phenotypes here in the monarch initiative and so and the um uh orphanet also annotates diseases to phenotypes the comparative toxico genomics database annotates diseases to treatments and um and also the um and clingen uh annotates diseases treatments and then ctd annotates diseases to exposures and so really what we really need is the representation of diseases that includes diseases variants genes phenotypes treatments and exposures right but we can't get all of those from any given source none of these many important resources that are used for clinical decision making every day share a common model so even if they use the same terminological resource say mondo for diseases we're still out of luck because we're we don't have the same model it's associating those diseases to variants so our pathogenicity predictive tools for helping determine the diagnosis of a patient are still going to fail because the data that we get from these resources is not aligned in terms of its model so this is just to kind of hit that home but we did an analysis of looking at rare diseases uh how to define so we don't even define rare diseases the same in each country so a rare disease in the u.s might not be a rare disease in the us and of course there's also population differences if you you um you know malaria is not a genetic disease per se but um it's not it's it might be rare here it's not rare in other parts of the world um so we uh we actually there's been a number floating around for many years of around 7 500 rare diseases it was actually that number was calculated back about 20 years ago as part of the orphan drug act and people haven't really updated that number for a long time do we actually finish this you know preliminary pass of the alignment of all the diseases and looked at what are all the leaf nodes that come out so what are all the bottom classes of all the ontology terms in this in this mondo terminology um and and actually it's interesting because um uh when we look at this um we actually there's a lot of sources that that have a lot of non-overlapping content actually um and so we end up with 10 500 rare disease concepts rather than 7 500 which is a huge difference um and so this diagram just shows kind of the you know what's unique to each one so you can see here that orphanet has a lot of unique content but then so the way this these plots work is that the dots show the sources the number shows the number of terms that are found in both of those sources so here in ncit and the disease ontology we have 704 shared concepts between those terminologies so it's an interesting way of looking at the spectrum across all the different resources and so we actually just wrote a little paper about this and um you know it's in it's it you know it might seem like a bit trivial and maybe we're just splitting hairs but it actually matters for treatment so for treatment and also for drug discovery if we can't actually have a shared model and have a shared label we weren't doing a very good job of building various drug discovery platforms to actually identify the right treatments and these are patients worldwide that you know are really desperate for for identifying treatment so anything we can do to help is is really critical um so just to kind of speak to those who are more clinical informatics in the audience so okay yep all right i'm just about at the end here let's see um you know what maybe i'll just uh maybe i'll just end with this slide so this this basically is sort of suggesting that you know we don't need to throw the baby out with the bathwater we have a lot of different clinical terminologies that are useful and well uh well regarded in our clinical systems but we can actually anchor them with some of these more robust ontological frameworks and disease definitions outside the context of those terminologies and we've been thinking about how to do this using the fast healthcare interoperability resource to help support that we have uh for those who are interested we have a new standard um to try to you know so we have all these ways of encoding genes of encoding phenotypes um but we don't really and we have lots of exchange formats for sequence information like pcf files or even fasta files but we've never really had a phenotypic a way of exchanging phenotypic information so those profiles that i talked about and so this really aims to help define better ways of representing disease phenotypes for exchange at a case level for patients so this is work in the global alliance for genomics and health and the new standard is called pheno packets so i'm just going to skip through all of this and go to the end even though it's all very fun in there so just kind of putting things all together this is essentially when we think about disease models we have to really move beyond as i mentioned at the beginning the notion of um you know using only genetic information or only even clinical phenotypic information but all those other kinds of expression data environmental exposure data treatment data treatment progression and these kinds of things and so even working as part of both the monarch initiative and a project called the ncats translator to build knowledge graphs that really bring together all these different knowledge sources which have different types of data together using a standard framework called the biolink model which tells us what kinds of entities are there in their world and what kind of relationships do they have to each other so that precision classification those relationship bits that i showed at the beginning really trying to put those together into one framework that allows various kinds of computational algorithms to run over these graphs and actually identify candidate treatments for drug repurposing for example and so here's an example for fantoni anemia where we're trying to find candidate drugs uh for fanconi anemia patients who are rather underserved in terms of therapeutics thanks so um i want to thank very many people but especially my partners in crime chris mungle and peter robinson who co-lead the monarch initiative with me and also julian mcmurray who really helps envision all of the research together with me and our group so thanks very much oh and our funding thank you [Applause] it's very nice talk it's really amazing how well this works because there's so much bad information in medical records a lot of it is wrong it's commonly incomplete you always have environmental exposures but we know almost nothing about environmental exposures affecting expression of disease how does it work so well well we do it outside the ehr i mean most of this work is done outside the hr so you know really you know it takes about a day actually to go through the combination of all the path reports all the laboratory assays ehr data patient reports imaging data to create these phenotypic profiles for a patient to be able to run these types of algorithms so that's one of the challenges that we have and there's been um some different so one of the things i didn't have time to talk about is actually i can actually show you really quickly um is we actually translated the hpo into layperson so that patients can self phenotype themselves to hopefully reduce the burden of the clinician in capturing this information and also because patients sometimes have phenotypes that are not well captured clinically so for example we had one case where a baby had no tears so that if the baby's not crying in the clinic you're not going to notice that the baby has no tears or a baby that's inconsolable if you know um these kinds of uh or snoring these types of phenotypes are capturable by the patient so we really envision the way that this needs to work as a partnership between the patient and the clinician doing the phenotyping so we've been doing a picori study to try to evaluate the use of this layperson version in patients and then the next step would be to see how well that works for the clinical diagnostic use case but so that's one thing i do have some colleagues that are also working on some uh sort of audio recording versions that would encode verbal descriptions into phenotypic ontology terms to help support this capture and help make that more efficient we have a variety of text mining tools that also run over the clinical records um that then have tools that will help validate that the clinician would validate and say yes yes no no this is not a term this is you know just trying to find ways to expedite the capture of these these robust phenotypic profiles and then also working we just got funding to work with hl7 to build a new resource for fire that would be this phenotype profile which is a pheno packet so that when the clinician goes to the trouble of creating all this content outside the ehr they can actually put it back in so that we can start to have more of a full circle to get this information out of the hr improve it get the profile that we need for computational use and then put that back into the ehr yes i have been in contact with them um yeah they uh they're very interested in this technology originally they were less interested because they didn't have as you know there was not a business use case for rare disease but they've also found that this technology would be very useful just for creating communities of of interest so there's a lot of community development in patients like me um and so um and they're also really interested in this lay person version of this terminology so yeah we've had some really nice conversations we haven't done anything yet but yeah so a lot of answers yeah yes they did you know thank you very limited uh that's a good question i i haven't had that conversation with anybody um but well and this is yeah and it's it's there's a couple real challenges there for one is that just because it's you know publicly funded or larger doesn't mean it's better um or or good in the way that you think it is um and so for example for clinvar which is a wonderful resource it's used by very many people but everybody who works on clinvar data knows how to clean the data for use in applications right and so for if you have a commercial entity who's maybe less familiar with some of those data challenges um you know how do you how do you make sure so just because it's clinvar does not make the application that's built on top of it good right um and so we one of the challenges that we really have in our community in general is feeding those data fixes back so i can get i can tell you that there are literally tens of thousands of people who have written the same scripts to clean that data from clinvar or omim or many of these resources but we don't have any way of putting those back in the hands of for the next person right and you know we try to be good citizens and give feedback but maybe our solutions aren't necessarily needed by all they're only needed by some so that you know it's just challenging um you know i think that the other thing is is um you know when we think we're very u.s centric here in the u.s and uh um you know when i when i i when i go to other countries and really work on the rare disease aspects in other countries you know they've got their resources that have their variances right and um and especially for um you know underserved communities the variances simply aren't common variants just simply aren't in the public repositories and so you know we end up really more highly prioritizing variants that that really shouldn't be and so there's a kind of a global effort right now to try to improve that which is actually going pretty well so i don't know if it will end up in clinvar but there's many other places that need to be part of that story so yeah yeah hi thank you for the talk um i'm just wondering about how you keep these ontologies up to date with current medical knowledge so obviously as time progresses um paradigms and medicine shift so how do you keep the uh these huge ontologies up to date with the latest ways of thinking in the medical community and uh maybe with phenotypes that we haven't noticed before how do you manage that new information that's a really good question and it is a big challenge um you know we we should have but don't really have good tools for kind of literature reporting that um you know we can sort of get automated feeds to look at certain content that needs to be added i mean it's hard because you're looking for content that you don't know about yet right um and you can't read every paper that comes out we also rely uh really heavily on our community so people who note that things are missing request things and we add them a pretty good turnaround time that's actually a pretty good way of staying current we also have a lot of workshops with communities that you know have emerging needs and so we'll add a lot of content in those contexts as well i think the bigger challenge isn't so much phenotypes because even though we get new kinds of phenotypes like um you know more molecular phenotypes we're not really in the business of capturing those types of phenotypes in the ontologies that's more of a data-driven type of approach nice to see you thank you bye um but you know rather the actual models so the models of diseases are what really change and you know well you know last year we used to treat this disease with this drug but this year we we now recommend this and here's the evidence for why that kind of knowledge and coding into the disease models is really hard to keep up to date and we we haven't really addressed it yet in mondo because we're still in the business of reconciling even the basic features of each disease i mean especially for rare diseases there's no we actually are working on a medical intervention ontology to associate interventions because many of the interventions are not even necessarily drugs they can be but also like dietary interventions or other behavioral interventions so you know there's no there's actually no good resource right now that even says what treatments we should be using at any given time for disease so there's a lot of work to do on that part and i think that's where the bigger challenge of keeping medical knowledge up to date is going to be a challenge i think of some of these ontologies are really like the atomic elements that can be used in these bigger models and it's the models and how things are put together that that really suffer from decay so yeah [Music] june and uh robinson last year a few months ago from last year in new england journal of medicine there is one of the people uh everyone the title of the table is classification on ecology and how it can basically come quickly and make some influence because we know that the geo-ontology one was published in 2000 and now you have been studying that the single people have been there for probably more than 30 000 times and then people are wondering oh wow so grateful and now hundreds from currencies are coming so we're trying to put together community effort to get the overall funding community and some bigger more influential oncologists like the mongol and so we are actually coming together really quickly and uh in the community effort and how it can be used so like um thank you very much [Applause] thank you you