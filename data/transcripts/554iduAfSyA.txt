oh okay all right the crush doesn't seem nearly as ready as it was last week still ready but it doesn't seems like new york-style alright so welcome everyone to the tools and technology seminar series I believe you've all been here before there is a sign-in sheet going around so please do sign in it just helps us with the pizza as you noticed we're continuing to trial out and dining for a pizza vendor so we're continuing to give them feedback so if you have feedback that you've not already provided to me please feel free to do so and so we can see whether or not we will continue to use them so today I'm pleased to introduce our speaker dr. Chuck Mayo and he is an associate professor from radiation oncology and he's going to talk to us about Big Data and radiation oncology Thanks for seeing me here so first knowledge mints I get to work with a large group in radiation oncology this group has a long history of pushing the envelope in radiation oncology with development of informatics or as radiation oncology Zavala from its infancy and it works through physicists physicians staff members so it's really a terrific group for what we're able to put together there's going to be a couple of common themes that I'm going to touch on that we're finding as we as we engage with people at other clinics who are trying to accomplish the same sorts of goals that we're doing that that really come through a lot one of them is community science that a lot of what we're accomplishing in radiation oncology and what becomes the basis of it is working together with groups not just team science not just the people right around you but reaching outside fortunately it works in our group that our department has a hugely high ratio of people that work to reach outside the department to form communities to do that in those efforts we're always looking for the win wins that's how we find the ability to construct something that will work one of the reasons we're really excited when you get gave us the the offer here to speak a little bit about what we you do is we recognize as we're engaging with other people helping them and they're helping us there's a real need to understand one another's domains and what what are our problems how are we approaching them a lot of times what happens is that what happens on the clinic is is really very interesting but it doesn't quite connect with what happens on the academic side so I'm really hoping one of the things that might come out of this is that we can start bridging that gap a little bit and certainly by showing you giving you a better sense for what we're accomplishing maybe that'll help so radiation oncology you may not know very much about radiation oncology as especially and what happens in the clinic I want to give you a better understanding of where we're coming from is we're addressing big data how that fits into it radiation oncology is one of the most data technology-driven specialties in healthcare so what do I mean by that for our patients we are delivering radiation to kill cancer cells radiation kills cancer cells it also kills everything else so hopefully what you're trying to do is take advantage of them being a little more sensitive than the normal tissues around them to be able to deliver a lethal dose to the radiation spare the other normal structures around them but then to do that we need to use some fancier techniques so we don't just point a beam and shoot and say we're done we have to find ways to sculpt dose surfaces as we go around so for example here we've got a patient with a brain tumor right in here okay and we want to deliver a high dose to this what's the problem optic nerve and chiasm is going right through in the middle so one of the things we want to accomplish is to be able to deliver a lethal dose to that tumor but not make the patient blind now that's not easy to be able to pull that off you can't just point and shoot and do that it's going to cover everything so one of the things that we do is we have these devices called a multi-leaf collimator these operate under computer control so we have this patients being treated with four arcs there's one that rotates all the way around the head there's one that does this way and arc that way and in arc this way as they rotate these leaves are moving so we're modulating the intensity so that we can sculpt a dose surface that helps us deliver the dose to the target and avoid the tumor now back to what's that or the normal and avoid the normal thank you now back to radiation oncology being data technology driven how is that done well everything here is happening on a computer connected to a database all of this information which beams are going to be used to treat are all plugged into the database and quantified so we have a wealth of information about how the dose was delivered how those leaves were controlled as we treated the patient we also know a lot about the dose is delivered to all of these normal structure so these are each quantified as well although one of the things and I'll come back touch on this later that we deal with is these this text field is free text this down here is quantity is fixed and quantified so we have a mixture of things that get manually input and things that are just fixed that we have to mine when the treatments delivered again it's a team approach so the the physicist or dosimetry will run that treatment plan on the delivery side we have an accelerator that's generating x-ray beam that comes in through the head here and the leaves are up there to modulate it the patient lays on the table our therapists here we have phil and bonnie who are treating patients notice the computer screens are surrounded by so at every step of their process whether we're talking about appointment types that are being entered in tracking various outcomes that's all entering into a database so what are the problems that we deal with when we're thinking about our patients so the point is did we say we want to treat the tumor and spare the normal tissue did we succeed what are the issues involved here's an example of a patient's being treated for a mediastinal tumor hair okay so we need to deliver a high dose to them so thank you right yes all right so we wanted we want to treat this tumor we don't want to deliver too much dose to the heart that's a few slices down we also don't want to deliver too much dose to the lungs if you deliver too much dose there the patient gets pneumonia and they can die of the pneumonia so you don't want them to die of that so we have to find a way to spare those normal tissues so this will be one of the things when we're going back and looking at our patients and saying how did we do we'll be looking at those doses and saying is there a place at which we saw a trade-off well you know we did a little too much on the lung and now we're seeing a complication another site where this comes up is spine so this is this has been a treatment that has become much more frequent in radiation oncology clinics in the last few years so a patient is treated for one tumor site cancer is an awful disease it metastasizes often it metastasizes to the bone it may land in the spine that's extremely painful so stereotactic radiosurgery is a way that we again sculpt very sharp doe surfaces to be able to treat the tumor that has landed there but also spare the cord so we're gonna be asking questions about how are we doing on sparing the cord are there any complications that resulted from this we have to connect the dots I know the dose I know that really well because we quantified it how about the outcome how do we know that can we connect it up does it matter what are the other factors so that will come in there as well where this is a VI is Brooke avi is one of our physicians and one of the the the world's experts in head and neck cancer so people come from all over to be treated by Avi and this is typically what happens in clinics now as a patient comes in and the physician is really at the middle of pulling all of this information together in their wonderful brain alright so we will they'll evaluate the options they'll design the treatment they'll deliver the outcomes some patients are on clinical trials typically about three percent nationally not much compared to what happens routinely those patients we know a lot about so they gather lots of labs data lots of outcomes data so you can connect the dots we know they know those pieces but we treat every patient right and a lot of our data is already in the computer we really ought to be able to be in a position where instead of dealing with a few patients that we can start dealing with thousands of patients in our own institution or being a community and reaching out and finding data sets that are tens of thousands so ultimately we'd like to get to the point where the physician then it's not all this is not the lynchpin that we are grabbing for each patient that comes in we gather the information we measure the outcomes and treatment for all of our patients and aggregate that into a common source in data from other specialties and then use automated approaches to analyze it carryout machine learning and reporting so we can participate in registries and then have that information feedback in this loop so that for every patient that comes in there information becomes something we can use to improve for the next patient that comes through this is Marie Curie so why when I think about what we're trying to accomplish in in looking how to reach that close that loop and what we want to reach toward the effort is very early on and Marie Curie is a physicist the curious thing when you go to read maurice marie curie's thesis this is not so much about physics it's more about industrial chemistry so in this earlier age they wanted to look at understand what was happening in radiation or what is this thing called radiation but to pull that off she needed radioactive isotopes you couldn't just order them so her her effort really required extracting it so she's mostly spending her time in her doctoral work doing industrial chemistry figuring out how to take truckloads of pitchblende blocks or rocks and extract out of them the small nugget the thing she really cares about in order to carry out her experiments not too dissimilar from what we're trying to do in radiation oncology we have a place we want to be we want to reach that goal where we can close the loop we're gathering all this information and building it into our database systems building automated tools to analyze the data but we're first gonna have to go through the work of figuring out how we can get to those pieces that we need so that's a lot of what's happening in big data in radiation oncology we've taken a look at what we need to do how do we need to stratify our approach so that we can start taking these things on one by one down here is the clinical practice here so this is we have many many data sources so there's not just one you have a question and we'll talk about this a little later you have a question you want to answer it where are you gonna get the data to answer the question it's not going to come from just one system so some supper organised in databases some sources are spreadsheets it's amazing the genomics data shows up in a spreadsheet the laboratory data comes from another database there are multiples that we need to be able to pull from so to be able to answer questions we have to be able to connect them up you have to know how this relates to that we need to know not just the key vitamins but elements but how they're related so we need to pull them into together into the aggregation share into a common database system now that's a place to organize the data this this process is really about reducing entropy in the data in that first step now that we have it we can start thinking about common standards for how that information can be exchanged and used in a variety of analytics tier approaches so we can do machine learning it ties us into clinical trials so there's quite a lot we can do here once we're able to get the data transferred over and establish some standards for how it goes so you're not spending all your time figuring out how to make two things communicating and what we expect coming out of this as as we learn from this data for our patients this turns back into how we affect our interfaces and what information is going to be communicated and then how this information comes back to inform that what we do for the next patient so the evidence based decision support so if we're trying to we're trying to find meaning in what we're doing and to find meaning in these large data sets we really need to have depth in our cofactor profiles and domain specific detail on key data elements a lot of times when we're sitting in the audience listening to big data conversations this sort of sits in the back of our mind is we're thinking about meaning because we're asking if so if the patient had a toxicity or they didn't survive the question is why right so if you're doing a big state of study and you're taking a you're tracking where patience or people are traveling in Ann Arbor suppose you're watching GPS coordinates on uber taxis or something you may learn a lot about where thing where people go but if you want to ask the question of why did they go there why did it happen at this time of day why this particular part of the month is it different you need to be able to answer questions this is the mother who needs to go pick up her kids somebody going to their work are they late for their job is this about health care what are the issues that they're dealing with so we need depth and those cofactors to be able to get to the question of why and we need to have domain-specific detail on those elements because you can't trust them just because it's there in a database doesn't mean it's correct so if you don't know the vulnerabilities of that data you're going to be undermined in what you can do with it so for example if you're tracking GPS coordinates to look at your location that works great when you're out in the suburbs and you're gonna land at them all I know where I am but if you go downtown whether you've got a high density of storefronts that are also vertical as well as laterally distributed you don't have quite so much information so understanding what the implications of that detail is really important in radiation oncology we have to do a lot of that the questions that we want to ask um cover a wide range of categories treatment of symmetric information are in our domain we can control them but we need to be able to pull information on demographics imaging chemotherapy surgery pathology labs a wide range of information and a variety there's a lot of it is manual entry by a variety of people um even labs labs are not manual entry but you'll find as you start to go pull that data that when you're looking for a particular lab type for example one one study we're doing right now is looking at liver response for patients who are not having cancer need to track albumen scores there's five different ways of designating albumin scores you only want one of them and we find in as we're pulling this information out of epic as we're labs is and a lot of the information one of the things you learn is you work with multiple institutions is if you've seen one instance of epic you've seen one instance of epic and so as we're starting to think about this community and how we're pulling this information in this is a fact about the detail of our data that we have to be aware of in our communications others so that we can if we want to develop a common approach so we can get to that goal of data set of 10,000 patients that we're going to need to be able to reckon with those factors another data element I'll point out too that is emerging is radiomics so this is a slide from assam they'll knock who's one of our faculty as well and so in addition to the labs measures we're starting to take texture measures from the images and incorporate that back because he's learning that he can take this information that he gets about intensity distributions of the household units inside of here and relate that back to response of the target or the tumor and how it might respond so there's a there's really a very wealthy set of cofactors that we need to track if this is going to work so what Prout and this often happens when we start talking with people in the clinic right they want to get to using the data you know really care about how you got there they just want to use the data well it's all in epic or it's all in in our electron shoot it's all there it's just ready take it dump and it's ready in fact there are vendors who will advertise they can do that just upload your data and we're good not so much we find as we go through this that a lot of data sleuthing is required for us to understand what's happening with our data before we can start approaching the big data question so we have to know you know what data do we need to answer that question what are the relationships where is the data can we get at it Who am I gonna have to talk to what relationships are we gonna have to foster in order to be able to get to that data and then what are the vulnerabilities in the data that can undermine some of those conclusions so let's take a look at an example it's a very simple question what are the rates of survival and recurrence for patients with stage 3 nasopharynx cancer okay may seem like a like a you know it's a little specific not too much but head neck cancer how they do you treat them how do they do rate comes up that's interesting right you can get a statistical measure of what happens and this is this from a publication from you know from that other state in Cleveland Clinic there and they do this wonderful thing every couple of years they will publish survival curves for all their disease sites fantastic you don't see that very often but you notice one so this is from 1996 to 2012 56 patients they probably treated more than 56 patients and what this goes to is how hard it is to get to this data not it's not lack of trying it's just this is not an easy question to answer because there's a lot of pieces that you have to deal with so when you're looking at the rates first you want to make sure that you've got enough numbers to be able to really talk meaningfully about the rates how do I know they have stage three nasal pharynx cancer is there a line in the chart that says no there's not it may be difficult to even figure out if they're head and neck cancer patients so what how do we how is this designated well there are a couple of things that help you we use codes that are used for diagnosis codes they get associated with billing to get manually entered they don't always get entered correctly if you're looking at the diagnosis and staging you know so diagnosis it's heading it's nasopharynx cancer staging how bad is it that often shows up his free text and guess what happens when it's free text you may not be right it may not be entered in a consistent fashion so if you're going back and you're combing through all the records you know you've downloaded you've got all those text records you want to find them if they're not represented in a uniform fashion then it's going to be very difficult to be able to pull that back out and you don't know if it's complete information so we have to deal with all those problems survival and recurrence right that's our outcome that's our question so we go back to our treatment planning I know an awful lot about the DOS how they do survival recurrences the disease come back that informations recurrence shows up as free text as well not consistent not necessarily in the same place not necessarily expressed in the same way from one patient or one physician to another or from the same physician overtime periods survival how do we know that they survived they don't always come back right maybe they go to a different hospital so now we're starting to get into questions of how do we get information when people go somewhere else we're dealing with privacy and compliance for some of our researchers when they get to survival what they've resorted to is they they have people who are looking through facebook entries things like that they're looking for an online profile unfortunately that reveals one of the other issues that you have to deal with is bias because what you know the if you're looking at your data you have to understand your data details that's the data that you're able to get also reflect a bias right you're only going to find Facebook for people who are interested in being on Facebook what's that and still alive right and you vote in Chicago Yeah right yeah those nasty details you can't you know it's a big data you can't just say oh I got this download of data it must be right I can go make conclusions based on it you know the need to dig in and understand where it's gonna bite you in your analysis is really important so we spend a lot of time doing that so you know sometimes we're trying to approach this and build these systems we ask what's the productive conceptual framework how do we go about thinking about what we want to do with big data and radiation oncology but you want to get to the point where we're doing analysis we recognize we have to get a lot of diverse set of data to do that you know is data mining is a common way of thinking about it but the thing that that implies kind of like Marie Curie's pitchblende right she didn't make the uranium or the polonium she had to go figure out how to get it back out she had nothing to do with it with its creation in healthcare we are plus the creators and the consumers of our data so it doesn't just lie there being made in the physical process the mining is made in the same way over eons in the human process it varies day to day on how that data may be entered and sorry and it may vary across practices so for example tell you what data set we've got we're pulling information on BMI for our patients so height and weight we need to know and in one of our data sources we go back and pull it through and discover there for there's a 14-foot patient that shows up and every time he comes back he's 14 feet tall right and what does that mean when you dig into the data it means every time they pull up the chart they just hit the button and they never look and that's not a that's just a normal human thing but it means it's a detail you have to understand about your data and if going forward you want to be able to rely on that data so you can get to the point where you have that automated system we were talking about right we don't want to have to manually do this we want it to do it every time here are B there's a pattern showing up in your data you ought to go look then we need processes that are going to be pretty reliable and how that data shows up in the first place so it really has to go to something more like a farming model you know so a farmer is thinking about the yield of their production and everything they're doing how is it going to result in more you know the rojo is interesting if you think back to early farming right they scattered the seeds now we have industrial farming that simple concept of organizing things paves the way for being able to construct machines that can reduce the labor and expand your scale so it's very similar to what we're recognizing we have to do as we're dealing with our data and radiation oncology to make it useful the question of dirty day that comes up a lot in discussions and usually what happens people will represent that you don't need to worry about dirty data the problem you know with that perspective is as soon as your question is over here but a lot of times our questions down there in the tails so I want to find the patient where there's this set of cuff factors that resulted in a complication and we want to be really sure that's correct and so having noise in that data means that all the people upstream could do this you know they'll look at it and say big data is a waste of time because look at this this makes no sense so a lot of our questions are down here we have to organize that I'll give you an example so in another institution we polled we're able to pull data pulled all the toxicity scores so in radiation oncology we rank the scores so for a pneumonitis is it not so bad grade zero or no not bad at all grade zero you're dead grade five and then so it goes from zero to five in between so if you call that we were looking at skin toxicity because sometimes you deliver radiation and get skin toxicity there were several grade five skin toxicities all right come on that can't be true right so that's somebody there's no curation in that process there's nobody going back it's just their job enter a score they enter a number it's grade five okay I picked grade five but if you're automating your system that's gonna hurt you because those are the events you care about not the low grades that everybody has over here to high grades so we have to start building in to our clinical process these abilities to check that data and spelling things are funky so that we can different be able to use it in the way we want to later on so this points to a culture change and what we're having to do in radiation oncology with getting people to recognize the data we enter it's what we have to do to get on with the business of treating the patient today so historically people would enter diagnosis codes I gotta have something to bill them it may not be right I'm gonna enter it in and they do but then when we want to use that data you recognize it's got to be what we use to improve the patient of the care for the patients tomorrow and that's a real shift it means more time for what people have to do most of the things that we work on a lot is adoption of standards standards in practice how we do particular things and this is again another example of community science for what we do so we this becomes picking the wrong one this is a foundation for us here having these standards and making this routine and as we start having this in place then it becomes possible to make it routine to characterize our norms develop analytics that we can use and automate to improve things for our patients this becomes increasingly complex as you go up because there are more people involved but it raises the value one of the things we're doing again on the community side in May we're going to be having a conference on a practical big data workshop so we're doing is gathering together groups from radiation oncology actually its international so we have people from London and other ones coming who are in the process of building these systems themselves recognizing our lives would be easier if we had common standards for some of these key data elements that we need and use that common standard to be able to exchange that information this is part of what leads to the ontology around some of these items and so people are our community is in a position where people are very ready to jump in and do that because they're recognizing the potential of what can happen with the big data if we get to the point where we start developing those common standards so we can then get to the point where we automate construction of large data sets so to give you an example of of what that means in our practice so our physicians have historically entered the diagnosis and staging here as free text in the epic note so as we talked about this can there can be variability and what's entered how it appears at different time points you may get different values you don't really know here there's no connection to what we did to treat write two different databases they don't talk so they know so we've shifted over into a process where we use quantified fields in the same system that we use to treat the patient so now this every one of these values gets cross-checked against a standard reference only fixed values can be entered it has to be complete notice this tells us the stage this is grade two this is stage three we're talking about two different things right so that would be one of the problems with the free text approach this is now telling us what how bad the disease is this is telling you about the characteristics of the cells and the histology this is what we need in order to make that graph so by transitioning to this process we position ourselves to have better data in the long run how do we get there this wasn't about me doing this so this was the community side so this was some of our therapists who are real data geeks they're always coming through our databases to see how they can pull through pull out information to tell us about how we can make our processes better they're really enthusiastic about this our physicians who want to be able to use this data so they really drove that process so it's a sign of the community and big data that matters to us if we want to get to the point where we can analyze the data we first have to reach in and understand the details of what the problem is and then participate in the conversation so if the real stakeholders could drive the change that's going to make it better so we really can get to large data sets where things are automated here's another example so this is a task group that I chair with the American Association of physicists and medicine we take on the issue of structure names right so we have this great detailed information you know structures we know a lot about the dose it's all in our computer systems we we should be able to then say tell me about the last thousand patients what was the dose to their optic nerve and chiasm guess where it falls apart people don't aren't consistent about the way they name things so if you're and they may name things close so there may be several versions of optic nerve in there how do you know which is the right one if you're going to ask the computer to go in and mine all that data it has to know this one out this one out this one out this one's right if they're all similar how do you know if you're combining information from multiple institutions and you'd like to have an automated solution to gather that how do you know so one of the things that we've done here is brought together a community to be able to take on that question this is one of the largest task groups that our professional group has ever had actually with fifty seven stakeholder it's an international group and it spans large academic or small community vendor systems trials groups DICOM working group so all these people who are grappling with the same pain coming together saying it's been our interests to figure out a standard way of doing this even if we don't like what the standard is the important thing is to have a standard because it will let all of us go to the next step and so this is one of those examples of where community science is factoring into what we're able to do with big data and radiation oncology as we get to the point of pulling out the data it's tempting to think it's all about the technology but unless we come when we go to these discussions people talk about big data and they have a variety of technologies they use this must be what our issue is it's not our issue our issue is being able to get at the data because it's complex we have to negotiate with multiple groups to be able to access that data when we get it we've got to figure out how to clean it up so all these ETLs are really what Monica what we're going to be able to be successful in getting the data sense we need we have a database now that encompasses all of our patients so 18,000 patients we have a wide variety of information we're not we have more on some elements than others so this is a this is a process right so get the data use the data prove value repeat and we just keep doing that through all of these these data elements to be able to pull that information the RIT and some of the challenges can be no inconsistencies and how its laid out unstructured free texts that's really a tough one changes in time and the format quality in detail right so the data in this period of time was kind of odd this one is okay how do we spot that because we don't want to be thrown off so we've got for example doe symmetric information that for a period of 2 months in 2005 in one particular field is just whack and there was something going on with the way it was being transmitted but you have to look into the detail of that data to know it so that you don't try to factor it into your analysis so we work through all of these processes and then we process you know we pull it into a data Lake server this right now is a hundred seven gig so it's not huge but it's that racing it gets processed and cleaned up so some things that are in the fields are not the thing you want to know so for example I want to know if this is an iron or T field there isn't a field in the database that says this is an IO or T field you actually have to pull a couple of theses together to be able to do that the vendor system doesn't tell you so that kind of processing that we do to go back we look at timelines for our patients what was the ordering of what happened that timeline isn't in the system so we have to construct it from other data fields to be able to answer the question of what's happening for the patient over their treatment course timeline so all of that goes into the processing and then it ends up in a primary server which at the moment is about 13 gigs so again not huge but for us is huge because it's all the relationships and it's everything so approaches you know we look at database technology and what should we be using couple of things are key to benchmark when we're looking at the options bench market against clinically realistic data sets for clinically realistic questions and ask how they fit into the whole process right we want to automate this process so it doesn't do us any good to pick a database technology that's not going to integrate there so yes I'm a Luddite I am I am an SQL user but for example here there is a question this is a practical one so we want to iterate all of our treated fields so I was about a million realistic plans and courses tens of thousands and asked you know how many disease sites got treated by day and will do it in the worst possible way so will make it will make a crappy SQL command that's using an awful lot of outer joints so we'll just push it and say you know if we do that how long is it going to take but 1.5 seconds okay that's fine all right so do I need another technology that's going to not be easy to use as we integrate into analysis no so for now we're using this we're keeping an open mind as we're looking at other elements will there be other technologies that we use and that may emerge but so far in radiation oncology most of what we need doesn't the process of constructing these systems now we start down here and you think you're gonna go by one it's just not there yet and this is we've seen this happen with a lot of technologies and radiation oncology it's just not ready to the vendors haven't constructed a system so you have to somebody has to start and so we do and as we start demonstrating value then we're able to get more people participating on our end and the perception in our community that this is what while that we've got more bang for the buck up here even though with a relatively modest investment a number of people at some point the vendor start saying oh this is making sense and they start investing a lot more than we're able to do but there's still their solutions not going to have the bang for the buck that ours does we know eventually there's a crossover point where there are enough people doing it they've developed their into their independent solution there's a vended approach to it that will work eventually the bang for the buck goes in the other direction it just doesn't make sense for you to do it yourself but the field is really right here right now we know this is coming but not when how do we you know so in this process of going for us this starts with just a small number and then it progresses we done pretty well over the last 12 months now we have a larger community there doing this but each step of that cycle of get the data used the data proved value then we're able to get more people involved so after that first iteration here this was like first contact we we hadn't hit warp speed but we had got a lot of data now suddenly we were able to pull in some some other people who could help us manage the data from epic and so this keeps expanding as this community grows and we're able to add the data elements we want to be able to use this I know we're running short on time so I won't go too far into it we have now started using this data to develop automated approaches for analyzing it so this was a bit of research you did years ago we developed a software package that integrated c-sharp code and R to develop an algorithm to detect a dose response right across go too much on my lung dose and I get a toxicity I want to throw in an arbitrary set of data and have it look for that cross over can I figure that out in fact it worked out very well we benchmarked that with an SP RT dataset and it so we had 26 DV h metrics 11 structures pulled out over 8,000 options in a couple of in a few minutes and from that pulled out seven structures that were highlighted as being significant for a dose response so that we checked that well was somebody else's study turned out to be exactly the same in terms of what things were coming out so it was like we you know he develops as you could shake it and that would pop what you wanted instead of having to piece by piece going through and picking it so if there's real promise for what can happen if you organize your data to develop these automated solutions um we develop we use a variety of dashboards now to help our end users be able to get a perspective on the data and how things interact using tableau okay now real recently this we've developed a statistical approach to characterizing our dose distribution so in most treatment planning systems all you ever see is that green curve so I'm going to look at the dose to a parotid what fraction of the parotid got this much dose and so I know this much about it in your head right in our original picture that's avi in his head he's knowing what's high and what's low based on his experience can we draw that experience out of some of these head and put it on the screen now that we have all the data that we've aggregated so we can inform them of where they are now with respect to historical experience and the objectives they had and the answer is yes so now we have a dashboard that lets us look at each of these structures I can look at this curve this is telling me the median value and then confidence interval so I can see where this sits with respect to our historic experience so this inform our clinical practice right this is one of the for us the winds we have the data we could fold it back into clinical practice we don't want to just get the data we need to do something useful with it so this is one of the ways that we do that we can use that same information to start quantifying practices so if I go to hospital lay in hospital B and they both treat how do they compare can we have statistical metrics that can standardize no matter what you know what domain you're measuring in so it falls on zero to one schooler that characterizes your objective and your history for being able to make it and we can use that compare institutions compare histories how did we do early on how did we do later on so developing these actionable analytics that let us pull in the big data and then use it to guide what our choices is very important we're using this information now as I showed you the dashboards but this is letting us reach out to other clinics both to send them data to look at pooled data also to pull it back so one of our projects is taking a look at head neck data from multiple institutions and understanding practice norms so this all sets the basis for being able to do that so I'll slide you might take a cut right through almost 50/50 60/40 hpv-positive not right heavy smoking right do you do that with teen lead or is that with lack you do that routinely so you can get it yes so that's that's one of the factors that we're pulling in in this particular study that's pulled out so we can make that differentiation yes you're exactly right and HPV has emerged as an important factor visit that underscores though one of the reasons why we want to make this automated loop because how do you know it's HPV well early on some people started seeing a pattern and then they started gathering data and if we had been in the position of that'd be happening automatically and reliably then you'd be in the position for that automated algorithm to say hey look there's something happening over here we don't know what it is yet you know you're still going to have to do a real clinical trial and understand but you should look here because there's a pattern and that will help us spot it so I think that kind of thing could have helped us earlier on with the emergence of the understanding of the role of HPV and head and neck cancer will understand more that's one of our factors in this multi-institutional trial of head and neck of things that we're looking at for norms that will also help us understand Geographic factors so that's important to that question also great question thank you so farming really you know as we're needing to pull together a community that supports developing what we're doing so we have to get the nurses the physicians the administrators everybody to see there's value we have to close that loop a farming methodology is really our farming model it's better for expressing what we need to do it helps them understand you know why the variability kills us just typing in the free text you want to is convenient for you but it means you won't be able to get at the data you want later on so let's agree to standards that work for everybody we have to figure out what those key data mounts are and whether we can trust them what their veracity is the the volume that shows up you know for us in radiation oncology we're not talking about terabytes we get all of those data it's fitting into a few you know tens of gigabytes on hundred gigabytes and it doesn't come in that fast so velocity in the sense the traditional sense of how fast it's being read in to you isn't our issue on the other hand velocity in the analytics is so that guides our technology database choices and how we're going to do the analysis the physician wants to sit down type get the answer so whatever we need to do so that that analysis can happen rapidly that's really going to be the key value for us and then we need to demonstrate value for using that data that gives us the support to then go to the next step go for the next data element make the dataset bigger and increase the size of the community so that that's where we are with big data and radiation oncology I think I've run a bit over I'm sorry take any questions [Music] so tell me a bit about you know in the penile house so the things that we have run into with needing to recognizing we need which cofactor profiles and we need to understand the details of those data elements if we're going to be able to use the big data in a meaningful fashion are there analogs to the work that you all are do me or it just all comes out reliable and it's a you're in a blissful world collecting good data to begin with aside from you know what changes like to the epic interface to get more structured data and to validate the data have you been successful thinking about behavioral changes yes you participate like in clinical documentation improvement efforts in that sort of thing absolutely yeah so to measure the impact of that kind of to bring about the behavioral change great question and so yes so the place is where we can close the loop you know get the data use the data show the value that's the place where we can start to get the buy-in so for example in that transition in how the diagnosis and staging was entered which is necessary so that we can construct those survival curves right not have it be based on 50 but have it be based on a few thousand we measure now how frequently that happens that they enter that information in and that it's connected up to the course it's very high and it's very high because people have been able to connect believe in connecting the dots to be able to do that and it's it's important for us to connect them to make that happen a place where we're developing it this is another good one is patient reported outcomes so traditionally a physician will enter a toxicity so this patient this head/neck patient has xerostomia so I mean you've treated you've delivered a lot of radiation dose to the tumor it's got the parotid and the submandibular glands that means they're not producing as much saliva that goes to likelihood of aspiration pneumonia goes to problems with infection or your teeth begin to decay and your day teeth decay and you begin to have problems with infections so there's a lot that happens from the zero stoma you want to cut that down how do you know and so the physician has a scoring scale we talked about that toxicity zero to five of the xerostomia we know that but one of the other things we know is that the patient's perspective may tell you something different from the physicians perspective and the patient lives with that all the time not just their particular slice of time so we want to capture that information to how are we going to do that it's not a technology issues that's another place where it's tempting to think oh you just got to go by this vended system it'll do it all put it in the cloud and you can download it and you're all done not so much where's the data going to go you run into compliance real fast what does that data live is it behind our farm well is it somewhere else how much does it cost that's the patient even want to interact with this electronic system that you've given them to put it in what is your likelihood you know you can you bring them in and you say here sit down you give them the tablet you can do that well they'll fill it out what about when they go home you know a year later and they don't come back are they going to fill that out probably not so much who's going to talk with the patient and give them that tablet so all of these things we have to deal with not technical those are all the things that stand in the way of getting the data so we can ask the questions about it and so we've now taken us well over a year to get to that point we're starting to gather it now we have to close the loop and go get that data out of epic so either can then show it to the physicians to say it's worth a while that we did this because now we had data that we didn't have before and then we'll be able to measure compliance in increasing numbers of patients that take this and then we'll say well we can go do another survey about a different set of questions and so we'll be able to measure that increase in the volume of data but all of that's coming not because of meeting technical challenges but meeting challenges that are not technical absolutely the American Association for cancer research which is big on boa organization for cancer research participates in something about turning the tide against cancer sort of the representative so one of our major outputs the past year and a half is on patient-reported data it's a really incoming thing first of all it's respectful of patients and as you just said it provides data you don't get from anyplace else especially about toxicity and about acceptability of it various kinds of procedures advice there's a much longer activity called patients like me dot Oregon yes baby calm we started by the brother of a young man who developed the Gary disease ALS and it was pretty amazing ten years ago already how much information people were willing to share we're so worried about privacy confidentiality for a good reason but a lot of people especially patients those reseed in the background when they want to know more and they have a lot of questions that feel are not being addressed and sort of being dismissed by the fish-off professionals in health care so there's a lot going on in this space and first head-and-neck is a very personal space yes it's true but one example where this comes to food you're dealing with sexual function and where are you gonna ask the patient this question then you find why were you asking giving the patient this survey when they were sitting in the waiting room when everybody else right so all of those other issues could come up that you have to go to understanding the integrity of your data if you really want to know what it points to and how that is collected but as you've said it's going to be such a rich source of information and once we get a pathway that works for being able to collect this data and be able to get other Institute asking the same question so this is one of our one of our topics in this data workshop is what PR Oh should we use because if you ask one set of questions and I ask a different set of questions and they add we can't find the merged piece so we need the experts to find that consensus whereas our our speaker yesterday from New York genome Center at Columbia University talking about Big Data mm-hmm talking about accepting corrupted data or data a lot of inaccuracies if you can have a thousand times or a million times the volume of data then you can take the inaccuracies and judge that to fall in the noise and my longtime stuff is sort of Google approach for certain kinds of questions it seems to be reasonably productive it comes back to the question of whether you have a hypothesis driven analysis or you're waiting for the data to speak to you any videos for them yeah because he mentioned that works only well for different specific issues on the population level you cannot not narrow down back to specific patient's because this is very important of course this is all about individual patient care in the end the clinic in the analysis you're spreading it to the whole country you can have a big data yeah but the people go okay so why don't you ask you a question directly go ahead all right well then thank you again