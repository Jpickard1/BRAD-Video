so normally toddler confirmed thanks chris you can't get away with much in this crowd in this audience here so um the uh all right we're going to make that the topic so normally marcy introduces the speaker but i thought since marcy isn't here i wanted to go ahead and sort of introduce myself not that i need to introduce myself but i want to introduce sort of tools and technologies again this is the first presentation for this uh this year we took a little break over the summer so you could kind of break your pizza habit um but i also wanted to uh just kind of look at a few uh statistics um i kind of went back and looked i went how long has this been going on uh we've been doing tools and technology and i did not count pizzas by the way i should have but that was gonna be a little harder stat to get at um this was actually started um way back in 2005 which doesn't seem that long ago but if you actually look at calendars are flipping through the years it's been going on for a while and danny rhodes gave the first presentation january 5th i think of of 2005 and a lot of this started because of ncibi and this was really the originator it was a way that ncibi did for presenting new technologies and trying to do a little more outreach um and ncibi um has sort of ended transmitted has begun and some other things going on but we kept the tools and technologies presentation because it really does give a chance for people to see some new things that are out there it's a very diverse set of topics um there have been 220 presentations in all they are all archived and available to watch so alex deserves a round of applause [Applause] because other than a couple times when zach or aaron or someone else's health with alex has been here and sort of setting up and recording and has been here for all of these um so it's pretty amazing that we have that many available that's the link if you want to go back and look at the diverse topics you can kind of search through by keyword and other things um and and just so you know some personal uh egotistical statements this is actually my seventh presentation uh on a unique topic um and and it is the 221st presentation therefore i have given 3.16742 of the tools and tech presentations um and uh dr element isn't here but he's always and he will want to point this out that whenever you give a presentation to think about significant figures computers spit out very long stretches of uh decimal places which aren't really valid so think about significant figures therefore i've only given three percent of the talks jim you didn't figure your rank among all presenters i did okay never mind thanks god thank you for that segway um it's actually there have been um of the 228 presentations there have been 200 and i didn't put it in the slides i did it later 247 total presenters out of 220 presentations of course being in bioinformatics and thinking about math and numbers and statistics i couldn't stop there so i had to kind of go through and do this um there are 168 unique presenters uh 247 total presenters and here is the rank order i only tailed it down to the beginning um but uh terry weymouth wins [Music] yeah you can have that one either side terry weymouth has given nine tools and technologies presentations rich has given seven i have now tied him for second place uh alex at five glenn five zack's given five aaron four uh man hong dai has given five so we had quite a list of presenters but the tale goes out quite a long ways we have a lot of people that have given only one talk and we i think that that shows both the breadth and um span of the topics that we've covered um and i did a few statistics over there because excel lets me do silly statistics okay today though the presentation itself um is oh and by the way for those that uh i didn't do marcy's standard opening this is tools in tech they're it is being recorded and we have people uh live uh a few uh signed in and listening from a distance uh i'm jim cavicolli and there's probably not too many people in the room that don't know me um i'm assistant professor here i'm also the director of the bioinformatics corps and i've been doing uh sequencing and dna sequence analysis since before it was called bioinformatics that explains the gray and the thinning hair and everything else so today i want to talk about a kind of a neat topic in the last year or so there has been some technology changes and advancements that really made sequencing small genomes uh a kind of a game changer in fact how easy and efficient it is to do this it's not that it was incredibly hard before there's a lot of cloning and and sequencing and other things and so i want to talk today about both the uh the technology and some of the bioinformatics involved in sequencing assembling and closing small bacterial or viral genomes why is this important to do um most bacteria and viruses in genbank if you look back five or six years ago they were represented by single sequences being this is what e coli looks like or this is what uh homophilus looks like and and we didn't have a lot of speciation or variation or strain there were some it was beginning in certain interest areas to do this um but bacteria evolve quite rapidly and there's a lot of lateral gene transmission so the word although it implies different things in different terms the promiscuity of gene transfer among bacteria is quite high and so what you define as a species or a strain can easily have a gene or two or four from something else that it was with in an infection something else it coexists with in nature and so the ability to change these genes around and insert them into the genome is actually quite high so the ability to rapidly and completely sequence a genome would improve discovery and maybe even epidemiology tracking outbreaks identifying drug resistance and understanding the metabolism of a given bacteria i'm not going to touch on today metagenomics or microbiome where you have a whole community of organisms that still remains a little bit of a problem but i really want to get at is singling sequencing and an isolated organism how many people here have heard of the pacific biosciences or the pack biosequencer okay so i will go into a great deal of detail i've got some pretty pictures here um but the the pack bio is uh called smrt and that does not mean it's smart it just says single molecule real-time uh sequencer and it records and identifies fluorescently tagged bases added by a polymerase which is bound to a well and the dna template circulates through this polymerase one base at a time and it actually reads the incorporation of these by real-time laser excitation you only get about 40 000 molecules per flow cell and i say only because in comparison with things like the alumina platform uh which is sequencing hundreds of millions of of reeds um this is actually relatively small however um and the single pass still has a significant error rate somewhere around 11 or 12 percent yes i didn't say point 11 or 0.12 it is 11 or 12 on a single pass however because of the length of the molecules no i'll get to that because of the length of the molecules has been increasing with the changes in chemistry we can now sequence um to very high fidelity molecules in the two to three kd range um and anything under that it has extremely high fidelity and so um the length of the molecule sequenced by the pak bio machine is also it's the only platform out there right now that's not in beta that will sequence these very long molecules and i'll get to some of the statistics here in a moment right now the average library insert size is running around 10 kilobases so 10kb um with an averaging sequencing length somewhere between three and five and five and seven depending on certain library parameters that you can get for a single sequence from a single molecule so how is this uh the libraries are constructed this way a given dna sample and by the way uh it does not have to be a cloned sample you can take dna freshly isolated from an organism without having to sub clone without having to do any kind of amplification if you can get enough dna you can sequence the dna directly the dna is fragmented down to a certain library size and this is a question of how you want to sequence this if you go smaller you get higher fidelity if you go longer you have the ability to scaffold um and assemble long sequences that that span um the repetitive regions and that's one of the hard points to get past with illumina or any of this short sequence reads is anything that's repetitive sequence beyond the length of the reed you really can't just sell them uniquely so they do end repair and then they actually ligate these dumbbell shaped adapters onto each end of the molecule and these each have primer locations on them uh and then and what happens is is the polymerase uh the the dna is added to the wells um and i'm not sure the exact nature of this i actually haven't been in the lab and do this but the dna becomes incorporated or bound to the polymerase and the way it is but these uh wave guide these are called zero mode waveguide cells they're actually a little metal cylinder that's about 50 nanometers across that has a window at the bottom that allows the laser light to be to excite the molecule and record the fluorescence um and then because of the size and the exclusion of this you either get zero or one molecules per well you can't have two you can't have two polymerases and you can't have two molecules in a well and base almost exclusively on size so this is a little bit more another cartoon showing how this is bound what happens is is that as the polymerase processes in real time so i think the the recording is about um i think it's about three bases per second that are incorporated i'm not sure the exact rate of this polymerase um but what's happening is the bases that are are being added to the flow cell actually have the fluorescent tag on the on the terminal phosphate and when the pyrophosphate is cleaved to incorporate them in here the release of this then causes the ability to fluoresce um and that that base is detected and so as this is going in real time flashing through um you can actually see this and so if i i'm going to attempt this to see if this will work i don't know if everyone at home will get this but i'm going to try oops wow that's really you know what i think for sake of time i'm not going to there's a if i'll send these slides out you can look at it you can actually um this is a youtube video that actually shows the whole incorporation process it's about it's about five minutes long and i really don't want to go through the whole thing but it is in here what happens is the time in which it takes for this pulse uh to uh both occur and how long it stays around gives some uh measure of amount of time that it took to incorporate that base and so the duration of the pulse is actually related to the type of base being added and that becomes important for some base modification stuff i'll talk about in a minute but it also allows you to get some idea of processivity and number of times a base is incorporated for homopolymer stretches as well so the pac bio platform itself is ideal for a relatively small number of reads around um a length eight to ten kilobases at the moment you do get some longer reads the tail is quite long um we've seen reads out in the 30 kilobase range the accuracy isn't incredibly high but you can if you're getting something that's 10kb long and you can get 30 out of it you can get a pretty accurate 10kb read um and all this information including the qualities is used uh in the assembly you get about 40 000 molecules as i've said really the recent upgrades to the chemistry um which allows for a longer-lived polymerase in part um and the other the other features would be uh that you're getting a little cleaner incorporation of the nucleotides and so that is um that is going on um that chemistry change occurred in around april of this year april may so what happens is in a cartoony sense here the dna fragments are capped and what we get is the ability to read this transcript because we know what the caps are we know what the primers are and so every time it reads through so if you follow me and it's reading reading reading as it goes around the block because the polymerase will actually go around those dumbbells and come back out the other side so you sequence both strands and the incorporation of the errors even though it's a high error rate is is relatively random um and so you you basically can auto correct by sequencing over that same insert multiple times and in this case they call these reads of insert because they'll go through and you get the whole thing as a single molecule remember one molecule in a well so they know exactly where that molecule is and now we get this read this read that read as many times around so right now you get two full reads of insert and a partial one at this point the polymerase dies we get no more data out of it and this happens in part because proteins have a certain half-life in here and you're hitting with a uv laser about 20 times a second so eventually you're going to break down the protein but here is a graph of some actual data um this this is from an experiment that was done fairly recently probably one of the most recent ones this was actually an e coli genome and it was done to test the platform by a researcher here in the med school and you can see out here around 30 000 base pairs these are the longest reads there was actually one around 35 but the majority of the reads are coming in somewhere in this 5-10 kb range although it's quite a distribution and you get some relatively shorter ones that that sort of die off early but the median distance between these adapters when it measures it the live this gives us an idea of how big the libraries are we're going from somewhere between five and ten thousand with the majority of them right around ten thousand this is ten to the fourth and is not readable on this in this graphic and then this sub read or this read of insert length shows that most of our reads of insert are actually peaking somewhere in this range we've got a little bit of a bump here and some and this this uh is average but most of our reads are falling in this five to 10 kb range uh again so it's actually quite good data um and we've been actually increasing the size and with reads that long we can actually do an assembly so that slide leads to this one uh which is actually showing this is the coverage across um this actually isn't e coli this is a klebsiella genome we were sequencing um that was 5.2 kilobases long and between the pack biosequencing and another lab that was a collaborator had done some other illumina sequencing they merged the assembly and in a span of about a month closed the genome and submitted genbank wrote the note and got it accepted um so they published this drug-resistant strain of klebsiella that had been in atcc you could order it but nobody ever sequenced it and so in a span of just over a month uh they were able to do that and this was right about the time that the technology was changing and we ended up using three flow cells to get this data so three flow cells about 100 not quite 120 000 about 110 000 reads um that it took to close that and the coverage is actually pretty good so we get pretty even coverage even though it looks kind of um jagged you get somewhere a little north of 50 x coverage across the whole genome with those long reads so we wanted to see what could be done with a single flow cell because the company has been saying and other people have been reporting that a single flow cell you can close a genome and so we actually said all right let's see what we can do and we ended up with five contigs for this e coli genome and it's it's a fairly standard e coli the sequence is out there already so this was more of a test of what can you do um and we don't use any reference to guide this this was with this was de novo assembly by the pack bio assembler there's there is a caveat here the pack bio uh data comes out in an hd5 format that contains a movie and a lot of quality scores and it's not amenable to a lot of other software tools so you're not going to use bwa or bowtie on the raw data um you can create these consensus sequences out of it to use uh in other other assembly modes but this is the assembled um the solera it's based on the solara symbol called blazer and that's that's its basic uh uh mapper um here was uh just under five uh megabases of genome assembled at about 40x coverage uh 35 to 40x coverage here and then there were these other contigs that showed up as well um and it turns out when and i don't have all the blast scores here it turns out that is the complete e coli genome and this particular one had four plasmids of various sizes and so from this isolate you were able to identify the different plasmids as well um and they're they're present at this one we're not sure is actually a plasma that's one thing he's still checking to see uh but the others we actually matched plasmids that were known to exist um in in e coli and so in that regard we were able to get that assembly and get five million bases um linearly assembled with no gaps from a single flow cell which i think is kind of amazing it's one of the reasons i chose to present this today is that it's really um it's come a long way since even a couple years ago with being able to assemble this data um likewise this this actually spans last spring somewhere around the april time frame and we had a couple of flow cells in the old chemistry and a flow cell or two in the new chemistry to test things out um but this was a novel um providencia stewart eye genome it's a urinary tract infection organism and this actually represents three flow cells kind of all glued together you can actually merge the data fairly easily uh in this case we got we expected the genome to be about 4.2 to 4.3 uh megabases that was predicted based on how close it was to everything else in the in the the tree um and we got this this contig zero as it's called which was just under four megabases like 3.99 we're like well maybe it's smaller maybe not so we also got these others and we thought well maybe plasmids but let's investigate what comes out of this so we the the drawing on some actually older uh style of genome comparisons it reminded me of my early days um when we actually did dot plots uh to look at comparisons between organisms and from homologous regions so if we compare on the x-axis um out here is our uh experimental organism and on the wat on the y-axis is this um mrsn2154 it's another strain of providencia that was actually sequenced and it was assumed that this would be very close to that reference and in fact it is the start point is kind of immaterial because the circular genome could start at any point this just happens to be where our genome starts here and it's actually the tail end of that organism um and then we've got here but there's certain gaps uh where you've got uh dna that's present in this organism that doesn't match anything in the reference or could be rearranged a very large uh kind of insertion here there's something missing or deletion in the experimental strain uh and then these other insertion points up here uh but it matched fairly well so we wanted to see what these other contigs actually looked like um contig 1 was actually fairly long about almost 380 kilobases and it turns out it matches this mrsn strain right around this 1.8 to 2 megabase or 2.2 megabase mark and if we look around 1.8 to 2 megabase there's this giant deletion or what appears to be a deletion in our assembled contact zero the main uh the main strain so sure enough we're actually trying to figure out the orientation in the exact position but it looks like this guy probably fits here and i'll show you why it didn't assemble in a moment that even though this platform is really good there are still some pitfalls that are just natural biology differences so what about the other context just to kind of finish this off um it turned out that this one called contag3 actually mapped back to contag zero except for some gap in the middle so something kept them apart we don't know if it's a novel gene or not this is still kind of under exploration but it just it kind of mapped right back to it so this we assume is conjugate 3 really belongs in the genome someplace and is fairly redundant this little bit here is probably new we're just not sure what it is yet we know it we know we know what the gene is and it's actually not um a probably density gene it's something that's come in from somebody else uh we think it's proteus or something in along that line um and just to make sure that it wasn't uh like a plasmid or something we actually test it against itself so one thing that's good about dot plots is that you can actually blast a sequence against itself and see how well it aligns to see if there's any duplications and in this case uh in this particular um guide it was nothing it was just that single line it was itself it's unique oh and by the way context four and five those other little guys out there there's no match to to known providencia uh strains whatsoever uh the actual genomes it turns out that um contig-4 if i do a dot plot and blast it against itself you get these wonderful little corners um that are indicative of the fact that that genome really is circular um and that's exactly what it would look like if you had a circular genome and so when we do check it and see it is true those last um in this case it's about six or i don't know what is maybe 10kb overlaps and if you trim that and circularize it you get a perfect plasmid and it does map to one of the known plasmids it's similar it's not identical there's been some changes in it and likewise contig 5 was a little bit smaller this was about 50 kb and about 10 kb on each end was actually overlapping and again so we have two circular plasmids um and they contain in fact this large one contains the gene they're very much interested in which is a urease that they've been looking for that doesn't exist in the genome so it's picked up at least one urease um by this plasmid okay so i'm gonna stop there this is this is sort of the the detective work that goes on afterwards if you get a perfect genome great but there's going to be some detective work to identify what are the gene differences and that's what makes it so powerful is within a span of a couple weeks you can get all this data in which you can then go back and test make pcr primers uh verify things there are a couple of tools one i did not mention here that allows you to actually take a genome like this that we've created and submit it and it will actually uh map it against known you tell it what you think it's close to and it will go in and actually re-annotate all the genes and boundaries um so you don't have to do complete or prediction uh but you can actually map it to the gnome ones and then go back and test the validity of those it speeds up that process a lot okay so i'm going to jump to one other feature of that makes a pac-bio platform really really interesting um and that is actually because if you're using unadulterated dna if it hasn't been amplified if it's not been cloned and sub-cloned in systems you can actually get a sense of the modification to bases that are present on your dna because the polymerase will pause differently and will take longer or shorter to incorporate nucleotides when a base is modified and i'll show you an example here that they this comes from the pack biocite if if the adenosine is methylated there's this long pause before the next signal comes out a normal adenine or adenosine that's been uh incorporated will give a pulse that is pretty much in line with the other uh time time sinks here but a methylated adenosine and um this occurs for other bases as well cytosine methylation uh and certain other base modifications that are shown down here so the ones that they are actually publishing on their site is 5-methylc hydroxymethyl i'm not sure what fc is i wouldn't expect it to be fluoro anything so i have to look into a couple of these others i don't recognize 6-methyl 4-methylcytosine there's an oxyguanacean and oxyadenine as well and all of these have different patterns of incorporation and because the analysis software in here is actually looking at the movie in real time it is actually can measure this time and see how often it occurs and if it occurs in repetitive patterns which i found to be really fascinating um please note if you amplify like somebody wanted to look at methylation state in a gene but they were going to amplify it up with a bunch of pcr primers you can uh pcr does not incorporate modified bases normally i mean there may be ways to do it i didn't research this deeply but if you have normally a normal pcr mix you won't get incorporation of the same 6-methyl adenine there you'll just get so you'll lose that signal if you're using any kind of modification so the output from this so first thing you have to do is you have to if it's an unknown organism you have to actually create the genome first or you have to have a reference genome that you're going to align this to and then you can take the reads from the dna and align them to the reference using uh the software tools that are part of the pac bio suite here for um for modification and motif detection and it takes about for the e coli we did it took about a it's about an eight or ten hour run it's not it's not a short period of time because it's got to go back and map and and analyze all the data but it's not too bad um and then it will give you these these great colorful outputs that i'm still learning to interpret um but but basically what they're showing you is for certain patterns in this case g-a-t-c in which the a and we've lost the print font here but in which the a has been methylated you get this interesting pattern of outlier of of the behavior that's really uh standing out and then there's another one c followed by five uh five a's four a's um and then another c uh that's another one that has a pattern that's distinct from from the others that are here and it then summarizes these graphs into a nice table which i found to be much more readable um in this case gatc in which the a has is a six methyl a actually it cov it uncovered um sixty thousand motifs that it detected this pattern in out of 60 600 that it found in the genome so 99.8 percent of that every time that gatc is there it's not it's got a six methylate um and in this case it's 99.8 also for the c aaa with the last a before the c being methylated and both of these patterns the first one explicitly um this one is less well-known and i haven't been able to find any literature on it but in this case the gatc is part of a restriction class in bacteria where they methylate their own genome so that any kind of invading phage or other organism can be subjected to restriction digest of invading dna where and it won't it won't degrade its own dna because the methylation is resistant um and so they methylate these patterns and then they develop a cleavage system to cleave that pattern when it's not methylated and so it's so it's basically an immune response if you will uh in bacteria and it's called a restriction class uh base modification the reason we did this was actually we did the klebsiella genome i showed at the very beginning they completed this they published it and within i don't know a week of the publication going out got a call from uh rich roberts um who is i don't know if he's he's either senior scientist or ceo from new england bio labs um and i didn't realize that nobel laureate um i don't keep up with all of them not that many but i really just don't keep up with them who have said um do you you know we'd like to see the methylation data uh because this is really important and mike bachman said we didn't run it you know and i thought that was the end of it he's like no no you have the data you just haven't all you have to do is run this analysis and then it came back to me so how much is it going to cost i said i don't know maybe an hour of my time we we set up to do it uh and the data came out within eight hours of starting the ron um if since sent it back to him we haven't heard back yet we just sent it in last week but they were they're looking for new restriction class patterns here or things for new enzymes and things to discover and et cetera so his point was we want to start making this mandatory when you submit bacterial genomes that have packed biosequence data that you start submitting these methylation patterns because the data's there you know you've discovered it it's just that you're not publishing it um so we may start doing this as more of a standard thing to start to look at these classes is it possible that the motif is difficult for the polymerase to put together and that introduces the delay i don't know it could be something about the the secondary structure there but since it's adding one base at a time you're getting that delay at every point in that in that phase and this is something that if if you were a study if you'd studied restriction if i had studied these restriction class endonucleases this is a known pattern uh it's a very common one so it's it's possible that you're discovering what's really there i don't know if it's an artifact we almost have to take an organism that has that pattern and not that class of restriction and see if the methylation was there pacquiao's done a fair bit of work on this i just haven't this is fairly new to me um i guess it would always be the same probably yeah yeah it's not really you're not it's too short to be any kind of hairpin structure or anything else in the in the dna itself it's too short four nucleotides is not long enough um and there's nothing about the pattern on any side these other ones down here that it finds at a very much lower level um at some point there's a spurious noise where you're finding motifs and you've got some of this and it's not it's not high enough so their cutoff is usually around this this um modification this qv value and they don't explain that well under 30 um they sort of say yeah noise um and the longer you go in the motif the more likely they are finding a spurious event as well so as those kind of converge around the lower quality and the longer motifs they're probably less likely to be real um that's what pec bio claims anyways so okay yeah i guess about the nitty-gritty because most of this is written from a movie it's mostly using um pac-bio software to analyze this right so when they go from the the movie to sort of these tables and figures use it straight to these tables of figures are can you actually get sort of like maybe a semi-raw readout of the the time between nucleotides and i mean do they go straight to say oh this is methylated or do they actually provide you the timing between the nucleotides and then you could derive your own statistics from that the current software you don't get those intermediate files in their web portal yeah um they have sort of raw data and they've got a series of intermediates but they're not really intermediates they're mostly these graphics that have already been derived um so but there is there are there's a whole underlying tier of command line uh programs a lot of python um and scripts that they actually combine together in these pipelines and so you can go into the individual ones and get that data out okay um it's just that it's it's not it's not easy to do in the you'd have to really you almost have to read the code their documentation on those uh subprograms is is almost non-existent right but that is not but that is something that can be done yeah and one of the things you know like go back to like complete genomics one of the issues that you know there was was that it was sort of really hard to analyze the raw data you had to deal with their sort of uh you know their varying calls and their statistics and there wasn't a lot of bioinformatics software that was developed around this as you have with illumina yeah see where that goes don't have the bioinformatics support it's sort of people like to tinker with stuff yes and and the pec bio software is more black box than i would like uh partly because it's the lack of good documentation um this this is a company that did a really good job of developing the technical platform um and the software and and this is a this is an adage that i've i've i've stood on this for the last 15 years that companies that build hardware should not write their own software and software companies should not build hardware i mean there's just the the twain shall never meet and they don't do it well um it's just it's it's a frustrating point because they're really good the platform itself to get this data is is really really nice there's some little glitchy stuff in it but it works really well there's software on the other hand we've run a lot of wrestling matches with trying to get it to work right uh it breaks it odd places sometimes or those or they'll say oh yeah but you can do that at the command line and the program file names are all different that you really have to sort of like read their own code so these are biologicians who have the code not software engineers so this makes sense point take it i i know i i call them the kettle black here it's like looking at my own code but yeah it it it's uh it is like that these i mean um i actually have a friend of mine who's a a software developer engineer that writes code for a living and and he when he took a look at the website i showed him for this um and and i'm sorry back by putting this on record um he said it was he referred to his dog food code because after you've after as an engineer as you've written code and it just gives you a like a debug report and you get used to it but pretty soon you get used to eating your own dog food and you don't notice anything wrong with the software um and so a lot of the stuff was released because there's there's just lack of good user interface and a few points and things like that but they're making improvements um and the underlying stuff is there the other thing which i am i am patiently waiting for is that this summer um at ismb gene myers gave a presentation to keynote and in it he talked a lot about pack bio and he mentioned a lot of software that was going to come out of his shop this fall and it's fall and they're not done yet but they actually specifically wrote things for putting different software applications out there for analyzing this type of data so i'm hopeful that now with some competition it would be like you know no longer you have to use api sequential you know there's all these other things that you can now use but it's i think the data is really cool for this kind of niche work so you mentioned a web portal does that mean you're submitting data for some of these analyses to their place no they created um their portal is a combination of their python code a web interface and a mysql database and so it knows where the raw data files are and you should go into this portal and you have to load your data to pick your applications it's long run locally yeah we're actually in the process right now it's run out of the sequencing core on on one of the on their storage and our server in the bioinformatics core um pretty soon that's going we're going to move that apart and set up a virtual machine that will actually use flux in the background because the number of process i can't throw enough processors at this and more people are using it but it is more locally we don't have to send data out um we do have a problem um with the way it's set up again hardware people that wrote software um their level of group control and access is sort of like um nobody one person everybody you know there's not a lot of levels of group control and so there's stuff in there where since i have view of everybody um and that's how they set it up i can see projects that we're not even working on and i can download that data and there's no restrictions on it whatsoever so we're gonna we're trying to get to a better level granularity of this new virtual machine and some other stuff we're doing um but right now we're running on the honor system that we're trying to create user names for a lab and let the lab groups see only their stuff but some of us still have to see everything in order to manage the system it's it's not anybody doing clinical samples no no there's actually been um to my knowledge no human samples other than a single gene amplicon that were run and it was just a single gene um probably not hip identifiable at that point um and you know we do know who can see it the problem is a large number of people can see it that's not what would be good for any kind of hipaa or clinical things but we do know how many and we know who they are it's just too many okay um so the other interesting thing is that um actually running a sample through is about 450 460 bucks to actually just get it through and get the data and we put in about two to three hours to get the assembly done and basic annotation so it's really not that expensive to run a sample through if you have a new isolator strain you're probably talking between you know seven eight hundred dollars per sample to get full sequence assembly um for a strain of interest um so i just throw that out there so people have some idea of what the dollars are like for that um and i think i'll stop there and take other questions and stop [Applause] can thanks a you can you you can detect the modification when you can talk based on it signals uh or you also mention many kind of modifications any distinct difference between all these kind of modifications yeah there must be although they don't go into great detail on their website i think what they've done is they've looked at um training sets where they've done that kind of modification to to dna and then run it through and looked at the signal processing part of it and there must be a way to distinguish between certain signals uh you know so perhaps if a delay is of a certain type and a duration then it consistently is a 5-methyl cytosine whereas a 4-methyl cytosine has either a shorter or longer and there must be something separate they don't go into great detail on their website as to how i did have a request from a researcher here on campus they went ahead and modified some nucleosides for rna incorporation and they wanted to run pack bio and pack by was interested in doing this but it's been like eight months and they haven't heard back they said can anybody else help us and i went no you know because right now there's nobody that i know of here that could actually tease apart that signal processing i pointed him to fan man and i pointed him a couple other people um that could could possibly do this um but right now we're having to rely again on the black box of whatever pec bio has said that this is a you know a 5-methyl cytosine or a 6-methyl adenine or adenosine another question is in order to get a reliable sequence of certain samples uh how many food processes you have to run for each flow cells can you rephrase that or what i mean is like at the very beginning we explained the uh uh the sequence process he said like it's it's relatively going over the circle again again right to fix the error rates how to fix the error so uh how many full pauses you have to run for this full cycles you have to run this we put our filter at three full passes primarily by default it's one full pass and i always change that i mean but three full passes gets you probably about 95 and a half percent accuracy and otherwise you're beginning to depending on how big your your fragments are that is plenty accurate if you have 30x coverage across the genome because if you're stacking up 30 high and you've got 95 accuracy you will have some base mismatches but you also get much larger um read length um if you want high accuracy we've done some very high filtering where we've gone as high as the website will again a hard-coded feature that doesn't need to be there website allows you to only go to a maximum of 10 passes i don't know why it's kind of arbitrary um but if you go down into the command line software you can change that number so we've got as high as 25 passes where that was the median and said we only want data that's gone around at least 25 times and the accuracy didn't improve after a certain point what's that was it um it depends on the sequence and maybe there is a reason why there's a 10 because it really doesn't matter after that no um by mathematics and statistics the air rate should continue to improve at least asymptotically but what we found is that um the amount of pcr errors that went into making the amplicons built up far before that um we were trying to get down to 0.1 percent error pack bows claims that at the highest rate you get down to about 0.5 error and between 0.1 and 0.5 percent and we couldn't get anywhere below about 0.5 and in fact i would i'd hesitate to go less than one percent error because of pcr incorporation um i have some unpublished data from uh sammy malik actually brian parkin um where we looked at they made amplicons across a a tumor gene they were interested in and the actually the most error came in the primers they bought we were seeing at certain bases in the primers we were seeing two and a half to four percent uh error of incorporation of base the same base over and over again so you were at you were seeing a c at this position and it's the third position of the sequence wait a minute that's not the gene that's the primer um and so after pcr incorporation either it's the pcr misincorporating always at that base or the primers you bought are dirty so i mean you could use this to really evaluate very low levels of error in things as well because of the short sequences like that you can easily get 10 on that short sequence we were seeing a median number of passes at 25 26 something like that that's why i set it as high i want to say okay what's the top half look like and it didn't get any better so jim help you here so you mentioned that we're going to implement this on flux which the battle flux is getting the data and raw data over there and getting it back is that a problem no these are fairly small um they're in the megabyte range uh because you're only dealing with 40 000 sequences um so you're not dealing with anywhere near the file size um they're they're uh five to twenty megs depending on how much how many flow cells you're mixing together and things like that so no and and moving ten mags not an issue uh have you done rna yet we have not um i think people have run it i just don't know we've not had anybody actually run straight up rna on it to see because if by default it's a dna polymerase that's in there um and i just don't know if anybody's run if you have to change the if you if they've got a flow cell with different polymerases on there to actually handle the rna yeah i think people have done it because i've seen some things out there but i have not really really studied it it may be an interesting way to look at it okay all right and the answer thank you five formal rules