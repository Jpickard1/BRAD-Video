so leading up to this symposium um and to encourage our students to get more involved we hosted a diversity equity and inclusion data challenge event and several students worked individually or in groups and um submitted to their projects and the winners were just determined yesterday so right now i'm going to hand it over to my colleague dr christina matreya and she's going to say a little bit about these day-to-day challenges and announce the winners before lunch awesome i won't keep you long from lunch i know i know how that is the but i want to do justice to the participants because these were great submissions we had the ba challenge and it was kind of a long process of thinking and then a talk putting it together and it happened during march 7 to 9. that's when the participants worked on the challenge they had very short time and they did great stuff during that time so if i go to the next time the timeline was on february 20 21st we announced the challenge on february 25 25 at 5 p.m we actually closed the sign up so that's why we don't have a lot of participants but we do have good quality participants on march 7. the challenge details were provided and on march 9 at midnight they they had to submit the report so there were two options option one was a team challenge teams of three we had teams of two as well and that was looking uh to score university of michigan disease related dissertation based on the eye criteria and the participants had to process text the text of 9251 documents the platform that they they uh used was offered by proquest so they have a framework where the participants logged in and they accessed the data and they did analysis uh there there were three prices offered first price 75 dollars amazon gift card second price 50 and third price 25 and the prices and the data computing were offered uh again by a proquest so this uh was set up to make people think of how to look for di related uh terms in the text of any manuscript but here we focused on dissertations and option two was an individual challenge to investigate an expression the gene expression omnibus database and look for data sets that are biased relative to relative to the relative to the us population using vi criteria like sex ethnicity ancestry and other criteria like that gene expression omnibus is a large database that contains data set of gene expression and the first price here again is 75 second price fifty dollars enterprise twenty five dollars offered by our department from uh our um uh iraq and faculty allies grant however we also have a sponsorship by uh at beta bioinformatics who offered an internship interview for the first prize and one free analysis on one of their tools that does battle analysis for the second prize and then what we did we got the sign up we got three teams just enough for the for the first challenge for the team challenge and eight individuals for the individual challenge we got the submissions and the submission was a report describing the analysis and the house all the all the teams and all the all the individuals did a great uh and we had all three teams submit the report and just five individuals submitted their report too so there were some that didn't meet at the time uh didn't submit a report at the end from the individual chance we had the panel of judges who might thank very much dr alvin raul dr g lu jeremy who's here uh dr schroeder i and austin meetings from uh from proquest were the ones that looked at this and evaluated the reports so just to talk a bit about what the participants did so the first prize from the team challenge for the team challenge goes to the uh team formed by catherine barnier jake schwartz and oligar al alj and the project highlight and their phd and master students as you see here in our department and the project highlights for these first prizes that they developed the word bank using online resources and personal experience that they could use to to do the scoring they use the normalized count score for the di related terms and then because they thought that's not objective enough they trained a neural network to evaluate the bi status of the words and i'm going to talk a little bit more about this uh in a second i want to uh mention the project highlights for the second prize which uh is uh given to the team formed by uh ford hannah and kevin yang and then they selected a set of domain-specific terms for the three domains for diversity equity and inclusion and they developed the score for diversity minus equity gap so for the diversity equity gap and this is the formula that they use they use a term frequency uh inverse document frequency uh scoring method and they did the difference between those for equity and diversity and they scored the dissertation based on that they also mentioned and had a nice discussion about the potential application for grant evaluation for instance for the third prize christopher castro and brad krohn again uh bioinformatics students here they uh the project highlights where they selected a set of di terms and calculated that again the term frequency uh invert document frequency metric and then if i could see my slide they checked the title the abstract and the full text so that was that was very interesting because none of the other teams looked at all of them they just looked at the full text they looked at the title and abstract and they also put a different weight they down weight in the full text because if you have the item in the title or in the abstract is more important and the final score was the sum of these three terms so for the first price project highlight for the team challenge we see that here the uh word frequency based metric was functional but heavily biased the the uh participants say and they attempted to correct for this in the neural network method and also they conducted five they conducted five-fold cross-validation and achieved a prediction accuracy of eighty-one percent on the testing data set so they managed to uh fully use this on the uh on the visitation data set they did the training and they were about to remove the bias that they had but there were some technical issues however the idea was great and they also provided us here with subject terms so they took more information from the dissertation not only the abstract title and full text they took the subject terms and they showed us how their the subject terms of the top ranking dissertations are distributed and the relevant terms like african-american studies african americans black studies and so on ethnic studies so the dissertations that were selected had relevant subject terms and they also looked at the uh classes for those dissertations and those include um very uh very relevant classes just like uh african study or ethnic studies for future work they want to um do a high ranking versus low ranking dissertation and use a benchmark to follow up on these projects so that they have an unbiased approach to look at it to look at manuscripts or any other type of document rather than relying on a score that they devise based on subjective factorial so uh they have here a list of the top scoring dissertation one was attitudes about disability and political participation since the 2016 u.s presidential election multi-clinical college students understanding interpersonal self-concept and the score was here the top score was 0.48 and the next one was close to that and so on they also showed here the ratio that was used to compute the score next for the individual challenge the first prize was uh given to manure will be given to manure gundam a bioinformatics student a phd student in our department uh the second prize to uh ho chi lee from uh electrical engineering and computer science and third prize to the king from chemistry and that's a dual degree bioinformatics student so project highlights the the first prize project developed a very thorough pre-processing criteria so they had to take geo data sets those data sets and look at the metadata and figure out if there are there is a balanced dataset between males and females or races so they looked at that and before they got to use that metadata they developed a very thorough pre-processing the gender can be stated as uh male female goal f or any other type of setting so it was hard to kind of hone in on those on that information the same thing for race they use the score based on the female male ratio and the goodness of feed test p value for the proportion of race to score the data sets and then they display the results for the individual criteria and combined as well per year and highlighted the difference and i'll show a couple of figures in the next slide for the second price project the highlight is it's on github they actually put the project on github which is very useful and others can build upon it or they can follow up they developed a very good thorough pre-processing and they used a kind of probability approach to identify the sex ratio not just the simple female to male ratio but they they use the probability approach to get the score that's a little bit more unbiased and that's bounded between zero and one and then they used earth mover distance for race and also looked at differences by year and they made this nice map they looked at different countries and they looked at the ratio per country which was pretty cool for uh the third price project highlights therapy processing um they develop they developed the shannon-based uh shannon entropy based score for gender and race and they had nice visualization like here where you see actually the uh here the equality for the two sexes here you see the the bias in some of the data sets and these were the top scoring data sets these were the mid score data sets and these are the biased ones that they said probably were the one that were prostate cancer or they were breast cancer studies so last the first press project highlight the encounter issues pertaining to how different research groups classify different ethnicities and genders which i mentioned the results uh gender only ratio shows that there are 116 data sets so from 2000 that they started with they had to do a lot of filtering until they got to only 116 that they had both gender and race information so there is a lack of that type of information in our data sets and then from 163 which are equal to and above 0.5 which is kind of a [Music] not a very strong criteria uh indicates that the good balance of gender whereas 43 were below 0.5 showing gender inequality and then they looked at difference per year and after 2015 the sex ratio shows more bias compared to the ethnicity ratio ratio and we can see here so this is before 2015 this is after 2015. we also look at the distribution of rays across all the data that they looked at they pulled it together and they looked at the distribution agrees and you see that definitely there is a difference between the the risk that in how they're represented in the data set overall so uh here they had only gender based rank and they got some data sets that were scored on the top five and then uh when they looked gender gender and ethnicity-based rank they they had a different uh different they had different data sets that included that information and they had a more accurate score so lastly what we learned from it is that the data challenge involves many people so thank you everybody that participate helped that provided the advice thank you a data challenge is fun it has the limits of the participants and that's the purpose in a sense di related bias can appear in many shapes and forms and thinking about it and being involved in this type of is can help you get your mindset in that space there are many creative ways to look at data you just need a reason and this is a very good reason so do participate in data challenges the scientific community should work diligently to identify knowledge and address the bi related bias in the assets and manuscripts and last thank you everybody and many thanks for participating judges and sponsors thank you yes so now everybody can break for lunch thank you and be back at one o'clock crazy you