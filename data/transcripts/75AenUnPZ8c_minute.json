[
    {
        "start": 10.08,
        "text": "so I think we'll wait until 5 after and then we go ahead you know people are hurrying from other parts of campus right I I want to say that there's a couple of uh couple of um set of perks of co uh that I was talking about with my colleagues one of them it's really hard to be very late for meetings right you're just uh you know you just have to get yourself to sign off and sign on and the other one is it's easy to learn student names now because there picture is always paired with a with a with a name right so before if you ever struggled with st's name that was really really easy so you know gotta gotta look at the positive side of uh things here right uh I think we can uh we have about "
    },
    {
        "start": 71.52,
        "text": "26 people so we're few minutes after four so I I think we can go ahead and get started so uh it is my absolute honor and pleasure to uh introduce today our our today's seminar speaker uh Dr SOA hassoon in and uh so I had a pleasure of uh meeting SOA uh at a uh conference um M metabolics association of North America and uh I was very impressed with uh the uh uh her research approach that she's going to talk to us uh about today and the work she's doing and so I was very pleased when she accepted our invitation to give a seminar my deep regret is that it's not in person but hopefully uh one day uh we can uh correct that when the pandemic is over and so Dr kassoon uh um got her "
    },
    {
        "start": 131.68,
        "text": "undergraduate degree in electrical engineering from South Dakota State University and uh the Master's Degree uh um from MIT followed by PhD uh from the Department of computer science and engineering uh at the University of Washington in Seattle and uh so she is a professor and in the past a chair of the Department of computer science at T University and uh so she is using machine learning approaches to um um study uh to study in develop tools for uh synthetic uh in systems biology and uh uh so she's uh also working in the area of metabolomics and so today she's going to talk to us about uh various machine learning Sol solutions that um she developed for uh "
    },
    {
        "start": 192.36,
        "text": "addressing the challenges in the field of metabolomics uh thank you so much for uh accepting our invitation and without further Ado um please proceed thank you so much uh I would like to thank everybody for coming for my talk I know there is a zoom fatigue and it's very hard to uh sort of pay attention for a long time so I'll try to make the talk as interactive and as entertaining as I can make it um and as all said I'm really excited to be here uh I wish it was in person but it's not and I hope for better times uh in the future so um I would like to start out talking about this favorite code of mine this quote is from Jensen hang who's the co-founder and CEO of Nvidia Nvidia is a company that started out in 1993 making processors for gaming "
    },
    {
        "start": 253.04,
        "text": "and multimedia applications so Nvidia quickly evolved into the business of making gpus or graphical processing units around 2001 in gpus the same program can run in parallel on on multiple streams of data and this type of Hardware is very approp appropriate for graphics card where you're trying to update pixels on the screen simultaneously to maximize the experience for the gamers what's really exciting about and relevant about the Nvidia Hardware in gpus in general is that gpus not only do Graphics well but you could repurpose them to perform complex computations required by Ai and um machine learning algorithms so I just want to put this quote in perspective this was uh stated in 2017 in reference to the state of software at the time and currently very few lines of software in the world Implement AI algorithms all what hang was saying is that once various disciplines start using more AI "
    },
    {
        "start": 314.479,
        "text": "algorithms II will become the dominant form of software you might say what does AI or machine learning have to do with metabolomics well it turns out that the GPU Hardware like the one from Nvidia is enabling novel software Solutions that will impact on how we do a number of things in life including metabolomics and biological and clinical data analysis so uh I uh this is sort of let me get everybody on the same page slide everybody's familiar with the uh central dogma of biology and the stuff that I'm interested in is actually at this level of metabolomic networks so when I talk about Network here uh I have metabolites A and B making C they're catalyzed by a particular enzyme and together all these make a network connection uh so metomic is obviously very important because the DNA gives you the blueprint of what the cicon does but obviously metabolomics is actually "
    },
    {
        "start": 374.68,
        "text": "telling you what the cell is actually doing at any particular point in time and we've already seen some remarkable work on how met metabolomics is allowing us to take a biomarker or a panel of biomarkers and make them clinically relevant or able forell for studying cellular processes in a recent work published in autism research scientists at neurop Point DX in collaboration with others reported how new findings uh reported new findings from the children's autism metabone project they identify unique met metabolic signatures in over 50% of the children with autism in the study this is an important step towards the goal of developing a panel of metabolomics tests that could be the basis of a biological screen to analyze the risk of autistic Spectrum disorders there are many other studies like the ones uh found in the gut uh related to the gut microbiota or to exercise that have shown metabolomics effective in identifying biomarkers and "
    },
    {
        "start": 436.4,
        "text": "linking to health and disease so really if we want to capitalize on this technology U the metabolomics technology we have to be able to interpret metabolomics data well and that's really what what uh my lab is trying to do is look at uh machine learning and try to advance the interpretation of metabolomics data so for my talk today I'd like to tackle three problems uh the first one is how do we use deep learning networks to uh do metabolite annotations and then I would like to talk about how you determine pathway activities and metabolite annotations using something called basan learning and uh the last last part of my talk is just going to talk about enzyme promiscuity and how it relates to metabolomics and how we could use it how we could use our knowledge about enzyme promiscuity to Advanced metabolomics I'll spend most of my time talking about the first two and I'll spend just a little time talking about the third ey so uh metabolomics is concerned with "
    },
    {
        "start": 498.36,
        "text": "measuring the masses of small molecules and I'm sure this crowd is very familiar with these small masses um and uh of course here I have a scale just to remind people what we're trying to do with metabolomics so in untargeted metabolomics where I'm concerned about biological Discovery I'm measuring everything possible uh that I could possibly measure in the sample um I measure thousands of molecules uh the masses of thousands of molecules and I'm what I'm trying to do is figure out what I'm what I'm measuring and it turns out to be a super hard problem so imagine that I measured a molecular weight of 892477 there are many molecules that have the same exact weight so these have the same atomic composition usually but differ in molecular arrangements so the biggest challenge in metabolomics is annotation which involves assigning chemical identities to measure masses so some very very very clever "
    },
    {
        "start": 558.959,
        "text": "people said hey uh you know collecting just the U Mass over Z is the masses of the measured uh molecules is not really sufficient to identify the molecules we're measuring so often Mass Spec is applied into two phases in the first phase we take the sample and we ionize it and separate all the molecules and you could use a gas or liquid uh chromatography uh to do this first step or you could use Ms for the first step and in the second phase what we're doing is we're blasting these molecules with ions and some energy and causing the molecules to fragment and the mass spec is actually measuring sort of recording what's going on with the fragments so now instead of just working with one molecular mass that I measured I can work now with the spec spectral signature of the molecule so now that we have more information to determine the chemical identity of what we measured uh the "
    },
    {
        "start": 619.44,
        "text": "problem turns out to be still difficult here's a couple of molecules they have the same molecular weight uh and it turns out that if I blast them through the second phase and this one actually is not second phase but it turns out that their spectral signatures are very very similar so if you look at these U molecules here the signatures of them just vary by some of these lower uh intensity uh signals so uh it turns out as I said this problem is very difficult and challenging and the work in this area kind of falls into two categories either we could take the measured mass and we could look it up in a spectral database okay and if I have a match then I know the identity of the molecule if I don't have a match then um basically at a loss and of course due to the experimental effort required to build these databases the databases are usually small in size and do not cover much of the metabol uh there's other computational "
    },
    {
        "start": 680.88,
        "text": "techniques for annotation so there's uh techniques such as CFM ID CSI finger ID and met frag and what they try to do is they try to generate a Spectra uh of some candidate molecules and then we find the one molecule whose spectral signature most likely matches to the measured Spectra so even though people have been working on the problem for quite a bit of time The annotation rates remain low where only a small fraction of measured data is annotated we have a recent study that shows you know with um across many studies with spectral lookups you can only get like 7% of the measurements uh annotated so from a machine learning perspective and I just want to remind everybody that I'm a computer scientist not a biologist so uh I I think about problems in a computational sense so when I see a problem like this I think about a translation problem I think I could think of mapping a molecule to its spectral "
    },
    {
        "start": 743.36,
        "text": "signature and we could think of this as a simulation problem where the mapping is effectively simulating the fragmentation process we could also think of this problem of of as mapping the spectral signature to the corresponding molecule that generated the Spectrum um and as I showed before similar molecules have similar signatures so we often do not and we do not often measure every molecular fragments so the problem of going from Spectra to molecules is actually a difficult problem and it's known as an inverse problem in many uh fields of engineering I personally very much like thinking about this translation Paradigm I could actually think clearly about these problems from a computational perspective and I could imagine how existing machine learning techniques and recent advances in machine learning developed for other fields such as natural language process processing and social network analysis can be used to "
    },
    {
        "start": 803.88,
        "text": "solve these sorts of problems and I'd like to point out even though my talk talk today is about Ai and machine learning to solve these sorts of problem we're really at the very very beginning of using Ai and machine learning effectively in uh this area of metabolomics and in terms of clinical and biological data uh sort of Discovery and Analysis so because we're sort of really early here what we wanted to do is we want to start at a very basic level and describe how to use a neural network to solve this forward simulation problem so I'm concerned with mapping molecules into Spectrum so again I start out with simple question is it possible to use these neural networks to map molecules into Spectrum a neural network is simply a layered network of nodes in this image the yellow nodes form a layered Network that is four layers deep so one two "
    },
    {
        "start": 864.04,
        "text": "three four layers deep each node is performing a calculation based B on a parameterized function the outputs of these nodes are typically numbers between Z and one the inputs to each nodes are based on the outputs from the prior prior layers the input to the network is uh these nodes in the red uh I I put the input on this side and the output is coming out on the right out of the blue noes this type of Architecture is often often referred to as a feed forward neural architecture ffnn uh so how do we make this neural network work for our molecule spectral combination well the data set that I have consists of molecules and Spectrum so I'm going to use the data that I have to sort of train this model to kind of spit out these uh Spectra when I give it a particular molecule so the goal of this training that I'm going to do is to learn the "
    },
    {
        "start": 925.88,
        "text": "parameters that are computed at the Blue uh the output of the blue nodes and I would like to make the output look as much as possible as my data that I'm using for training so this type of um feed forward Network only understands vectors as input and vectors as outputs so here at the output Vector I could Bend all these Spectra into bins and I could say that for each one of these spins I'm trying to predict the relative intensity of the peaks in those bins so that's a vector and it has different values and we typically use a bin size of a thousand and uh each one of them corresponding to uh a small portion of M over z uh so what do we do with the inputs well it turns out that we could represent uh molecules as fingerprints as vectors so the fingerprints are "
    },
    {
        "start": 986.199,
        "text": "simply binary vectors that indicate the presence or absence of a particular uh group functional group or a ring and there are many types of uh fingerprints so now the neural network could actually be trained to map the molecules sorry the spec the fingerprints into the spectral output so in 2019 uh Jennifer way at Google brain and other researchers published a paper based on using these feed forward networks uh to create additional Spectra that they could use to augment their GC Ms spectral libraries so we use this model as a Baseline and we improve over it okay and the question is how can we improve over it if you look at the step where the molecules are represented any time that I go from a molecule to a fingerprint I basically use some information so what we try to improve of this Baseline is actually how do we improve the representation of the "
    },
    {
        "start": 1047.36,
        "text": "molecule so we could capture more information about them so we can take advantage of the structure of the molecule we could think of the molecule as a graph where the atoms uh where an atom is a node in the graph and a bond is an edge in the graph so this snow could correspond to carbon this Edge could correspond to a double bond for example to another atom and it turns out there's a class of techniques called graph neural networks that are designed specifically to take advantage of graph structures one particular type of GNN is called a graph convolutional networks and they work by propagating information from the neighbors of a particular node to the nodes themselves and this propagation information propagation is repeated for each node in the graph and repeated multiple times if you're familiar with convolutional n "
    },
    {
        "start": 1107.4,
        "text": "networks or CN uh this is very similar but for graphs um so that's sort of one way that we tackle this problem is to use this GNN another thing that we did is we looked at adding what's called attentional modeling so it turns out that the contributions of every neighbor of this particular node may not be equal so what we do is we add something called ATT attention modeling where we actually learn the relative weights of the Neighbors when we're trying to learn the representations of each node in the graph so now our model for mapping molecules to Spectra is updated to replace the feed forward neural networks with the graph neural networks so this is an image of a graph neural network so we no longer need to use the fingerprints and what we're really doing is we're actually learning a mapping from the molecules to sort of a new embedding a vector and then we add a "
    },
    {
        "start": 1169.48,
        "text": "small layer that Maps uh that learned embedding of the molecules into this predicted spectral output so we've minimized the loss in terms of uh removing the fingerprint so let me tell you a little bit how we evaluated the performance of the graph neural networks so in our test data set we have Spectra and we have known matches okay we know the molecular formula of each real match so now we could go to pupim which is the biggest molecular database and we could come back with possible candidates that match to the formula of the real candidate so my GNN will then generate the Spectra for each one of these candidates and then I could compare the Spectra that was generated by the gnm's against the Spectra of the mole of "
    },
    {
        "start": 1231.44,
        "text": "the molecule that I measured in my test data set and out of all of these I figure out which of these Spectra best matches my measurement in the test set and then I could go back and say oh the molecule that generated the spectrum is is the best one it's my best match so again what I'm trying to evaluate how good this GNN is doing one thing I have to evaluate is how well the Spectra match but ultimately I want to see how well it does in picking the correct candidate and hopefully it would pick the the best match here so here's how we kind of did the experiment what we did is we trained and evaluated and uh data from the N data set this is for lcms for so liquid chromatography for all of by masspec and we selected a subset where we kind of knew something about the um "
    },
    {
        "start": 1293.24,
        "text": "precursor types and uh we limited sort of adduct uh selection so we ended up with 6,289 molecules in our training set and we actually used about 1500 molecules for our validation tests set the validation set allows you to select the best model among all the variations of the models that we tried for both GNN and the feed for neural networks again because this is more of an art than a science designing this neural networks you end up trying lots and lots of things so the validation set is really saying pick the best model out of everything and then what we do is we say okay now we could test on an independent set that has nothing to do with the training or the validation set and for that we Ser we saved a thousand molecules and for these thousand molecules we went to pupkin and retrieved their the candidate sets associated with these thousand molecules what I show here is a histogram showing "
    },
    {
        "start": 1354.559,
        "text": "the distribution of the number of candidates many of our test molecules have uh hundreds of candidates and it turns out that the average number of candidates was roughly 1530 so using this candidate set we can now evaluate how well the GNN and fnn ffnn perform before I get into the details of that I want to show you a sample spectral prediction it's this green one right here so here we have something called a mirror plot this is what I measured and this is what our tool is predicting and you could see that this is a close match so I have to admit when I saw this one I had to ask how my grad student who's working on this project if this was the best plot that he had generated and he did say that it's one of the best but I made him go back and look at many many more as a matter of fact we looked at the ones that did really well and looked at the ones that did really badly and there was a lot of them that had high similarity between the actual measured Spectra and between the predicted spect "
    },
    {
        "start": 1415.48,
        "text": "okay so the accuracy of the spectral spectral prediction is not the only metric that predicts the performance of The annotation tool then turns out that the number of molecules in the candidate set plays a big role so here I compare the performance of the GNN and feed forward networks assuming a different side different sizes of the candidate sets I basically take the uh distribution that I showed you the histogram distribution of the candidates and I down sample it until I get a Target average number of candidates per molecule of 50 of 250 and 1,000 okay so then I score the similarity of the generated Spectra against the misss Spectra and I rank the candidates based on the similarity score so in each of the figures I'm actually plotting the top K rank this top K rank simply means that the likelihood of hitting the target "
    },
    {
        "start": 1475.919,
        "text": "molecule when I look among the top K candidates for example when I have 50 candidates and I'm looking at the and I'm using the GNN which is this dark line right here and uh when I'm looking at the top rank top 10 ranked candidates I have an 80% chance of hitting my target molecule okay so out of the 10 that I test uh there's a chance that I'm there's an 80% chance that I'm going to actually find it so here's the number for candidates are 50 here they're down sample to 250 and then to 1,000 so there's some trends that I want to you to observe first in each one of these cases the GNN the purple line outperforms the green line the feed forward neural networks and of course they both uh perform just a random guess and I want to point out here is the performance of both the GNN and ffnn is really very much dependent on "
    },
    {
        "start": 1536.64,
        "text": "the size of the candidate set as the candidate set size increases you're going to see a decrease in performance I also want to point out that it's not just the size of their candidate set that influences this topk rank performance we designed another experiment to sort of evaluate the quality of the molecules in the candidate set for each of the 1,000 test molecules we selected various size candidates of 50 250 and 1,000 and we handpicked the candidate sets as follows so for example in the case of the size of 250 using the fingerprint similarities on the candidate set we determined the most similar 250 molecules and the least 250 similar molecules to the test MO Ule and we use those 250 molecules as a test set so in this sense we actually made up "
    },
    {
        "start": 1596.72,
        "text": "a candidate set that has the least similar molecules and a candidate set that has the most similar molecules and we repeated this for U the candidate size of 50 and the candidate size of 1 1,000 and for each one of these spots on the top and the bottom the darker line shows the performance when the candidate set is not so similar to each other and the lighter color shows what the performance is when uh the molecules are super similar to each other so the top three plots show how the performance of the feed forward forward neural network on the least and most similar uh sets and the bottom one shows uh the same experiment on with using the gns so the takeaways here in both cases the performance is a function of the similarity of the candid set to the Target test mules it seems that the feedforward networks are less sensitive to the similarity than gnm in each of "
    },
    {
        "start": 1659.08,
        "text": "the feed forward networks the performance gap between the most and least similar sets are narrower than they are for the GNN but keep in mind the GNN outperforms the feed foral networks so there's a sensitivity sensitivity and performance trade offset play so here's summary of sort of the first part of my talk uh we talked about how to use GNN to map molecules into their Spectra and then GNN outperforms the feed forward networks due to the Learned molecular representations that we're doing with the gns so the performance results are function of number of candidate the number of candidate molecules as well as this their similarity to the Target molecule and this is really pointing out that we as a community need to be more consistent in the way we evaluate metabolite annotation techniques we could not really compare our work with any of the other tools because they train on different data they evaluate on different data and we can't really recreate exactly the same uh "
    },
    {
        "start": 1720.6,
        "text": "computational setup to compare apples with apples and that's a really big deal when uh you're working in algorithm and machine learning you have to do comparisons fairily I would like to here thank my students how and Shaman and Professor liing Le who's my collaborator and there's a a short paper that kind of describes this work on the archive okay so in this part of my talk uh I would like to talk about the interpretation of untargeted metabolomics data in the biological context of the sample and you know what I'm going to take a one minute break and say does anybody have any questions about the prior Parts about the gnn's or the Spectra or the results hi this is Chelsea uh I was wondering how do you estimate how many um the size "
    },
    {
        "start": 1780.64,
        "text": "of the data you need to train a valid and um trustworthy model it's an excellent excellent question you know there was this big notion when uh they started working on machine learning that you really needed huge huge data sets and it turns out that you do really need to have huge data sets but sometimes you only have what you have right it's not like you could invent new data sets even though there's uh techniques called Data augmentation that help you kind of increase your the size of your data set but it turns out there's like um something called overfitting so you train your model you train your model and you just don't want it to memorize all the answers for you so when you train even if your data set as size your your training data set is small you just want to make sure that your model is not overfitting okay so you could train with a smaller set you're not going to get the same quality "
    },
    {
        "start": 1840.679,
        "text": "performance that you would get with a bigger set but you just have to be careful that your model did not get very specific to that particular smaller data set does that does that answer your question thank you yeah so this data issue is always a problem right we always want to have bigger data the you know this is the sad part with the state of biological data uh there's so many inconsistencies there's so many contradictions you end up by the time you clean up your data you toss out half your data set because of various issues so it's really uh really problematic but we do the best that we can without spending all our time on curating data other other questions great question Chelsea all right uh so okay so this in this part of the talk whoops I'd like to talk about the interpretation of untargeted metabolomics in the context of the "
    },
    {
        "start": 1901.32,
        "text": "biological sample so in this case uh what I'm gonna do is I'm GNA have some measurements untargeted metabolomics and what I would like to know is I would like to answer two questions which metabolites are present in the sample that's always the question that everybody wants to answer and the second one I want to know which pathways are active or which Pathways produced The observed measurements uh and in this case um I have a very precise definition of a pathway being active I will say a pathway is active if the likelihood that the pathway generated The observed measurements is above a particular user defined threshold so our goal in this work is to answer these two questions use using something called probabilistic modeling um sorry I missed the slide here okay so there are several techniques that people have used to determine pathway activities uh there's something called over representation analysis I'm sure uh "
    },
    {
        "start": 1964.2,
        "text": "some of you working in uh gene expression data or modomics have seen this before and here we want to know if a pathway is enriched in measured metabolites to a degree different than expected by chance when compared to other cellular Pathways uh in or those in a reference sample and enrichment analysis also encompasses technique that compute observe metabolite centrality and connectivity and these metrics here kind of reflect how important the metabolite is in a pathway or a network the earlier works that uh interpreting metabolomics in a differential fashion so for example I compute the enrichment ratio of a perturbed sample as compared to a referenced sample these techniques sometimes assume that the metabolites have known identities and one technique called Mommy chug actually bypasses this metabolite annotation and computes the functional enrichment of modules relevant to others in the sample without actually annotating the metabolites and that's sort of the "
    },
    {
        "start": 2026.76,
        "text": "direction that we would like to take I like I like drawings they always make sense to me so in our work we don't really want to focus on differential analysis between a perturbed and a referenced sample what I want to do I want to use all the data that I have okay as well as the network structure that I could get for the sample to interpret metomic data so to better understand the data basically we're going to capitalize on on our understanding of the uncertainty in mapping measurements to metabolites to Pathways so here I have a snippet of a pathway of two Pathways pathway one and pathway two each pathway is associated with several metabolites so pathway one "
    },
    {
        "start": 2087.52,
        "text": "is associated with these metabolites pathway two is associated with these metabolites and so on and you could see some some metabolites like two is actually associated with both pathway one and pathway 2 when performing metabolomics we observe several masses or M over Z's okay uh in this picture the masses are represented as squares some measurements such as a W1 can only be attributed to one metabolite J1 because J1 is the only one associated with the pathway two uh we could potentially say that pathway 2 is active due to the presence of this uh measurement and and its related metabolite um some masses like the one here with W2 can correspond to multiple metabolites like J2 j3 which can be associated with multiple "
    },
    {
        "start": 2150.04,
        "text": "Pathways we could all agree here that we have more certainty certainty in attributing W1 to the activity of pathway 2 then the certainty we would have in attributing W2 to the activities of either pathway 1 or two or both so the idea of this work is simple I would like to use probability to model the uncertainties in mapping the measurements to the metabolites and to the pathways to solve this problem we use probalistic modeling this involves several steps first we Define what's called a probabilistic model using random variables our model captures relationships between Pathways metabolites and their masses then we make assumptions about the distributions of the random variables and then we once we have the model in the model parameters we can then form hypothesis and calculate the probabilities of the hypoth hypothesis given the observed "
    },
    {
        "start": 2210.2,
        "text": "data and this is a pretty standard machine learning Fair we can use Bas rule to compute such probabilities so I'm going to give you sort of the visual of what I just said because I think sometimes uh it is dense to sort of take that in all at once so again uh what we do is we introduce uh four random variables in our case here so we have a random variable that tells me whether a pathway is active or not a value of one says the pathway is active and a value of zero indicates that it's not active you can imagine if you have a cancer pathway or an uh or some sort of uh biodegradation pathway there's and and you don't have a reason for those Pathways to be active they will have zero activity while other things like a TCA cycle it's very likely that it will be active so in this case we have as many random variables as we have number of Pathways the second random variable "
    },
    {
        "start": 2270.8,
        "text": "indicates if a metabolite was generated due a particular pathway the third set of metabolites the third set of random variables indicates if a metabolite was present in the sample there are as many random variables here as there are metabolites in the network finally there's a set of random variables that ingates if a particular Mass within the bin centered on each Mass within the network is observed there are as many such Mass bins and corresponding number of variables are there are masses in the model so I want to point out here this random variable the observation is the only random variable that's actually observed using the mass spec while all the others are considered latent or hidden variables I don't know anything about them I don't know if they're there in the sample or not and I need to know learn more about them through this model so to continue with this to Define our probabilistic model we assigned "
    },
    {
        "start": 2331.2,
        "text": "distributions for the ver various random variables so we assume pathway activities denoted by letter a has a beri distribution over a parameter of Lambda that is we assign each pathway a discrete probability distribution of a random variable which takes the value one with probability Lambda and uh the value zero with probability one minus Lambda metabolites within the active pathways are equally likely to be generated by the pathway with probability mu and random variables associated with each metabolites and the S samples denoted by m are derived based on the contribution of individual Z variables associated with each pathway metaboli parent finally the random variable associated with each Mass bin in the model is derived based on the observed accuracy gamma associated with the mass path and if any metabolites associated with a corresponding Mass was generated by an active pathway so in this probabilistic framework our model "
    },
    {
        "start": 2391.4,
        "text": "parameters are actually Lambda and mu and gamma right here so we could assign the parameters some values we have investigated the sensitivity of our model to these values the model is actually not sensitive to these values because it's the structure of the model that plays that is the dominant factor that derives our influence results so uh we use inference uh and the way this works is the model we developed represents The Joint probility distribution over all a random variables using a probalistic model we can infer pathway activities and metabolite presence from observed Mass measurements so we calculate two probabilities first for each pathway P we calculate the posterior probability of the pathway being active given the observations of the masses W and then "
    },
    {
        "start": 2452.56,
        "text": "for each metabolite in the model MF we calculate the posterior prob ility of the metabolite being present in the sample so these metabolite annotation the probabilities can be used for annotation and if the calculated probabilities are above a user defined thresholds the probabilities are used to suggest and rank the best metabolite matches for each Mass measurement so I would like to emphasize here that the way that we've used inferences this work is different from other prior works for example prob that assigns empirical formula formulas given potential formulas using problemistic modeling so this is different than firework so we could carry out the inference using something called GB sampling which utilizes sampling to approximate our probability distribution in this work we used something called collapse Gib sampling as we marginalized out hidden variable z&m the sampler therefore samples only random variables associated with each pathway activity we "
    },
    {
        "start": 2515.24,
        "text": "achieved significant speedups when we did this marginalization because we had fewer variables and we could run the inference on the examples that I'll show you uh in three or four minutes when we draw a thousand different samples so let me jump to a sort of uh some some some results here we built this tool called Puma uh probalistic modeling for untargeted metabolomics and we analyzed three data sets uh a synthetic Benchmark data set and two data sets that we collected from our collaborators I want to talk a little bit about synthetic data sets and this is really really important when we're doing uh things in biology often we actually do not have the ground truth so when we say one algorithm works better than another algorithm you actually have no ground truth that tells you indeed that is the case so even even "
    },
    {
        "start": 2577.319,
        "text": "though we have metabolomics data sets from many databases such as metabolites metabolomics work workbench there are currently no untargeted metabolomics sets where they identified the pathways and we can use as ground truth when predicting pathway activities so what we did is we built synthetic data sets to mimic the biological process okay where genes uh within Pathways work in concert and result in entic activities that produce metabolites so we used the something called a Chinese hamster over cell to kind of generate these models and we were able to generate different data sets assuming different pathway activities and different metabolites being active within each pathway but now because I have these synthetic data and I actually know what the ground truth I could actually compare different techniques on this synthetic data set and I can tell you I know this algorithm is better than this one so what we did is we compared the area under the Curve "
    },
    {
        "start": 2637.4,
        "text": "for synthetic data sets uh and we compared Puma with this enrichment analysis um I will I will kind of speed up a little bit to give times uh for answering questions at the end across all our experiments it turns out that Puma outperforms the enrichment ratio by roughly 8% so uh this tells us that Puma is able to recover pathway activities better when using enrichment ratios we also used it for um metabolite annotations and we outperformed a tool called bam that Aggregates various data sources like mlin and hmdb and other annotation tools and also network connectivity um so here's a quick summary of part two we developed this probalistic model for metabolite annotation and for analyzing pathway activity and we used inference to compute the various activities um and we show significant improvements over other "
    },
    {
        "start": 2698.119,
        "text": "tools for both uh Computing the enrichment ratios and also for uh identifying metabolite identities and we have a paper that's published so you're welcome to look look through that I want to move on to the last part of my talk and that's the short part is we wanted to look at enzyme promiscuity and metabolomics so in this case there's two areas relevant to metabolomics that actually motivated us to look at enzyme promiscuity you could generate possible metabolites that don't exist say in databases by applying promiscuity prediction on known uh molecules within this sample okay and as I showed earlier in the talk when we did the metabolite annotation the quality and the size of the candidate set matters so what we're doing in our work here is we're using enzyme priscu "
    },
    {
        "start": 2759.52,
        "text": "prediction to help us generate a relevant biological candidate set um the other work that we're doing in the space is we wanted to analyze unexpected enzymatic products when you do engineered uh cellular host so typically when you design uh a synthesis pathway that you add to a microbial host like eoli you see lots and lots of unexpected anetic products and if we knew something about promiscuity when we measure those products in the cell we're able to sort of explain where this data can came from so let me tell you about our PR enzyme promiscuity techniques our uh group has been working on this very actively and we are we a few years ago we came up with a a tool that's based on rules so I learn uh enzyme x per forms Biore reaction B so I could look at the "
    },
    {
        "start": 2821.0,
        "text": "pattern biot transformation and I could learn what the pattern is and I could apply it to New molecules and it can predict new products and actually all the work that I showed uh before here was really based on proximal and as we got really really good results on these studies we're like wait proximal is not really that awesome we need to come up with better ways of predicting perity so we have several machine learning techniques that are in the works and some of them are close to being published we for example we use recommender systems like the ones that you use for at Amazon or Netflix uh where you you you you you recommend products to users uh we actually do recommend molecules to enzymes and vice versa we also use natural language processing on protein sequences to predict interactions uh with molecules we also have a way of using it and I'll explain these two other problems that we're working on uh in the next couple of minutes so this is H one of the first ideas that we started "
    },
    {
        "start": 2882.28,
        "text": "working on and got very excited about with machine learning and I just love love this idea and it's very very simple I'm sure you're all going to be able to relate to it there's a powerful Concept in machine learning called graph embedding the idea is super simple nodes within the graphs are more connect that are more connected should appear closer together in a multi-dimensional space so here I have a cartoon I have nodes one two three uh they should appear closer together in this two-dimensional space with uh X1 and X2 so again one two and three are closer together here than uh than say one and nine right which are really far apart in this graph so we could uh build a reaction network from databases such as keg or Brenda and then what we could do is we could ask questions like this what's the likelihood of node one being connected "
    },
    {
        "start": 2942.64,
        "text": "with node four meaning if I have uh compound a and compound B here what's the likelihood that they're connected by an enzymatic reaction and I could say how does that probability compare compared with finding an enatic reaction that ties one and nine well we could use the distances in the multi-dimensional space and we actually train um train a a shallow Network to to learn uh sort of what they what the likelihood of these connections based on these multi-dimensional representations of the nodes within the graph so we have some great results in this work was just published at uh in bioinformatics the other idea that I want to talk about is uh using multi-label hierarchical classification to predict if a particular enzyme acts on a molecule so uh the idea here is very simple I build a classifier and the classifier's output correspond to a particular enzyme class okay the enzyme "
    },
    {
        "start": 3005.76,
        "text": "classes are given by the enzyme commission numbers so for example uh the enzyme Commission of this enzyme is given by these four numbers the more uh further down along towards the fourth digit it tells you more specific information about the substrates that the enzyme acts on so what we did with this U multi label classification is we actually utilized the hierarchy that's inherent in these enzyme commission numbers and we were able to generate some very interesting results that showed lots of things such as uh when you train these classifiers with inhibitor molecules you actually do better we also showed that if you do uh some realistic splits on the data your performance varies tremendously compared to just doing random slits so if you're trying to use the these kinds of machine learning tools to predict on unseen data you really need to think about how you're training training your model okay so a quick "
    },
    {
        "start": 3067.04,
        "text": "summary there's great opportunities to utilize machine learning in AI to advance metabolomics and biological and clinical discoveries in general and the time to do that is now our lab is doing some very exciting things in my opinion in my students opinion to do metaboli an annotation pathway analysis and enzyme promiscuity prediction to be used in metabolomics annotation and other applications I would like to acknowledge my funding sources the National Science Foundation and an R1 from GMS and uh my lab members this is a picture from the summer during Co time are just absolutely phenomenal and Incredibly productive and exciting and engaging I am very lucky to sit between collaborators on the machine learning side uh liing and Mike are my learning collaborators and the other collaborators are all metabolic or biological Engineers or synthetic biologists I'm always looking for bright and motivated PhD students so if you're interested or know somebody who might be "
    },
    {
        "start": 3128.48,
        "text": "interested please let me know and we're planning a special issue on mod metabolites with Simon Rogers and Justin vanderhook if you're interested in applying for that let me know all right and with that I conclude and I ask you if you have any questions oh thank you so much um I don't know I would like to you know in view of the Applause uh Applause from the audience thank you so much for the interesting uh questions so maybe I can start um so I um the part that is sort of you know the most near and dear to my heart is The metabol annotation and so do I understand correctly that uh in your uh sort of approach and your uh simulated data set that you created there so you you're assuming uh the metab the "
    },
    {
        "start": 3190.04,
        "text": "identities of the metabolites are known and uh the pathways consist of certain number of metabolites and uh obviously not all metabolites are measured uh and uh sort of you know vice versa so not not everything can be mapped to Pathways is that a correct did I understand that correctly yeah so for that you're talking about the synthetic data set right right for the second part of said how you build it yeah yes yes I'm talking about this yeah we basically assume uh if is the pathway active or not active and if the pathway is active you say which you know some some portion of the metabolized with the within the pathway are are observed right or or are exactly active are actually act like present right because not every metabolite and every pathway is actually "
    },
    {
        "start": 3252.16,
        "text": "active right it depends on what you're feeding the cells what's going on right biologically speaking absolutely yeah and then we also assume that we are not measuring everything that is there as well right right and you know so my question yeah go ahead no no go go ahead what's the question then okay so uh what I'm wondering is and you you're comparing uh the performance to traditional enrichment analysis uh type methods right and so what I do know is that um compared to for example you know ini methods that are being used for say gene expression data uh in metabolomic uh the uh uh there are various metabolites such as um nadp ATP and so on and so forth like basically you know that mapped mapped to multiple Pathways right and uh then they're also uh you know there also "
    },
    {
        "start": 3314.64,
        "text": "metabolites that are very highly correlated by virtue of being the substrate and the product of adjacent reactions or something like this which usually has uh some effect on traditional analysis methods how would you say uh your approach kind of uh handles that sort of situation does it give an advantage or um so these are all very very uh very very good questions obviously you're really into the thick of it um so what we did with the uh with the popular metabolites right these are Hub metabolites there are commodity they're in every part of the the cells so what we did is we actually removed them so we we're not trying to measure any ND nadh right I mean it's it's not very inform right so we actually removed a big all we have a list of co-actors that we have gotten from our biological engineering opat and we kind of ignored that the um so the other question is is "
    },
    {
        "start": 3378.72,
        "text": "that some metabolites are occurring right within multiple Pathways sure it's it's normal right so the point of here is that what we're doing is we're trying to find the probability of the metabolite being generated by that pathway so again let's say uh the metabolite is you know part of two Pathways if I end up if if both Pathways in real life are generating this I should get equal probability right that both Pathways were generating that metabolite if one pathway is not active or just not generating that metabolite I would hope that the other evidence that I measured right is telling me there's chances are higher that one pathway generated it compared to the other pathway so I really think about what we're doing here which is different what other people are doing with just the you know the differential analysis I'm "
    },
    {
        "start": 3440.72,
        "text": "hoping that some of the context of all the stuff that you're measuring is helping we make a better informed decision about what's going on in the cell and back to your other question is sometimes you have substrate product relationships right we actually do not account this model that we have for Puma right now does not account for those relationships but we have uh we have ongoing work to sort of incorporate that in in our re iteration of this great thank you other questions well if not I guess you know thank you very much again for the wonderful talk I understand that you are standing this link and uh talking to students next is that right yes I believe so yeah Chelsea and honey right yes "
    },
    {
        "start": 3502.4,
        "text": "I okay thank you so much it was nice to yeah it was great to see you I will have to follow up with you by email I mean I have more questions but uh we can do it offline and kind of you know I'll follow up thank you thank you wonderful "
    }
]