yes so this is all the technology seminar series used to researchers at all today's speakers I want to win if he is assistant professor in learning on Frank Sesno it's actually got a prequel back let's go back from a pharmacy in computer science a whole everyone and thank you for having me when they do a sound check are we okay you hear me in the room and I was doing okay on the audio alright great so I'm delighted to be with you today and grateful for the invitation thanks for having having me over to the tools and technology seminar I have a suspicion that the work that I'm doing is probably not work that is something that seeing a lot of but I may be wrong about that and so my hope for today that this will be interactive and as you go through here that you can help me make this you know contextualize that to make this relevant for you surfacing examples and I'll have a few stopping points here as we go through my approach to the title I'm told assumptions technical literacy courses and finite result I was asked to give a title a while ago and I wanted to give a title that would give me some latitude together and so I came up with a playwright that it actually worked I think it's all going to come together quite nicely but that's where that came from really this work that I'll be reporting on today and interested in getting their feedback on it's Reyes about research and development we're really thinking about organizing computation or data-driven science to support a future evaluation learning and using the outputs of scientific research particularly when they're fully computable or machine executable to generate case specific rotation specific advice depending on what's needed there so as you know the the intro which I also appreciate and respect I appreciate the invitation this is my background and mainly it's important to share I think our background so you know where my biases are and all the things I don't know about and so my background is not in computational biology and bioinformatics I first trained here at Michigan in the 1990s in pharmacy and and at the same time in computer science although I don't have a degree in computer science and the professional programmers who I work with they know what my limitations are and there are many of them programming which is why I'm fortunate to work with all of them I'm also besides being here at the medical school now after having received the PhD recently I did a mid-career PhD received a PhD from the school of information they need to be almost two years ago now and so I was offered a position and I was glad to take it and we'll continue working with dr. Charles Friedman in the primary learning Health Sciences of our medical school and you may know or may be new to you that the Department of learning Health Sciences got its name in 2014 had been since 1927 the department of medical education but as our mission and that department expanded our mission still includes researchers and medical education but we also have in our department assumed the clinical simulation center and the science the clinical simulation gets studied in our department and then there's a group of not in our department that looks at organizational learning and systemic learning and infrastructures for learning in the future and so that's the group that I work with and so as the mission of the department expanded the name change from Medical Education to learning Health Sciences and then I'm also part of relatively new national or really getting to the international community called mobilizing computable biomedical knowledge and we'll have our third meeting next summer third annual open meeting at the National Library of Medicine and so our connection back to the NIH campus at this point through that group runs through the NLM and very happy about that and we get to work with the folks over there if you have questions afterwards or would like more information by all means peace I reached out to me happy to engage so the agenda for today I'll very briefly focus on some issues in epistemology and very briefly we need to just anchor ourselves and some concept of knowledge that I hope will be something that we can all live with as we go forward here don't take too long with that then talk a little bit more about changes and scholarly communication so the changes that we see in biomedicine are generalized across scholarly communication so what I mean by that I mean the publication the way the journal will operate is being disrupted by technology in a big way so how many of you have familiar preprint servers and news preprint servers and they'd be interested in that we've heard of those so these kind of innovations are coming into the scholarly communication where along with other things and we're pursuing particular aspects of that which I've got to and then finally the biggest part here if these were three books on the shelf you know I spend most time on the design and development of compound digital objects and show you some examples and tell you why we think they're important in our work but we'll go to that hearing q um so briefly I have to think about knowledge if we're going to have knowledge management and knowledge organization and that's the thing those are the things that I work on well we have to have some definitions I'm working definition of now is what's being managed and what's being organized and so you may have heard about or read about or thought about knowledge is justified true belief that's one way or the Philosopher's think about knowledge and because of Betio problems a refinement was made to that idea and we come up with justified true belief so wrong if it's not inferred from any other and I don't want to go down the rabbit hole of fake news and things like that but you know these things are important to keep their mind the way that we think about what is knowledge so these are a start but I don't think they're the most helpful for today so I'm going to show you three other chelation of knowledge that I didn't come up with but that I value because they all point to knowledge as explicit knowledge as something that it's information that somehow gets upgraded to knowledge and that's really the knowledge that I'm trying to manage and organize in the world and so one way of thinking about that luciano floridi at oxford over the past 10 or 15 years just published several works I'm an information science and thinks about knowledge of semantic information which is better than a network of questions and answers which accounts for it so what I like about this where I was thinking about knowledge is it's highly relational the knowledge that we have essentially is is can be thought of either as a set of relations correlation causation you can think of those things as relationships between things and I think that's helpful to remember that now it has some fundamental relational element to it nature to it over eons I'm thinking from the point of view of computer science and data compression and particularly has a little bit of a different thought about what learning is and then the results of learning you can think of as knobs in an information form so if we have a large data set we can somehow compress it and go to a description of a model and the description of the data that are less than the data set itself and somehow cohesive and sensible besides then this is adriana concept of a ten-part code knowledge this isn't coded software code this is more general than that but I would point you to those couple of papers in the last 10 years to learn more about this perspective of upgrading information to create knowledge so I think it's interesting and important and then dr. Friedman over the last several years in our work on learning how systems has articulated his view of what we're managing and organizing when we say were in the business knowledge organization and now it's management these years that we were organizing the result of analytic and/or deliberative processes that are valued by some community all of these things under the line there in my view are explicit now it's knowledge that somehow can be made explicit so we do understand also there are tacit conceptualizations of knowledge that's intuition is expert knowledge that lives in perhaps only in human brains does not make it into a page or a piece of software but these ones the red line I think are the explicit kind that we're thinking we have knowledge to manage we have knowledge to organize okay so with that Li Lin again this is a reiteration you think of them from an information stage what I'm saying is that for the purposes of this talk and for the work that we're presenting we think of explicit knowledge as a subset of information the special kind of information whether it's these concept of updating semantic information or whether it's in order can delivery processes whatever that is what we're talking about here is something that is an information based view of knowledge information based view so there are other views of knowledge of course and I'm not trying to be entirely comprehensive just trying to get to something that's workable all right so this is about the end of that little snippet of epistemology any questions or concerns about this information based view of knowledge does anything strike you is that we're already off track and we need to find our way back to the path or does it seem reasonable enough to go forward example of some other views of knowledge decisive information yeah so I think one of the major ones is decide to a tacit knowledge that if that people have it from they gain from their expertise and that people have knowledge in their minds that they can then apply when they see the situation and and whatever that pattern-matching and understanding that experts have when they engage a situation and quickly understand a problem space and a solution there's a kind of knowledge that sometimes now that can be written down never can be truly understood we can interview people we can watch them work but we may never be able to completely capture that kind of expertise so that's one oh it goes back to that idea of belief you know what somebody believes and what those beliefs are predicated on and we don't always know what people are breathing what those beliefs are predicated on and so there's something that's a little harder to get out there for example yeah yes yeah and so a lot of work actually been done here on the concept of understanding knowledge within community I would just point out that in our scientific communities when we think about for example peer review and the process of peer review in a century when I lived through and have a paper peer review we're engaging some community right a community around a journal or a community in a particular scientific state and it's those individuals and the way they conduct peer review and the feedback that we get right that will sometimes determine whether we've reached the bar and we have a new contribution in a space or whether we have not reached the barn we have yet to achieve on your contribution so that's one way to think about the community philosophical has those certain assumptions of that person's own personal biases the information based knowledge also has its own biases identity information is the knowledge yes yes don't get me wrong don't want to go to the attention or talk more about that somehow information these now just better or it comes without you know problems or without bias either not necessarily better but it's it's what my work is about that's what we're trying to manage so I'm just making that distinction and as a suggested based on absolutely great point all right so this will be important to keep this in mind with and I'm coming back to this again again so thank you for letting me start with it and then just unpacking the subtitle here a little bit there would be lots of ways to think about how now I just used in the world this is just to give some examples again not to be comprehensive that in research and evaluation existing now it's in the world and so we examine what gets published and what our pilots are doing we can try to validate it related things incorporated into other thing summarize it synthesize a combine it extended and so on so when we find a paper with some other scientific output that we value in our own work we can do all of these things actually with it morning is different use of knowledge I would argue a little bit different we can study what other people have learned we can tell our students to the test of their understanding of it we can teach how that we can generate new hypotheses also with knowledge and then my work tends to focus here as a pharmacy they're coming out of the clinical world the years of age they're there there's often times to get to advise we want to understand what's known in the world about a particular problem so we can answer some of these questions which medication would be best in a certain situation for example or which dose should I use in why should I usually you want to solve problems with knowledge we want to make plans that are informed by now so I'll put that in this broad carry category of advice so however we categorize these things the point of this slide it's just to say that let's not lose sight of the fact that we use knowledge this information they find knowledge in lots of different ways okay we certainly depend on it in research context but it gets used in other contexts as well and it's all around us all the time it needs to happen so the taking off point for a lot of the work that I'm currently doing with address on a team in the department of learning Health Sciences is this are doing that explicit knowledge is now being formatted more and more as machine processable stuff oftentimes including code which is ultimately somehow interpreted or compiled to get the machine instruction and so what I'm encountering in our medical school around this campus and I imagine you are as well researchers that throws their motto into a spreadsheet and then maybe send that spreadsheet to other people will use R or Python or some other technology to create a file and end point a result and represent that result a model or maybe use I or the web ontology language or I found you know a biopython other tool so I don't know this is types of flow from the machine learning world I don't know the tools that we're all familiar with and so they may not be represented here that's that's just an oversight to imagine the tools that you're using to create results that come in the form of something highly structured that see the Machine processable or actual code they could spoil down into Michigan inspections that's what I'm returning and as more and more of our scientific output comes in these forms on our package or an R file an Excel spreadsheet which by the way we find very problematic and so we're trying to come up with better forms than that you know Python code and these other things this is what we're responding to this is what we're reacting to we're thinking about how we're going to organize this explicit knowledge when it comes in these forms and what's different about knowledge when it comes in these forms and when you have a paper that's intended for people to read how should we adapt to that across the biomedical Enterprise for all of those users of knowledge the research uses the learning education uses the advice-giving uses so I think this is no small change are you seeing this change in their own lives and in their own work are you feeling this does this make sense that knowledge that you're encountering or producing we're generating is now coming more and more informed at our machine processable this the chronic that you're seeing does it make sense seeing most head nodding yes so so we're trying to respond to that we're trying to thank information science and information organization and now it's management's perspective I will respond to this change I think it's a major change and in particular our group has been working with with the products that come to us after research work has been done in Python or our or several projects where the researchers have worked very hard to take something and make it computable in the form of an Excel spreadsheet when they write their paper or they put a invitation in to readers of the paper if you like that model will set you send us email we'll send you our spreadsheet but we find that problematic and that that's not going to be a suitable way to share this knowledge going forward to working type of problem so when knowledge comes in this these in coded forms when this [Music] not suitable yeah so the issue that we're gonna have is I have a current project right now in neuro-oncology thank you for the question so so a researcher want to share some computational model or point scoring system or what have you and they build the code into itself once that excel file is let out as maybe a supplement or maybe they email it or maybe they put it on their web their their lab website we don't know that's gonna happen to it after that it's it's so did somebody then change it and pass it along to somebody else how do we version that how do we control the content in that what we're used to is publishing a paper that goes to peer review and becomes the paper and if you're going to make changes to it you have to publish an errata or something that goes along with it there's some control in the publishing world over how those changes will come about but they're sending files to each other we lose a lot of them and so we can lose track of any changes over time and we're very concerned about that and we're also concerned that the little or no testing might be done on these kinds of things and so people will quickly transformer or move from one use of knowledge to another so I may send you an excess bed sheet with a model in it and I may have in mind that when I'm doing that we can use it for research and you would never use that to drive try to answer a clinical question and then next week you know the person that receives that from you they may actually go back to it and use it in a way that you never had intent and so who's liable for that we're concerned about that who has the right to use these different things in different ways so all of this is unclear as we're sending Excel spreadsheets to each other to answer your question it's not specifically itself sharing it's not just little bits I was just a good example of where things break down if they break down in other ways and we're going to try to put some energy into the system to keep those breakdowns coming thank you question I don't have anything against excelent person I use it all the time but this purpose of scholarly communication we find Excel and other tools like it could be a Google sheet equally problematic and these are some of the answers I'd have to scare with your question what's what are the problems you know what are we trying to do well we want carry along with the knowledge that we share the scholarly communication that we do where we are such what a relevant assumption and we also if we're going to have technical artifacts we need to indicate to people whatever their your sink recedes what's special about that artifact how should it be used why was it built the way that it was and so on we need instructions on how to use these things safely again particularly if we're going to move them from a research context into an advice giving context topper test or another area that we're looking at we want to be able to call out identifiable or known biases in this kind of artifact will also encounter information about the identifiable and no biases goes back to your earlier forum limitations you know every paper that we publish pretty much as a limitation section we're going to have to think about limitations also along these lines and then past an anticipated impact so one of the things that we noticed with actionable now executable dollars actually call it the computable stuff you know folks wanna know who else is use this model and what have they use it for and what records what is the record of that so how are we going to help them identify others that have used something and what what they learned from using it so that's this idea of retracting who is using what and understanding person anticipated impacts and this is quite different in the library world there's a library world bribery ethics often times with direct that's not to collect information about reading one and so we have the other tension there if you haven't seen it I don't so nobody's seen this read the paper and a year and a half ago I think was in the Atlantic Pacific paper is obsolete I'm sorry about the bummer but burning up in front of our eyes and what I'm saying here so if you haven't seen it I recommend it to you and it points out you know why we're to this point where what we're doing with scientific articles is not going to suffice in terms of our overall scholarly communication and so they talked about a lot of these same issues it's the artifacts that are coming from research change we have to change our approach to communication so we're working on and trying to figure out a lot of things about how to communicate this kind of knowledge when it comes in this encoded format how do you document that version it how do we verify from a technical perspective the code that's they're tested and provide tests for it how do we document and share the performance of the code how do we validate it in future scientific work what about error handling if you've got a model that has a set of inputs and outputs and you can precisely tell someone this is exactly what you need for your inputs and then this is the type of output to expect well what if you don't get exactly what's needed a lot of work in the software world goes into handling the edge cases in the air handle but sometimes when we're building models and in the research where we assume for the perfect you know state which is that we're going to get exactly the inputs that we expect and nothing else so there's oftentimes worth if we're going to use these things and other contacts to make them more robust their code and add more code to them you have to think about how we would support some of these models as they become products for the long term integrate them with other systems and platforms license them handle liability issue point people to dependencies or otherwise help people overcome problems with dependencies or underlying code that we need in order to run the model that we have yes okay who says that the universe and programmers are currently with each other programmers are making bigger better programs of those so the work of knowledge management knowledge organization is to conjure chaos and we're only going to be able to counter it up to some degree right which I think that's how I'm interpreting your points there's what we're only going to get so far so long as we're not hurting people and we can maintain momentum in science then I think those would be good reasonably good goals we won't get to perfection so these are the things that are on our mind that we're working on let me just be clear about something when a journal says you're done when you have a link and github and you put your code there we're saying though that it's not sufficient okay there that maybe we'll push tab but we're saying that's just not going to work and I don't know about you but I've met many did hub repositories now full of interesting stuff where I just don't even know how to get started because you know the reason is essentially banker has a title and that's all and of course in context if you're working with the group that created that stuff you probably don't need that information you could probably understand what's there but the whole idea of scholarly communication is to transfer what we know from one place to another place or for one person to another person to transfer it you have to do a lot more documentation and we going off and see that it's hard it takes a lot of work and so it's going to change the way all this work and it's sometimes not the most fun work to do that this is what we're gonna have to adapt to so if the scientific field truly is obsolete the core that I want to spend about the next 15 minutes on then have time for Q&A the core message here is oh okay well it's not the scientific paper then what are we gonna do what are people thinking about what comes next and these are images here are some examples of things that I've put through in a minute so what's next after the scientific date and for this because I'm a pharmacist and I think all of you who actually rhotic a role for this I try I'm trying to anchor it something and have common ground with everybody and so does anybody by the way recognize this with that I'm looking at some in the back of the room right now it is Kathy all right so this is caffeine so that's in hydrogen and some carbon and tonight to Jim into market dinner some of these more modern drugs but we're used today we're used to this idea that you can molecular structures and that there's some fundamental underlying set of elements that ultimately get combined to form these structures so I want to use this as a simile so chemical compounds are like and this is where I'm coming to this idea of compound digital object so now in the library information science world and in the research world over twitter overlaps with the library information science let's say for example at the National Library of Medicine there are discussions going on about these things compounded to the live text sometimes it is called digital object and the idea here is to begin to take several parts and pieces and put them together basically create something that's akin to a molecular structure or information artifact now we don't have a periodic table but we can't begin to understand that there will be different types of information artifacts that ultimately come into these objects you may have binary artifacts we may have code that's in this case human readable programming code slides images waveforms audio cable because the point makes sense parts and pieces being organized and reorganized to generate structured objects that's really the main point I'm fortunate to have the cross train in pharmacy and information science because you know I can so begin to see what's happening in the information world in a similar way when I had my organic chemistry and all those courses long ago we were working with those kind of molecules at least we can give these objects structure we can set a standard way to build an object and what needs to be included in what are the parts and pieces and so that's what our group has been doing we've been pioneering some different types of objects and we have properties in mind that we want to achieve this like you sometimes do when you think about synthesizing molecules you think about their property but we're thinking about the properties of these objects and what we're trying to achieve with them to upgrade and improve scholarly communication as a response to having more and more different artifacts one thing that we can do not unlike chemical bonds we can declare different types of relationships that we can have artifacts that could be converted back and forth one to the other we can have artifacts that have that define other things you can have artifacts that provide values like a value set to other things and then compute using that value so we can have descriptive artifacts so we can actually using the Semantic Web kind of technologies that I'm sure you've heard of we can declare these kinds of relationships and we can build objects where these relationships are made explicit this is what we work on and we work on this because we want to make that there were objects findable somehow verifiable so we want to have kind of a checksum mechanism that you can tell when an object is out there that the object hasn't been tampered with or otherwise change corroborate ball we want to include somewhere in here provenance and other critical information of who created the object when for what purpose and why and how in particular because we're talking about executable code we're very interested in activating objects was very interested in running the code that we embed in these out there and so we think about that and then we're interested in interoperability I want to create objects that don't just work in one platform but work across many platforms so this is the tall order and the science the R&D that we work on is well how do you bear objects what can we achieve with this method all of these things I just mentioned you can kind of map them back to these various types of higher-level artifacts we can have a path service descriptions with our objects we can have version persistent unique identifiers we can embed and we are embedding software tests in our objects that not only do you get a snippet of code but you get some tests that you can run to ensure the code is operating as the Creator intended we can run this and put binaries in there and try to handle some dependency problems that way overcome dependencies that way we can include samples of data we can have statements about purpose bias limitation validation we can provide good instruction yes that's right so not unlike being presented with you know a whole whole lot of elements you know in different bottles and bins and trying to synthesize all of that so the binges in the information world is if we declare our schema and the standard for one type of object and also several exam then we can actually read software that will facilitate and with some pages automatically build these objects for us but the automatically good strictly because as I said you know some of this is going to require all of us to include additional information that we may not be including today in our scholarly communication and not all of that would be obvious and automated so when I get to the examples I think it'll better answer your question so we're building this on 30 years of thinking about digital objects and a key paper in this space was published in 2006 but actually refers to information in the mid 90s and it's this paper by kannan Lorentz the a framework for distributed digital object services okay so this is an anchoring paper in this field we go back to it more current thinking based on kind of women C's work and with the help this is how rethinking the Internet and it's perfect and so the rethinking goes from this idea that we've really got embedded in our minds a lot about email and the world wide web as happy host and you get web pages and email and things like that to thinking about the Internet as ordinary organized around the discovery delivery of information and okay so when we think about this problem of scholarly communication and we think about modern Internet technologies you know the idea of scale the idea scale this up in a big way and so others are working on this kind of digital object architecture idea I imagine we're headed for a world where we'll have a whole variety of different I would specified and well-understood types of these objects but that's what we're working on today all right so let me let me give you some examples too from the research data lines from the RDA well then I guess this is just about a year ago they published their current view of digital objects or essentially data sets and wrapping data sets with additional metadata which would allow those data sets to be used by other people that's the goal and no idea of a digital object here is a very general idea and so they say we're gonna have some good sequence of content in your adverb to have some metadata and other things about it to have some other data or information about its operations and you'll have a persistent identifier shows up in all of this work the idea is to have large ecosystems of these objects the same way that every pubmed article has a persistent unique identifier the same way that what gets published in journals has a persistent unique identifier same way to put through these objects will have them as well that's sort of one of the fundamental pieces of metadata so you see that in all of this literature so the idea of thinking a lot about data objects primarily data set out of Manchester in the UK Carol go role as a computer scientist there has a grouping and now first they need to be 14 or 15 years they've been pursuing something they call the research object and they build these objects and they have five points for them they have a specification of what goes in the regional traffic and it includes these kinds of things approachable publication one or more letters some results that are somehow described from the data to the result may be described the work some additional metadata describing the whole scientific process and some laws automatically from machine that were used in the process and bundling all that up and putting in a package and here at the sort of box is the box that indicates they're the type of objects that they're creating so we talked to dr. guilfoyle periodically since we're working in a similar space and we have some ideas our team can work together you can go online and you can find the standard that describes what is a research object and you build tools that will look at digital object and basically and you know indicate whether that meets their standards or not they build validation tool the research objects these objects are highly heterogeneous they could have lots of different things um we're doing this an interesting the objects that were pursuing are a little bit less so yes notice the parts and pieces to it and they give sort of this idea of an example and again they're representing over here they have a formal model of the relationship having six of ten files in a folder it's actually having files in a folder along with the description of what those files are and how they interrelate and that description is often going to be in RDF and machine consumable so that description itself becomes metadata that can be fed out into other library systems to support search and finding things and so on but that's important it's important to recognize those relationships between the objects between the essentially between the the items there of the object so in their case they're really responding to what I'm sure you've all heard about and talked about before they're really responding to this problem where challenges were having with scientific work and repeatability replicability and reproducibility so their main motivation for creating research objects and platforms that can communicate and manage them is so that research processes can be upgraded and improved in our scholarly communication is better so other people can verify I work to the weaken verified other people found and extend it and so they built these highly heterogeneous objects their scope is mostly covering information about research studies and they're really not focused very much on the execute ability to put code in one of these objects but their main purposes what about making sure the code bhooshan face-to-face as part of the communication not so much making it well making it run and what we're working on is a little different which is why I point that out so these are some things that if you look at that all's that you'll read about again just a reminder what space are we in here I've been here at Michigan we're responding to these new types of artifacts particularly when they're machine executable being the results of research work and so we have also specified an object that we call a knowledge object and this knowledge object also has a set of parts and pieces that are interrelated and give a formal model for these objects and so we'll have some edit metadata with a persistent unique identifier and a knowledge object ecosystem we will have some implemented algorithm some code maybe some pets and then we'll include also that we identify or the code context an API specification so every now jump type that we create carries its own API a specification because we're very interested in making it as easy as possible to get this code running and interacting with it so every every object becomes a microservice API essentially I mean put some technical details also in the deployment specification so we put these files together again following a structured format like a standard and we create what we call a knowledge object this is part of a larger project and I'll show the software here as I end up with a brief brief demo happy to talk about it more all the work that we've done is represented the key gorg and we call our project of knowledge grid the idea is ultimately to take advantage of the Internet and have these kinds of objects moving in a fluid way throughout the research world and beyond so we're building objects like this we have many examples now and we study the project where we're taking these kind of objects into a project working with folks to do predictive modeling you can do other kinds of work where they create or generate this kind of machine executable knowledge artifact and then we're working to help them manage that overtime version and keep it up to date and so on so key thing our key commitment in the knowledge field which makes these knowledge objects somewhat different from the other compound digital objects that we're seeing come into the world we think about this process of activation our commitment is to look at the static objects as resources at the same time every object in this ecosystem that we today because has this API specification activatable we should activate it and get a service so every object can be thought of as a static resource also is an enabler of a web service and that's the exploration that we're doing that's the R&D that we're doing how do you build objects like that how do you make them work at scale and so on this is a general need in order to get to these kind of micro knowledge services and so that's why we're on this path the department of learning Health Sciences we think of large-scale learning systems and so we think of this technology the now it's great as support for those kind of large scale learning system which are coming about in the world so we hope that our timing is good again now the objects are a little different than research objects or the more general digital objects used to tear a data set perhaps we're interested in externalizing and modularizing the kinds of knowledge that ultimately can be used to generate advice in EHRs for use in a classroom for education purposes or use to propel research and evaluation so externalized modular eyes get a service or an api these are the things that we're going for and so in order to do that that should well actually I should say moderate you could have had a abnormality we don't have as many different types of things in our objects as they do in a research object our scope is not so much an entire research study as it is some battery or collection or module of computable knowledge and we're very much interested in making these things executable very quickly and as easily as possible without the personal encounters and having to do a lot of technical work so that's those are our goals so you may get from these ideas that are two projects the research at the project and the now that the project manager basic about results one where we think about the results and you can imagine a future carrying one or more now so these things can work together we're not in direct competition in that sense but some of our projects that we currently have going on our packaging predictive models for chronic kidney disease that the project join you here in the medical school and so the models actually be created in China on a large data set there and then the idealist to ultimately declare them to generated bytes and patient care we provide epi for a bed ranking algorithm in neuro-oncology so this is a set of researchers cheated with created an Excel spreadsheet they now want to share that with eight other sites around the country they knew a different way to do it that they can control our version test and so on and sort of helping them upgrade what they dot with a knowledge object method providing api's to do EHR integration for risk or in in OBGYN hysterectomy in particular and then combining preventive service computable diet computable with utility models of the value that you get from doing these preventive services as an individual and giving individualized guidance these are the kind of project that we currently have let me finish with a brief demo so in the space of clinical pharmaco genomics and genetics there's a group at memphis and stanford federally funded called seat pick anybody hurt or worthless you know they attended sits in the pharmacy and pharmacogenetic area - Russ Altman at Stanford you may have heard of as part of this group and what they do is they create guidelines and so they're helping us understand how do we go from genotype phenotype or certain genes and enzymes and then once we know phenotypes how do we go from phenotypes recommendation so they take the basic science they bring people together in groups and they create these guidelines that are really intended to take this science and apply it in practice and findings here provide patient level advice and so now let me go out of PowerPoint told you I'm totally right up here in the middle and now I'm gonna go over to a website where this material comes from so we're working with this group they're Memphis as I said they create guidelines so this is our website today you can go here see all the guidelines they have different drugs and genes we'll look at one today we'll look at one for SL co1b one in Tim in the drug simvastatin so here's what they create so they created a PDF human obviously human and readable publication does get published in inter and all those tables that I just showed you are a slide this is where they came from so there have it that trips around the country around the world wearing clinics and hospitals will find these PDF will go back to their home institutions and will somehow take the knowledge of tier and encode it into their electronic health record systems in order to improve read selection and drug dosing and they're hoping that that pretty much happens at every place where the EHRs being run and of course that's a big challenge and will take a very long time so if we rely on that way of sharing this information which is our current practice okay it's gonna take a long time to adapt to this sign so how can we do better that's the kind of thing we work on so we've taken on pretty much every byline on their website and every mapping table they have from genotype information and we made it computable thanks so we've taken it out of the PDF and we've turned it into pretty straightforward software and so what you're seeing here is the end result of our having done that so imagine you have a patient and now you get some lab values back and now for all the drugs that are on that see pic website no longer relying on the tables in the PDF we've just made the lookup automatic very simple straightforward not difficult to think about how you would encode data do that this is pretty simple mapping and if kinds of statements but we're trying to make this information much more actionable apply this now it's the patient specific cases in ways that you really can't do with a PDF that's this more idea of mobilizing them so this way they would come from the lab good question so and what's happening today in some advanced site is these three that are coming in a coded form that is reliable from the lab and they can automatically be processed by computer to get to the recommendation or they get to a report them in many places that's not the case in many places these data are coming back from the lab and a paragraph right where the lab sent back a result but it's not computer directly computer processable without a lot of help and so I'm going to keep that the barrier that we have to overcome so folks in pathology post in primacy folks in the basic science here are all getting invested in how can we take some of the friction out of this system and make essentially happen the way you describe but at most place to say it is not happening I wish it were happening the way you describe here at Michigan medicine not yet but people are working on um this is what the peptide that shows where once you have this this computable knowledge here's what we can do with it um but this had all of a knowledge in this app all this explicit knowledge is actually kept in these objects and it's all GPI driven so any app can tap into this that's the point not just one app so the app itself does not contain or encapsulate denial here Oh an API store what about those API so this is prototype software that we've created women are essentially Arab for this work in the now this is a library concept for now adopted so you're looking at essentially a digital library concept of the future each one of these items is an object and to save time I just queued up the object that I'll walk through today greasily so searching for simvastatin I find this object in the library and I can open it up and the first thing you encounter in this prototype is something that looks a little bit like a card catalog card back I'm just some very basic metadata here also a link back to the original page where that recommendation came from so we want to as best as we can take advantage of what the net allows and connecting but also in here and that bird your up spectrum of etymology object is all represented here and go form we have a variety of parts and pieces one thing that we have some some actual human readable JavaScript code representing a part of these guidelines but then we also have an API specification I mentioned every object that we create one they could also remember with service and so you have to have the code in a CI specification in the object that's how we go our object once I do that and I have all that information organized in a particular way suppose you're really a question about how do we do this at scale and how much work will this be and so we're basically saying is if systems could begin to produce objects that flip this standard then we can potentially gain some efficiency and so one of the things that can potentially being this being able to pretty quickly run these items here see this is what happens when I think and I won't waste too much time I'm kind of push this item over to out of the library over to I think I have have one little issue that's not working there um so I'm not going to get an attack I'll stop here but the idea is to show you the API that goes along with that object so what happened is as I was setting up two or three times on another computer I didn't quite get that right but in a case I'm not to troubleshoot in a moment what happens we basically show that you can pick what's in the object get to the API and now you have something that can be integrated yeah yeah so if we're talking about rules and rule sets they get managed in one way in the world if we're talking about other types of computable artifacts so predictive models for example I need to be calibrated and recalibrated over time and you may be referring to something like that in our work with the folks in pediatric neural oncology they have a scoring model new drugs are coming all the time they anticipate having to update their model three or four times a year and so one of the benefits that we want to show with our work is that we can create tools and tooling that will allow people to more easily manage the update process and push out new updates to those people who are consuming without their yeah absolutely there there's a lot that we have to learn there so in the clinical world there will be many concerns and there will be a very high bar before people let me push encode into their system and that's a good thing we're going to have to come up with ways that people can trust what the produced understand its source where it's coming from perhaps subscribe we're thinking about publication and subscription services that would have let people subscribe to one or more objects or a collection and then when anything is changing in that collection be notified of those changes and they ultimately decide for themselves how they want to handle those you need enough people missed and make it a more efficient how are you gonna get that buy-in yeah compression so so the good news is that we've already got a start on that so this group that's the meeting at the National Library medicine would be the third summer this year it's about 150 people and that major stakeholder groups are represented there so we have folks to do data science work if folks are in the library there we have folks who are thinking about the ethical and legal and social implications of these kinds of artifacts and changes as they go through the world and so that particular group also we have people from industry as you would expect and otherwise so the work that's going on there is to set standards and begin to make this you know this kind of thing that widely available build that kind of buy-in that will ultimately have to have you know if we're going to be successful my sense is that our knowledge object may not be a winner we're Rd you know we hope that it's useful but these objects one way or another people will be creating these ecosystems for these kind of objects I think that path seems pretty clear but who can build the best object you know that's what we're trying to do that's part of the work yeah I think it refers oh you know come from digital objects is tostada an upstander by the for management but I think another way that we usually use is organize those things BIOS model questions Molotov a thing related to that question together like in chemical molecules we sometimes sometimes care more about not only that each of the elements but also care about the functional groups though I guess how do you think about like organized by topic yeah so actually I think there will be many dimensions that we would need to think about the organizing topics would be one maybe not the only one types might be different types of objects might be another one so we think about we use oftentimes we go back to metaphors and examples from the library where that already exists today so if you think about special collections in a library where people curate and manage and bring things together for particular purpose that may be somewhat akin to what you're talking about it may also be the case that we find that several different types of objects always you know need to be used together like a functional group so independently they're not as useful as they would be if you had three things working together for example so those are lessons that we we are learning along the way trying to figure that out apparently when I came over here today the work that we're doing this morning like right now is to think about collections of objects and how would you describe a collection and how would you describe the logic that drives that collection it will cause that collection to come to be yeah so you said those like github is not sufficient I think the communities recognize that and they create things called docker yeah kind of encompass the cold and the environments and programs necessary yep you see my file Python um where does that fall short yeah so compliant containerization strategies like dr are also very important and we've done some work with containerization as well we still when containerization may not be sufficiently attending to the library use cases that we have in the curation cases so having a container is great having a container that it's a part of a larger object that has the material with it and a persistent unique identifier and somehow gets peer-reviewed and published in the future state there's a different thing so it's another one of those I think that's the containerization story is important then they help with overcome many dependencies if we can give people you know the necessary software to run different types of objects we in September we work with a group and at the University of Indiana Medical School on some machine learning models that they had and we use the containerization strategy for that another concern that we have with the containerization strategy is security concerns and so when you when you about all of these different technologies into your technology staff or otherwise into your objects you're also adopting you know any any security gaps and other things that are there so so docker today over on the other side of this campus in the hospital I don't think it use very much because they're concerned about the security of it