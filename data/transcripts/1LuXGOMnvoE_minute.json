[
    {
        "start": 25.38,
        "text": "I think everyone actually signed it if you didn't do so cheese I'll bring it to the back with me but as a reminder is just also to the reminder we do have people watching remotely so if there any questions are asked on lab we'll try to also if you ask any questions they try to speak out to help the room microphones that way there's a little bit better so I'll introduce today's speaker we have Walker inside the stuff "
    },
    {
        "start": 87.57,
        "text": "that our lives been working on like was just because we do a lot of phonetics even though that's not fairly the quarry okay so you start out with just a couple of slides introducing kind of the problems that we work on and the kind of biological technologies but are developed in our lab oh just so you get an idea of why I'm informatics necessary would you begin them so you start off with this kind of very simple idea of all of modern neuroscience trying to accomplish that's understanding that in in this case the mouse brain at all millions or even non-mammalian grades they're capable of these complex integration calculations where they took in all these different types of signals in this case now I have a couple and then 15 there's a bunch of different health right so you can hear what I'm saying you can kind of parse that information and you can do maybe "
    },
    {
        "start": 147.9,
        "text": "later on go and download one of our tools if it helps you here and so how do the 71 million are on that make up the mouse the most nervous system how do they work together to do these tenders and so to do this kind of need to understand what the parts list and how that works listen together so essentially like if you've taken an introductory physics class right you know that this is the diagram for like a very simple like your circuit you know you have a battery resistor a capacitor but when you close the the switch here it will charge a capacitor and then it'll take it in that it will the charge on the capsule okay away convex initially and create like a time dynamics or something right but the only reason you're able to understand what a certain diagram like this does is because there's a standard set of abbreviations that that you know if you didn't take it for this class in class well know what they would be so in in "
    },
    {
        "start": 210.42,
        "text": "our lab we're interested in how we can build a map of how the neurons connect together it's a little similar in sentence to this diagram but rather than sending electricity obviously through neurotransmitters and so in a similar way even in this you know cartoon diagram as well as this this very well drawn out one you can tell that there's a bunch of different types in there and so you would expect just do to know the biophysics of the situation that each one of these cells is going to respond differently it's going to have a different set of properties okay if you want to understand how the nervous system works NECO know the morphology and the parts list as well as the evening and so um this is kind of very well summarized in this and it's make care where it's describing how you can categorize inter neurons and neurons that operation and "
    },
    {
        "start": 271.4,
        "text": "they can be categorized basically using these four properties morphology connectivity so how they're shaped how they're connected like I was talking on the previous slide as well as cell type markers and their properties and in an in our lab there's basically someone working on every aspect of this but the stuff that I'll be talking about today again and so we ask the question can we build a better tool kit for to find the wiring diagrams and morphology of neurons so to do this I'm going to tell you about basically four memories the first one is how we use the technology rainbow to do high contrast spectral neural imaging um this is kind of the one biological portion of it just because if I don't introduce rainbow you'll have no idea what's going on for the rest of it then I'll be talking about a paper that published last year about a tool called increaser which we use form the "
    },
    {
        "start": 332.04,
        "text": "quantification of the images producing number one then I'll talk about some very recent work I've been doing creating a Python API or for analysis of data being generated by a tracer because I look at into these who are kind of explicitly and then finally I'll talk just for a couple of slides I had to shorten this just to make sure that I could fit it within the hour about Neptune's technologies for hydrogen engine look the time ongoing work that we have basically speeding everything up or next generations and so I'll start by saying that you know doing reconstructions of nervous systems that have happened before you know literally symptom so I'm not quite a century ago but for a long time we use electron microscopy to understand neural structures just because it gives you a very fine resolution so it gives you high resolution contrast and you can see down here these are individual axons um it's very easy to find fanatically "
    },
    {
        "start": 394.11,
        "text": "separate them out because it's very quick on you can see in these in these images that prolongation membrane would get a very very dark line because of the difference in electron density and so you can create very high resolution maps but I just anyone who's ever tried an electron microscopy x-ray tell you it's very expensive it's very complicated because you have to in this case section you're actually their sample so you have to actually physically slice it into onion pieces nothing on films image each girl and so even the best tabs in the world can only work on very small scale so to put this in perspective this figure is actually a little bit outdated because there is a paper like a month ago that that keep this finally by a little bit in the house I'm starting to get a library system but in the mouse current system the largest like human annotated the largest human annotated a volume of nervous tissue that that are been "
    },
    {
        "start": 456.08,
        "text": "published is that original Q when this animation started and you can see that at this scale where this is the mouse gray this is the Kuban brain that initial cue is so small that it doesn't even render as a single pixel so basically that gives you an idea that there's a scaling problem and how these how these problems have been addressed previously because again you know when you're looking at this initial edges nature paper that I alluded to that contains 89 so most of 89 cell bodies of neurons and then approximately 50,000 processing so axons and dendrites that are projecting through that volume and um that that project took like six months to do and so that gives you an idea that electron microscopy does not feel very well to the levels no creating a map of house so "
    },
    {
        "start": 519.56,
        "text": "come alternatively light microscopy is another another obvious solution it was it's been used for as I was saying centuries the fact engaging fingers among all those we're doing mapping of mapping of your on morphology like that drawing that I showed you very early on was actually a positive several of the drawings from some peas and it's very simple because you know even in an undergraduate undergraduate lab you can create slides of a neural tissue theme and put them under a microscope and do it you didn't have a set but as you can see by by this image here they probably run inches conference so when you look when you look hearing out like kind of lunging in cell bodies and as the projections come out of the cell body so you can tell anywhere that they cross there's an indicator so anywhere "
    },
    {
        "start": 579.6,
        "text": "that one of these working for agents comes out to intersects if you are trying to come up with what the structure of this neuron is you might accidentally you know go to volunteer action because there's just no way to tell those apart at the resolution that light microscopy operator because obviously the diffraction so how how find the physics of the resolution can go this one is different between an electron beam which is very small thank you perfect I looked it in energy versus a optimum and so um it basically the limiting factor for doing just trying to knock anyone light my cross microscopy is the opposite of where electron microscopy it so didn't sleep there so information tends that you need to have you know teams of people working or months to produce the samples right here it's very easy to produce the samples but II put the imaging is good and so "
    },
    {
        "start": 642.899,
        "text": "this is really well well described in this paper from late last year in our archive where a group from the island Institute which is kind of one of the leading groups doing this kind of neural mapping work they this is just one of their summary figures from the preprint they mapped out 96 different projecting neuron pathologies and to do that they actually had to they had to kill I believe it was accidentally good about the same number of mice so they have to kill about 109 so the number of cells that they are producing per animal is only one and so this gives you an idea that a very low truth but because you have to choose things so you have to stain the morphology so sparsely as to not have these nervous problem I showed you in so that's why you here like this not it's very easy to tell where where it's projecting to but it has to be physically separated from the sister neuron but you don't have "
    },
    {
        "start": 704.42,
        "text": "that and so to to do that our lab uses the technology offering of where in those previous images there's kind of like one color of labeling in this case it's shown as green but it could be you know any color that you choose before there's a time for it and it's open Brainbow rather than using one color like green beep we amplify that so we use three different colors and kind of like a more traditional and that three three different posts will gives you three different possibilities for the neurons to neutral pair house and then when you multiply those together because they're not mutually exclusive right that gives you a total of seven different color combinations right so you can have jr. on then it's depressing green blue or red or you can agree to blue or move ahead and so and so and so what this allows us to do is take images that this is this I just kind of like pseudo T saturated rather than actually this being the color of the emission and "
    },
    {
        "start": 767.779,
        "text": "and where this is a soma and you can start to see that this problem of intersection where you can't tell where things starting in and in terms of in something like this even just projecting it to the you're able to tell here you have a red of itself it comes down and branches down here and this projection for instance is others saying you know that it came from another neuron this is it touching rather than rather than a projection going the opposite direction and so um this is what what dolly did during his postdoc is an optimal technologies and and it allows us to do this neuro imaging at a much higher contrast and much higher density and additionally all note that again we a graduate student who just dependencies from undergraduate student work on from Riis English the second option so now you can you know you can have four "
    },
    {
        "start": 828.84,
        "text": "different or different colors or in different colors as you will do create this shoe you can have any different colors which you combinatorially combine to increase this this color complexity even further and just like traditional you know in information theory and computer science because these are linearly independent you think of it like the number of bits in a word of a computer memory and the more of it you have the more things you're uniquely able to identify right so if you have you know 15 different colors you can have 15 neurons that are physically touching without having any sorted or without increasing theory have a problem under coercion because housing ambiguity so um additionally as has noted in the title it's a just a plain bow that expanded during those issues here's a technology called expansion mccroskey "
    },
    {
        "start": 889.23,
        "text": "which was originally energy hey Mouse tissue samples this is just a diagram of a characteristic experiment where you take mouse tissue samples you embed them in a hydrogel so this is this is similar to kind of like a cello if you think about in terms of its systems either of the pipes of the street but you would you embed it in a gel if you hydrate it so you so you increase bonefire you decrease that you can trace the salt concentration so that the water flows into the job and that gel physically expands so you can take a mouse he's not a shoe maker physically expand it and be able to image it at a higher resolution because now the proteins in the gel have been physically pulled apart so by combining these technologies with with rainbow we're able to get not only high contrast in color space but also high contrast in visible space as well as using this "
    },
    {
        "start": 951.48,
        "text": "technology called me reacts that friction again another we can compile other types of antibodies in this case deferent assume to mark in this case the Naxals but you can use it for assault type marking as well so in this case be a TV and a pendant are two different types of neurons felt there - neuron cell type markers that kind of third column I showed you in that summary figure earlier and so we can identify using the combination of this and this what the cells are expressing how they're connecting to other cells through this kind of staining as well as the rainbow to get your mythology formation and so I'm gonna show this image just because it's it's really impressive from from right and essentially you can look at these images and they have both a you know X&Y "
    },
    {
        "start": 1011.69,
        "text": "dimension but they have the Z dimension as well and so the problem that I'm going to be addressing for the rest of the talk is how do we take these these huge dimensional data sets and quantify them right so so it's really nice to look at this data but we need to be able to get some sort of qualification out of it and reconstruct specifically apologies know so the challenge is presented there of going from the raw data to see sort planification first is they get to coordinate the display of four more colors so this this image specifically is actually only using three for the frame though but even close there's more complicated types of rainbow very alluded to earlier you can have you know four or five or six even more channels that you need to be able to display at once now it's really easy if you have complete map it on Jill you know RGB and and it makes sense to the hue hi but once you have four channel written about network that's what the channel do we "
    },
    {
        "start": 1073.31,
        "text": "need to be able to store these structured annotations of your images images and specifically they form kind of branching connectivity Maps so much like computer science I just love neuron instructors can you represent those trees as you have and but what when you look at the tools that are out there for Hannah cheating by mental images they're not built for imitating trees that both imitating lines or squares or you know putting points on your so you need to need to deal with that and then finally you need it to work inside of a kind of dynamic human processing toolkit because even though these images look really nice when they're and they're all done before you can use them for science you have to go through a process and crop the images and if you have to do more program to managing align them together so you need this tool that you're using to be so um leading directly meeting "
    },
    {
        "start": 1136.94,
        "text": "them from that I'll tell you about our tool in tracer that so essentially what interests are is a plugin for a piece of software called the PG if you've ever done image analysis you've probably heard of it because it's kind of like the golden standard for open source um and so increase or is a plugin for PG that allows you to do this sort of structured annotation that I was telling you about that's not going to go so these are just kind of keywords but you know it allows you to trace edit visualize and organize these annotations so because if you thought of inside of Fiji when you launched it up you get a window that is literally just as well as a couple of utility windows here this is a memory monitor and a contrast control and then these two windows are PG windows that show you your your raw data that's your maximum projection of your "
    },
    {
        "start": 1197.059,
        "text": "raw data so you can you can do this basically actually do your annotation here and it's a little bit better picture in so there's a process and then you can find the same process you can see a little bit more of it because this is adding in the frame fare above and below and then the the book of program is this window column right here a few traits are the Falcons number one um it allows you to do all of the stuff I just mentioned and so I'm gonna walk through just real quick so first up here you have up you have this bar it because I made the windows small to it to make it aspect ratio wise fit on the screen I'm just going well it starts to cut off the text so basically all these Care allow you to label them and I think that you are tracing with interesting next "
    },
    {
        "start": 1260.39,
        "text": "you have this box right here which stores all of the tracings of you that you are either in progress of joining or have completed and because it is a tree structure he uses a sleepy the Java file viewing file viewing plug-in um we're we're normally this would be used to show like a file structure book because file structures are just a type of tree um we kind of co-opted here to give a nice a nice interface for rolling through these races and then you down here if you click on any juice or on there's all these different all different labels here these are these so month layers that have been traced so in the cell body it treats the cell body as a volumetric as a volumetric object so these are all of this important that you have traced which I'll show next you have you have this table which shows you "
    },
    {
        "start": 1320.69,
        "text": "again the points would be traced to the track of kind of where you are and if you need to skip back and fix something you can click on it here in the table and it'll skip up your image and your your editing tool back to triple point you click on you have a panel that allows you to actually do the editing so so all of these different buttons map to all the operations that I've told you about post-war as well as you know jumping around the tree so if you want to find the last place that you that you have like having finished the tracing you can use these buttons to jump that point or buttons like which we'll go through and try to autocomplete the soma mayor that you are currently working on there is tools to change the display the display features is there uh because as your education we want to be able to see kind of where you are where you're going "
    },
    {
        "start": 1381.11,
        "text": "where you're going with the tracing and so by changing these overlay so it changes the content all the different calipers and and such to make it easier to you as well as there's some there's some kind of like gift antim earth gift and export tools that I'll show and there's a couple slides that he's also modifying and then finally you have the parameters for the actual algorithms underlying in tracer which I will talk about in just a moment and these these parameters allow you to to change the behavior finally to deal with that that problem I was saying of dealing with three or more channel images you can select down here this first tab allows you to identify which image channels wanted to be doing at mon-sol which image channels to look to actually use or the calculations as well as in this toggle and use choose each channel that you want you to switch between you so "
    },
    {
        "start": 1442.46,
        "text": "that you can map it to a hotkey to only show a subset of your very image and then you know set the color so to actually use the software um you fired up on you or your image you perform your pre processing using whatever eating tools they are they say you need because there's a plug-in library of literally like thousands of different software to do different space or direction um you find a location on your under cell that you want to that you want to trace you control click on it and it does this thing I apologize this came through the translated um it just was been called a neat so it takes a box around this panel center of mass of the and then it shifts "
    },
    {
        "start": 1505.799,
        "text": "the square so that it tries to find the highest intensity kind of centroid so that's what you have right here this is the point where you theoretically click and then it shifts over here because that's where the actual me right is and that's where the center of mass same thing is anything down here with this so basically once you have your starting point I apologize it doesn't show up very well and projector there's red box right here where the white arrows going up you click on another point and it does the same concept B premise it does it solves the path between the start and the end point using a maze finding algorithm so it uses the a-star algorithm if you encountered that in a computer science class and then you basically just repeat the process that a question um and usually just repeat the process so you go click press s complete the process so so boy once you're done you "
    },
    {
        "start": 1566.76,
        "text": "hit the complete button which was in that which was in that user interface I showed you a month ago and it goes during connects the the last one he tries to do the first point you traced and and in this case I've gone all the way around this all the way around this layer so now I have this state in New Zealand it also supports manual tracing because since VG is again a general-purpose in mid processing platform it has tools to just kind of freak and for all on your on your data so we we come up one of those to basically allow it to just eat it with your mouse or if you have like a drawing tablet or a touch screen computer you know there's trace along to the outside of the soma and again press press s and it will that you know convert this into a volumetric representation and and basically as you do this they show up in this stoma panel like I was saying and well what I did just for this for this example I took this image this is "
    },
    {
        "start": 1628.68,
        "text": "the first one that I showed you so it shares up a Z level 59 because it's basically image slice 59 in this in this image stack and I repeated it for a bunch of them and very quickly even just I was doing this freehand with my mouse so that's why you see kind of like irregularities you can start to build volumetric representations of your data in this case just so um as I've been talking about up until now you also want to be able to track them to track all of the processes that are coming out of this so again I apologize for the appearance of the red but there I this example have clicked on the edge of the summer right here there's a red box that appears and clicking further down there is a box it appears you you can hit a hot key in this case a and it will fill in the gap between those two points and you can repeat the process to trace all "
    },
    {
        "start": 1688.89,
        "text": "the way down here again I apologize about the red on red because it and as you can see in this in this process it kind of comes down this way and then it also branches off this way to the left so in this case you can go you can kind of backtrack and double-click on the point right here where this blue arrow is it will jump back in the table to where at that point that you traced floods and continue tracing in this case to the the left by repeating the same process and then as you do that it will obviously ask you if that's what you intended to do but it'll start to create this branch structure that I heard that that you want to build and so in this case there is the you can process the kind amount this way and now we have another process that's coming out here to the left that's being represented by 1 1 2 where this is the entire con this is the first branch of the first neuron "
    },
    {
        "start": 1749.01,
        "text": "this is the first branch of the first range of the first branch and then you can do repeat this as far down as you need to go towards represent some of these very complicated some of these very complicated trees for some of the more complicated Guinness that's I I won't be showing you today some of these can go out you know many many many and it's so since I've joined the labs a lot of the development of interest that was done before I before I started I've been working on adding things to increase her to build this piece of software that we're calling entry search well you know typically the first one is I've developed some changes to the Fiji input-output system so because these images can be very large as you would imagine they are represented by essentially n dimensional arrays where you have X as one dimension wise another dimension Z as the third and then your color space as your fourth channel um these images can get very very large especially when they're they "
    },
    {
        "start": 1809.85,
        "text": "have to be basically stored roughly uncompressed um traditionally if you load a file into Fiji it will do one of two things it'll either load the entire thing into RAM and make your computer very sad if it's very large or they'll do or they'll do this other thing called a virtual stack where as you're scrolling through the image it will try to read individual slices of the image now this is very good for your memory use you know you can run you can open a really big image on your laptop but it is very slow because you have to basically open the file every time you change your position so we've been implemented some changes to Fiji to allow it to use kind of a first in last out or first in first out back to cache the images as it's reading through them so if you're scrolling back and forth in the same region of the image it doesn't actually touch your hard drive at all it just reads it from this additionally um I've "
    },
    {
        "start": 1870.36,
        "text": "implemented some algorithms to speed up the visualization so this is that same image I will show the earlier after it's been traced by traced out for every process that appears in the image you can see that you start to get this very this very complicated coloring that appears this has been maximum projection so it's showing like everything the image at once rather than so it's showing everything in the image at once rather than just showing like a certain to exaggerate that effect but to actually draw this image the computer has to reprove the entire entire Z stack because it needs to know what the colors that that it represents these lines at and so by rewriting some of the internal code there is kind of some more in this interest in 2.0 there's some smarter logic that goes through and subsets out the portions of the image that are important so these high intensity these high intensity regions of the tracing and compiles them down to a hash table which can be easily distorted memory "
    },
    {
        "start": 1930.82,
        "text": "even for very large images because the actual information density of one of these relatively low compared to physical dimensionally so additionally as I was showing you earlier we have the ability the Costain or synaptic markers so there's software tools to go through and automatically identify these synapses so be very impo synapse pairs though if you've ever seen a picture of the synapse you know they come in like this and someone's marking one the other ones part together we have new information this is just an example of the distance between these two between these two synapses but the there's also new logging tools available for measure color diversity and things such as that as well as new visualization tools which I'll show you just in a I can convert eyes image beauty so up until now everything that I talked about was kind of like already published ish so if you "
    },
    {
        "start": 1993.01,
        "text": "have any questions now would be like a good proportion image segmentation which can't be traditionally nomadic yeah yeah so our lab actually has some doing work on that with a group who was previously a postdoc and now is a professor Kate don't we haven't we have thought about that but the deluding factor is that a lot of the traditional convolutional neural networks don't perform very well at like high spectral capacity so taking off-the-shelf components and trying to do this turns out to not perform super well oh yeah we had we do have some like more customized approach is using cycle games that do perform "
    },
    {
        "start": 2055.24,
        "text": "much better but they're still kind of in nascent States so it's not something that you can use today it's still in development the the other consideration is that for like electron microscopy data there's a group at Google who's working on they call it's like filling networks they're a convolutional neural network that processes through the image in a inner of a current manner so it takes a section of the image tries to find boundaries of neurons and then scans through the entire energy on this but um for one those those programs have only been shown to work in the in data and for two they're also very computationally so the only people who have actually been able to use them are Google because they have basically unlimited give ability even and even then it takes them months to do us in gold so pushing about the point back to "
    },
    {
        "start": 2119.68,
        "text": "the data collection the extension microscopy technique and just the challenges of that I mean is how hard is it to control that for the distortion and the rate of expansion if you want to compare across samples on this so it's been shown that the distortion is actually relatively big basically the way um one of the ways of us can show is by taking taking images that weren't extended and we're just processed through like super resolution so carefully were like Stormers dead and comparing that directly to image are the same kinds of samples that were processed into microscopy it turns out that if you measure a lot of the dimensions of for instance actin filaments they come out the same between those two methods um it turns out that at small scales because this expansion is so as a product if there aren't very many distortion effects as long as you control for like be actually physically working though maybe you just have to be careful in and handling it to Notley actually rip it or actually like it's "
    },
    {
        "start": 2182.259,
        "text": "very element the it basically comes down to the same concerns apply for handling these types of these types of samples as if you are just handling very thin slices they're just something that's been routinely done for me with the changes that you that were made to access random access that these images they show that they're they're very promising but that's after traces of already the data but the big bottleneck is actual creation of of the traces of which require a lot of access of the images yeah so there's that like don't look too little too late almost that that's a very that's a very valid very valid might I don't have any quantification of it just because it's it's so much more because it's like you're you have the human interaction it's very hard to like on I in a meaningful manner but because it's using this this first-in first-out structure what we often find is as a "
    },
    {
        "start": 2245.559,
        "text": "human doing the data analysis you'll scroll basically back and forth and the thing regionally a lot because you're trying to find basically where something starts or something you'll scroll you'll kind of scroll through the image I I scroll back you know make sure you're correct and then actually start doing your data and so in that operation it does end up being cached because of the first time where you're just kind of quickly scrolling through it sees the regionally it buffers that region and then when you're going back and skipping back and forth between different deep frames those have already been read in because during your human overview you've read through that region in a true first-in first-out arisen hilary it's so so the version that's implemented right now is first in first out I have some like more clever implementations that turn out they'll like it depends on a hat you basically have to tune them or percent and actually make them faster so it turns out the dummy implementation ends up performing much "
    },
    {
        "start": 2307.68,
        "text": "better than something more complicated but I've explored how do you interpolate continuous values over the z axis so in this case it basically just desperate eise's everything to the XYZ grid oh and so if you notice in the tracing tables all of the coordinates are recorded in X um so it's not interpolating so now I'm going to be telling you about some stuff that I've been working on very recently and in particular this this kind of Python package that I've been working on called increaser Pi which is as you can tell by the name a pythonic station working working name if someone comes up with a more clever name so um basically I've been telling you about how we go from raw data to this kind of tracing "
    },
    {
        "start": 2368.46,
        "text": "again this is something writes recent paper and basically this is just plugging out all of the traces that we're done using and tracer on you know X Y and x/y access services in production but and when you and I look at this we can you know try and try to make some sense of what's going on here but to actually do anything no statistically and rigorously meaningful you need to be able to turn this into a qualification that can be no compare using whatever method you choose and so in in tracer that those of those features aren't aren't actually built into the software itself and traditionally there's basically like two software that have been used to actually do this kind of market metrics the biggest one called el mejor was developed at like what was last like readily updated in the 2008 and it relies on a version of Java 1.6 that is "
    },
    {
        "start": 2428.82,
        "text": "again not been updated since about that time and because of that it can do simples it can do simple analysis like how many the number of branches in the file that that we export from interests or it's called estimates deepali make sure it's just a linear representation of that tree structure um it can do simple calculations but it's it's very it is it's hard to use and just very it's a piece of software so there is a there is a updated version of the same idea from the Allen Institute group that I showed you did those long range projection projecting apps that earlier in my slides they actually re-implemented that entire software in db2 use it for their data set because they couldn't get it to work with theirs in a standardized way but now that that piece of code has the same problem where it only works well if you're using it with their set of tools and there's very "
    },
    {
        "start": 2490.83,
        "text": "little in Turkey hat ability I'm gonna interject and this is why we teach by automatic students oh very good pointed and honestly my thinking about this was actually motivated by the way that you explained your thinking so it is a very very and and and so in addition again if you go through the effort and we actually have scripts basically set up to convert our file formats into something that these other tools will accept which is how for instance this this graph was produced even though we're able to do that fairly easily it's just kind of a data processing task you still have this problem where we're our representations as I was showing you we treat the cell bodies as having a volume so we treat them as a volumetric tracing and whereas most other previous morphometric studies actually didn't acknowledge that Stelter that cell bodies had volume so they they basically fit a sphere to the cell body and so we "
    },
    {
        "start": 2554.19,
        "text": "whenever you try to calculate the metrics so the surface area or volume of a those metrics come out completely wrong because they don't know how to parse this kind of more complicated implementation of the swz file so to deal with this I've been working on a Python library that allows you to do all of those different things much cleaner interface than using a command line Java tool from 2008 and and so basically I have just a couple of Python notebooks that'll walk through that if you're interested in API development my artisan interest in this case this everything is encapsulated in this thing that I have been imported here on but that's actually an arbitrary arbitrary name because I've imported into this new space essentially you're able to import the file just by calling calling it very simply it you know has this kind of internally this very complicated data "
    },
    {
        "start": 2616.78,
        "text": "structure that's being used by tracer but it's representing everything as needed as you can imagine you can do very simple things like just saying dot plot and it will call matplotlib plot out your data and export it it doesn't show up very well on the black slide that there is actually axes labels and so along the edge it's just this slice is a dark gray in the text is black um you can do calculations like calculating the total books on the surface area you can iterate through all the points that you've traced using so all of the all of "
    },
    {
        "start": 2686.32,
        "text": "the data that was traced for Red's piece of paper and done kind of a meta-analysis of what are the volumes of the difference oh no and you can see here that and if you have additional information like annotation of what the cell type is you can start to do you know very complicated statistics using relatively little code and particularly not even though there's a piece of software called blender which you may be familiar with if you've done kind of like 3d animation or or like tiny a sort of 3d image processing that is all that also happens to be written completely or the back end is written in Python so the because of this you can import these tools and use them to do plotting like it was very complicated example in 3d - didn't - in blender no user space and then using using the blender kind of "
    },
    {
        "start": 2746.65,
        "text": "compositing tool to make really nice animations like this that that in this case highlight you know that there is a depth piece tracing and it looks a lot better than like a TV production does didn't least into those now additionally this is something that I've been working on this last week you can come out a bit more complicated shaders so here this this black box is the raw data for his paper that he's working on and so great with it you know show the raw data show the tracings as it comes out of the raw data you know put it into physical context this is a library I should have said that so if you are familiar with plugging in brain neurobiology you to be able to use that context to understand those and then you know in this case we just lay out all of the different retraced so that we can make an argument about you that are very similar "
    },
    {
        "start": 2808.68,
        "text": "and so because of this anchor because this is all going to do Python the code to actually generate leads are is relatively simple giving them all the name in blender and so this is something that actually especially with if any of you do processing there's a project calling Aparri that's currently being that's correctly pretty popular on get help where people are trying to implement a lot of the features of image J and some of the kind of commercial image processing tools purely in pipeline but I hope that in the future we'll be able to use visit rates between image J so that was just kind of a preview of that that I kept short because it's definitely an "
    },
    {
        "start": 2870.0,
        "text": "unfinished story and so finally I'm going to be talking about adapting these technologies right now um and but but I will say that these slides so everything I've shown you today is produced through something called confocal microscopy essentially here in blue is the excitation light so the laser beam that you send to your sample to light up the green is or detection field so in this case it's the light that your floor or Die it gives off and everything I've shown you today is confocal so essentially you go through and you do a point scan of your entire sample and at each point you record pixel value and that's how you composite up a one of these 2d images function in the last kind of like ten years there's a newer approach called lightsheet fluorescence that has kind of taken hold as the next "
    },
    {
        "start": 2932.16,
        "text": "generation of how we do this under high resolution imaging experiment where instead of exciting doing a point scan and scanning your local field like this you do a yield in the illumination from a orthogonal axis so in this case you can see it comes down lights right here and then you do your detection in parallel because now you excited this entire plane of those rather than just you know scan so late she first microscopy is as a result much much faster and while still yielding the same prostitutes so this is a part summation that that Delhi did a lot of back where if you look at like a one millimeter cube cortical column that's kind of like a repeating structure in the house and wasp or pets and you image it with these resolutions using a microscope it'll generate like "
    },
    {
        "start": 2992.25,
        "text": "three terabytes of data and take 3200 powers of energy which decides the kind of technical difficulties of that it's basically impossible to run - go 433 days without something great and so what you're going to expand this is approximation to a whole mouse brain which is mini which is like an order 500 larger in volume you would have to actually run this for 1,800 years and you know because we don't want to be doing an experiment or here's we need you know kind of a faster way to approach so using using a estimate of the speed of like a place you plant you can do this experiment in approximately 20 minutes and you can do this is started approximately seven days but the decide you're generating using we are an "
    },
    {
        "start": 3056.21,
        "text": "image that's mm by 2,000 or of them 100 times a second that comes out to a grand total of 24 to get bits per second which you're starting giving to the order basically taking in that V so if you've ever purchased a computer or a server you'll know that in that you know there's this kind of computer data pyramid where the bottom we got your teeth back up so your your place put your archival detail once you punch your network you comment at the top you have your processor registers you there cashing your RAM and as you go up this pyramid it gets exponentially more expensive and but also exponentially faster so when you want to be able to deal with this amount of data you have to get sufficiently high up this this pyramid to deal with this so um as a result we are currently testing some we are currently testing a bunch of "
    },
    {
        "start": 3117.27,
        "text": "different how Biggums with again the tambi\u00e9n lab at Texas State who's doing our that automated that automated machine learning approaches to tracing that I said oh we're testing using GPUs to do real-time compression from our light sheet microscopy to the earth and so using a set of algorithms called egv which which are kind of imagery print form right now we're actually able to which takes us from you know doing a Netflix movie every every second to Netflix movie every no minute or two which is a much more easily as well as we have been working with hits and our chips deal with or to build Network explains with physical infrastructure between our loud and the University of the University Network do move this data into the super possible so I don't have "
    },
    {
        "start": 3180.03,
        "text": "any any kind of lied about it because it is ongoing work but what I'm working on right now is coming up with ways to adapt to this set of tools so increase their increasing high up to work with this sort of approach to mission so this analysis and as you alluded because these images are getting to handle it by pure cute asian working so I will close with my everyone in the this island so specifically he scored generated basically I think all of the data we call today except for the sample images from the site from the middle so mom whose work on the microscope divided us at wouldn't because possibly man who is working on "
    },
    {
        "start": 3240.54,
        "text": "all of those different Doug who's a previous post office now we've got green grad at Ball State who took that other image or each of these things which are used and then use it usually different because the excitation had a an orthogonal angle the the pinhole is to restrict this axis but in the case of like sheet because you are restricting the excitation you no longer neither being accomplished by a pocket "
    },
    {
        "start": 3312.079,
        "text": "questions bigger speaker over time "
    }
]