hi everyone I'm Joshua piger thank you for the introduction um I'm a student in dcmb like you were saying in in dear rx's lab um today I'm going to talk about the hypergraph analysis toolbox which is um a toolbox of a bunch of different methods we have uh been working on in the group some predating me some were're still building out um and the methods are all sort the theme is we can do a lot of different things with hypergraphs so I guess today sort of I'm going to tell you about a different a bunch of different things we can do with them not following any one specific data set or problem but sort of showcasing on a few different examples what we do and what will the general methods are um these are ideas I'm very excited about I've sort of been stewing uh learning about hypergraphs thinking about these for like the past three years I'm really excited about them I like it a lot um if you have any questions during just call out or after I'm like really into this so with that I guess let's just get going um so so to give like a little bit an outline of what I'm going to talk about or how we're going to frame this um for I'm just going to begin by giving some general background of what is a hypergraph why am I so excited about them why I think you guys should also be excited about them um and to frame sort of the story or what motivated the our group beginning working on these I'm going to talk a little B about pory data which is one type of chromosome confirmation capture technique that allows you to capture multi-way interactions or um it gives one multi-way picture of how Chrome tin is folded within the nucleus then after I give a little bit of motivation for why hypergraphs are so sighting I'm going to talk about a few different things we can do in the toolbox of different ways we can represent the graph how we can compute different distances and similarity measures um how we can do some basic tensor entropy and other tensor based calculations and then I'm going to talk a little bit about dynamical systems on hypergraph which is one of the areas I'm most excited about and lastly I'll just say like a little bit about some current projects we're doing to continue this work so with that let's get into it so hypergraphs are a very simple idea the idea of a hypergraph is hypergraphs are networks where edges contain more than two vertices so if you've heard of graphs or net Network science or graph based neural networks traditionally the idea is you have a set of vertices and typically your vertices are going to be the variables you're interested in so if you're looking at um RNA seek your vertices might be uh the genes you're interested in and then you're going to have edges which are going to be pairwise relationships between the vertices so um and in like a gene regulatory Network your vertices are going to still be your genes and your edges are going to be which genes can regulate or co-regulate one another and those edges can have different weights they can be uh like activating they can be repressing you can have a bunch of different sort of graph setups but many types of interactions you can't uh describe exclusive ly with pairwise interactions that's where the hypergraph comes in instead of one instead of two genes regulating one another you might have three or four or and many genes that are all regulating each other together and because that we have one hyper Edge that's going to describe how they all interact with one another um so hypergraphs are this idea that was originally comes from math but um they're being used in a lot of communities in bioinformatics um an ecology and supply chain um recently I was reading this paper about how Amazon is trying to use hypergraphs to improve their search algorithms so it's it's one thing that we're going to talk about pory data but um it's it's a general it's a general idea that we can fit sort of many different types of data or many different problems to so I think there are three values of hypergraph and in short there that we can have more exact representation the Dynamics on hypergraphs very Naturally Fit like nonlinear systems and that they're very efficient to work with from a compute standpoint so to talk a little bit about why they're helpful for representation let's just think about suppose we have five people we have Amy Bob Carl Dan and Ed and they're going to email one another so let's say Amy emails Bob Carl emails Dan and Ed and then Amy emails Carl Dan anded so in a graph setting our vertices are going to be people and then our edges are going to be who emails who so if we go to the graph case we're going say oh Amy and Bob were on one email here so we can draw Amy and Bob together one Edge between them and then we can say oh we know Carl Dan and Ed all email each other so we have Edge between Carl and Dan Dan and Ed Ed and Carl and we can do the same thing for the four-way email and if we look at just this picture of the graph representation what we're going to be able to see is we're going to know who was definitely emailed at the same time as one another we're going to miss all sorts of information about what the community structure is if we preserve the multi-way interaction we're here we have the same vertices we have the same five people but now we're going to capture each relationship with um sort of these colorful hyper edges which are shown to like contain multiple people in the same email at a time we're able to see oh or we're able to preserve the structure of Carl Ed and Dan were all emailed together and by keeping it in this structure we actually have more information that if we go to the graph structure so um from like it's most simple reason why hypergraphs matter well if we go to the just regular graph case which I think is a little bit more common um you lose all sorts of information so the the other advantages of nonlinear Dynamics I guess I'll talk a little bit about more in a bit and then time and memory efficient the reason they can be uh very efficient to work with these graphs is because storing the sparse information or storing the hyper graph structure where you have the multi-way edges as opposed to the pairwise edges you actually have to store fewer hyper edges total here we have to store like three edges here we have to store more than three edges oh so we're going to save a little bit of space in our computer which can make it faster to confute some stuff so um to talk about remote like how our group got into working with these I want to talk a bit about Chrome Zone confirmation capture and the idea of this is if you have your Chrome tin unfolded in the interner phase nucleus and you want to understand um how the chromatin is uh relates to one another and what regions are near one another you can do the class of techniques and what you get is you'll get some type of picture of which lowai were near which other lowai and the idea began I think in 2002 or 2003 where you could capture pairwise interaction you could say this one low side was near this one low side and uh in 2009 he you came around and you could do the whole genome wide um pairwise interactions where here in this contact Matrix I'm going to use a pointer I guess maybe or I'll just point okay in this contact Matrix um the vertices we can think about it as a network the vertices are going to be the different regions of Chromatin and then the weight inside of the Matrix is going to be how often those regions of Chromatin were observed as being in contact with one another and we can think about it as some type of network where vertices are low side and our edges are going to be interaction frequencies and it captures like a very nice pairwise picture the the multi-way or one multi-way analog of high SE is pory and there are other multi-way analog but I guess I'll talk about pory because that's the data we have't already gred and pory follows a similar process to highy where we begin with the interface nucleus and we have our Chrome tin sort of floating around to some free strands and the idea is we're going to take these regions is we're going to freeze the chromatin we're going to fixate it we're going to digest it so we're going to cut off um or sort of snip out these these trunks here and then we're going to connect all of these trunks together so that when we sequence it these concatamers are going to show what are the regions that were initially uh connected to one another in in the nucleus and by doing this sort of we're we're going to see oh these two regions we're going to have one Edge between this vertex and this vertex here we're going to have a three-way Edge these three are all near each other the same instant and there we have a four-way Edge and similar to the email case we could go ahead and say oh well since we have this three-way Edge three-way hyper Edge we really just have um three pairwise hyper edges and if we store that information we could store it um in a matrix just like this which people refer to as like virtual pairwise where really you extract a multi-weight contact and then you store it as pairwise but when we do that we're going to have the same issue of the email case of where these three all together the same instant in time or were they observe separately as being pairwise related but there's no multi-way interaction so pory allowed us to extract the multi-way um interaction or the multi-way contact at the same time and because of that if we want to keep that information we have to represent it as a hyper so here we have sort of the same figure on the left describing this process of we have our chromatin and we extract these four-way contacts now let's talk a little bit about okay what does a hypergraph structure look like so here we have a bunch of vertices which are going to be different low chrom chromis and low side and we have um a bunch of multi-way contact extracted from fory data this is what uh what's called sort of the incident Matrix representation where the rows are going to be your vertices your chromatin Loi and your columns are going to be your multi-way and there's going to be an entry in like the I row and the J column if the I low size is observed in the J uh chromatin contact and this is sort of the most sparse storage of your incidence Matrix of your hyper here's sort of the same set of context we do this virtual pairwise expansion we're now rather than storing m multi-way interactions we store each pairwise interaction and when we do that we see we have many more edges rather than hyper edges and now we can store it similarly in this incidence Matrix or we could do like a high C adjacency Matrix type thing but either way however you store it it's going to take more space to store in your computer and it's going to um be less precise because you're not going to be able to uniquely say which regions were together at the same instant as opposed to which ones were just being observed your one about it so um the the work we did with this or one of the projects we did with this data was we took pory data we constructed a set of hypergraphs from the data and then we wanted to see okay when we extract these multi-way contacts can we actually uh learn anything interesting about is there actually some regulatory structure going on that we can observe uniquely with pory that we can't observe with highy so what we did was we took our pory data and then we filtered it down using a bunch of attack seek and RNA seek and we looked for transcription uh genes that are co-regulated by the same transcription factors we found a bunch of clusters of genes where we know each of these genes um or that the genes in these groups shown here all colocalize in the nucleus meaning we they were observed in the same fory concatamer and they have a similar regulatory mechanism as one and we were able to find this because we preserved the higher ordered contacts but if we removed the higher order context we went just to parse then we wouldn't be a we would be able to say oh we know uh it's possible that these genes are near each other at the same instant in time and we know it's possible that they have the same regulatory mechanism but we couldn't say definitively that regulatory mechanism was acting on them uh simultaneously so this is like one of the one of the projects we did with the for D um something coming soon is we're in the group we're working on doing single cell course SE where uh we we basically do the same technique on single cells this is a project um that one of my labmates Cooper stanbury is very involved in and very excited about and shared the slide with me so I could tell you all about it so everyone can get excited about it but I don't have too much there yet but we're going to have a lot of hypergraph once we finish uh with this data currently we're struggling not struggling but changing some ways we align it to see if we can just get any more information out of it um okay so that's a little bit about what hypergraphs are why I think are important because uh again they're precise and they're efficient to work with um and a few instances of what we can do with pory with a hypergraph representation but pory is by no means the only area we can apply hypergraphs um Canen is uh one of the students that used to be in our group and is now at UNCC and he's been doing a lot of work on metabolomic networks with hypergraphs this from one of his papers I forgot a citation um people have been looking at hypergraph to understand the structure of the brain and how neurons are interacting with one another by analyzing MRI data and also people have applyed to ecological networks to understand how different species regulate one another so these are just a few instances of other areas we could bring this idea okay so that's I guess a little bit of an overview why I'm excited about hypergraphs and what they are um and now I'm going to talk a little bit about what we can do uh with this toolbox but again if you have any questions it's not clear what a hypergraph is or why you should be excited pleas call question um yeah so I know um the graphs youve shown in previous slides uh are like directed graphs is there like a directed version of a hyper graph ah so that's a great part so here we sort of have arrows denoting um how how these edges are going to flow we can see oh from A and B we flow to C D and E there's some notion of directionality um in the pory data we're extracting that all of these chromosome Loi are are near each other at the same instant in time there isn't so much directionality associated with it we could look at and we've thought about looking at when we read the concatamer ver we read one low sign then another and then another and trying to use that to associate like some Direction with it um we we haven't been able to do that so much with um with like when we were trying to identify the transcriptional hubs there we can say a little bit that there's a hyper Edge or directed hyperedge because we know there's particular transcription factors that are co-regulating all the same genes so maybe we could say the hyper Edge is the genes that are seen together as well as the transcription factors and those are being directed at um but like with most pory Data before we do that we're saying it's undirected but um for like some of the Dynamics definitely people Define directed version of this yeah yeah so I don't know if there is such thing but like a can you add like weights to to the hper edges sure so so directionality and weighting are two things we glossing over um you can add both directionality and weight a to them and in like uh high C the weighting is clearly just the number of times that contact is observed so when we look at this is like an adjacency Matrix we see there's like um the int chromosomal contacts or like more brightly colored red because we know there are going to be more contacts there and we think of that as being like the waiting in our Network where if there are more contacts of high SE we know uh that the those low side are closer to one another we just call that the weight we could do a similar thing for pory where we say oh if we observe um one concav many times we could assign it a weight similarly to this um one issue or way that can be a little bit more challenging is with high we're only looking at pairwise interactions and the set of pairwise interactions is much smaller than the set of multi-way interactions so each concer is more unique so it's tougher to assign a weighting to it but we could do that as well or or for example with u with like a network a reaction type Network or um yeah with a reaction Network you could also assign waiting as different rate constants for how fast or slowly your reactions will progress um and lastly also about the directionality of these networks I think the first example is this email network of like Amy and Bob and Ed there would be very natural to say oh we have a directed hypergraph where one person is the sender everyone else will be the receiver um so you have some notion of who sent it where it starts where it goes to so yes we've uh directed and weighted versions of these another thing that uh I didn't mention so much but is also important is in is what's called a uniform hyper graph so in a graph all your edges are going to be uh pairwise every Edge will have exactly two vertices in a hypergraph you can have a hyper graph um where every hyper Edge contains a variable number of vertices like if we're looking at um if we're looking at 4C data okay each concer is going to contain between two or like eight maybe on the larger end uh chromes and low side that are observed at the same time and that's we call them nonuniform but if we have a graph or hyper graph where all um hyper edges contain three-way interactions or four-way interactions we call that uniform um and that gets becomes a little bit important for how we represent these as testers so I guess that that's actually a good um segueway into like oh how do we actually represent these hyper graphs so this is a figure that we made sort of outlining all the different things we can do with this toolbox and now I'll go through and talk about them each a bit so um here here's this is I believe the instance of the same hypergraph I had in the cartoon model of generating fory data and we have sort of five vertices and we can pretend they're our chromatin low side or whatever other variable of interest and we have three hyper edges we can say those are our pory concatamers or whatever other type of relationship we want to say we have among our data and we draw it as a hyper graph where the edges are going to toote hyper where the colors are going to toot different hyper edges and this is the instance Matrix which I think we talked about a little bit before where the vertices are going to be your variables or your noes or the rows are your are your nodes and the columns are going to be your hyper edges and um for for uniform hypergraph we' like to think about how to represent these as tensors and in The Matrix case or or the graph case where is really like a two uniform hyper graph every Edge in a graph is exactly two vertices here we have a bunch of different graphs we think about the adjacency Matrix as being one of the main ways we represent it we we represent numerically the graph structure and what goes on in The adjy Matrix is here we have vertices one uh 1 through four and there's going to be a one in the i j entry of your ad Json C Matrix if vertex I and vertex J have Edge are interacting with one another so here 1 2 and three all interact with Vertex 4 so basically vertex the column row four are dense with ones and the hypergraph case or the uniform hypergraph case we're now instead of having paralled interactions we can have three-way interactions like here we're going have an adjacency tensor which is just the multi-way analog of the adjacency Matrix so here we have a three uniform hyper graph every hyper Edge has three vertices so now our adjacency Matrix becomes an adjacency tensor where we have rows columns and then uh maybe slices going forward and back and each one is similarly indexed with vertices and for instance this blue square here is going to be indexed with V4 V2 and then oh in the front slice V1 all right so blue is V4 V2 and V1 and the hyper edge here is going to be the blue hyper Edge above is going to be on vertices B1 V2 and V4 so that's sort of how we get these like uh tensor representation of the hyper graph another thing we can do if we have the hyper graph is uh we can we can still represent it as graphs like we talked out about before where we say each multi-way interaction becomes a set of different hairwise interactions so here above we have another hyper graph on five vertices and what happens here is we can do what's called The Click expansion and in the click expansion youve your same vertex set and each of the three-way interactions just becomes three pairwise interactions like we see or like what we talk about with doing like virtual pairwise from pory if you take take your forc and you decompose it into all the airwise contacts you get um like it almost looks like high SE data and it's nice because we have the same vertex set in this click expansion as we do with the initial hyper graph but it's problematic like we talked about because you're actually going to lose some information by your system another type of way we can represent hyper graphs as graphs is we do it's called the star expansion and what what goes on on the right side here is we make a graph representation of the hyper where we actually increase the number of vertices so now we had five vertices and three hyper edges in our hyper graph and in the right side we're going to have eight vertices five representing hypergraph vertices and three representing um hyper gra hyper edges which are going to be the ones on the left and we have sort of an edge in our graph between the vertex um and and a hyperedge representing vertex whenever that vertex is contained in the Edge and what's nice about this is from the Star expansion you can uniquely recover your hyper graph which is very nice you you never want to lose any information and how you're storing your data but it's problematic because now our vertex set is different so if we go to actually draw this as if we were to like draw The adjacency Matrix of what this looks like it would look nothing like uh the virtual High SE or the adjacency Matrix we get with this structure um so from the hypergraph the takeway sliders we can represent it as a few different graphs we can represent it as the tensor the tensor is very important so we're going to compute all sorts of different uh higher order svds and other tensor properties from um so one one thing we can do with our toolbox we can compute different hypergraph similarity measures so if you have your hypergraph the most natural question whenever you VI your data is oh what is the distance between my data points if we have pory from two different cell types we might want to compare or ask ourselves how is the structure of uh the Chrome tin in these cell types different from one another and we can do that sort of a few different ways one one way we can do it is sort of uh the the simplest is we can take our uh pory data we can do this virtual pairwise expansion we can make it into like a a regular graph and then we can look at different distance metric on The adjacency Matrix of the graph or on just different graph measures another thing we could do um is we could take it we can make it into the star graph which is even better because now it's going to preserve all of our um all of our structure but it's going to have this awkward issue of now we have a new vertex set and then the third type of measure we've been working on is we could take um the tensor representation of our data and compute different T tensor distance metrics the tensor one is nice because it preserves in the best form the multi-way stretcher but it's problematic because if you have non-uniform data if you horsey data and you want to do some tensor based distance metric well you have to find some way to make your non-uniform data fit into your tensor so sort of what what showed on this slide is we generated a bunch of synthetic hypergraphs using like standard random hypergraph uh methods and then we have a bunch we have a few we have each of these different distance measures where we comput it on the click graph on the star graph and directly on the tensor and we have hamine and centrality based distances and what what is shown in each of these plots is each color is going to correspond to a different type of random hyper graph we made so we made some that are totally random some that have scale free properties some that um are small world we make we make a bunch of different hyp graphs and we try to compute the distances between each of them and then we projected with P so you can see what's going on and we see with some measures like uh if we do the star expansion and then we look at a Hamming distance on it there's very nice separability between all of these graphs with other measures if we do a tensor based caming distance this would not be good we won't be able to see how the data is different from one another so um sort of the part part of this project and all the things we compute let just proposer look at different ways we can compute these measures and even though in this case star Hamming is probably the best one up there um you have to choose the distance that'll be appropriate for your data so on these random Networks that one works very well but um on different types of networks You' want to use different distances to discriminate ask a question oh yes please it looks like in this case The Click is not much worse or even better than the star haming is that right oh yeah click Hamming is good thank you for pointing that that's uh not a hypergraph approach because it's making all the edges do you have a synthetic case where the using the hyra is actually beneficial so that's a great Point um in in this case the start the the start expansion and the click expansion you can both discriminate the data very nicely um and then the synthetic data shown here certainly not certainly to do a click or Star would be would give you the best discrimination um one thing I would say well like one cave were you're saying is oh the graph based approach works just as well as hypergraph based approach it's true because of the click um that works well the click graph it's not true because of the star graph because the star graph is still preserving the hyper graph structure so so um like talking about the click graph as a graph both of these are graph objects but the star graph object is still representing the hyper graph structure but in this case I think like yeah they're definitely like work as well as one another I don't know does that make sense yeah I mean I guess if you just go to like the normal graph rather than the paper graph in this case yeah you'll do just as well so I'm curious if you had a synthetic example where the hyper graph actually outperformed not using a hyper graph I didn't we did not have we don't have a synthetic example for it we have um like I guess when we've looked at a lot of this porc data we've found that U the hypergraph case works better or the star expansion case is the best the reason I say the star expansion case is the best is because in the synthetic Example The Click does very well and then not synthetic in some of the real data we've seen the click has not done as well um the star expansion in my mind is preferable for the tensor representation because U even though we can store these tensors um very sparsely Computing uh like spectral measures on these tensors with a large number of vertices or high order is a little bit expensive um yeah we can talk about okay okay yeah uh there's a question question online from Gil and Gil I think I've given you the ability to unmute yourself if you want to ask your question yeah I think can you hear me yes y great so this is a very striking slide Josh I didn't quite understand your explanation normally with tisne we want to see as separated fosi as possible but I think you said that the star method with overlapping of two the three uh subgroups is uh somehow more informative than the click method would you try again to explain the star versus click sure so um I'll use the pointer maybe if you can see it on Zoom if I can get this to work it's the bottom button top button oh top yeah I see it yeah okay so I meant I meant to say the star Hamming distance the one on the left over here is as good as the click Hamming distance the one above um the star were you referring to the star spectral yes yeah so the the Star Hammond and the star and the clip The Click Hamming distances perform about as well as one another because like you said we're able to see a separation between the clusters right um and then why do the what is the spe is that a different experiment altoe so the the spectral distance is a different type of graph distance that we can compute on the star graph or on the click graph so um it's it's going to look at what are the igen values of the click expans of the click graph versus the star graph um or in the tensor case the tensor values um and the reason we show all nine plus slots here is because with this synthetic data the um the star Hamming distance and the click Hamming distances do the best those are the distances where we see maximal separation between the synthetic data um the reason we investigated these other or the remaining seven distances is because with other data sets we found um that some of the tensor distances perform better than uh the star or click one and you have to choose sort of an appropriate distance for your data is it possible that some of these methods are showing separation that's not real not biological um in in this case it's all synthetic data yeah um so so so that to explain maybe the experiment more clearly we um generated hypergraphs according to three different models we used an Erdos Renee model where you randomly on a fixed set of vertices you randomly choose hyper edges we generate them according to the watch stroad model which is a variety of a of a small world Network where um you begin by sort of making a lattice on your hypergraph and then you randomly per permute um which hyper edges are attached so you're going to have some attachments that are going to go across a lattice and then the third model is going to be a scale free um hypergraph where what we expect to see here is a degree distribution that will follow some type of power law um and then on these hypergraphs we we wanted to discriminate and see if we were able to find U oh distances that discriminate them well and the star Hamming distance and the click Hamming distance perform best in this case on these synthetic data I don't I don't know if that answers uh your question yeah I'm just trying to understand what the physical meaning is of these clusters and maybe that's not what's being shown here um what's being shown here is if given the hypergraph we're able to predict or separate out which model was used to generate it um for instance and the the problem we would want to do um if we were looking at data in this experiment rather than um these uh synthetic examples say given a set of hypergraphs or given porc from different cell types can we discriminate only from the porc data which type of cell or what was the process that contributed to that hypergraph we observed um in this case I think it's tough to say what uh if there's like a physical meaning behind the distances we're just trying to discern which model of graph it is okay thanks thank you for the effort I appreciate it U maybe we can talk more about it after yeah but thank you sure um okay another thing besides distance we're interested in is uh compute entropy of different hyper graphs um and entropy is important we've looked at it um we've looked at hypergraph entropy of um the organization of of this uh chomon confirmation capture data from fiber bless cells throughout both the cell cycle and um cell reprograming so the the tensor the reason the tensor representation is important is because um we compute tensor based entropy of these hypergraphs and the the way tensor entropy calculations work is we're given a tensor up on the left p and we compute some type of higher order singular value decomposition and from the singular values we then compute U like standard entropy with Shannon entropy and and what's shown on the left is on the top if we're given if we begin with um and seven vertices on the top and seven on the bottom and we want to add hyper edges in a way that is going to maximize the entropy of the graph we can follow the procedure on the top and in the bottom if we want to add hyper edges that are going to minimize entropy of the graph we can follow the procedure on the bottom and um one thing we did with our data was we took um hypergraph representation of the Chrome tense structure of fiber blast throughout the cell cycle and normal proliferation and what we try to do is compute the entropy at different time points so we have eight different time points and on the left figure we show um the tensor based entropy where blue the blue line is going to be the entropy of the reprogramming fiber blast and the orange line is going to be the entropy of the proliferating or the fiber blast just going through the cell cycle and here we on the right hand side we compute the same thing we compute graph and entropy so we take the hypergraph representation we compute entropy on the click expansion of the network and one argument we tried to make or we we make we make that was made in this paper is that when we look at the tensor entropy we're able to sort of distinguish um distinguish these two processes slightly better um yeah that's the idea of I guess tensor entropy but um we've I guess tried it on a few other data sets as well sir can you explain how you can see that that's better discriminated on the left than the right that's a great question uh I think it's sort of a qualitative argument it's not I don't think it's a good argument that it's better discriminated one thing we could say is we look at the scale of the change from here it's about a shift of 04 in entropy here the largest shift is maybe about. 2 0.02 um there I I guess so a larger change is there any replication here I don't see any errors on the data we we only had one replicate of this data so there there's no error bars and it's probably not the most compelling I will give you it's not the most compelling instance of yeah um okay um one thing I've been working on lately is um think about like dynamical systems that occur on your hypergraph so if we have a hyper graph we have these vertices which are going to be our state variables our variables we measure and we have hyper edges um which are going to we like be the interactions in our Network we can take our adjacency tensor and sort of write down a homog the homogeneous polinomial of the adjacency tensor and we can look at what are the controllability or observability properties of uh of that system so and sort of maybe the the best example of this is down here I a graph on three vertices and have a hyper graph on three vertices and this graph is going to have some adjac Cy tensor a the hyper graph or well this will be an adjacency Matrix this will have an adjacency tensor and if we write down I guess sort of the the classic like linear Dynamics on a network we're going to get X do equals ax on the graph and in this case we're going to have some linear differential equations where derivative of X1 is going to be X2 plus X3 and the hypergraph case rather than having linear uh linear equations we're going to have nonlinear terms and those nonlinear terms are generated by the like homogeneous polinomial of the tensent and what we really mean by that one way we can think about that is we replace every addition with multiplication so this term X2 + X3 will become X2 * X3 and we're going have nonlinear Dynamics and from these Dynamics we can think about how can we control the system how can we observe um or make some type of sensor measurement from the system um so this is a project I I did not do at all but talking to um a system is controllable if it can be driven from any initial state to any Target State and in the graph case if we have um these linear Dynamics determine if a system can be controlled from a set of input nodes is a classic problem where we form what's called a controllability matrix and the idea of that Matrix is we can give it a very simple test where we just look at the Matrix rank how many columns are in independent of one another and when the Matrix is full rank we're able to characterize if we're able to control the system from a minimum from the set of uh driver nodes that we have access to this is an important problem because if we have some type of system and we want to say what are the minimal inputs we need in order to control the system we want to have some procedure for identifying those driver nodes or those variables we have to modify um rather than having the linear case we'll have the we have these nonlinear dynamics of like hypergraph and now we want to be able to ask the same question how do we identify the minimal set of driver nodes um that are going to allow the Dynamics to be controllable so uh we have sort of an algorithm for doing that based off um Computing like repeated uh svds of the adjacency T of of this nonlinear controllability Matrix we're able to evaluate sort of how different input signals are going to propagate over the network and then say if this nonlinear control build Matrix is full rank similarly we're going be able to control the system here we have um this isn't a great data set but I have a few different graphs that are shown up here and um this is not a good figure this is not a good figure but what's going on in this experiment was we had a bunch of Time series data um and we fit uh polinomial models to this data and from those models uh we set oh we have this hypergraph structure and the hypergraph structure was formed according to the polinomial um the the we found the tensor whose homogeneous polinomial was a polinomial we fit to the data then given these different hypergraphs what we want to do is we want to say if we look at the hypergraph representation versus the graph representation how um how does a number of driver nodes that are required to control the system change and what we saw is for the connected component always the number of driver nodes required is going to be smaller than the number of driver nodes when you a linear model to your data um this is flawed in part because the graph isn't always connected because we were trying to make en force a sparse constraint on our model or or on the model we fit to the data um another reason it's flawed or it could be flawed to say that we need fewer nodes to control the hypergraph system is because oh well if we fit a linear model we fit a nonlinear model to the data still we're only fitting a model so the ability to control the system is going to be predicated on our assumption that model model is actually a good representation of the system but it um it was interesting to see that these Dynamics are easier to control in the non-lit case do you have an example of where you would use this St model um for for the observability case I think it makes a bit more sense to to say um yes yes I do would you mind sharing it yeah let's do it all right so okay here here's where we're going to use this model suppose we have these same nonlinear Dynamics we have these polinomial on the adjacency tensor now instead of controlling it because this is my project the control was done before me the observability one I guess is what I'm working on now so um and we we say similarly the system is observable if the states of all nodes in the hypergraph can be uniquely determined from uh the sensor the sensor nodes we have so if we have n variables we're only able to measure M of them over time what we want to be able to do is to say from the is to pick the best M variables that are going to allow us to estimate the state of all other end variables and we think this is important maybe for biomarker detection where we want to find the minimal set of sensors that are going to allow us to estimate or observe the rest of the system so um maybe in from from talking about the polinomial model I don't know if that'll be more convincing or to talk about the data but in these polinomial models we have a bunch of graphs in this figure and what we did was in these graphs we're going to have linear Dynamics and we use the this um observe building Matrix which is similar to the Control building Matrix to say what are the minimal set of vertices that we would have to monitor over time in order to make the system observable and we drew sort of one Arrow towards each of these vertices then we what we did was we added a single hyper Edge to each of these grip s to say now we have a mixture of three-way hyperedges and pairwise vertices and we did the same procedure again to say what are the minimal vertices that are going to be required in order for us to observe or make some type of estimate on the system and then we added in a bunch more hyper edges again and again we ask what are the minimal set of vertices that are required to make some type of estimate on the system and as we added in more hyperedges or more higher order interactions the number of vertices required to make system observable and the Dynamics are changing from linear to little nonlinear to very nonlinear the number of hyp the number of nodes required to observe the system decreases and what we've been looking at is we've been uh the data we've been looking at for this is sort of Time series RNA seat collected during uh just normal fiber blast proliferation as well as time series RNA seat collected during um fiber blast reprogramming to myogenic lineages and we're trying to think about different ways we can use this sensor selection approach to find what are the most important genes that we have to be measuring during these typ series experiments because if we can reduce the set of all genes we measure to a very small number we're able to we would be able to capture that at a higher frequen a higher frequency or temporal resolution which might be helpful for making some type of estimate about the system still maybe it's not that compelling you're going say oh it's only a model but we think if we can fit these linear models to it and we can uh we might be able to find smaller sets of sensor genes that are important to observe yeah it possible that in any given model all these relationships actually exist for example you may have linear relationship has non linear relationship across different um so there are two things there um to repeat the question um so the question is is it possible that all of these different types of relationships can can exist across different time points we have linear relationships we can have nonlinear relationships and these can change over time um definitely it's possible not possible probable like certainly uh the relationship is going to change over time um we've been working on how we can do linear and nonlinear relationships together in the same instance to select observable nodes um and we've also been working on uh temporal linear relationships so if you have linear relationships that are changing over time and now the next thing like I want to do is to think about oh if you have these nonlinear relationships that are also temporal how we can model that um and the thing that's shown here is I guess if we select different sensor genes how well we can estimate other cell cycle genes um this is the idea is like can we actually apply this can we find some subset of genes that are going to be informative for estimating the other gen um and in this case the different color lines are going to correspond to the number of genes that we're measuring um I think ranging from like 1 to 50 um and the black dot and again these aren't beautiful plots are the real data and what we want to see we want to see over time is the estimate converging to what the true measured value is from uh based off only estimating the censor or only looking at the value of the censor and then I think my last slide is one is talking about how well we can actually scale these models and one issue among many with these tensor based models is uh the scalability of of tensor of tensor calculations if we want to look at controllability of the Dynamics we have to compute um higher order we have to compute a variety of a higher order SVD if we want to look at uh different distance measures or entropy measures between hypergraphs we have to compute or one way we can do is by Computing tensor igen values or tensor decompositions which can be very expensive if we have like a high dimensional data or many different high order interactions so the I think of the last thing is um I've been looking at different ways we can Factor the tensor using some type of chronic or factorization and then improve the calculation or the time it takes to calculate um different tensor IG values and tensor decompositions um I think this is my last slide of just the people that are involved in these projects Cooper helped me a lot with building the tool that does all these calculations we have he help me a lot writing the code K used to be a student in my group as well and and de's group and now recently just started at UNC and then uh Professor BL am R and Inda were involved in helping make all these methods um yeah that's what I got yeah you said at the beginning that there was some computational efficiency with the tenser representation like Less storage did you see that in any practical applications that that was a beneficial effect of the method um so in in terms of like um efficiency in terms of tensor calculation or tensor storage I I guess you said that one of the reasons why you might want the the hgraph representation is that it's more compact yeah and that might lead to computational efficiency sure did you see that that was an important factor in any of your applications um in almost all of our applications the speed at which we can like uh these calculations take a long time and it was always an important factor to have both the most sparse storage um as well as the most sparse representation of using like spar tension form lastely but no quantive assessment uh yes we didn't we didn't really do a quantitative assessment to see how much slower it would have been because we sort of tried a few things and we're realizing it's slower like we we we saw it so we we we saw there was an advantage to doing it and we never benchmarked how much faster it was all right yeah um in your example with emails you don't have any uh FAL positives and in certain types of data you won't have as many false positive but in 4C due to chemistry it can happen that sometimes You observe uh certain regions being Clos even though they're not actually Clos biologically so the frequency of like how often we can find certain region together is important to know as a threshold after which we can say okay this is actually biological interaction not just artha um do you have any false positive filters or some other weathing that you do in not we we don't have any false positive filters um one of the one of the plots um or one of the things we thought about with the entropy based calculation say as we add more hyperedges how is that going to change the entropy of the system to see if one hyper Ed is going to cause like some very unique change and all of a sudden it's it's going to be very different or whether that won't be the case um we we do have some code for saying given this set of hyper edges how can we predict new hyper edges which is going to be the opposite problem you're talking about how do we say given this how do we F find false positive we don't have any methods for that so for your uh would you be able to also calcul some uh regular properties that the regular umor centrality or small worldness or clustering coefficient or diameter um yeah we we um I guess maybe I should have said that we can calculate all we have code to calculate all of those as well um and one other thing about the tool I guess I should just tell you to plug the tool is we wrote it in both mat lab and python because we wanted to just really make sure uh we were getting the same answers between both um so you can use it in either language um and uh yeah it's easy to download so Ione to check it out link I should link on the side okay all right thank you all for coming