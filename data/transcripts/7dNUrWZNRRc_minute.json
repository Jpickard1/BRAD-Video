[
    {
        "start": 0.03,
        "text": "and then did postgraduate training at the world-famous Cook County Hospital I mean that must have been an experience and he started Zaka democrat the University of Pittsburgh Medical Center then moved to Northwestern University and then ended up down the street or yeah literally South you know at the University of Chicago where he is an associate professor as I mentioned in the section of general surgery the unique part of the story is that you know you're a surgeon and you work in intensivists and to have that coupled with computational biology and complex systems work is really a very attractive and interesting commerce combination gary has been a leader in the swarm community for years and years he knows several folks at our Center for the Study of complex systems Carl Simon sends his regrets for not being here but "
    },
    {
        "start": 61.859,
        "text": "he's with you in spirit you study you know wound healing host-pathogen interactions and all kinds of stuff and uses computational approaches and simulation and modeling and is a consumer of consumer computing cycles you know at Livermore at the at the Oak Ridge National Laboratory probably with Jaguar some of those systems and so you know years and years ago we used to do a lot of supercomputing when we were in the center and you know we don't do so much of it I think Zhang does some but so it's gonna be really interesting to see and to learn from Gary how a simulation and modeling approaches forward approaches and I think I saw Dan here you know are really you know part of the repertoire and what comes after big data that is a really good question and so we're actually especially with the launch of our data Science Institute you know and separating the height from reality and big data I think is one of our challenges in the role of dynamic "
    },
    {
        "start": 122.969,
        "text": "knowledge representation in addressing the translational dilemma in a supercomputing age that's an excellent title and we're looking forward to hearing you elaborate on that Gary welcome really happy to thank you very much thanks Brian for having thanks Kevin for having me as well you know as Brian mentioned I am a clinician that's the only area formal training so I live in blessing ignorance of mathematics and computer science and an actually basic basic biomedical research so to a certain degree that allowed me to be a relative blank slate going forward when I started my research career but will also give me an excuse in case I state some clear falsehoods as a disclosure I'm a consultant for a company called a metrics and Pittsburgh that does large-scale in silico trials of sepsis and rheumatoid arthritis so given my background as a clinician my "
    },
    {
        "start": 183.48,
        "text": "primary goal is try take care of people right I want to fix people and when I was a young trauma surgeon at Cook County Hospital in the early 90s I spent my energies on making sure I was the best surgeon invest intensivist I could be and yet I found it somehow wanting and it turns out that I was not the only person because the FDA put out this critical path document back in 2004 which I'm sure all of you have seen where on the screen left you can see expenditures on biomedical research and on screen right the number of deliverables to the bedside as I mentioned I'm not a math person but those two graphs should not be going in opposite directions right there's a problem with respect to this discrepancy and it only appears to be getting worse and in the last decade that has not gotten any better okay to the so we have this paradoxical situation where we know more and more about the biological systems we presume to want to be able to control and treat and yet aren't tools "
    },
    {
        "start": 245.16,
        "text": "to be able to do that are wanting so I apologize to the next slide but as a clinical surgeon I have to show him he's one gross Surgical picture so this is someone who I took care of about about five or six years ago now an unfortunate young man who got stabbed at the base of his right neck and his right chest lacerated his internal mammary artery through his innominate vein bled into his chest required about 70 units of blood in the first 24 hours in order to control this for those of you don't know the human body holds about 10 to 12 units of blood and during the course of this procedure despite how dramatic this looks so the guy's head is over there his feet are over here this is his chest which is open there's his lung sitting on his chest because when the patient bleeds that much when you give them that fluid back they swell up they develop what's called abdominal "
    },
    {
        "start": 308.009,
        "text": "compartment syndrome so he does it basically at the cut we add to an open and so a plastic bag on top of it so the pressure can be relieved to allow the other vital organs to work this is a technical exercise this is trivial this is cutting and sewing right now surgeons spend a lot of time learning how to do this well but the fact of the matter is this is just woodworking it's carpentry work okay and the fact of the matter is that one of them in the operating room doing this at one o'clock in the morning and and sure the patient's immediate survival depends on how well I happen to do those particular technical exercises while I'm doing this I know that the primary determinant of whether or not this patient is going to survive their hospitalization is whether or not they are going to get over the inevitable multi-system organ failure need for dialysis knows a corneal pneumonias ventilator-associated pneumonia is ventilator induced injury and all the potential problems associated with their "
    },
    {
        "start": 368.07,
        "text": "medical care up until that particular time where that patient may be fortunate enough to leave and the fact of the matter is even though we have some idea about what the molecular processes are involved in that and I don't need any sort of tests to predict it those things are going to happen I can't do anything about them before they happen I can give antibiotics I can support the lungs as best I can I can put the guy on dialysis but as far as making him better causing his biological system to increase this trajectory back towards that state of health I have a single peel and nobody does you can't address what's actually wrong with these particular people to make them better so that's very frustrating and that's what prompted my interest in it because I have some idea what's going on I can't do anything about it so that led me to a diagnostic approach to what may be the gaps in our current tool development pipeline and taking "
    },
    {
        "start": 429.88,
        "text": "care of patients so I'm a first principles kind of guy well I'm we're actually interested in in all medicine is organ function right because disease is at this function of some organ at some level all right so we want to be able to fix this now we know organs are composed of multiple individual cells which are themselves composed of multiple interacting molecular pathways and what we're asking pharma to do in this day and age is given the complexity of this particular system infer ahead of time what potentially manipulating this molecule is going to have on that entire system and I propose that we can't do that intuitively we can do this potentially augmented the computational tools for data analysis and simulation but doing this intuitively does not work it does not work because biological systems are organized in such a way that there are essentially epistemological boundaries but towards between the multiple hierarchies of organization such that "
    },
    {
        "start": 490.57,
        "text": "you can't necessarily Intuit what give effect of manipulating at one level of organization is going to be at the neck Club next level organization right things do not necessarily commute across these levels of organization right so this is a problem this is a particular issue because this is where our bio men of our biomedical experimental workflow is where each one of these particular sets represents the experimental platform and we are making inferences with respect to what we gather information that we gather from one platform and trying to translate it off this particular organizational scale right and the is what is the justification for the knowledge that we are punitive Li translating right we do it intuitively this particular month model system has the other pathway ergo it must behave in a similar fashion when you move to another platform is that valid you can "
    },
    {
        "start": 552.87,
        "text": "we test that in some sort of way and that leads to the question is what is similar what is conserved when you move up this translational and that's the Katori pipeline so as an example a tail two papers this infamous paper from the glue grant a couple years ago that was in PNAS and in the New York Times right which which led to much gnashing of teeth and rending of hair and all sorts of stuff associated with how how these people should be burned at the stake and led to response papers like this okay which you know I mean these are intentionally provocative now so let's leave aside for a second that there might actually be some methodological concerns with either of these two these two particular projects the fact of the matter is that both of these groups are respected scientific groups they both utilize tools that they interpret using their expertise and they come to "
    },
    {
        "start": 612.959,
        "text": "completely different results and it becomes then a political issue right as to which one you're actually going to believe this however does not help you getting to it toward the solution so the question then is how do we actually affect this translational goal by taking basic science knowledge and it's moving it up the organizational pipeline to get to clinical output so I would pose that this slide represents our current operational strategy for doing this okay we hope for the best we hope that we guessed that this particular preclinical platform works we hope that this particular drug candidate is going to survive phase one two and three trials and not kill people in phase four right we hope that these things are going to happen and I would propose that this is not a very robust strategy right we should be able to do better than them you should be able to utilize our "
    },
    {
        "start": 674.24,
        "text": "knowledge of what the scientific process is in the advances in technology to be able to show our work take this miracle component out of it and actually make this in a explicit fashion such that and this is important our failures are our usable right what we want to be able to have is usable failure because of if we're counting on a miracle that doesn't happen then we don't really know money much more than what we had to begin with right so as I mentioned we have had a revolution in science where big data is powerful right data center right and this is incredibly important revolutionize how we look at systems and how we analyze and can interpret what might actually be going on in these very complex systems that were dealing this guy Nate Silver is University of Chicago "
    },
    {
        "start": 736.64,
        "text": "person being able to predict elections with a certain amount of precision but he cannot tell you how to win an election right he can tell you who's gonna win he cannot tell you what you can need to do in order to win that election right so if we want in biomedical research and the biomedical endeavor do something other than just describe what might be happening we need to move beyond what data can provide which is extremely powerful it's but it's a trap okay it's possible that if you just get stuck in the idea that if you can collect enough information and throw a big enough compute at it then you can get answers and that's just another form of a miracle because you got to move beyond what that big data can actually provide to be able to do something to be able to fix patients right so first "
    },
    {
        "start": 798.529,
        "text": "principles kind of guy scientist science right this is a scientific cycle we all know this Francis Bacon Isaac Newton you know 16th century kind of stuff observations and data identification of patterns interpretation of that data construction of hypotheses testing of hypotheses with experiment this is work for 500 plus years our sum total of technological advance is based on this particular cycle and yet I'm telling you it is not working as well as it should work in biomedical research at the Hmong and the question is why well on one hand part of it has to do with the complexity of biological systems and the diseases that we're trying to deal with today right so those particular diseases that are linearly reducible to a single cause right so in a very coarse sense if you take the appendix out and appendicitis you know you'll have appendicitis anymore anymore if you decide that you should stop drinking your own feces and "
    },
    {
        "start": 858.6,
        "text": "water you're not going to get cholera anymore right so Public Health and certain aspects of surgery you know have are linearly reducible but when we're dealing with wound healing cancer aids aging diabetes obesity these are diseases that are represent dysfunctions of systems where they're [\u00a0__\u00a0] shifted or there may not be a single cause that can be reduced out in this particular cycle the other problem is that we have an embarrassment of riches with the increases the dimensionality of the data that we can collect so much so that our scientific cycle is imbalanced so technology has allowed us to be able to gather more and more information out of each particular biological system and advanced computational tools are able to extract that information out of those particular experiments and we're actually able to make inferences out of those particular patterns into potential hypotheses but this critical step of testing hypotheses to check the "
    },
    {
        "start": 921.45,
        "text": "plausibility of our punitive evaluations of causality right this remains in a cereal form reliant upon the life cycles of cells and rats and the labor of graduate students and postdocs I we cannot keep up so there's a bottleneck here so from a diagnostic standpoint as a clinician this is what we wanna target this particular problem right so thinking about science in a particular way right this is another projection of this right you have data that you do all the great stuff you do with great data and you generate hypotheses but yet remain hypotheses they're possible explanations what what's needed is to close that loop with some sort of means of evaluating the causal causal mechanisms that are inferred from that particular data analysis okay this is a cyclical process obviously and the emphasis here is on data I mean knowledge interpreted data data "
    },
    {
        "start": 984.42,
        "text": "that has somehow been processed evaluated looked at and comes out with something that says I think this is what this data means and the question is how do we test that particular process now part of the problem is that hypotheses are always incomplete texaco can't know everything about everything as much as we would like to know and therefore at some level if we want to be able to get the useful information our goal should be sufficiency of explanation I'll get back to this in a second so one of my favorite authors has this little thing about the item well so the model is a very much of a loaded term it means very different things to different people a model is essentially a formal representation of one system with another system all right so you can have a statistical model you can have a conceptual model you can have a model that is a computer program etc all right I'm gonna make a distinction between "
    },
    {
        "start": 1045.77,
        "text": "what I'm talking about in terms of simulations or executable dynamic models right and that is a means of closing that loop because you can have a data model of a data structure and come up with a hypothesis all right but turning their hypothesis and making it go right is the role of a simulation or an executable mod all right so this is Borgess this this little short short story on exactitude in science right you've had time to read this essentially a little bit but but this is a trap right because on one hand we kind of think we want something that's exactly like what we have because that's precise on the other hand you end up with something that's as complex as the thing you started with and then you can't really do anything more with that so here's a little example of this this is Marcos Cobert did this a couple years ago at Stanford where they simulated the simplest bacterium that you possibly could do with a cluster about 128 computers right so only 525 genes the 10 "
    },
    {
        "start": 1110.129,
        "text": "hours to do one cell division which was actually longer than the biology and generate this amount of data which is a impressive technological engineering feat but the fact of the matter is the goal of science is selective abstraction right because if everything is its own precise thing and how can you compare it to another thing which is got its own complexity and its own identity what we want to be able to know is what level of abstraction of description of one particular system is applicable to another level of system all right if we think about the quantitative sciences with their production of theory right abstractions of Hathway to theory the idea finding natural laws commonalities that have greater explanatory power right and that's actually what we want to have is we want to have knowledge that can explain as much as possible right so this is a little bit different than how people may think about how you "
    },
    {
        "start": 1173.999,
        "text": "gain increased information about a system right as opposed to degree of detail of knowledge is which is important but how can that knowledge be translated from one system to another so by our biology carries its own challenges right I showed you the organizational component and it has this legacy of being almost completely empirical I mean biology has one theory right evolution and that's pretty much it right and therefore the tendency focus on increased degree of description which gives us this problem infinite regress so again first principles guy so let's go back and say what are the questions of science and how they fit into this particular paradigm all right so why don't we stare at studying how does that system work and why does that system exist in that particular way all right and the idea is that you want to gain deeper scientific knowledge it has more general applicability through greater explanatory power right and this "
    },
    {
        "start": 1236.46,
        "text": "is the key towards understanding how biological systems work right so what is the weather by out well that's this is description I all the data concerning a particular system goes into describing a phenotype of that particular system and it represents a rep a description right and this is agnostic to scale because you can have metadata population data I rather data all the way down to your different levels of elements so here's a fanciful classification system for biological systems right again completely so this may seem kind of funny or ridiculous but on the other hand this is agnostic at scale and there's no reason that this is the invalid means of describing system or a biological objects it's as valid as anything else you can do yeah there you "
    },
    {
        "start": 1299.85,
        "text": "go so you can have different classifiers based on these particular component this is the Zoological or botany basis legacy of biology right biology up until the time of Darwin and Mendel and molecular biology was basically a descriptive but you wanna know what the how of biology works and why is that important because it gets us the function function is what we actually view in terms of this what disease actually represents which is dysfunction you need to know function before you can characterize dysfunction and this is the means by which one phenotype transitions to another phenotype right it is what goes in between it is the dynamics of how biological systems exist all right so it's a dynamic interpretation of data right how does one dataset transform into another data set in a biological and scale becomes important right "
    },
    {
        "start": 1361.89,
        "text": "because as I showed you with that nested hierarchy of organization events don't necessarily commute all right so scale is actually important and then finally the why alright so generally people are don't like to talk about the why because your wrists Italian final cause issue which leads to you know teleology and intelligent design and that kind of stuff but naturality right we do have a final cause of biology which is evolution right because if we know one thing about biological systems is that every single biological system we have it's a product of evolution and therefore that particular process represents a constraint on how these things can actually emerge right so evolution is diversity plus fitness selection and and we'll come back to this concept a little bit so modeling the simulation in BIOS and science I think about as a path towards theories binding together disparate systems and disparate data sets and because of that right because of the uncertainties "
    },
    {
        "start": 1424.44,
        "text": "associated with biology right we have to have to be able to have some plausible validity first before we get into precise mapping between one model system right this plausibility is very important right because it's not an engineering task well you have a constraint system you have relatively comprehensive knowledge of how the the components of that constraint system works and you can do optimization right which is not biology because we all know what the rules are we don't know what those structures are so building robust models along the lines of a model simulation is akin to building robust explanatory theories looky here all right but the key here is you need to rapidly iterate this with an experimental ist's who are the experts in actually extracting knowledge out of biological systems so a colleague of mine came up with this idea of "
    },
    {
        "start": 1484.7,
        "text": "translational systems biology more words words words right because all the other words have been taken this is of course it's nice good that's all translational right it's systems and it's biology but right but what actually what sets this apart we think is that the focus is on constructing clinical phenotypes right so we're not modeling as important as they are yeast bacteria per se individual experimental platforms etc which again are incredibly important in gaining knowledge about mechanism but our goal is to affect that translational step to take that knowledge and contextualize it in something that's clinically relevant and this is important because control is the goal right as a physician it is not adequate for me to just to be able to diagnose and prognosis I need to be able to do something about it so just as my patient who was stabbed in the neck right I "
    },
    {
        "start": 1545.45,
        "text": "don't need any tests to tell me what he's gonna get doesn't matter though I can't do anything about it like ahead of time I have to wait for it to happen so in order to turn applied science into actionable knowledge we need to know punitive mechanisms we need to have inference of causality because those are things that are interventions in our fourth focuses of control are going to happen on alright so we build these simulation models with the idea of investigating control all right so we talked a little bit about the importance of dynamics yeah the idea here is that these are evolving systems they shift over time they are actually very robust because even with your disease states most of the processes are actually functioning in in a program sort of way but this is important right because "
    },
    {
        "start": 1606.139,
        "text": "there is no disease modeling without health modeling you can't model pathophysiology without knowing the physiology from whence the pathophysiology arose because then you don't know how you get back to the healthy physiology which is what the goal is so therefore every model I'm going to show you starts off as a model of a healthy system that if you perturb it in a particular way becomes a disease State and therefore we consider disease as a specific dynamic state so as Brian mentioned I do agent-based modeling I'll run through this very quickly but agent-based modeling is a discrete event object oriented ruled based computer simulation method that basically creates virtual objects that operate on series of rules you create virtual populations and you let them run around and you construct essentially in silico experimental platforms that you can now trot use like other experimental platforms right the keys here are your generating population behavior and "
    },
    {
        "start": 1667.64,
        "text": "encapsulated biological stochasticity whether that true stochasticity at the gene regulatory level or stochastic see that's doing two measurement unknowability this is important because anyone who's ever worked with a cell culture can set can realize that you can have monoclonal cells perturb that in one particular way and you get a distribution of how those cells act and that's as a set so if you take the diet of slide number three so every bioscience talk is slide number three one is a title two is the theory hypothesis three is the diagram right that shows all the arrows and stuff like that if you take that diagram you add it's stochastic stochastic into it you bed them and computational agents you can essentially try and reconstruct what a biological system may the most people know agent-based modeling through popular culture in these movies is the screen shocked or Lord of the Rings these battle scenes like the zombies and World War Z etc these are all agent "
    },
    {
        "start": 1728.58,
        "text": "based model right where each individual creature is a computer model sitting on a checker board or a hex board and has certain rules associated with I'm facing this the direction if I have X number orcs in front of me fight if I have Y number of elves behind me standing fight or run away or whatever okay and the idea is that this mimics how many biological systems work and therefore we get these very biomorphic sorts of appearing behaviors however all right so each creature is an individual program when they started doing these simulations for these CGI's what they found is that they couldn't get battles to occur because they program what we're actually very plausible stand and fight rules well once you put them in a population that incorporated space and neighborhoods right every time as the armies came together they turned around they ran away because they couldn't anticipate that population level effects could be inferred by how individuals behave because they couldn't do it right so the "
    },
    {
        "start": 1791.37,
        "text": "solution was to turn the survival instinct way down which there's a lesson in there somewhere I don't know but the one I choose to take is that there's power and population right there's the ability to encapsulate the range of behaviors that individual cells want of a better time intake so the idea is that you can now use agent-based models across this translational divide right where the reduction is necessary absolutely necessary reduction its mechanism by which we do basic research by taking things apart and finding out how things that could work we can reverse humpty-dumpty and reconstruct that particular system using an agent-based model in some form of a distraction impossible so I'm gonna give you three examples of where this works all right or my example of how I've used it I don't know whether you can tell me whether you think it works about right so the first one is actually my first "
    },
    {
        "start": 1851.4,
        "text": "work because as a critical care surgeon my interest was in sepsis and I started guy the thing that actually prompted me to get interested in this was the failure of the initial anti cytokine trial anti-tnf at the il-1 anti endotoxin right it led to again existential crisis in the sepsis community what's going wrong bah blah blah and then returned mug right but what I took out of this is well maybe if you had a model that represented the knowledge that people had when they made those clinical trials and you used it maybe it would they told you that it didn't work it wasn't going to work right so this is a old model right it's over almost 15 years old now and basically it's a representation of the state-of-the-art thinking about how systemic inflammation work in the 1990s at the time that the anti side the kind trials were done cell types mediators whatever relatively abstract so as I "
    },
    {
        "start": 1914.28,
        "text": "mentioned I'm not a computer science kind of person so I use a computer programming platform called net logo which is intended to teach K through 12 students about ants and traffic and stuff like that that's my level of computing programming expertise but what you see here is a endothelial surface that's perturbed with a trauma and you see inflammatory cells responding to that secondary injuries etc etc they're stochastic involved here basically it's an abstracted endothelial blood interface that I use as a proxy for an individual all right again abstraction now despite this level of abstraction it is plausible because it is able to reproduce all four big buckets and behavior to injury right if you can either heal it can have pro-inflammatory serves and die it can have immune compromised while the organ failure where it's "
    },
    {
        "start": 1975.16,
        "text": "susceptible to an otherwise trivial insult and then die or can have overwhelming again very large abstract it actually is valid because it reproduces the cytokine profiles associated with clinical patients we have substance right so every legal rule that's now put in that particular model can then be manipulated as a example of a control mechanism so what I did was I took that particular model and I simulated these anti cytokine trials both the ones that were failed and some ones that were in animal studies and combination therapies which were not logistically able to do not and the question is given the knowledge that you have and a representation that behaves plausibly right do any of these things actually change outcome and the fact is they do not so the critique of this paper of course is that we already knew what the answer was none of those things "
    },
    {
        "start": 2035.82,
        "text": "work okay but the fact of the matter is that the process by which this was done assumed that they should have worked right because I I gave the drugs every chance to do exactly what they were intended right so no question about bioavailability no question about whether the dosing was appropriate those things are fixed right so given a system described in this fashion you perturb it in that particular way it doesn't work right so system what is so robust it couldn't be changed because if you gave me antibiotics the things got better which is again plausible right so watching this gave us insight because what happened was if you gave the intervention the TNF would go away for the time that TNF was an anti TNF was administered but the damage is still there right it shuts the entire system down such as the system can't heal so it just delays with the implement so you get this pebble in the stream effect right associated with the intervention right and and the problem was not "
    },
    {
        "start": 2098.18,
        "text": "parallel pathway we're done to see which is one of the things that we raised at that point in time but you didn't block enough of a stop it's temporary robustness because the system can't correct because you're blocking the things that are needed for the thing to actually correct right which subsequent to this is realized that sepsis does not endogenous anti-tnf monoclonal antibody deficiency right that's not what the disease is it's a different thing right and therefore that particular intervention is not the appropriate thing to do and systems died because they couldn't clear the initial damage and recover quickly right and this is what we actually see right so the function of functionality of this is essentially you can think of that computer simulation as an instantiated thought experiment right where it's a conceptual model it's a hypothesis that you can now visualize and see how it can actually go and you advance by taking hypotheses that don't behave oddly throwing them away in advance positive ones "
    },
    {
        "start": 2158.319,
        "text": "and this is something can be done a candy discovery this paper was a decade old anissina is a European pan-european initiative to look at in silico trials I'm going to their next meeting in Barcelona it some of you may be familiar with this right but but this is coming down the pipe all right so now I'm going to talk a little bit about cancer I'm not a cancer biologist again I don't nothing about these sorts of things I had a student come to me say I want to do a project in breast cancer like okay that's fine so how does breast maintain its own duct epithelial population at baseline what's the healthy state so we decided to start with that right and this is the schematic that shows the components of this right requires all these other other than duct cell pathways and when we put this into a net logo program it is plausible because it reproduces the cycling of the breast tissue associated "
    },
    {
        "start": 2221.109,
        "text": "with hormonal stimulation and actually shows expansion of breast cells in pregnancy and it also is calibrated to hormonal cycle to detect the proliferation of breast tissue so the basic cell population levels are plausible and then we said okay now we're going to add our Genesis and what is oncogenesis well August Genesis is DNA damage in traditional mutations so we created a synthetic genome that has particular functions that if they get knocked out no longer work in that particular model alright and these are our functional changes so the other you know 9990 to jeans they don't do anything because we don't care about that these are genes that are associated with oncogenesis they get knocked out and the things that they're supposed to do don't happen anymore alright so what we then did is we wanted to now bridge this mechanism to population level modeling so we "
    },
    {
        "start": 2283.15,
        "text": "simulated 40 years of menstrual cycle so this is pre menopausal cam alright and now since cancers a rare event that takes a long time to develop we define cancer is unregulated growth and try to see whether or not we can match the intensive development of cancers over time so the big problem is with that particular conceptual model you couldn't get any are positive cancers which is a problem if you go back really quick our only way for cancers to propagate is if they're damaged cells replicate in ear positive cells don't replicate so he said how do we get er positive cells to replicate I just see Matt's involved in suppression of their replication so the question is what suppresses c-met in an ER positive cell and our student found this thing called Bronx 3 which is a tumor suppressor gene "
    },
    {
        "start": 2344.15,
        "text": "that's identified and gastric cancers and we put that into the particular model and we generated plausible population dynamics of both wild-type at verka knockouts both in terms of endpoints and trajectories with respect to C or population right and runs 3 I think has also been shown to have the increased express in ER positive feelings on a ex post facto evaluation so this also led us to think about a more in-depth question of about what cancer is is again I don't know anything about cancer I don't know how all these different pathways etc right but first principles approach what is cancer well first of all cancer only occurs in multicellular organisms bacteria don't get cancer all right and they're disordered cells with this order to grow so the question then is what are the failure points that are possible from an evolutionary standpoint that lead to "
    },
    {
        "start": 2406.22,
        "text": "cancer behaviors which looks like you know cell your behavior so came up with this generative hierarchy for cancer right where first order profit processes represent actually the DNA damage to the base pair switches or the production of snippets second order processes are the manifestation of those particular disorders or dysfunctions as cellular dysfunction so problems associated with apoptosis loss of growth regulation etc and then third order processes which are how do those cells behave within the context of the tissue right so these are stromal affects angiogenesis etcetera now the source of the damage a causes of DNA we always know that they're external things toxins radiation etc the inflammation of course is a well-known a intrinsic "
    },
    {
        "start": 2469.02,
        "text": "biological process that dissociates so the question is now can we contextualise cancer in inflammatory milieu we come up with this schematic right where the declamatory damage these different kinds of processes and the key here is that you're shifting these damaged cells first a second order disordered cells it's now colony behavior so they behave like unicellular organisms we're from an evolutionary standpoint genetic plasticity is not a bug it's a future because unicellular organisms utilize genetic plasticity to survive so now you have a cancer that is utilizing its plasticity of its genome its ability to increase its incidence of mutation as a means to escape any sort of therapy that you want to do that's predicated upon eradication right because that's what evolution is right fight eradication same sort of synthetic genome and what "
    },
    {
        "start": 2529.14,
        "text": "this shows basically as you would kind of expect again not an unlawful output that as you increase the amount of inflammation you generate increased number of cancers and these micro tumors and that increased cellular disorder is associated with more inflammation which again this came out about a year before but that paper in nature about the number of the the cancer is chance type of thing right where the more replications you actually add the more chance you have mutation which seems so obvious but right but to here is that the disorder needs to increase possibility of resistance to put any particular therapy so the implications for cancer treatment are that you can't account for second or third order process unless you deal with the first-order plastic because then you're just skimming the top of the iceberg all right so Eradicator therapies that induce inflammation are bound generating resistance by the very nature of how "
    },
    {
        "start": 2590.82,
        "text": "that system is doctor so what you want to work for is potential environmental control as opposed to graddic ativ strategies take those components of the cells that are actually functioning right and use them to make them be happy right so you live with the tumor as a as a follower that gets us to host pathogen interaction right so the big schematic this is a very hot topic right now microbiome all that kind of stuff all right so I'm going to give you a couple examples of how we've looked at host microbe interactions primarily in the gut so there's a disease called necrotizing enterocolitis right greatest cause of neonatal gastrointestinal morbidity and mortality and basically what happens is if you have premature babies and if you feed them they sometimes their gut turns black and die and there is a bacterial component but there's not a specific bacteria that's associated with the particular disease "
    },
    {
        "start": 2651.03,
        "text": "it's hard to study because in order to do this they need to like throw a little baby rats and hypoxic chambers and refrigerators and stuff like that which we don't do with children so the question is whether or not the experimental thing that you're using to generate a particular phenotype is actually mimicking the processes that generate the particular disease so we came up with a minimally sufficient hypothesis that immaturity of reactive oxygen on species management and immature and recites allowed them to become fragile as a result of metabolic stress which a mature enter site doesn't have so the usual diagram is all the stuff that goes into the agent based model and what this model does is it generates the different disease space is associated with necrotizing enterocolitis where you have a subclinical survival phenotype this patchy next scare phenotype which is important clinically right because that's your actionable window and then "
    },
    {
        "start": 2713.819,
        "text": "perfectness occur OSIS which you have to operate on and the idea here is that you can generate a disease space based on the fragility of the enterocytes and the virulence potential of their microbiome not tied to a specific bacteria but what that Bureau's potential is within the patient's microbiome at itself so that might be manipulated with formula feeds maternal milk other types of probiotic agents etc but that gives you potential control knobs that you can now triangulate in a space to reduce risk so those used abstract bacteria this is an example of more detailed bacteria I collaborate with a guy John Albert II at the University of Chicago right he studies Pseudomonas virulence and got derived sepsis so what we did was we took an abstract model of the gut ecology and we embedded models with his "
    },
    {
        "start": 2774.41,
        "text": "rule so this is exactly dynamic knowledge representation of that diagram which is the canonical diagram that represents what his lab does so if I go to a particular basic science researcher and I say what do you know they write this big thing on the whiteboard and say okay I can put that into this program we'll see how that runs and what we do with this particular model is running along with his in vivo experiments to help try and predict and examine what the various states are in between his sampling points or in conditions that you can't logistically do with his particular lab last model I'm going to talk to you about is a spatially explicit all-purpose model of in Care Act issue we really really struggled to get something that would come out to a word this is a virtual gut that basically recapitulates the histology of the gut surface and this is our current state-of-the-art gut model and it has "
    },
    {
        "start": 2834.81,
        "text": "this control structure with the idea of reproducing histology histology is important because that's still used as a marker for disease clinically right so these are the pathways incorporated or in this inflammation blue is morphogenesis and as with the runks 3 situation we need to make a hypothesis as to what a potential link was between these people third path we came up with p10 which has subsequently been demonstrated to be actually up regulated in a particular right but the model maps to the histology so here's the gut crypt the lime we construct a set of rectangular boxes they have grid spaces on them this is the grid space unfolded in the model and this is a on a single processor you let this run run run but if you do the supercomputing version of it "
    },
    {
        "start": 2897.67,
        "text": "you can generate essentially a Billis architecture here that looks like the less architectural this is a supercomputing of innovation right well each one of these little dots is an agent so this model is validated because it generates plausible mediary gradients with respect to the morphogens and its general purpose because it doesn't have one disease and it replicates because we replicate the state of health right it's able to reproduce healing of local injury it's able to reproduce the effects of ischemia reperfusion on the gut mucosa and it simulates metaplastic change as would be seen in the pouch of a patient that remedial surgery for ulcerative colitis right by changing the Crypt Billis ratio due to persistent low-grade inflammatory stimuli so we've extended this particular model as I mentioned the segment HPC which is a supercomputing implementation at the C++ "
    },
    {
        "start": 2959.809,
        "text": "geometric partitioning for those of you a computer scientist 'add we've run it on a Cray the Beagle at at U of C there's 12,000 cores we can simulate about 60 square centimeters of tissue this is the paper in PLoS ONE just came out and the idea is that now we can scale across molecular scale to an atomic scale issues like flow dynamics tissue architecture etc all right so we have a director's grant on this particular project and the BT two of a are on one pending hopefully we'll get funded yeah and we have allocations on Sierra at Livermore Mira argon and Titan at Oak Ridge which is their largest this is the euro one that we have just set in the MSM consortium right that uses segments to study pouch itis again hopefully so in this the microbiome is "
    },
    {
        "start": 3020.47,
        "text": "relatively abstracted but it represents a control feature and this is goes into a Department of Energy Initiative called basic right so I'll just talk very briefly about this the basic initiative is an attempt from these National Labs to look for something for their supercomputers to do because they're tired of simulating nuclear bombs right so they want to be able to use their petascale exascale computer to simulate something else so they're looking at biology right so it's a consortium of federal deal we laughed academic partner it's an industry from tech Intel Amazon blah blah all right and the idea is to get direct federal earmarks along the size of exascale computing initiative means a couple of billion dollars a year to do this right so the current basic track structure has predictive pharmacology pathophysiology hatha biome this is done at Harvard by Joe Liske ah "
    },
    {
        "start": 3081.25,
        "text": "so who's the chair of medicine at the Brigham I believe Tim Buckman at Emory is running the sepsis predicted pathway I'm leading a modeling component of that particular pathway and I'm also co-lead of the predicted path of biome which is looking at antimicrobial resistance potential in the microbiomes of ICU patients all right so I'm sorry I'm going through a lot of this stuff that we can talk in more detail about these things that it like right so I'm here to be recruited nothing tell you anything different all right so these are the rolling horizon of deliverables that we want to try and do all right so there are short-term things classical bioengineering things that can give us clinically actionable output right now then there are medium-term data centric things prognosis diagnoses these classifications bio knowledge it's that but to actually get to the end point of being able to engineer new therapies and really deliver personalized precision medicine you're gonna have to go to "
    },
    {
        "start": 3142.72,
        "text": "simulation it has to be this way right because the key is being able to represent outlines and simulations allow you the possibility that being able to explain outlines so when you do data too many possibilities right we all know this increase dimensionality data increase intentionality of explanation right and theories are the things that constrain what those explanations are right and this is where the personalization generation of state from those particular constraints thank you this is our translational goal and as much as we would like there to be there is no shortcut to that scientific method all right we still have to test you still have to evaluate with those hypotheses actually all right but you can potentially accelerate accelerate that cycle so this is the last thing I'm going to show you we have come up my colleagues and I with this thing called "
    },
    {
        "start": 3203.89,
        "text": "the computational modeling assistant right where you essentially semi automate those processes that can be automated in the construction of computational models right so what this does is it basically a big database integrator where you take knowledge that's expressed in near natural language form and it uses a logical rewrite system to say if I have a hypothesis of this particular structure you can generate computational simulation models of these particular types and it will generate code for that in these first set of code and will tell you how those experience simulation experiments should be want right and what it does if it takes to a certain degree to copy the modeling simulation computational biologists a little bit out of the loop because we all know how difficult it is to actually get that ball roll right it is a collaboration facilitator for those of you who are interested right this is what the software "
    },
    {
        "start": 3264.79,
        "text": "infrastructure for the CMA actually is right uses cocoa this is the data level SQL system application tier uses mod which is a logical rewrite system from U of I or banished Champaign and the simulation engine it's based in biochemical by alarm runs on GPUs but may be used on other clusters right the guy I don't know anything about how this actually works this guy Scott Chris Lee the computer scientist who worked with me to develop this system so what does this all get you right so if you have a model that behaves in a plausible fashion well then that's plausible and now you look for ways to break it that's outside today right and if it doesn't match then you say ok now I'm going to go back and look at that hypothesis structure and say what parts of those things are I am not sure about right and since electrons are cheap you can run all those different possibilities and "
    },
    {
        "start": 3325.03,
        "text": "see which ones actually behave positive though you always have to remember this Mark Twain quote it ain't what you don't know that gets you into trouble it's what you know for sure or that just ain't so right so you guys always go back to first principles and check what your underlying hypotheses are the vision for the future is that scientific research community lives in knowledge ecology right where we use evolutionary principles on science where you have all the wonderful data collection interpretation capable capabilities placed into a HPC augmented hypothesis testing environment that allows people to investigate sort out and select those hypothesis structures that that that are that's that passed the test of new observables right right this is the fitness function those hypotheses that are fit because they can match newly observed data are the things that ended "
    },
    {
        "start": 3386.95,
        "text": "cycle this is what I talked about in this 2010 paper about bridging causality and correlation in the petaflop age it requires by the way we're the book about this this is biology pretty expensive all right that's it any questions sorry it's a lot of stuff so that that's good but I go back to the Mark Twain quote with these agent-based models you're assuming that you know sort of what the knowledge base is and the reality is for example the central nervous system in humans we don't really know a lot of the pathways and what's going on there so any kind of agent base "
    },
    {
        "start": 3448.82,
        "text": "model would have to have some kind of built-in ability to be I don't know accept new data and extract it from not knowledge to make the agents oh right so so the question is how do you deal with unknowability is a big problem yeah so how do we deal with it now we just say oh I don't know that I try and get some more information all right the question is we don't know what we know right so assuming that this is incomplete assuming that that might be wrong assuming all those sorts of things this gives you a visual visualization of how that actually might behave I would say that that's actually a very useful piece of information because you go into it knowing it doesn't represent ontological truth you go into it knowing that they're going to be gaps just as as I demonstrated in our examples our models were wrong with respect to the breast "
    },
    {
        "start": 3509.66,
        "text": "cancer and with respect to the initial link between morphogenesis and inflammation the question that is it now focuses you on finding what is the thing that's actually missing right so of course they're incomplete they're going to always be question is whether or not the model you had is good enough to represent enough of the data that's out there such that that model could be potentially useful in engineering that some therapy or prediction for that particular system yeah yeah yeah well it is this follows "
    },
    {
        "start": 3586.45,
        "text": "along with the knowledge that becomes acquired right so part of the problem with the kuhnian paradigm is you don't know it's happen until after it's gone right he doesn't tell you how to bring it about right you can't I mean by definition right you can't do anything about that right so yeah that's right you are in the midst of it so the question then is whether or not you can utilize any sort of tools that will allow you to gain an understanding into what you actually know now right so explanatory models like the type you're talking about right represent the endpoint of that is still a hypothesis function the degree of precision with respect you believe the hypothesis is up to you and your trust with your particular system but the fact is that now you want to manipulate that particular system right if you only use an inference program you can't test that until after you've collected the data on that whatever "
    },
    {
        "start": 3646.609,
        "text": "intervention you've actually done because you can't test that right what we want to be able to do is project forward into what are the possible sets that might happen understanding that it's not going to be perfect right this is why it's still an open research here we want to be able to develop the tools to increase our level of trust in those particular projecting simulations to allow us to move both [Music] okay good listen you know your model is based on I'm putting in data that simulates a model and you're testing sort of the integrity of what you're putting in but again to extend that to things that are outside of that model I just don't see how your system can do that and maybe I'm just missing something right so one way to think about what these models are if they're essentially hypothesis representations for conceptual model verification right "
    },
    {
        "start": 3708.89,
        "text": "so using verification in a computer science sense as whether or not you're conceptual model behaves the way you think it's going to be given all the multiple connections that are present right that's the first test because if it doesn't behave the way you think it behave then either there's something wrong with the model which is possible right how that model was implemented but there might be something on anticipate in what you actually bought your knowledge actually represented so right now science tests something very if microscopically in a dish right a very controlled experiment very controlled calm and then there's like the population reality which is a macro yeah environment which is very different than unlike this type of environment and really you're trying to sell that you want to make that leap you want to be "
    },
    {
        "start": 3770.059,
        "text": "able to make these big active models in the population but really you're using data from that micro environment well so you're using some of that data and you're you are not constructing a model of that data you are constructing a representation of the generative mechanisms that produce that right so it's very important in my mind to separate the data which is the list of observables that you have that are your let's use Plato for a second the shadows on the wall right represented by the light that you can see but you don't know what's behind right that's casting that shadow you make inferences about that okay so what this does is it says okay I have this shadow that looks this particular way in this shadow that looks looks this particular way is and I know there's somehow kind of similar is there some sort of conserved generative mechanism that can allow you to represent both of those now "
    },
    {
        "start": 3833.48,
        "text": "my argument is that this represent this is a question of parameters as opposed to models function so let me use the thing I talked about this morning within is that I think it was game on where the range of biological behaviors in human people in many ways is an issue of parameters not necessarily component know kind add the same gene go here go there right but even an individual because I'm sick now my parameter said is different than it was when I wasn't sick okay but it's the same model structure underneath so what you want to be able to do is to have a conserved enough robust model structure such that it's regions of parameter space can capture outliers and this is the key it's the importance of outliers so if you construct the data model and I don't know enough about how data is done right but my understanding is that if you have "
    },
    {
        "start": 3893.51,
        "text": "a very wide dataset right you want to be able to try and find the best fit right you don't necessarily and by doing that you have to us to a certain degree except that your fit is not going to hit those outliers now the fact is those I liars were generated assuming it's not you know experimental error or whatever right the biological system had the capability to generate those particular configurations however it happened to be able to do that there is some fundamental level of representation of those generative mechanisms that can allow you to do that in a simulation right so this bd2k grant and I'm having I kind of flips the idea about what it means to parametrize a simulation so of course in systems biology the parameterization of your model is a big deal as you would expect it to be right and unfortunately many of them are too brittle because the parameters are "
    },
    {
        "start": 3954.03,
        "text": "relatively small okay that's actually not a very explanatory model that's a very precise model that's not very explanatory right what you want to be able to do is to have a broader exploration of what model parameter space is and say can I actually reproduce these outliers with the model structure with those particular method now what you're looking is at as categorization of parameter values when you evaluate follow-up biological systems as opposed to specific component that you buy it you know I mean it's yeah I mean it's how physics works Kevin yeah but it's not the data you're "
    },
    {
        "start": 4020.27,
        "text": "putting in it's the knowledge that you are using to construct how that data right there yeah yeah but that's what we operate on I just want to make a comment I mean as a clinician I find the agent-based modeling sort of exciting because it's providing a sort of a more phenotypic output you know which is really important and the other thing is that it's it's probabilistic as opposed to deterministic and so when when we run these models time and time again I mean we'll get an output plus what's the standard deviation which is again what we observe biologically but I don't think dr. an is suggesting this model as opposed to all others I think it's an important tool and you get to multiscale modeling there's certain aspects of biology that are best modeled using certain techniques and this is certainly I think one of those so again when you're looking at really "
    },
    {
        "start": 4081.12,
        "text": "complex systems inflammation and coagulation and those sorts of things where concentrations and neighborhoods become really important this this gets really really exciting in my opinion all right the CMA that we've developed doesn't just build agent-based models that will build any kind of computational model that you Dan just a simple question you're emphasizing somehow the valuing role of the outliers and in these simulations just methodological question is it possible to go in and pull out the data points that correspond to the outliers and run the mechanism backwards to see what it was like you say within the biological potential of the system you can generate this outline outline behavior so can you actually do an "
    },
    {
        "start": 4143.46,
        "text": "etiology of your outlier why did it go bad yeah that's what I want to be able to do right because we I I currently do not have the resources to do that degree of path investigation right so this is the model checking checking that you know was invented at CMU I think but but this is the idea right so that you take the ones that are your unusual one pay you back trace those and see whether or not how it got to that but the Third Point is a plausible sort of thing I think outliers are important because that's where the interesting biology is so that the the capacity to generate outliers is the key to why we have heterogeneous population differential responses to disease and why we mean have something like this to get to "
    },
    {
        "start": 4204.3,
        "text": "precision medicine the precision medicine is just the right drug for right person right it's the right drug for right person at a particular time based on their particular health state Jerry you in an earlier slide you defined evolution and gave some kind of sub steps in the process of evolution are you utilizing those principles kind of as an expansion of the genetic algorithm and some of your simulation effort I have not I have not done that because when I talk to certain computer scientists these models have too much randomness already right and GA s you know are black boxes and we don't actually know what's going on with respect to that we are looking at the use of GA s and other types of machine learning to do to build potential classifiers when the behavior spaces of these particular models and see I mean "
    },
    {
        "start": 4265.95,
        "text": "came on a great conversation this morning about potential project where we might be able to do this reverse machine engineering to nap back at work between simulated data sets input parameters into dealing with but when it goes to the predictions to have predictions that works and ones that don't work that outliers reverse engineering reverse machine and allows you to train another related model to trace this back to the parameter basically improve the weather to devote a mad scientist early and goes back and forth through a process to make sure that your mother is actually instead of overfitting it's basically matches thank you okay any last questions well I think you've generated you've gone "
    },
    {
        "start": 4326.22,
        "text": "through play-doh and you know Frances breaking I mean you took us through over 2,000 years of thinking about science and Thomas Kuhn in their gourds e'en so lots of good ideas and lots of practice so thank you very much it's very stimulating I mean your question yep [Applause] "
    }
]