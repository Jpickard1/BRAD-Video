right so welcome everyone tools of technology seminar series we're gonna go ahead and get started I do see a few new faces so just a reminder or to let anyone who's new know and this is basically just a weekly seminar series at this time on Thursdays talk about new tools technologies methodologies actually not necessarily new there are in development there are recently developed or they may be are old but may be used in a novel way by researchers so we have a great lineup throughout the semester so today I'm pleased to present Jake Carlson a minister and Scott Martin from the U of M library who are going to talk to us about deep blue data right thanks Marcy so I'm Jake Carlson I'm the research data Services Manager for the the library deep blue data is part of a larger suite of services so I'm going to talk a little bit about the the services and sort of where they came from and what we hope to help support you in doing with the research data I'm going to turn it over to Amy and Scott talked more about deep blue data and the services we offer through our data repository so we start off with a pop quiz and you think of a library what's the first thing you think of forex but hopefully you don't think of that right this is not a library this would be a faculty office or my office on occasion but it's not a library this is a library and the difference is we don't just get books or get journals we organize them so that they're easy to find that they're grouped together on like subjects so that you may come across other things of interest based upon where you're looking we provide structures to make them available to just refer them to people we have means that you can access this information you can go to the library and pick up a book off the shelf and check it out and we have structures in place to preserve this information so I'm going to just buy it and let it sort of slowly die a horrible death we be sure that it's taken care of and stewarded and connected to a particular community so the challenge is these days the work environments you know don't let shouldn't look like like the office they look like this you know you have your desktop and you have stuff so spread all over the place and you know who knows what exactly is there maybe that's okay for you because you know exactly you know what this particular file is but somebody else coming to look at your desktop will be totally lost by all of this this is a chaos and so yes again this is okay if it's just you increasingly now it's not working yes so increasingly your data it's not just something that you were gone but others worked on with you if you're doing collaborations if you're working with partners and increasingly some agencies publishers others expect you to do more with your data than just let it die slow horrible death in your computer funny this is indeed a message of plan asks you how are you going to share your data are you gonna make it available if he's funding I'm an agency you can't just sit on it you have to share it in some way shape or form how are you gonna do that publishers also expect that data will be included or made available somehow through the publication and a number of folks tell me that in their field they can't just read a paper and let me understand what the finding is all about they have to see the data to more fully understand the significance of the finding to really sort of understand the depth or or meaning of the finding it'll to be able to trust the finding as well it's not just putting it out and saying this is what I found trust me it's providing some more evidence or some more ways to reproduce that research so if in fact we're more confident that the results are what they're being reported some conspiration can really bring some complexity especially if we're he would put some different discipline people sort of have the norms and practices about how one works with data management data how one labels of data when you get together it can be difficult it's almost like speaking a different language from working with one person to another so how do you share data effectively even within your own groups that can be challenging as well data really needs to be well described and documented to have value outside of the place where it was generated so again you may know where your data on how labeled am or you know what actually that number three means and your dignify because you're familiar with with how you generate it and put it into but everybody else take a look at wouldn't be able to make sense of it or understand it and so we're looking at how data are described and documented to have value beyond its its place of origin and finally we have a lot of presley now to share data but so you do that it's just I have to share the data so here's something but do it in a way that has value and impact to your work how do you get credit credit for the work that you do so how can libraries help in this in the sort of new environment of increased use of data and sharing data well we have a long history of taking disparate sets of information and creating structures and platforms that present them in an organized fashion so we we have information from sociologists from art historians from civil engineers from biochemists our system we organize it makes it available and accessible to anybody who may have an interest in those particular topics we also understand the ecosystems of how information is organized and shared and messaged in different disciplines so billions we have a certain type of librarian core the liaison librarian and they have a connection to a particular discipline or department and what are their roles really is to understand how is information shared what kind of norms and practices are there in structuring information and making it available ensuring its longevity so we have people who are dedicated to understanding and applying that information that's finally we think in the long term I think we're one of the few agencies in the university that is tasked with not just acquiring information and making it available but thinking about how we preserve it and preserve its value or come on in term beyond just the sort of the heat of the moment that's missing this we're looking at how can we apply what we do have done with books and journals now those sort of print materials how do we apply that now to the world of data to help you do what you need to do or want to do and messaging sharing and preserving the work that you develop there your data sets but so don't just happen you know they are worked on they're developed over time and so we're really looking at we structure our services to help you do more with their data to the data lifecycle so at the beginning can we help you find the data sets it's sort of an extension of the work that we typically do not that you find information that information in data sets as well as again books in in journal articles so how do you track down the data sets you might need to inform your research or to give you ideas we give you a sense of what's been done already in the area of study that you might want to pursue that's lighting up management planning so not just the two page plan you might need to submit to the NSF or they didn't start collecting about you to develop for the NIH what are the kinds of things you might want to think about when you're just getting started in terms of structuring your your data and how it's going to be generated how it's gonna be managed help might be organized to benefit people later on down the line but the benefit yourself if you work through the data rather than consent to spend time sort of thinking about well what do they do three months ago or six months ago and having to sort of recreate the wheel can we help you structure the dataset in a way that makes it easier for you to use and develop and grow during the project itself that's it towards the middle of the project we're not going to be doing the data collection of data analysis obviously we're librarians but we can help you consider documentation you might want to generate in order to make your data meaningful and valuable to others when you get to the point where you're ready to share it think about what the metadata of some structured informations and structured description you might want to apply for your data again to make it more useful both for yourself and for others later on down the line and then how did you organize the data so that it's not impenetrable but fairly easy to understand how the different data set fit together to make them more accessible more usable and then towards the end which we will be talking about how can we help you share data in a way that gets you credit for putting it out there for how do you might want to polish your data set I'm using duis or other sort of identifiers to enable your data set to be cited to give you that credit and how might you want to preserve your data what are the important elements to preserve how might you need to stretch your data or prepare your data for preservation so it's not just and available at the moment but has some long lasting duration and again it can be cited as an object of scholarship and so these are sort of a summarization of the seven types of research data services that we offer from what I didn't cover we also offer visualization services that are offered Muncie actually has a hand in that I think I'm actually probably aware of the kind of things that she does we could have to consider how much you want to tell your story through data and give you some ideas about what kinds of software our approach is you might want to take to tell an effective story to communicate the the research that you've done in effective ways and so with that we're going to focus more on the sharing of publication and preservation aspects and I'll turn this over to you aiming in Scott to talk about deep blue data okay so as Jake said we're gonna be talking about a particular facet of the research data services suite at the library which is a product that we call deep blue data actually probably should have put these slides in the other room now I think about it so let's let's start here how many people have used deep blue before or know what deep blue is how many non librarians in the room blue before or no and deep blue is okay Gil knows okay so deep blue is the university's institutional repository this is an online repository by the library for depositing archiving and making accessible scholarly products of the university deep blue has been online for about a dozen years now and holds several hundred thousand files the vast majority of which are PDFs of scholarly papers written by researchers at the University there are a number of other things in there as well but they tend to be along that theme of sort of print format documents so PDFs Word files public presentations things that humans are going to didn't understand deep blue data is an expansion of that brand into the world of making data available archiving data sharing data so material that is probably going to be consumed by not necessarily by humans probably buy computers computationally so we've created a system here that is optimized for access and preservation rather than a human readable document consistent reservation data accepts a wide variety of things we're conceiving this as a cross-disciplinary repository so we're not confining this to just STEM disciplines on campus or just you know humanities and Social Sciences we'll accept anything from any researchers on campus and we'll accept data in any format now obviously because we're librarians and we have particular ideas about the ways that people should be sharing data we're going to encourage you to use open non proprietary and widely used formats what that's possible we recognize that that will not always be possible and so we're willing to work with you to get for example proprietary instrument files that are an integral part of your data set it's a deeply data we're also not putting any size limits upfront on the data sets that we take we will take all sizes that are technically possible what that means is whatever we can find a way to shoot oran into the system so the interface that Amy is going to be demoing in a couple of minutes is a web browser interface obviously web browsers have some limitations in terms of size of material that you can easily upload and download I think about two gigs is the limit that we're gonna be able to ingest before your browser starts to timeout we will take larger data sets what ingesting larger data sets means is that we need to come up with a way to physically transfer things into the server so if that means we need to come over with a handcuffs briefcase and pick up some hard dirt on some hard drives and then carry them back and put them on the server we can do that we really want to do whatever is gonna be necessary to meet the needs of researchers in terms of the size of data they have stored and the libraries made a commitment to fund deep-blue data with an eye towards storing as much material as as possible rather than trying to there the size range that we're talking about we've we've talked to a wide variety of people not only not all of which you are necessarily gonna want to save for publication right so that's that's the thing about deep blue data is that it's intended as a publication repository not sort of dark storage for things you think you might need later so we need to have we'd want to have conversations about what is necessary to publish for particularly needs settings used in your programs that can change the results verifies the documentation of oh yeah I'm sure it'll explain you can't have a different program or different parameters that you use you couldn't do that yeah we do want to have many reasons as to what is the most important to save for your particular purpose so if the idea is I really want a dataset that it helps explain my findings that's a different set of data then I really want a reference set of data and others can use and and do analysis by it's a different different level of depth in terms of documentation and in terms of structure and such and if it's stored somewhere like in a public system you have a way of inserting things instead in other words a lot of things require data right so linking so um we have a way of linking to papers right now but I think what you're talking about is much more independent to get to the day itself right so if the data is deposited at NCBI and that is your main mode of access to it then that probably is the way that you should go so we are putting out deep blue data as a solution for people who may not have a key source like ncbi or from that community source isn't appropriate for whatever reason but if there's a better resource out there that it's more connected to your community that's more able to handle your particular needs we are still very much willing to sit down and help consult with you to figure out how did it go into that particular place so this is a solution not the solution yeah we're limiting not based on size or based on needs so we're working with a professor of astronomy right now and how much data does he I think like 30 30 terabytes I want to say it was guys in creeks oh yeah so we're working to ingest that and develop a workflow on that so it may actually not be a bad idea to be able to create entries that could link out to the NCBI record so there would still be affiliated with U of M and people could easily find it make it more discoverable not only by searching NCBI so we talked about that and I think right now we have deeply data and it's a platform and we have a certain idea of how people want to engage with that platform but we recognize that there's many other possibilities as well and so if you haven't seen the interest in terms of like perhaps putting pointer records in deep blue that would point to different data set we haven't done that yet but we're definitely open the possibility of the talked more about what would the value proposition be both for you and for the community and how what we have might enable those up the value of our position is to come to pass we're always looking for test cases okay so why deposit in deep blue data I probably don't need to convince anybody here that data sharing is an important goal deeply data provides a way as we said not necessarily the way for any particular station but a way for you to make your research data visible to the world in a protected and secure fashion this is especially useful and as chick was alluding to earlier in terms of question compliance increasingly funding agencies are requiring a deposit of data for public access after the grant project is complete deep blue data gives you one means by which you can demonstrate to your funding agency that you are meeting that requirement using a resource that is funded more more well-supported than just putting stuff up on your website assuming you don't have anywhere else to put stuff we also make it easier for people who are using your data to cite it um you can assign a DOI a digital object identifier to a data set in deep blue data most of the emerging standards around citing data heavily leveraged do lies and so this is one more way to make it easy to cite that material as they go in um and then preservation the library is committed to preserving data that's deposited in deeply data now the question that comes up there of course is what does preserve me a minimum level that means that the bits you give us we promise to faithfully store and spit back out when somebody asks for them for highly used formats PDF a would be one of those we commit to not only storing the bits and spitting the bits back out but as those storage formats are updated by the communities that generate the standards for them we commit to migrating the files that are there to stay in compliance with Miller forms of say the PDF standard format we're still working out for which formats exactly we will be doing that some of those what these formats are open sourcing well-documented enough for that others are not we're always looking to engage with researchers and conversations about which formats we should have more developed preservation plans forward for but at a minimum bits in bits out we preserve things faithfully for you things deeply he does not accept we do not currently accept data that are under the purview of the UN research compliance programs so anything subjects to export controls or things that present conflict of interests for the university or researchers or whose distribution otherwise constitute a violation of research ethics or compliance which is to say at least the moment HIPAA HIPAA data yeah so sensitive data difficult aining personal identifiable information and administrative data from the workings of the university the university has an infrastructure of its own set up for storing and making administrative data available internally deeply data is not that if administrative data is being used for research purposes and we have the consent and agreement of the parties involved in the library then we can't host administrative data it's deeply data but those are going to be relatively few and far between I think in terms of in terms of actual applications and sensitive data so things covered by HIPAA or FERPA other appropriate federal laws the University so material that has been produced by third parties that we've licensed for our use yes although I'm thinking more of a case where at the university we were doing sort of quite contract would that work for a third party that put restrictions on what we could do with the stuff we produce if you're going to deposit data in the deep blue data you have to have the authority to do so so if you are bound by a third party contractor so when you need to be have some assurance that the third party is aware and has signed off on your ability to deposit into deeply data okay I'm not so much concerned that is once it's in deep blue data is there any way you can put restrictions on it which gets absolutely few my next slide so that's a great segue great so accessing deeply data the way we have structured deeply did is that everything deposited into it is open access anybody who has a web browser anywhere in the world can come in browse our collections and download data so in terms of if we have an agreement with somebody else that that restricts data to only on-campus use or only members in the university community this is not going to be your platform that's not the way that we that we've structured it now depositing into deep blue data is substantially more restricted as with deep blue our documents repository we're making this a repository of research products the campus of members of the U of M community which we're defining this way us faculty and research staff on all three campuses so folks from Flint and Dearborn can deposit as well and we've been out there talking to our colleagues at those libraries about how to promote deep blue data to their campuses awesome the institutional collaborative groups that include at least one U of M researcher who will then presumably be the person doing the depositing proxies who are designated by um faculty and staff this is something that we've run into is actually uh related to an issue that we came up with when we were starting to work with um NIH footprint deposit was that frequently the people to try to deposit preprints of papers for NIH grant compliance what the researchers they were designated administrators within the Health System or other parts of the university so with that in mind we want to make it possible for faculty and staff to designate proxies who can deposit data under their accounts whether they're grad students or other research staff within your particular labs or administrators within the UM Health System who are working to coordinate particular labs whatever the proxy system is designed to allow that to happen we do also allow students both graduate and undergraduate students to deposit with faculty permission we don't want students just chucking and you know whatever they feel like putting in their stuff from the undergrad classes which might not meet sort of general scholarly standards for data publications and we want some sort of faculty control on that questions about any of this nope turn it over to Amy and we'll see how this works okay so I'm Amy I'm the research data librarian and I oversee deep blue data so if you email deep blue data at umich.edu I'm the one who will probably be answering your email so we've been talking about this thing I think the best way is actually to look at it and dig into it so you wouldn't mind are you gonna drive for me Scott so we've talked a little bit about deep blue so if you go to deep blue that live that you may be you um you'll see that there's a new page that says deep blue is expanding and you'll see here's the dichotomy of you know here's our documents that Scott was talking about and then here's the data kind of portion of deeply data know in there um so here's what it looks like the two really big things that you can do is you can either browse data or you can deposit data so let's click click browse first and take a look at what this looks like so if you hit browse you'll see everything that's in this repository we've been open we did a beta launch on last February so I guess we've been open a year now not quite quite a year yes and we did a public launch in September so we have 57 datasets in here so this is looking at everything if you want to get a little bit more specific we have some really basic facets here on the side so if you want to look by you know discipline and say and you want to look at you know what's in engineering you can click on that and then that will bring up everything that researchers have identified as engineering for example so if you want to click on one of these that one looks like so I mean here's the description so this is um the metadata that the depositor has entered about the work and we'll take a look at what doing a deposit looks like - but we've kept it pretty simple I'm just really the title the methodology description I'm the creator again here are the disciplines that we've had them select keywords 8 coverage language here's the DOI the digital object identifier that Scott had mentioned so this is what you can actually stick in your paper to allow people to cite you with that DOI you don't have a treat for the size of the file you know what we don't and that came up recently I think we were at class talking to them and they said how do we know how big it is before we start downloading it and I thought that was a brilliant suggestion so we're going to be adding that no definitely not because not everybody wants a DOI or people perhaps want to make more changes to their upload before minting the DOI that's like the final step so is it done it is yeah so we can take a look at that when we when we do it's just a button you click it yeah um okay so that was the metadata and then here are the actual files attached to the datasets so you can see the name the four minutes what data was uploaded but yes size is not there and I think that that's a really stressed parameters this is molecular system is a simulation that's usually gigantic no it looks like it's just an excel sheet though so yeah my guess is given the title yes yeah not sure if we reviewed this yeah this is a newer one so we have not gone through and done a big review of it and I'll talk a little bit more about that um so that's just really what it looks like you can download those individual files if you wish yeah nineteen yeah great alright do you want to step back one screens dots um see I also would like to maybe show what a collection looks like if you want to get rid of that discipline facet and then just kind of search through I think there's one on the first page that's the different neighborhood I think next page should be fine so we have two different icons here the kind of single box this is like a single work or deposits people also have the option of depositing collections of data that's what this kind of multi box thing is we're gonna be redesigning our I can't thing but if you click on that that really allows so I should step back for a minute so a work can contain multiple files so deposit can contain many many files we have some that have a couple hundred and then you can bundle multiple deposits together into a collection if there are thematically related or I saw somebody make a collection for all of their labs things like that so this is a way of describing a group of works if you scroll down then you can attach those into the collection if that makes sense I'm good so that's what that looks like yeah what strategy would you use or like version so I publish a paper I create a tool and some data that goes with that but then every year after that I refresh the data and there's a new version of a pencil would that be a collection that's a perfect question that's a perfect use case I would say for a collection so each time you publish that would be a work or deposit and then when you make a new one you make a new deposit but bundle all of those into a collection so you correct yes yep so as the library we are very concerned with keeping track of what the scholarly record is so we're not gonna delete anything once it's in deep blue data we would just say this is version 2 this is version 3 but in the metadata or something we would say this is deprecated this is no longer the pointed forward exactly yeah but it's important to have its own record because you may have published version 1 people who encounter that publication would need to be able to understand version 1 we did rather than version 3 which may not be relevant for the particular papers you put out of especially if you assigned it to UI which is that what you can resolve and see the version 1 there needs to be something there to say this is the version that this published work was based on there is also an updated version FX out here yeah definitely yeah we're working very closely with icpsr and we want to make sure that we're not overlapping so we have pretty different models they heavily curate things that come in they did out openicpsr is different yeah and as Scott mentioned earlier this is really for all disciplines so it's kind of like a like a more shallow like a wider net I guess for more disciplines where as they go very very deep for the social sciences so if a researcher comes to us and says hey I have social science data you know we want to make sure that icpsr isn't a better home first before taking it I think Marcy didn't somebody contact us and we told them to develop engine or to deposit in GenBank yes that would have been a better home so that's really our goal is to make sure that the data gets into the best place maybe it's not deeply data that's definitely okay but yeah we talked to icpsr a lot one of things that we do that I think is art doesn't is we are willing to come to your office sit down work with you go through the data and figure out where is the best home and then work with you to get it there get it structured and probably submitted and then it is you know representative the value might be in that respect it's sort of an intermediate model between the deeply curated regular icpsr repository and the very very shallowly curated openicpsr we have some consultative services that go with data that I don't think you can get if you just came in today icpsr yeah and now would probably be a good time to mention um it's a good segue so we after deposits we actually do a review of them and we do kind of like a post deposit curation so I'm working with a PhD student and he and I go through look at it make sure that you know we don't have any recommendations like maybe you forgot a readme file that would be helpful for you know somebody needing to know how to run your code things like that and so he and I are working with the subject librarians like Scott for example and then getting back to the researcher and saying you know we recommend these changes here are the things we're willing to do we do these things kind of negotiating that in an ideal world we'd have those conversations before depositing usually because someone would come to a subject liaison like myself or like Morrissey and say hey I'm thinking about this is the work I'm doing with data what do I need to do to follow best practices for this discipline we could you know counsel well you probably want to think about these metadata formats and you know bundling things think about file naming in advance exactly yeah but in the absence of that coming coming back to things and say hey glad you put it's a deeply data we we took a look and we have some suggestions and we think might make your data set even better can we talk to you about them exactly yeah because the ultimate goal you know it's to get stuff in there and to preserve it but it's also to make that stuff usable so that other people can come find it use it and go from there all right so if you wouldn't mind going back to home so we'll take a look at what a deposit looks like so you can either deposit once you're logged in you'll see this nice ribbon here otherwise you can click deposit metadata definitely yes yes yeah so we talked a bit we do do complex and you can find it you know through the data sites website and through through Google in many cases we are also looking at how do we expand our browsing capabilities because we have you know four or five facets but they're still fairly broad inform each other so we're looking at how do we you know further refine what you can do we also have a search bar up at the top so you can type in a particular term and you know searches you're not limited to plows definitely great question um so this is what the deposit form looks like if you were to make a deposit some of these look familiar from looking at the record from before title creator method um you'll see that these ones are required keep scrolling description we also have date coverage that's not required because a date doesn't always make sense with the data set we have so you can add a date range too so if I was collecting samples from this date until this stage that kind of thing you can add a beginning and then go ahead and click it cool yeah we also ask that depositors select a Creative Commons license to license their data under a lot of data repositories pick that for the depositor but we really wanted you guys to make your own choice about how you want your data to be used so we have three options the CC 0 that's just I'm putting it out there anybody can use it that's it we also have the attribution so that means I'm putting my data out there but people have to cite me I would say that's probably what most people are using people like to be cited and then we also have the attribution noncommercial so that's you have to cite me and it can't be used for commercial and purposes so that's another option all right non-commercial not very often a lot of it just lets do their work do exactly exactly - anyway they don't license that's true exactly yeah most people pick just you know attribution just cite me um alright and then discipline we just have the really top-level disciplines right now some science or social science you can add multiple we're working on adding you know deeper down so science biology point that's actually from the library catalog or the same phase that is populating the library catalog so you see like music curative action doesn't make a lot of sense in this context so we are looking at how to define this mm-hmm definitely um keyword is an option you can put as many keywords as you like so this might be words that describe your work that aren't you know aren't elsewhere in the metadata so that they come up when you do a search as you were describing we also have language and then citation to related material so this is if you have a paper published somewhere else whether it be in deep blue or in a journal you can put the citation and link to it so the data and the paper actually linked together it's nice we also have this deposit on behalf of so this is the proxy feature that Scott was talking about so if somebody has authorized you to deposit for them like our project manager has authorized me to deposit for her I can just go ahead and drop down and pick that just nice and then finally we've added this draft functionality so if you want to mock things up and show it to the rest of your team or you're not quite ready to publish yet you can put it in draft and then it won't be available to the public and you can continue to work on it and actually Scott if you scroll back up we probably should have just put in some like stuff junk into the required fields if you wouldn't mind then I'll just show you real quick what the upload looks like and if you could make this a draft so it doesn't go public that would be great otherwise we'll get all excited with seeing deposit my gosh guys perfect we're depositing on behalf of newbie a lot she'll be so be pleasantly surprised yes so you click Next there save and then here you'll see a summary of what you have just done here's the mint DLI buttons or when you're ready for that if you keep scrolling down this is where you're gonna upload your files so it looks just like any kind of you know browse your computer and you can select individual files or you can select an entire folder so you don't have to upload individual files we have some that have like 300 some files attached and that would be obnoxious to do that you know 300 times nice perfect um so you notice when Scott did that nothing happened and because he has to click start upload and he can't because he has to agree to the terms first and I mentioned that because our terms are not obnoxious they're actually just a paragraph you know we're not Apple we're not having you like sign away your firstborn they're really quite reasonable it's saying this or I have you know I own this I have permission to put this in I've gone through IRB from a research those kind of things so that's what I trends look like alright so if you've agreed you can upload would be pretty fast PowerPoint there we go haha so it's been uploaded and then don't do this up but if you wanted then to mint a DOI for that the buttons right there and then it'll just show up right there don't do um so if you scroll back up if you go into my works now now that we've deposited something because technically this is not your work oh right so it would display here and you could go in and make changes to it since it's still in draft mode and publish it when you're ready and those and your app and also this is where you can go in and make collections like we talked about too and last thing really quick if you click on dashboard I just want to show you if you scroll down a little more a little more this is where you can add your proxy so if somebody who can deposit on your behalf so if you have a lovely grad student or diminished rative assistant who's willing to do it just have that person log into the system then you can search for their name and add them to your accounts and then they'll be able to deposit for you you can deposit for me cause of early yes perfect alright so that's what this thing looks like what questions do people have yes my recent activity so you deposited it's been transferred to the beetles account because you were depositing as a proxy for her and have attached this file to the deposit all right yes suppose someone has deposited a large data set over two gigabytes mm-hmm and I want to get a copy yeah how do you do just arrived so we are working on that problem right now we don't have a solution yet we're worried about getting stuff in first we're doing that in a couple different ways some people are giving us guest credentials to their server for example and we'll go out and get their stuff and ingest it what we're looking at doing is possibly setting up a torrenting sites actually and seeding that so people can can download that way we're also probably gonna be set up I think so I most certain as a Globus end point if anybody here is used to Louis yes I see lots of head nods so it's like the big firehose right so you can like move larger data from one place to another so that's on the very short list so not ready yet but definitely working on it did you have a question he had an administrator who is uploading something they then cannot go back and double check that all 300 files they can actually so so it doesn't appear like to anybody looking at it but if they were to like browse the system and look at everything it would show up in the results list for them because they have editing access to it but yeah it does not show up in their works because it's not their work alright so if any had a statement of deposit as Amy she could go back to the results list that you saw and she started showing the clear data and her submission would appear in that list but it wouldn't appear to anybody else still in draft mode just for her so that's the way you can sort of go back and check and be sure that things align the way that you thought they would complete the way they thought you did that you've learned before you go ahead and pull the trigger and publish it for good does that make sense so your administrator can't go to my works but can go to the it will be for the person if they have editing access to it yeah these are things that I have access to as well yeah definitely definitely I think we've talked about that right yeah we have so we're using a system called high and Hydra gilma gating system has certain sort of base level functions and Hydra is repository software that's designed for multiple different types of repositories and so for the dinner repository we still have some things we want to tweak and we're fine that are appropriate for this repository going to see so Hydra is a larger community of practice that has a lot of different developers and lots of different places Michigan is a partner in Hydra so we have the ability to raise concerns and to do some work and continue code to the larger Hydra repository so these are the things that we're trying to raise as hope challenge we'd like to see or the data pros are using it as a data repository it's pretty cool let's open access software and so we like what Jake justice just described is us contributing to a shared code base so we could develop that for example and then Stanford who also uses Hydra could pull that down into their repository and use it or maybe Princeton would develop something that we like and then we can grab it and put it in R so it's pretty nice because it's something bigger than ourselves but I like that suggestion yes so where's the data no so it's actually in three places it's an IDs then it is off-site on North Campus what is that data center column I always forget it sounds like a lake name - yes thank you yes exactly and then actually the tertiary copy is backed up on tape and like deep dark storage yes it's really really reliable so so hopefully nothing will ever come to tape but Scott mentioned like we really have the or was it Jake whatever we have the long view right so where is the state are gonna be a hundred years yeah you have good questions so what our plan is is we'll take everything and in ten years we're gonna just take a look at it and review it and make sure it still makes sense to be in deep blue data we're not going to do anything like oh this has been cited fewer than x times we're gonna delete it that kind of thing but maybe if like a subject-based repository in your area has cropped up in the meantime and it would make more sense to be in there because that's where other researchers are looking we might work with the researcher to migrate it there we're really taking care and looking at our collections and making sure that it's still a good fit if it is we're gonna keep holding on to it it's the kind of bits in bits out so long long-term plans great except how you're gonna handle faculty they've left the university that have retired yep case by case basis really and if you know the person is no longer around we'll work with the department or will work with the subject librarian this is very much like a team-based effort this isn't Jake and I kind of willy-nilly like yeah we don't like this anymore that's a hot presentation works yeah yeah we will do due diligence so obviously the person positive later at first choice we can't find that person or that person has retired they passed away you know we will look to what is the next best sort of scenario that we can engage with to make sure that is everything is about you yeah we're working really closely with our digital preservation librarian and you know writing these policies and procedures with this shop so we'll be taking good care of this right even if you have a rubric I guess I I wonder like what is the scalability of managing this sort of 10-year review plan I completely understand and with all the nuances guys not here and well this is version 5 [Music] however you know you know I just have a question about scalability whereas like we're talking but I get it like a traditional collection of books or whatever and you take the subject specialist librarian area like we'd this week and they're all these books so you have to make a decision and they go out and they go talk back to members yep but it seems like is like how is that scaling this is their print deal I should mention that we're hiring it into work closed session I think you're right really the model that we have a preservation is based on the library model that we have now so it's not just again a me or I going through and say what do you think I don't know it is involving the subject specialist it is looking at how do we better understand the community with a subject specialist in place so that our reading practices follow the same along the lines of what we do from reading books and other materials and you know you know the scale of that from from practice that can be you know something that that's is an investment of time and effort but we don't see this adding anything you know more significant than what's already in place I mean we have we've been open now for about a year we have you know 50 different entries some of those are collections so then actually individual data sets they're about the patience of individual data sets some of the interests we have here are one or two files some are 300 plus and so clearly you know we will face some challenges and the 300 plus things especially get a lot of them but I think the basic model we have in place in terms of the weeding practices in the library is it as a good starting point to make that happen and I think you know as we are successful and we get more deposits that will just you know give us leverage to perhaps hire new positions like Jake said we're already hiring someone I'm working with a grad student now I think we will just grow as and I think you know it's not like we've got this open we're gonna walk away come back in ten years we've got a thousand deposits obviously as it is so we've been open for a year so in nine years we're not gonna say okay now we're gonna review ten years or an haasan's we're gonna do the first a year and do certain Rowling review so in that first review pass were probably going to look at about 50/50 deposits start breaking those down by subject areas that means you probably have a number of subject liaison who are looking at a handful of deposits each yeah that's a manageable workload and in the mean time we'll have been keeping track of how much new stuff is coming in we can look at the workflow process for review in that first year and say how did this go is that gonna scale to the number of miles we're gonna have to review next year what do we need to do differently yeah so I think you know as long as works you can track of how much stuff is coming in and thinking proactively in terms of scaling the work flow to suit we're probably gonna be okay I think I mean you know it would be if we had the problem where we had too much stuff to review effectively I think we would view that as a great problem yeah awesome yeah and then we'll figure out what to do with that in the event that that happens exactly what's your total luminous it's just a very few dozen 57 mm-hmm I think only 52 of those are actual data sets or main functions doing any notion on just the total disk size Oh total disk size uh what does Sebastian said nothing is too gigantic we have several that are in process right now and we're like ingesting them from the backend because they're larger like all of these have gone through the browser yeah so most of these have come through the browser so they're like under two gigs per file but we are ingesting you know 30 terabytes of astronomy data that we're working on right now so so small so far like babies with session time I think that's one of the questions that the preservation policy yes this is important but it's really not getting the kind of use that would justify giving up an active spinning disk maybe that gets moved to tape and we put a note saying hey if you're interested contact us but for now it's all unactive yeah the challenging thing here is that there's not a whole lot of models and follow this is a relatively new kind of service so it's it's something that you know we have put plans in place but we haven't actually had to test those plans yet and so I'm sure we'll find things where oh we finally go this way too in fact it's going that way only to adjust accordingly a lot of other universities are looking to Michigan and saying well we'll wait and see what happens with you guys follow you to some extent we were both building the boat and learning to navigate all the voyages other way all the challenges that presents great alright any any last questions oh great well thank you so much for having us [Music] please do contact us we're more than willing to try to work with you the community need we'll provide service development