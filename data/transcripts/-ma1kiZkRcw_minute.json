[
    {
        "start": 0.08,
        "text": "pleased to present today's speaker we have y Fang JN who is a grad student in dcmb yeah hi everyone uh actually the title for today's presentation will be the expert using the large language model for the Radiology report but this is part of the really like a huge project called a necklace and it involves a lot of like a background so I'll just start from like a necklace and then I'll switch to the main method that I propos and use in this uh in in the research so necklace is a project is a um is an abbreviation for the project necrotizing and the cus labeling and computer enhanced diagnosis and today's presentation will be uh divided into four parts background of the disease and why we wanted to build these system and what what is the challenge of building this system and there are two sub aims so the first a is "
    },
    {
        "start": 61.519,
        "text": "what we are going to uh talk today and the second one will be for the future so um um NE is the uh like the a disease that uh uh and a very serious and gastrointestinal disease in premature infants um that cause inflammation and the tissue death in the intestine and the disease can progress really fast uh it's around like 7% among infants whose birth weight last between 500 and 1,500 grams so the motality is aluminate high ranging from 20% to the 30% so if we can uh if we observe the if uh yeah we can see from the images show here on the left side is the abdominal uh uh yeah yeah the abdominal three and this is the abnormal uh "
    },
    {
        "start": 122.92,
        "text": "structure that the the the the the the the bow or the intest is U full of the air but we can see on the right side the normal axr the abdominal X3 like it's very clear and the current data we have is actually the text and the the image pair data the text is the Radiology report and the images is the abdominal X-ray and in the Radiology reports it has several sections uh the title will be the time of the um the the the examination performed and the followed by clinical history comparison uh impression and the routine test the things with like the uh the impression section is mainly described what the Radiology Radiology just observed in the Radiology images and we have the around "
    },
    {
        "start": 185.64,
        "text": "15,000 data points in total and the clinician we discussed with clinicians and based on their needs they actually want like the system performs like when the radiolog images comes in and the the um the model will immediately flagged as like a um abnormal or uh normal so it's so the system were purely based on the images but the key problem here for us is that we need the labels extracted from the Radiology report but this is unstructured uh text how should we extract labels from this unstructured um data so um there are main two challenges here the first one we we can uh DEC P them into two uh aspects the first one is the clinical aspects so the timely diagnosis is very crucial because as I "
    },
    {
        "start": 246.879,
        "text": "mentioned U the dis the disease can progress really fast so any delay in review can postpone necessary treatment and the worsen the patient's condition in addition uh This is highly relied relied on expertise it's um so like not all the general physicians can um make inclusions from this like from the Radiology images it uh it requires uh like very specific domain knowledges and from the technical aspects as I put before the uh we don't have label the label is implicitly uh stated in the impression section in the Radiology report so how should we extract labels from the report and the second um technical challenge would be there's no public available abdominal as data set we we actually don't have a very large data set we only have 15,000 we only have 15,000 pairs of "
    },
    {
        "start": 308.919,
        "text": "images and uh text but based on on um I'll talk about the the the other work uh later the on the chess x-ray or other Medical Imaging there are a lot of public data set they can use so they can they will have a really good initialization they will have a um pretty much like a uh a a good understanding of like what the normal abdominal asate should be but we don't have such know knowledge right now so that's will lead to to our A1 it's uh it's called the human asert facilitated the Privacy preserving life language model for abdominal asay report labeling so we'll talk about this part today so the after we build the whole system we we uh the um the um on the left side is like how the whole model the necklace model uh is built the first "
    },
    {
        "start": 370.16,
        "text": "box is what we are going to talk about today the first Box means like we have the radio AIO reports and we invited human experts to annotate these Radiology reports to tell uh whether there's um neck description in the Radiology report or not and we then extracted the we we we then use this like the annotated data set to train a model um and we use the the trainer model to label the remaining unannotated data set and then like the the second the second box what we uh do next is is uh train a image classification model and that will be uh uh mainly used in this in the whole clinical support system um so um like the the the uh the um tremendous research have been mainly focused on the chest x-ray and there are "
    },
    {
        "start": 432.28,
        "text": "a lot of chest x-ray like public chest X3 data sets out there like a mimic uh and the like the chest like like K uh and the chest X3 14 there are like a millions of um chess X public data sets out there so benefited from from this um extensive data set there are numerous and rapidly evolving chess ASR labeling tools developed but current we only have the single facility um single facility of the dominal sray data set so we have no available public tools we don't have enough data sets so but we still can learn from like how people build these um uh chest X3 tools so let's let's do a quick literature review like how people in the past to build the chest as related tools so we can build our own x-ray related tools so the first one is U like in the chess "
    },
    {
        "start": 495.159,
        "text": "xray report labeling the first tool they developed is called um neck Bell or chest bir they are uh solely based on the regular expression on the surface text and they are very limited when attempting to capture complex syntax constructions such as like long non phrases so the limitation will be very obvious like they you they usually miss the nuanced and varied language patterns in Radiology report sometimes the the description of the certain diseases can be the the observations in the Radiology report can be very ambiguous so the the the regular expression they don't have this capability because they are based on the surface he though so they are incapable of to capture such nuan um expressions and in addition they needed to identify the negative uh in the sentence like no like a no evidence of so it's um so so there were some they "
    },
    {
        "start": 557.44,
        "text": "were they are very prone to typos and um ambiguities so they are and they are out of dat because we can see the paper all published like into 2018 and 19 and after Transformer is um introduced in this field uh since 2020 and 21 people um kind of like switch to the uh bird based model like a chest bird or chest bir Plus+ so first they will use the previous rule based labelers to annotate the um the unannotated Radiology report and select around U 1,000 reports and invited some uh board certificate radiologist to to wbel them so like the first one is is like a very um initial result like initial annotation results so this method kind of like we we "
    },
    {
        "start": 617.92,
        "text": "trained the model use very initial low quality annotations and then fine tuned using the uh the ASP curated data set so to improve the model performance so the Improvement will be the first one is that it utilize the direct report to label mapping from clinicians uh and the second one it's it will balance between the rule based labelers and the manual annotations because the manual annotations um needs a lot of like uh uh clinician's time efforts so it can reducing cost and the label but at the same time maintain a really good um model accuracy and as LM intro like a um introduced like a last year um a lot of people are exploring like a whether it can be utilized in this field but most of the work are using the in contest learning in contest learning is like we give some examples to the GPT models and "
    },
    {
        "start": 681.16,
        "text": "uh give them like a unannotated report and trying and trying to ask them to uh annotate the the the unannotated report based on the several examples we feed into the model and it's the um the core is to develop a finally crafted prompt that can appropriate um describe the whole problem and help the GPT to understand what you really wanted to do so for us it's impossible because um the gbt is a close source the um tools and uh if we wanted to use GPT we needed to send our data um to open Ai and it's which is very sens sensitive patient data it will compromise the patient privacy so what we should do like oh so this is the performance comparison of all previous the methods and it turns out that the "
    },
    {
        "start": 743.12,
        "text": "GPT model the large language model shows really good model performance compare compared to the the the um the very standard one and uh the bird based models so it shows promise but we cannot use GPT so so let's talk about the first what is the the task here the uh the neck is the air in the intestine but um it has three subtypes the first is called pneumatosis is air in the air in the ttin and the second where is the and the second will be the PVG it's called a portal uh Venus gas it means like the air flows along the vein into the liver and the third one is called the free air the free air means it's like a full of the abdomen it's all over so which means it's the most severe one we invited the sorry we "
    },
    {
        "start": 806.56,
        "text": "invited the clinicians to annotated the Radiology report based on the impression section and give three labels for for the the first task whether there's air in the abdomen and the second one is like is it a pneumatosis or PVG or free air and uh sometimes because the impression like said like there's a bubbly looses or something they cannot tell if it's a stool or if it's a bubble or it's air so they will label it as uncertain so they actually there are three like a multic class multiclass classification problem positive negative uncertain and the same uh for the next sub type classification task and this is the method that we propos so we have around uh 15,000 samples in the data set and we selected 2,500 samples and invited three U pediatricians who have the domain knowledge to help us to uh lay this data "
    },
    {
        "start": 869.839,
        "text": "set uh and in addition to this we um we use the we use the 1600 of them to yeah to uh for the training purposes and the rest of them for the um H parameter tuning and the testing and we designed instruction tuning prompts that uh that describe the um that that describe this whole task and uh trained uh large language model gamma and mistal AI model they are uh open source model it can trained and deployed locally and after we've uh well trained this model and Achieve really good model performance then we wanted to um because there are some problem also some problem with these type of lar large language model because large language model is a auto regressive model it will kind of like encoding the um the internal token to token "
    },
    {
        "start": 932.639,
        "text": "relationships and it will somehow uh also Rel Ral the the the patient information in some way and the large language model um requires a lot of computational resources so that's why we wanted to to do a model distillation to transfer the knowledge in the L language model to the uh to the bir model um because Bird model is a relatively small model and it can quickly do the inference so um this is the whole flow chart and uh there are two questions we addressed using this uh framework the first one is why we use llm so because there's no public data set and the llm in the previous like lit review we can see it can be considered as a um an expert model in addition it reduce human label cost and the second one that why we want to do distillation the first one is to improve the the model latency the "
    },
    {
        "start": 993.88,
        "text": "latency because use llm it takes uh I think I put the numbers uh in the results section but like it it greatly improve the inference time on the GPU and the second one that we can reduce the uh the cost because the llm requires a lot of computing resources and also the Privacy as I uh put it before the bird Only Store the weight but um um but the LM store like the also the um not only store the weight but also the the the token relationships so this is the The Prompt that I designed so uh the first one that I told the model this this is a like the uh yeah this is a Patric Radiology report and and the input would be the impression section from the Radiology report that I showed before and there are uh three there are four multiple uh "
    },
    {
        "start": 1054.76,
        "text": "choices questions like the first would be um does the child have um neck a yes B no C uncertain and very similar for the other sub types uh and for the uh like to to facilitate the downstream um post processing uh I asked the model to to to give the answer uh you using ABC and in the answer tag so I can easily extract the answers uh from the out from the output that the LM generated and uh evaluate the model performance and during the training we know the um we we we actually know the um label so we um yeah so like in this box so in this box um during the training we have this box but during the will let the LM to generate the the answer themselves so there these are two like a "
    },
    {
        "start": 1116.64,
        "text": "models we used the first one is gamma model the second one is Mr model the gamma model Mr model they all use like a multi quar attention group attention sliding window attention these like attention methods will uh like reduce the the hyper param the the the the parameters trained in the self attention uh and also like the uh like the Norm like profan chunk they are Bas basically to accelerate the training and the inference time and reduce the Computing resources and this is the configuration that I used uh I used the single Nvidia A40 GPU and I request 16 16 gigabytes usually the large language model requires a lot of like hundreds of gigabytes but like the the reason why I only requested 16 gigabytes is because I used the uh method called K quanti the low rank adaptation methods and uh and these are the hyper parameters that I "
    },
    {
        "start": 1176.72,
        "text": "used uh for the model training uh I actually made a table here the epoch is actually 10 here so I only used the 10 EPO and achieved a really go a really good model performance compared to the Baseline and this is the what is qara like the uh qara is the in the original model or like a bir or other model we will do the full F tuning because we don't have a lot of like parameters in the models but for the L language model it's impossible for our lab to do the full fine tuning so we used the Q Laura Laura is like uh so so so the Lura is a combination of quanti model plus Laura Laura is basically introducing the auxiliary matrices uh that only learn the update of the weight instead of the the whole weight um and uh the Q means the quanti "
    },
    {
        "start": 1239.039,
        "text": "in the original model they use the floating 16 and the currently they uh using the ca we can first quantize the model into the four bit Frozen based model and we only to we only learn the several adapters during the training not the whole layers and the this adapter only applied to several important layers like in the self attention like there are q k the the qu matrices qy matrices and the value matrices they the the time complexity for these matrices can be like the O Like Big O and square but if we use the adapter we can reduce this the the like the time complexity a lot and uh during the inference we will do the like a dequantization the four bit Frozen model is only um like uh after we like while we doing the computation we "
    },
    {
        "start": 1300.64,
        "text": "will converted this this quantize model back to the original floating 16 model and the um and we added those the the um the output from the adapters and the in instruction fine tuning uh I I I don't think this is important so this will be the last proposed uh component is the model distillation there are three main model distillation Paradigm the first one is called the online distillation the online distillation we have the the the two models one is the teacher model one the student model and the the model are um trying to learn the the patterns of the teacher model But the teacher model uh also updating at the same time so usually the last uh design here will be the Q KL diverence they are trying to match the two distributions and the second one called the offline distillation that that is what we used "
    },
    {
        "start": 1362.679,
        "text": "we first well trained a teacher model and use the teacher model to to annotate a distilled data set and then we use the distilled data set to train a student model so the teacher model is fixed it's no longer updated but the teacher model will train the data and use the data to uh to tell how the student model uh should behave and then the third one is the mostly like uh proposed it's uh like called like a parametric um trans yeah parametrical knowledge transfer it only applies to the large Lang uh in in their paper they like only apply to a large language model they have like a lot of like La Rel layers and they are using the SVD to choose which layer is the most important and only apply those important lur layers to the student models like the so it so so that's why it's called a parametric knowledge "
    },
    {
        "start": 1422.679,
        "text": "transfer so we are going to use the second one because our teacher model achieve really good good model performance so we don't need to update the teacher model again so this is the yeah this is how the data is split the the um yeah we have the 2,500 of the the manually annotated reports and we split them into training uh testing and development and observe the this like data distribution like the the data distribution table uh for the positive cases and onc cases it's uh the the the sample the the the number of these sample are relatively small compared to the negative um samples uh in and in addition to like so so it's a super uh imbalanced data set and also it's not a very large data set because "
    },
    {
        "start": 1483.159,
        "text": "like in the previous literature people when they are trying to train a birch model they will they will use like a million of data point to train the model but we only have like a s of the data so this is the the uh the result that we are on we are comparing LMS against the fine tune the bird models so the bird model we use are they are PR trained the um one is called the clinical bird and the other one called Blue Bird clinical bird is trained on the pre-trained on the mimic data set and the bird Blue Bird model is pre-trained on the um P met abstract so so that can kind of explain why the blue birth model uh is a slightly is slightly better than the clinical uh birth model because like the mimics really say the patients like they are aged over 18 but the blue so so so like we are basically focusing on the neck patients uh who are "
    },
    {
        "start": 1546.52,
        "text": "premature infants uh so that's why it doesn't perform really well because there are not too many like a relative knowledge in the um in in the pre-trained model and uh but the these two bird based model it doesn't perform good because the the F1 score for the positive and uncertain is about 26 and 38 but if we use gamma 2 billion uh or gamma 7 billion Mr 7 billion model the model performance is actually uh really high like for The Knack positive cases the F1 score can uh can be up to 0. n and for the uncertain cases it can be up to Point 778 and we do the uh we we We Run The Experiment three times and the standard deviation is relatively uh small um yeah so that is the how the LM performs against the bir models and uh "
    },
    {
        "start": 1607.48,
        "text": "and the this time we are focusing on the gamma 2B and the gamma 7B models uh the we can concluded from like gamma 2 again and oh and the the ratio here means how many like a um the the proportion of the training data sets that we used during the fine tuning process so point two mean means here here we use only 20% of the training data set to finding the data so we have the uh uh 1 1600 so like point two which means we only utilize around 300 training samples so from the gamma gamma 2 uh billion we can see the the model performance is actually um well well when the training uh when the fine tuning St increases the model performance is is actually uh increased "
    },
    {
        "start": 1668.36,
        "text": "uh as well and so the story are the same for the gamma 7 billion and the mro 7 billion so we will not talk about mro 7 billion here because the Mr 7 billion model doesn't perform like very stable uh and the standard deviation is really high so we are focused on the gamma 2B and the gamma 7B and compared to the gamma 2B and Gamma 7B uh no matter what the fine tuning ratio is the model performance the gamma 7 billion model performance is still is consistently uh better than the gamma 2B uh model so we can conclude that a larger model uh has better capability here and the the the second the the the second solution will be like when we increase in fing size size the model performance actually uh increase so that is not very surprising because like we have like "
    },
    {
        "start": 1729.44,
        "text": "more data to train the model and the model can um better model the relationship between the input and the output but we actually observe there's a jump um when we increase the F Unity dat assess from 20% to 40% I I I I initially thought that would be like something they will they say like a emergent ability but like emergent ability is only talking about like when the model sizes increases to certain uh like what the model like increases to some certain size and a lot of like uh they can solve a lot of complex task they can never solve before but I'm not so sure about if this is U also works for the fine tuning data set but I'm I but this is like a I only did the empirical experiments so I didn't "
    },
    {
        "start": 1790.12,
        "text": "study the theory behind so it's just the observation like as the fine tuning dat increases model increases the model perform increases and also the um there's a jump here for the gamma 2B model but for the gamma 7 billion model because the gamma 7 Bild model is a relatively large model it has already a lot of knowledge PR trained so therefore even the model uh even the the functioning size point to the model performance REM remains relatively high for the positive and uncertain so the the next conclusion would be smaller model benefitting more from the larger data set and the last one is that for the PBG and freeer they are they are they only have like just the like a like a four to five samples in the data set so even for the gamma 7 billion model um they they needed to have like a full fine tuning data set to achieve like a0 n or8 "
    },
    {
        "start": 1850.72,
        "text": "model8 F1 score um point two is not enough for for them to perform to yeah to perform well and the last one is that like how the distill model uh works because in the previous the Birch model only no matter um if the clinical bird or blue bir model uh the F1 score for the neck or neosis is very low and we wanted to know like if we use LM to teach the Birch model whether it can perform uh better compared to it's baselines so we can see like the we after we do we we we did the model distillation um gamma 2B 7B Mr 7B they all like uh increase no matter what a teacher model they use the model performance all increased and it can be comp like it it's on par with the uh the llm the teacher model itself "
    },
    {
        "start": 1912.399,
        "text": "itself so we have the like a two conclusion that this this Ste the model can achieve comparable model performance to LM teacher and the better teacher Model results in better student model like the gamma 7B is doing better than the gamma 2B as a teacher model so the take away message for uh L llm in the abdominal S3 uh classification is that the first one is the different LM shows varying capability in labeling abdominal a report and and the large models consistently are performing smaller ones and the second one is that increasing the size of the fineing data set significantly boost model performance particularly for smaller models and the classes with limited examples and the third one that using llm as a teacher model can substantially improve the performance of The Bird model making it "
    },
    {
        "start": 1972.84,
        "text": "comparable to llms so that will conclude the all the previous results and there are future like discussions the a so like I I said like why we choose the gamma and the Myst model instead of gbt model because the gamma and the Myst model they can be run locally preventing incentive data leakage and distill models uh can be easily fine tuned and transmitted because it's only store the weight and the limitation is that we simplify the model into classification problem so this is what a clinici request because they wanted to the images comes in and the label comes out but we like uh uh there are a lot of people out there they are doing like a report summary report generation so that will probably be the future of this project because like we will never know like what cination we want in the future and in addition this is the retrospective data and uh and only from "
    },
    {
        "start": 2037.08,
        "text": "uh single facility so that will introduce the bias like into the model the model may not generalize very well to other data sets so now we are collaborating with the next society and the hospitals and trying to get more data and the to and to address the previous limitations we will probably like improve model interpret interpretability to for example introduce CL explanations in the loop to improve the like the the model like we all know like when we interact with GPT it will like give you explanations alongside with the the the the answers so probably we can improve the reasoning abilities using the um like a direct optimization or direct preference of optimization and also um for the multicenter medical data because we have a lot of like collaborations and we are not very sure if they wanted to "
    },
    {
        "start": 2098.04,
        "text": "data to us so probably we can use like a Federated learning to preserve their local uh privacy uh in this uh process yeah I think that will be all I wanted to talk about today because the rest of them are the image part so it's probably irrelevant to the topic yeah so is there any other questions about this yeah go ahead yeah interesting talk so um so I see that your comparisons are for different llms and different language B mod right then different language you compare different models different parameters and so even though we are uh comparing these there are there will definitely be uh misl cases and other other things so we you able to compare it with the actual "
    },
    {
        "start": 2158.8,
        "text": "uh label data from the C and how how well all of these language models perform comp back this is the results compared to the clinicians actually okay yeah because we split the data into the the training validation and the testing and the the results I reported here is the the model performance on the testing data set okay yeah I have so uh these are there any other metrics other than the uh prex report on the that have that can be used to generate are you talking about like what else input um currently only the r a reported [Music] up the actually the impression section like the gas extending to the rectum the only the section is used during the "
    },
    {
        "start": 2219.56,
        "text": "training and the average token uh number is around 250 "
    }
]