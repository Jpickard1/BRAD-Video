i mean i'll probably give folks another minute or so we'll start 1202 and then we'll see how it goes sounds good i could edit out the dead space at the start so no problem all right folks we have about 1202 uh this afternoon on thursday the 8th of october thanks very much much for joining i'm evo dino here i'm faculty in health behavior and biological sciences and computational medicine and bioinformatics uh it's a pleasure to present today um a technology seminar so i appreciate your joining i know it's lunch time um you probably have better ways to spend your time but i i'll try to make it to the best of my ability worthwhile so my plan today is to speak about space-time analytics and we usually do these things in person but now we're online so i will try to at least break every 15 minutes or so to see if there is any questions uh from the audience so by the way in the ch you can find a slide we just do google search soccer news go to today's event and you're going to find a pdf and and all things that i'm going to be showing in the demos and so forth are going to be shown this website so very quickly on outline uh i'll start so my goal would be to essentially spend about half the time uh not really lecturing but presenting the foundations and then i want to get into the point where we actually show you how these very deep you know scientific and philosophical concepts materialize uh when it comes to data analytics so i'm going to start by a formula a few of the big data challenges then i'm gonna spend a little bit of time look it is important it's a new concept for most of you uh what what is kind what's complex time something that we call kind uh what is space-time analytics uh what is the mathematical foundations and so forth i will not go too deep i promise um but the reason why i want to kind of very quickly glance through so so you have the the slides on the website and you can download them and actually go over the details and if anybody is interested in i send you a preprint of the book and then and then i'm going to go over the r package that we are developing in parallel with the mathematical theory uh that's called tciu time complexity inferential uncertainty and then we're going to do some demos hands on that's the plan so let's start off in the beginning you know what are what are some of these challenges uh okay so part of my little uh experimentation here with the red lines uh i i try to see how the annotation engine works here in in powerpoint so um we i have looked at a number of different case studies not only in biomedicine and health but in environment econ and various other disciplines and the seven common characteristics that occur over time over time over and over again are the following these data sets are large we all know that they're very complex in terms of their representation uh uh uh you know um in terms of their storage representation and and heterogeneity they're very incongruent um which makes the problem of aggregating and harmonizing them challenging most of the time they're they're arriving from independent sources that are not intended to uh necessarily interoperate uh very often they're multi-scale which means that the data is viewed the same data objects are viewed through some kind of a prism uh the way we decompose white light into the spectrum of the rainbow spectrum that's exactly what's happening many data sets are high low uh medium and micro and nano scale resolution uh very often they have a longitudinal dimension to them so so they are uh varying with time and they're never complete so these seven characteristics i typically use as my uh you know yard stick to to measure is does the data require any special treatment or or can it just be plugged in and and processed in in a standard way just to give you a little bit more of a pragmatic focus we are going to be talking quite substantially about functional magnetic resonance imaging fmri and these fmri so here's a little animation that we've done fmra is essentially a four-dimensional data object that has three spatial dimensions and one longitudinal dimension and the state-of-the-art approaches essentially use either time series analysis or some kind of a network-based analysis to interpret the various stimuli that are applied to the brain and then try to understand how do they affect brain physiology structure function diffusion and so forth in our world we're going to be uh extending this notion of time into complex time which leads very naturally to this time series which we're all very accustomed to viewing these these time series they're going to become actually a two-dimensional manifolds which have very intricate structure and we're going to call these manifolds chyme surfaces so and just to give you a little bit of a again a pictorial view of what is the distinction between these two classical space-time analytics and in the space time analytics you know if you have an object where you ignore the second dimension of time you may be looking at an iso contour of a two-dimensional fmri slides across time that kind of looks like this we're just tracking the iso contours so so these are iso surfaces across time whereas if you factor in the correct second two-dimensional time representation you get a lot more detail as you can see in this snapshot so let's go ahead and now define a little bit about what is this time and how does it come into play now most of us have seen the fourier transformation i'm not going to spend too much time here we can go from space to frequency and back and by the way most of the functional magnetic resonance data is acquired in k space in the fourier domain and then it's inverted in the time domain so that we can actually see it i'll just show you one one little example here and uh because this is a static image everybody can actually see this example we did this over 15 years ago oops pardon me um right up here so you basically with your mouse you can go ahead and actually draw some kind of a signal it needs to be periodic signal okay uh for the obvious reasons and now this thing kind of decomposes for you directly the signal into the magnitude the the 48 magnitudes and then the phases okay so these are very important you see if i bring the mouse over any one of these components it it it will tell me precisely you see when i as i move the mouse about you see the yellow curve on the top kind of shows me the effect of this phase this phase or this magnitude right and i can perturb my signal a little bit by changing either a magnitude or a phase right and i can manipulate the data right and see the exact effect so it is very important to understand that there is a one-to-one correspondence between this signal and the corresponding fourier decomposition of this of this data so um to make the problem a little bit more interesting kind of go diving deeper a little bit in in this notion of of the phases uh i'll consider two examples so imagine if i have a two-dimensional image of a square and a disk and then i pipe them through the fourier transform and compute um uh both the real part of the fourier transform and then the magnitude which we saw in the one dimensional time curve a little bit earlier and then here is the corresponding phases because i have in this case not a one dimensional but a two-dimensional signal where the intensities are black and white very very very very simple kind of characteristic function uh but the the the representation of the domain of the magnitudes and the phases would be exactly on the same kind of grid except that it's obviously in the frequency space you do exactly the same thing for the disk and now the trick that i'm going to play is i'm going to try to recover back the original images from their magnitude and face decompositions with a twist in these images right up here that you can see where there is aliasing artifacts i'm gonna be completely setting the um i'm going to be swapping i'm going to be using the phases of the disc and the magnitude of the square to reconstruct the square here and i'm going to be using the magnitude of the disk here the correct magnitude but the incorrect magnitude of the face and you can see what you get now at the same time if you completely negate if you completely zero out these phases and you reconstruct the images into space time image domain you're going to get these objects and arguably this does look like a disk this topologically looks like a square but it's it's not quite a square right okay so the point i'm trying to get across is that the phase representations make a huge difference and now obviously if i'm going to be making inference on objects like this where i ignore the faces i'm probably going to be getting somewhat different uh predictions forecasts and and so forth so it was over about a hundred years ago when a mathematician and a physicist theodore kaluza and oscar klein put together this theory about a five-dimensional space-time space-time they were essentially trying to to generalize um einstein's theory of relativity where they um uh introduced an extra fifth dimension which was time-like dimension it was not a space-like dimension and their idea was that this dimension is is very very very small okay so it's so tiny that you cannot traverse it but it does include a perfect orientation or a face representation so in other words you can see this greeting here that i've that i've drawn illustrates uh the essentially the planck distance you know you cannot see anything between this line and this line because it's below the planck constant okay so however you have these directions that are non-traversable but the uh kalooza klein theory was that you know you're looking at minkowski space time the standard space and then you cross this you uh you multiply this by an s1 object to account for these unobservable phases so in our world we're going to be defining time as a complex time which has a magnitude r and this r is going to be exactly the or the longitudinal order of events that we refer to as time but we're going to have an extra fee here and this c captures the phase of time okay so you can imagine now here in this three-dimensional rendering i've compressed the three spatial dimension into a single flat line and then i have swapped to it perpendicularly a two-dimensional plane which i'm going to be representing in polar coordinates as you can see here where the r coordinate is essentially our intuitive measure of time and the phase measure is this direction of time that allows us to um represent objects that are taken at the sp at the same space and time location we have multiple instances and they span the distribution of the phases so there is multiple ways that this can be represented mathematically i'm not going to go over all of this but this ultimately leads to a space-time manifold okay which obviously can be defined very synergistically to how the minkowski space time manifold is is defined and then there is obviously a metric tensor for the euclidean flat space kind the metric tensor has signature plus plus plus for a spatial for the three spatial dimensions and minus one minus one for the corresponding to um temper time-like dimensions so this all leads very naturally to an extension of the standard newton leibniz calculus of integration and differentiation to space-time calculus and you know you can define first order second order derivatives they obviously are defined in terms of vertinger differentiation okay and then uh this obviously leads to um definition right the opposite operation of uh different differentiation is integration you want to you want to have a fundamental theorem of calculus proven so we've gone over these things this can be done very nicely you can generalize the newton's equation of motion which are in space-time listed like this they generalize very naturally into this higher dimensional space and then uh and then what we have is we can generalize a whole bunch of other things like what are lorenz transformations that are preserving uh the uh the uh the square integral the interval in space time these are transformations that essentially preserve distances in this high dimensional space and there's a whole bunch of other generalizations i'll just mention one here the notion that we can actually solve pdes we can solve partial differential equations like the wave equation in these higher dimensional uh lift spaces uh and and this is just a small rendering i'm not sure how clear or visible this is on the on the projection screen but you can see i have um just a reduced two spatial dimensions these are the x and y then the vertical axis goes from uh from uh from minus pi to pi for the phase and then the dynamics of this system are across our natural intuitive temporal dimension so we can see this is kind of a blend between surface rendering volume rendering representation of the solution which is very tricky business by the way because in general these solutions to the wave equations uh uh in in higher temporal dimensions are not well posed these are ultra hyperbolic equations but under certain non-local constraints these equations can be solved and and it leads to due to very very natural representation so again i'm not going to go uh over this but we we've proven that under certain situations these equations exist uh and so forth so so here's one example that i want to show you look the notion of the phase of time is very a bit counter-intuitive because we cannot see it we cannot perceive it it's difficult to measure it's exactly the same phenomenon as we do when we sample and you know i teach my students very often what does it mean to sample from a distribution and this is again an animation that we did a number of years ago we have a publication right that demonstrates the central demonstrates the first and second fundamental laws of probability through simulation so you know obviously most of you guys don't know what is it what it means to sample from a given distribution in this app you can actually go ahead and um and the link is over here just like i showed you if there is interest you know like i can show you guys how this thing works it works in practice but you basically draw from this distribution and then you make some inference about the sample link distribution of a statistic of interest like the mean or the variance or kurtosis something like this well exactly the same thing happens when you when you sample when you take a large sample that's exactly why people take large samples because you a large sample is guaranteed to cover the distribution domain okay and that's what we're going to be doing in the face space now now the phase space is a periodic right it goes from minus pi to pi okay and we're going to be randomly sampling as you can see right now in the next slide i'm going to show you how we sample from three different distributions one is completely unbiased it has an expectation of zero one is positively biased its expectation is pi over five and one that is negatively biased that it has expectation the red one of minus pi over three so on this next slide i'm um effectively showing how this thing happens so here i'm randomly walking through space and time okay so uh i am uh um walking through the um space kind manifold these two-dimensional manifolds where the size of my these projection rays coming out of the center their magnitude is our time this tells me what longitudinal order position was the observation taken and its orientation of the ray tells me the phase so you can see as we keep sampling from the space i can reconstruct the three different distributions in this periodic phase domain all right so there's a lot of open math problems we're not going to go over them i just wanted to point out here okay so now what i want to do is okay so this is all nice and dandy there's a lot of math there is a lot of symbols a lot of analytical expressions how does this help me with data analytics let me just quickly break up here and see if there is any questions or comments from the artist because it is difficult sometimes to see the chat now i lost the chat somewhere okay i don't see any posts but again for if anybody joins a little bit later um there okay marty just posted there is a link to the to the uh slides if anybody wants to see so i don't see and i certainly don't hear any questions can i just get a confirmation at least from somebody that audio and video and screen sharing are projecting well everything's working great sir everything looks good thank you all right so let's press on then so now what we want to do is you want to translate some of these mathematical physics into practical data science so we're going to draw parallels between particles and objects observable quantities and features states of particles and datum for an individual data point particle systems and problems or data systems and the most important one for us to kind of realize is a translation of wave functions into inference functions and now the way functions they are very important okay they essentially describe the state of uh of various systems okay inference functions of course in data science are very important because they lead from you feeding data into a wave function and it outputs some kind of a decision right it outputs some kind of a prediction forecast class label derived phenotype you know something like this so this is the most important if you remember anything from this talk i guess the translation from mathematical physics from wave functions to inference functions is the ones that we're going to be capitalizing on substantially here and there's obviously some other ones as well just to give you one very practical example suppose i look in mathematical physics at solving the wave equation now there is a very clearly well-defined solution it's called the wave function or a traveling wave that can be expressed mind you exactly in the same format magnitude times euler's formula for for expressing this um inner product between the uh the uh the k space variables and the space-time variables now this so the wave function that solution to that problem uh in our case in data science would be the inference function i'll give you just two examples a very simple generalized linear model where you have a data set o observable that has predictors and an outcome y and then what you're looking for is you're looking for finding for instance the order least squares solution of this specific linear equation and you know so so here is our model i have a model i have some data i plug it in and then my my inference function of wave function the influence function assessed at that data observable object is effectively translated through that formula into actionable information now for this effect size beta estimate vector i can tell you you know i can compute this variability i can compute its likelihood not to be zero and from there i can do a test this you can find out how important in a statistical sense is the effect of every one of the predictors on the outcome another nonlinear example kind of suggests something very similar with support vector machine classification where you do a lifting of this process from a low dimensional our ada space to our d space where this is much higher than eta and then exactly the same thing here your inference function is effectively a representation of the observables some kind of an analytical representation of the observables based on which you can actually derive border lines between points to separate and induce these support vector machine classification that comes with uh these kinds of uh studies so all right so uh assuming we have all of these things we are going to be doing very similar strategies of what people are doing in crystallography where people try to identify the structure of very very small crystals uh and and they expose them to very high energy particles and look in the background as the diffraction pattern but what they can only observe in the diffraction pattern is the magnitudes they're missing the phases exactly what we have with our space time data we observe time perfectly we can measure now a second later a second later second later we can measure that perfectly but we cannot quite tease out what is the phase how do i represent and uh track the phase representation so what we're going to be doing is we're going to be doing various tricks using transformations like the the fourier transformation the laplace transformation and various other transformations to estimate these unknown unobservable phases and then reconstruct the data into the data analytics space through various uh discrete or continuous transformations all right so just to give you a little bit of an idea here so in this specific example suppose this is the correct image that i'm trying to reconstruct two examples two rows cyrillic alphabet image and an english alphabet image and then if i try to reconstruct these by completely ignoring the faces i get two uh two images that you know they kind of they don't have human readable textual representation and if you swap the phases if you use the english character phases to reconstruct the cyrillics you see the blend that you get between the two alphabets and exactly the same thing in the opposite case where you use the magnitudes of the english alphabet image but you pair them up with the cyrillic phases and you reconstruct them the image back into the space either way so here is an example of of an fmri image so so these are simply three different time points the one on the bottom is time one the one in the middle is time two and the one on the top is time three and i'm just looking at a two dimensional cross sec axial transverse cross section of the brain and and that's what they look like kind of reconstructed as a surface representation so this is an image that i showed you before again ignoring completely the kind phases so so so reconstructing time by using a zero phase kind of gives you um a longitudinal kind of perspective vision iso surfaces that look like this when in reality if you do the perfect reconstruction there's a lot more detail that's embedded in the um corresponding isosurface so you can imagine that some of the statistics that you're going to be deriving using this representation or that representation may be the same but they certainly will not be identical all right so we're approaching uh we're approaching here uh uh at 12 uh 27 so it's probably a good idea for me to stop with this and i'll go into the hands-on uh demo phase one important thing this is kind of the last thing that i'm going to show you um remember we're going to be looking at data that varies with time and we like to think of it because it's very intuitive for humans right i want to see the trajectory of the time course i mean think about stock market think about people's vital signs uh think about you know i don't know comet right now you've all seen how people have graphed and plotted so so these time courses are essentially time uh time series when you pair these things up with the phases these automatically become kind surfaces where a projection a cross section with a plane of these kind surfaces you would precisely occur that looks like a like a time series so that's what we're going to be doing over and out uh before i forget you know i obviously have to uh recognize before i switch into the transition slides because i probably will forget to do this at the end yeah a lot of my students and colleagues have contributed to this uh my carter milan valerie at burgas technical university is a key player the soccer lab we have some grants and a lot of colleagues here from from university of michigan so let's let's go ahead now and um if my screen is still visible i'm going to go back to now to to kind of doing the demonstration so i'm going to try to go full screen here let's see uh okay marcy posted something that's good thank you all right so uh this is the the website that i put together specifically for this presentation again the the slides are over here you can always uh get them and see how that works so let's go over now to the space kind if you just type space kind space kind with a k k for for complex so you're going to get to this page where you know it kind of gives you the the splash screen the for the front page it kind of tells you a little bit about what it is all about how do these things these concepts uh arise in practice and a little bit about this notion we give a number of examples here okay this is a cool example the does the animation pop out actually look uh okay on your screen i'm not sure if you can actually see that the spinning spinning surface with with the with the projections okay so you see i've actually intersected the climb surface that we use to reconstruct the data in this high dimensional space when i cross-section it with a plane and this is of course idealized kind surface right this is a model base this is not real data but you can see the blue line and the red line are two different k you can think of these as two different cases two different patients under exactly the same condition under exactly the same experimental uh situation now so the red and the blue ones represent what we and obviously their heights represent the time series intensities and the radial positioning how far away they are from the center is the time on longitudinal order now the most interesting part for us however is going to be the angular momentum or the phase of chi okay so we're going to be putting these things together and we're going to be going from let's say a thousand individuals for which we have these time courses into a single representation of that process in space kind as a manifold which obviously is going to have very intricate geometry topology curvature and all kinds of other characteristics that are not visible to you if you simply look at cross sections it's exactly the same problem as try to reconstruct the exact dimensional shape of my hand by looking at the projection from a light source on a back screen right this is a very difficult uh imposed inverse problem that cannot be solved perfectly obviously there are computational ways to solve that so so we're going to be doing something some something very similar here here is another animation of the same thing and and this is kind of yet another one that kind of shows you different ways that these kind surfaces can actually show up in practice so uh you know so now we're going to dive a little bit deeper into the technical detail so this link here is going to lead us now to the actual demonstrations now for those of you that are interested um if you just go to our github site on the soccer website uh the github github.com soccer statistics online computational resource here is the tcu package we have a whole bunch of packages and software releases as you can see this specific one as it says here is on our package right uh and you you you can download it either from here okay and you know we go through the detail and and and we show you how to run demos and and how to uh uh implement it and so forth and you can also um uh find the direct uh if you do see ran pciu it's going to get you directly to the uh if you're in our notebook you know if you have r you you can download it and you can see all the vignettes that we have here we have documentation we have uh you know other things that are there listed over here version control and the description and all these things so i'm not i'm not going to go over these things everybody knows how to read these things there was a recent release that was done and so forth so i'm going to kind of focus a little bit on the on the technical because we have about 10 15 minutes i want to show you hands-on uh what really happens okay so let's go back to here okay so uh on the main website um you know you you can look at some of these uh for example we have a few interactive links that kind of walk you through the whole process so here is for instance a very interesting data set that we have looked at that allows you to interactively see the different characteristics uh in this case of the uh of the data and then what what you can do is uh you can do obviously forecasting right so you you you you use the first 20 or so years 30 years of observations and then you prospectively forecast you prospectively forecast the behavior of this time series and this is simply a slight zoomification here where you you can actually track both confidence limits and and predictions of the forward-looking time series and compare it to the uh to the actual um uh prospective data so the green color indicates what we train on uh the red color is the um uh a rima forecast and then that is based on space time and then and you have confidence limits uh that are 80 or 90 uh and so forth so this is a very simplistic example so here we've actually looked at the distribution of the of of those phases okay this is the distribution from minus pi to pi again for different variables it's not really important as much what the data is as realizing that these phases are symmetric distributions typically and if you recall earlier when i sampled from the uh from the from the circular uh periodic distribution i i had one example where the distribution was you know a positively biased or negative bias the one that was unbiased uh so the code for all these examples is included over here and again we can do forecasts using this and now in the next section what i can show for you is perhaps if you scroll up to here i i want to show you this uh interactive plot right that you can um earlier i i showed you the uh okay that's interesting sometimes firefox um sometimes firefox um plays these games so let's just quickly switch gears and go to chrome i need to restart firefox to make this thing work so what i'm going to do uh quickly is i'm just going to go to chrome which never fails you they say um and i am going to uh i'm sorry i meant first to show this interactive plot that we saw a little bit earlier again i want everybody hopefully to understand the notion that these black curves represent instantiations of experimental observations just tracked through time the entire surface reconstruction represents the corresponding process in its entirety right now obviously if you sample long enough if you have if you sample 2 000 individuals under exactly the same experimental conditions you're going to have 2 000 of these radial curves projecting over that space and then you can use these 2000 curves to reconstruct the the corresponding single time surface representation of your data uh okay so this is an interesting example now it takes a little bit and this is by the way on our notebook most of you are familiar with notebooks so i'm not going to go over the details if i zoom in a little bit okay it's going to show me that this this is kind of really a hands-on tutorial you guys it starts with what is what are the laplace transforms in terms of a discrete and continuous how do you do path integration in the complex plane then it defines the continuous laplace transform and it shows specific examples including an fmri example so so that's the content of the activity and i'm just going to walk you through some of the interesting examples so this laplace transform you see takes in a function which is just like a a time series is a function a mapping that takes in the positive views into some kind of a vector space for example the complex plane the real line and so forth this is what a time series is now imagine applying the laplace transform to this function okay the laplace transform allows me to complexify the domain of the function so all of a sudden the laplace transform is a function in the two-dimensional time space now it's a complicated function granted okay it's a complicated function complex valued complex argument complex domain complex range okay and its inverse laplace transform is well defined as well by this specific integral so we know how to go back and forth but the question is let's look at some examples all right so let's start with a very simple function okay suppose you have a function um that is uh effectively you know represented as one over z square so suppose this is the laplace transform this this is my kind surface okay then this inverse back is a time series just as t so give me a time and i tell you what the intensity of the signal at time t it's just t itself so obviously everybody sees that this is kind of a silly time series right it's essentially a linearly increasing time series a simple function a simple time series more complicated function more complicated time series right let's everybody see the analogy here so so we can go back and forth between these kind surfaces that i've been showing you some examples and animations from and uh the corresponding time series that everybody is looking into now and we go through some validation here so uh let's go ahead and and look at some of these examples done uh pragmatically here okay so i'm going to take now a little bit more interesting example okay suppose you're you're looking at a function that kind of looks like this now i may have to zoom out a little bit to get okay this for me maybe i can minimize this okay that kind of works okay this barely but it works so this is a more this is a more interesting kind surface okay does everybody see it it essentially consists of four components that are mixed together with equal weights now does it have to be this function no but i want to see what is the corresponding time course that yields this specific time surface representation and of course each of these functions individually i can i can transform into the time domain as you can see right so this for example time surface corresponds to the trigonometric function sine of x this component of the time surface corresponds to a exponential this one and so forth right so so so i know what the exact analytical things are and then of course you guys remember we we have various formulas that allow us to um uh to uh to to process you know if you take laplace transform of linear combination multiplication translates into convolution addition is preserved and all that business so i can analytically actually derive the exact model for my time series it's going to look like this a linear term an exponential term and a trigonometric term right and then i am going to actually visualize this kind surface that's over here this kind of surface i'm going to be visualizing it as projections right you can imagine these this kind of surface that i've been showing you i can actually go ahead and and project them in a two-dimensional space and just show you the contour plot the iso surfaces if you want to come topological maps whatever you want to call them to um to to do this and then okay i'm trying to make up my mind how much zooming i want here and then i want to go ahead and actually visualize this this is what i'm sorry this looks kind of in standard latex format but this is the function that we are visualizing here that's what that's what the kind this is what a realistic analytical kind surface represents it's got some points of singularities obviously because they've got z's on the denominator okay that's kind of natural but that's what the kind surface looks like right i hope everybody here is with me and can see this animation then what i'm going to be doing is i'm going to be asking the question what is the corresponding time series what's an instance of a corresponding time series that that is in one to one mapping with this specific time surface and then what we're going to do is of course we're going to be applying the inverse laplace transform okay and then this is the corresponding time series okay just the real part because it will be complex value with you guys but the real part looks like this now is this an interesting time series maybe maybe not but again this kind of shows you the uh the the um the mechanics of going back and forth between observable time series quantities and reconstructions in a higher dimensional space that we call time surfaces because ultimately remember i want to do the analytics on the kind surfaces they're very rich structures that that include uh information that's not visible when you're looking at this specific time course here okay and here is another example where the um the original uh time surface is the magnitude of z okay and turns out that the corresponding time series is monotonically increasing with time okay here is yet another example that kind of shows this specific uh kind surface here again it corresponds to this specific um reconstruction okay and it's actually it's actually this specific function sine of 2t sine of 2t okay obviously this is a function with period of pi 0 by c from 0 to pi because i have 2t so if i were to ask myself suppose my time series is sine of 2t what is going to be the corresponding kind surface is visualized right up here right all right so so these are some examples and we can do these things in in fairly good ways i want to get back down to uh okay and and here's the function sign we can smooth these things we can we can reconstruct them and you can see that they uh their reconstructions albeit not perfect they can be uh represented fairly accurately all right so and here is one example where we actually have two of these kind surfaces superimposed on top of each other now i would like to get down to the situation where we actually look at some real fmri data all right so here's an fmri example i showed you a few snapshots earlier of fmri data so remember it's four dimensional okay so the first thing and the code is kind of hidden here but if you guys click the code and by the way by the way i invite everybody to go ahead and try this i've released the data you guys can actually look at the data the data is available on the soccer server everything that i'm showing you here is either completely functional or it doesn't exist and this is not flight this is the real deal now if you want i can actually open my uh our notebook and show you how this thing works in practice but basically you point your uh our environment to the source of the data you download it locally using these two commands then you interpret it as the nifty three-dimensional nifty compressed file it's of these spatial dimensions the the spatial step sizes these specific spatial dimensions so i have 180 temporal uh temporal time points and the spatial domain is 64 by 64 by 21 um axially and then what i'm going to do is i'm just you know for the sake of a demonstration we're going to extract the time course of just one voxel location the one that's kind of in the middle of the volume remember so i'm going to pick 20 20 and 11. i got to pick a random not really a random but one location in in the volume and i'm going to look at its entire time course so i will smooth it out a little bit because fmri series are notoriously noisy the signal-to-noise ratio is less than four percent these are incredibly difficult data to uh to analyze and i'm just going to go ahead and plot them so as you can see roughly speaking what are we talking about for a single voxel location and now i have many tens of thousands of these voxel locations that span the entire brain so here is the data right time one time two time three time four it kind of dances around quite noisy i smoothed it out just to show you a little bit of the behavior because there is something behind this signal that drives that up and down most of it is noise but some of it is due to the underlining experimental design of stimulus stimulus rest stimulus rest so this is called event related design where uh there is obviously a little bit more complicated that there is hemodynamic response functions and all kinds of other things that come into play but i'm interested now in eyeballing this and asking myself what is the corresponding time surface representation for that time series so we're going to use the laplace transform for instance there is other ways that i'm not going to talk about right now i'm not going to have time but i'm going to pipe this through uh the laplace transform and here is my reconstruction here is my univariate longitudinal time series as an object that has now two time dimensions one is the um uh the direction the kind phase which kind of goes around and one is the radius from the origin which is called the time that we have okay so that's what this fmri series looks like as a time surface now just to validate this i want to apply the inverse laplace transform and pull it back into the time domain and confirm that this is a one-to-one correspondence i mean everybody would agree with me that i need to do this now it's not a perfect reconstruction as you can see here depending upon how you do it remember the original signal is this blue curve the reconstruction is the the the green curve and then a slightly smoother version of this as it says up here smooth reconstruction is red the raw reconstruction is green and the original smoothed version of the fmri is the blue one so it's not a perfect reconstruction but you have to imagine that there's a lot of numerical integration and numerical solutions that come into play that kind of caused that slight discrepancy between uh the fits and we're currently right now as we speak where we're working into uh into figuring out how to do this thing better now in the remaining of five minutes or so um it's probably worth it showing uh this example um sorry not this one okay so here the example that i want to show is the following still loading just bear with me this is you know this is real science i'm doing a live uh demonstration for you guys and and it's gonna take a little bit of time uh let me zoom out a little bit so i can see uh you see the the the table of contents here so that i can quickly navigate to the to the uh right plot so here is the first thing that i want to do okay so the first thing i want to do is i want to look at the entire data set okay now remember uh this is just uh you know axios sagittal this is axial sagittal and coronal cross sections of the fmri data and here is just one location 40 30 and then um and then this is uh [Music] i'm not exactly sure what this value is and then here's the corresponding time course so that's what i'm going to be looking at now for this time course i'm going to be remember i have 180 observations i'm only going to use the first 130 to learn the pattern and then i'm going to be forecasting using my spacecrime analytics approach okay so here is what you get at the end once you apply this into the three-dimensional data in this specific case i have a very interesting data set that involves finger finger tapping okay and it's done both on the uh with left and right hand and you can see that precisely if you get the side of the brain precisely the somatosensory motor area of the brain and a lot of other sporadic noise is available right so for example there is similar in the vestibular ocular in the cerebellum here right so some voxels are showing statistical activation in the back of the brain but the bulk the bulk of these of these statistically significant regions are precisely near the cortex in the somatosensory area so i'm kind of happy to see that right and if i scroll down and do a post hoc test okay using uh using uh using false discovery rate i can remove most of these sporadic activations and i'm gonna kind of have a more focused representation precisely as to where the activation occurred uh in space so you see bring the mouse over kind of tells you exactly how significant it is yeah i can only show the most significant regions if i want to i can show some of the less significant regions right etc so so so you can toggle on and off uh with our software and only show uh some of some of the most significantly one important boxes right okay now i can also do cross uh cross-sectional views of these as you can see here axios digital in coronal you can do contour plot plots with these things and then you can also compare the p-values okay you can compare the p-values between different uh schemas and then ultimately now what we want to do is we want to look at what regions remember it's not really voxel-based morphology that we're doing here we want to be able to find out which brain areas see this is for example superior right superior frontal gyrus this is the left superior frontal gyrus etc so left middle front frontal gyrus and so forth so so we have an atlas for the brain right and i want to know i want to do a two-level statistical analysis i know it's 12 54 and people are probably dying to go and grab their lunch so i went i promise you in just a couple seconds but we can do a statistical analysis and find out which regions of the brain are activated with this specific task so you see we can do roi region of interest based analysis in addition to the voxel-based analysis and then we can subset we can apply a second level analysis only on the activated regions right so so i can limit the scope and then obviously we can find statistical significance in the time domain once we've done the space time reconstruction so it's probably the best thing for me is to stop here and see if there is any questions or comments that i that i may be able to uh to address i'm just trying to go back to um to the regular zoom uh and see if if anybody has any comments re-chat again if you're interested in most of the stuff is available on the website as well as on github all of this is fully reproducible we just recently re-ran the entire notebook materials you know we have vignettes that are available online and uh you know and we're still working on the science so there's a lot of open problems if there are students on the call that might be interested in some of that in some of that science shoot me an email we can chat and see where we can get to this thanks very much for joining i appreciate the opportunity thank you very much evo that was a really nice talk thank you so i i'll stay on the call for a couple minutes just to see if anybody has any questions if not again thanks for joining evil this is really fascinating work i'm still trying to wrap my mind around exactly what this um these spacecon manifolds represent so if i understand correctly um you're sort of unrolling the one dimension of time into two dimensions do the two dimensions have any um intuitive interpretations or is it sort of collectively the two-dimensional space represents the variation yeah so so this is a great question uh let me see if that might be a good explanation imagine you guys if we are trying to make a decision we're trying to come to some kind of a consensus about the university reopening in winter of 2021. now we gather so suppose we gather uh surveys on a weekly basis for all the faculty and i've got let's say for the sake of the argument suppose we have 10 000 faculty each faculty is going to respond on this questionnaire across time and we're going to gather the data so at every one fixed point in time week not week 0 the baseline week 1 week 2 week 3 etc the measurements of every faculty's response at that week are going to represent are going to be randomly sampled on this circle of the phases where at a given phase it's some kind of a faculty's perception about the opinion of whether or not let's say binary should i open or not zero or one okay uh and then longitudinally these opinions are gonna are gonna change so everyone's trajectory across time is going to span different phases but if i put all these things together it will represent a single kind surface which i can then make projections at every one point in time i can for instance very very simply suppose we take 10 weeks survey so my time surface only expands radially up to 10 and it stops but having the surface you see i can project i can extrapolate the behavior of the service outside of the actual observational range now if you want to know where is the majority of the faculty standing at any one point in time outside of the survey area you see what we need to do is we need to come up with some kind of a consensus these consensuses represent you know characteristics like the mean faculty response i don't know median it could be i don't know how you know how dispersed our opinions are and what not so in other words the if we have a random sample if we have a random sample this random sample is guaranteed to span the circular distribution of the phases and the argument is that we can make a better inference or prediction or even at the at the final point in time we can have a better consensus about what is the opinion of the faculty than simply taking the mean response of you know 50 percent of the faculty set open 47 said cost yeah something like this so so in other words uh we we're generalizing we're we're increasing the dimensionality a little bit which comes with a lot of gorp as you can see the approximations are not perfect there is a lot of numerical processing that happens but ultimately the goal is to be able to model these processes kind of surfaces and then do forecasting do what we call phase aggregation which is build consensus from all the observations into what is the real state of the system in other words what's the real public opinion about uh about the opening so i'm not sure maybe this was the obfuscated answer but um in a way we're trying to think of the phases as being almost like randomly sampling from the distribution of an unknown uh process i see um that's that's helpful um can you give a concrete example of a type of um phenomenon that you can discover in the face space that you can't on the in the 1d time axis yeah this is this is a good question so let me see if i can show you here in the applications we didn't get to the applications um but uh let's see in this air quality oh i beg your pardon okay okay this is this is still not uh up today so let me just see oh you know we haven't gotten these things posted yet um we have looked uh let me just see if i can switch back to the on the in a powerpoint i do have some examples um if you just bear with me for a second right up here so let me see so in this in this slide here i'm showing you uh this is uh uc irvine uh air quality data set you know 10 000 hourly uh carbon monoxide observations across time we're kind of decomposing them here into the harmonics 14 different harmonics kind of overlaid obviously the first harmonic is just the average the second harmonic is the lowest frequency and as you go up in the order they get more detail added to the system so what we did here is we fit in auto regressive integrated moving average model with exogenous variables and it turns out that this model on the perfect data set it has a pd and q of 114 if we ignore completely the phases we're going to get a different arima model okay with like different coefficients and if we replace all the phases with a single value of a face which represents the average phase why the average well because remember if i don't have the phase distribution a simple univariate characterization of it is what is its mean so i'm taking the average of the phases that i that i obtained by reconstructing the signal into the fourier domain and i replace the unknown here uh phase estimate the new phase by the average just one number the model becomes two zero and three certainly not perfect but look at how much better this model is with a single additional piece of information about the average phase not the distribution of the phases the average phase it captures some of these moving averages that were completely ignored uh in in the model that that completely ignores the phase also some of these coefficients even if the exogenous variables are present in the other model the model with a little bit of additional phase information gets much closer to the estimate of this coefficient in the true model so i'm not sure if this kind of resonates with people but again so we can show examples where very the most simple of all phase estimation strategies an average measure does a lot better than completely ignoring the face and there is obviously more elaborate ways of modeling the face but but i wanted to have here one example that kind of illustrates that that simple thing and we have we have some other examples uh that i can point out using more advanced methods for example uh using uh decision trees and so forth so at a high level um the phase space allows you to capture some kind of covariance that the one-dimensional time axis is not as obvious right i would love to chat about um whether this might be applicable to time series genomic data yeah absolutely yeah let's push base offline and see and see how it goes josh thanks anyone else okay there's there's only a few of us left anyway so uh oh there was a chat posting okay tour the force yes uh sorry gil i know this is uh uh this was difficult i know but uh uh see if i had only done the demo so it's very easy to do the demos it's gonna be no it's impressive that's a positive statement very positive okay so thank you all right everyone well thanks very much again i appreciate your joining and uh listening for an hour during lunch thank you evo you all have a good day okay