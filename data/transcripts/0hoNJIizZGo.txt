yeah machines writing in the hey welcome to Road to the tool technology seminar series spring break it's so nice and quiet perfect talk so there's a sign in cheek going around as always please remember to sign it I'm pleased to present today's speaker Matthew Flickinger he is a senior applications programmer for the Center for statistical genetics in the School of Public Health all right thank you yes so as I already mentioned I am a application programmer in the Center for statistical genetics I got my PhD here in the biostatistics Department University of Michigan working with doctors banking Gonzalo on methods for detecting DNA contamination in sequencing studies which is also interesting but in writing my dissertation I didn't like the writing part very much so I liked distracting myself and I found I started answering questions on Stack Overflow for our I felt like these little little wins I could do every day instead of trying to do one giant document so I got a little carried away with that so according to stack overflows own little statistics like the answers I posted have reached over 2.7 million people which is just like page views from search engines I'm not sure how many people actually found that useful but I've answered a bunch of questions and it helps me kind of stay sharp and just interested in how our works so today's talk is about the deep liar package specifically in R so I'm gonna assume that you're already kind of familiar with our I'm not gonna try and sell you on R or anything like that but if you haven't been using deep liar I'm just gonna try and maybe show you or even if you have I'll try and show you a few features why you would be interested in it and maybe a few features that you haven't used of it just to make your lives a wrangling data a little bit easier so they designed to spend a lot of time just manipulating data wrangling and summarizing it cleaning it creating statists some summary statistics about it and those steps just well they're so common it's also nice to have just a very easy language to like express what you're trying to do in it and deep wire kind of helps give you bigs like kind of basic building blocks to make a very expressive kind of procedural analysis plan now besar is perfectly fine from any of these tasks so if you've been using R for a long time you might think like why do I need a bother with deep liar I can do all these same things using square brackets and dollar signs and stuff like that but I just find that the syntax can kind of be may be verbose or a little bit ugly with old-style stuff and it can also be kind of slow for big data a lot of the functions in deep liar actually do have accelerated kind of c-level counterparts that on the it can actually just run faster using deep liar commands so deep are just exists to make code easier to read and hopefully it is primarily not a speed improvement but it does make it a little faster so deep liar is one package in this so-called tidy verse a collection of packages that is becoming very popular in our so I'm not sure if you've familiarized yourself with it but the from the description of the tidy verse page is just a collection of opinionate opinionated collection of our packages designed for daily assignments so they all have kind of like similar looks and feels and how they describe their parameters how they work together how things like chaining work so they're all kind of a collective bunch and they all work very well together so it's almost like a new layer that's kind of built on top of base our just to make a lot of common tasks easier and deep liars kind of like the data wrangling the data manipulation part of that and I just bring that up because the the tidy verse is very popular and it is gaining traction and it's also I do teach beginners are I also find it's actually a very useful way to introduce people to our and doing the types of tasks that you do in our so if you are also gonna be teaching others how to use our there's a lot of great advantage of talking about why teaching tidy verse first just helps make people more productive right away so this is kind of signed if you do want to type these commands along as we're going today and you happen to have a lot laptop in front of you you're welcome to do that and if at any point I do have our study of studio open so if you want to see me type things cuz you want to see you have a question about how something works I'll be glad to demonstrate any of those for you as well so feel free to ask so you can either install just deep wire or you can install all the tiny verse packages at once it is a lot of packages grouped together it's kind of if you if you're in a fresh or install it is a lot of things it installs once but hopefully that means you don't have to install many other package ever again later or you can just install deep liar directly a lot of the specifics of some of the syntax is changed a little bit from older versions all the things I'm using in the slider from 0.7 dot one which has been around for a while now since unit 2017 but just make sure your D prior versions up-to-date if any of the code samples don't work here there are new versions of deployer as well but not much has changed significantly since then and for all the slides I'm gonna be using example data from this NYC flights 13 data or it's a it's a package and it basically has a few tables that contains a bunch of flight information about all the flights that left New York City in 2013 so it just has some sample data to work with for all these tests so you just install the package and you load it and it's available to you so this is the primary table that I'm going to be working with for most of this examples it's called the flights table it has information like month/day/year the departure time the schedule the actual departure time the scheduled departure time departure delay arrival time things like that and also you know this this printout looks a little different than a normal data frame does in are it's actually what the tidy verse world calls a Tibble which acts a lot like a data frame and it just storage data's but instead of like if you have a very big data frame it can like take over your console if you take if you type the name of the thing this just kind of clips it out a few lines and just wraps it columns that it can't display there so it's not just these columns there's also like flight numbers the distance that was traveled travel Eric the time and air things like that are all in this table as well so that's just the sample data we're working with so the kind of the fundamental building blocks of deep liar are these kind of single table verbs so it has a bunch of kind of again just useful verbs that you apply to your data to get results so there's things like filtering so that just keeps a subset of rows selecting chooses a particular set of columns that you're interested in a range is the deep layer verb for sorting the rows in your collection mutate allows you to create new columns summarize allows you to create columns by collapsing information basically summarizing across groups in creating a new calculated value from that and then there's grouping by which allows kind of you to say I want you to logically perform these operations in these groups of data values at a time and either summarize or mutate within those collections without having to do a bunch of sub setting or something like that yourself manually so I'll start showing how these well I should say all these verbs have a similar property and that they always take the data source as the first parameter so some sort of data table or data frame or a table going into the first parameter it also it always returns a new data object so it never updates in place these like ours a nice little functional language do something new so if you want to save that you make sure to sign it somewhere and it also you specify columns of your data sets as these um unquoted strings or symbols it's kind of like the technical term for but basically you're just kind of putting a the bare word name of the column exactly as it appears in a lot of these expressions so for example starting with the first basic verb of just filtering so here's what the call looks like right it's it's filtered again the data that you're using goes in is the first parameter and then you have some sort of expression that's telling how you want to filter your data so there was a column called destination I'm looking for all these that are going to dtw they're coming this way and it has the little logical operators that you can combine so I'm also looking all of them that came to Detroit in June and that's gonna subset that data frame that way now again filter is not magic a lot of times people using base hour might do something like this using indexing again you're just kind of having some redundancies of having to repeat the flights and then having this comma what like you know maybe not exactly obvious what that is but it works nonetheless and also base R also has a subset function which works almost exactly the same as filter with the same syntax but again again you can do this stuff and base R but filter is gonna have some other properties that we'll talk about later that are nice but that's basically how it works another verb that you might be interested in again it's just select so select again it takes the data frame that you're interested in and then you just put a bunch of commas or a bunch of column names after commas and you just pull out those particular columns you can exclude them by putting a little minus sign in front of them and you can select ranges which is also nice by putting a little coal in between them so it'll take all the columns that are logically or that print out between month and departure delay it'll select all those for you it also has a lot of really other kind of nice selection options again you can get to like the help for any of these functions in our budget typing question mark and then the name of the verb so question mark select shows a bunch of these examples but here you can select all the columns where the name starts with D or ends with time contains a RR for like a rival all those that don't start with D and then you can also rearrange them so the order that you put them in is the order that they come out of select so you can say select fights I want the flight column first and then just give me everything else after that so there's a little keywords for everything so a lot of functions to help you select names of columns should you be extracting those and if you use the everything syntax it D duplicates columns it will not do flight again okay yeah so it'll do everything that's not already been specifically requested so now here comes the more kind of fun part of a deep liar is when you start combining verbs together and what does that start to look like so you know one way of doing it would be to go ahead and filter your data set save that to a new variable and then do your next verb on that filter data set again filtering itself doesn't change the flight data at all you need to save that new transformed object to somewhere so you could do this or maybe you next these calls so first we're gonna filter and then we're gonna select the the carrier from this filtered object now both of these are possible but there may be you know you have to create a bunch of extra variables or you have to like get really long expressions if you're doing a bunch of things so what deep liar is kind of championed and it's actually the Magruder package specifically that implements this such as part of Tidy verse is this kind of piping notation so similar to like when you do stuff at the UNIX command line you can pipe the output of one program into the next program so you can find Apple in this file maybe describe the first 50 lines that have it cut out the third column sorted it the pipe operator works a lot like that with D plier allowing you to change a bunch of nested expressions into a series of statements so for example if I'm calling the function C on X and calling beyond that and calling a on that I can now use this pipe operator to start with some value pipe that into the C function whatever that output is gets piped into the B function or whatever that output in gets piped into the a function so these are pretty much syntactically equivalent but this one tends to be a lot easier to read especially when you read this pipe operator as just saying then so we could say that we take the flight's data we filter it and then we select it so this this expression here is equivalent basically to the same output that would been a generated by those two statements previously but it becomes a little bit easier to read so for the rest of this talk I mean you basically use it in this form we're gonna anchor with our table first and we're gonna be piping it into these extra columns so again this this pipe operator is not specifically used for deep wire you can use it in any functions that you want all it logically does is it takes the thing that's on the left side and plugs it in as the first parameter to the thing on the right side so that's why the all these functions are kind of empty because basically we're just the the piping operator is just plugging them in as the first parameter now you do have control over where it goes if you really need it but that's basically how Piper works so yeah and yeah wait the shortcuts this pipe thing because I think that's maybe I don't use it enough but I think it yeah it kind of sucks typing this for Sam sure I know there's no shorter way to alias it for the most part our studio has a control-shift-n which is a nice keyboard shortcut for just popping that pipe operator in there whatever IDE or text typewriter you might have it has to do mostly with the weird way so this is again that's not part of besar it's an add-on package and the only way you can add in fix operators that you want to define is to have these two percent signs on the opposite side that's the only thing the our parser that'll put it into the right syntax rearrangement so yeah there's no way really to shorten that pipe but again most times it's pretty easy to put a keyboard shortcut together to make typing it painless so yeah now just continuing with the other verbs so we've talked about two verbs pacifically we talked about how you start combining verbs so now I'm just gonna talk about again about some more verbs so arranging again it's just a way to sort your rows by however you want to sort them and you can use this descending function around column names to just you know do the reverse descent our ascending that way or you could even put a minus sign I guess the descript descending I think - I'm only working with numeric values because it actually like does the negative value of that but so if you want character values sort of descending just use the descending operator and then you can you know you don't have to create new variables that you want to sort on you can put complete expressions in there so if you want to you know look at the difference between the actual departure time the scheduled departure time and then figure out where like the biggest delays were you can always put that as an expression there so that's just kind of how a range works now now we're getting into more powerful verbs so instead of just kind of sub setting in and grabbing things out and putting the order now the power of mutate allows you to create new columns from existing columns so this is where a lot of times of summary information that happens and it's very useful so say I was interested in figuring out which flights had the best leg overall average speed across the whole entire journey so here's what I can do I can now do a mutate and I can take in this case air time is in I know it's what I do miles per hour I guess hours know must be a minute yes thank you in minutes yes minutes so then I get the hours okay so I take the total flight in this the distance divided by the number of hours and essentially I get a speed in miles per hour so essentially with the mutate you give a new column name you put an equals then you come come put some expression that has other existing column names in it and it gets evaluated in the context of your data frame and now what pops out here is essentially a new data frame that has this column added and now we can arrange based on that calculated value that I have and then I can just select maybe just a flight number and the speed for all these things so I can just see all the speeds in a list there and remember that this new thing doesn't get saved anywhere it just prints to the console if you don't do anything with it so if you want to save it make sure at the beginning of your chain you assign this to a new variable somewhere so you can use it again now the other interesting thing which sometimes can be tripped up if you're not expecting it is that these values that you create along the mutate can be used by the next thing that comes after each of these comma so you need commas between each of these assignments but here you can create a new column you know the distance in kilometers you know I did miles per hour the first time but say I'm interested in kilometers per hour here I can do a translation and then in hours I can create this separate variable here again to make it more clear that I'm calculating the hours and in the kph I can use these two columns that have created in previous steps to get to create this new expression here so they're created kind of in the order that they appear this does mean that you can overwrite values so if I were to have assigned this air time divided by 60 back to air time there's no way to get to that original air time anymore it kind of gets overwritten so just make sure that when you're doing this that that's your intention so the order when you put those in doesn't matter a lot but so yeah that's just a little note about that so mutate never changes the total number of rows that are returned it essentially is just adding a column and keeping all of your data so there should always be just a new column for never changes number of rows now summarize tends to collapse rows for you so what it's gonna do it's gonna create a new column but it's gonna apply some function to the values of that column and and give you some sort of just summary for that so you want to use functions that take a lot of values and and get them down to one so for example mean I could take a mean of many numbers and in the end I get just one number so in this case there happens to be some no values in the arrival delay if there's no delay so or missing values I should say so but I was trying to find the average length of the delay so I take the flights I just filter out those that are missing and now I use summarize and I can get the average arrival delay by just taking the mean of that column so instead of getting rest before we are calculating calculating the km/h speed of every row we just added a new column now in the end I'm gonna get a table here that just has one row in it that has the mean across that entire column so you can use the a variety of again base R functions there are a few that deep layer adds deep layer adds things like n just to get the number if you're interested in counts or the number of distinct values or the first or just two laughs for some reason and then you can use all the standard base functions you know the mean median variance standard deviation then whatever you know whatever kind of summarizing functions you want to use you can write your own it doesn't matter just any function will work that takes a list of values and returns one value so you know collapsing that whole table down to just one row it gives you the average maybe across all carriers but sometimes you have groups that you're interested in and you want to see how the summaries differ by each of those groups so that's where this group by function comes in and it's really I think the thing that makes deep lie are much nicer than most base functions is this very simple kind of grouping by verb you don't have to do a bunch of splitting or stuff setting or the AVG function I mean you can do everything that's kind of group aware and functions like mutate and summarize are performed within each of those groups that you define so for example before we calculated just the overall delay but now we want to know the delay by carrier code so again we filter those missing values I had a group by carrier and then my summarize statement again is the same thing but because I've done a group by that column is preserved and I get a summary for every unique value in that carrier column so allows you know again you can do more complicated fresh in you getting group by other variables both essentially these group buys kind of sneak their columns along and summarize these so now there's only one row for this carrier Cody nine it's all been collapsed via the mean function that we described so mutate again will not change the number of rows so functions like max will return the max for each group so that means you know if I wanted a column where the max departure time for every four that carrier was also on the row so I could see maybe the difference between the maximum arrival delay and each individual rival delay I can use mutate and that'll within that group will return that same value for every one of the rows in the group whereas summarized collapses does that does that kind of make sense okay so a group I post mutates so this is yeah just going into that so what I was talking about so we filter out those that are missing or grouping by carrier and now we're doing a mutate so that we're calculating the mean arrival delay for each carrier and then selecting just three columns here so it's prints more nicely so we can see now I don't just have one column for the I believe this United Airlines I forget my carrier codes I will have a I'll show how to merge in that information later but now this same or average rival delays return for each of those columns so I'm still getting all three thousand two hundred and seven thousand rows but again within that group that columns the same it's been summarized and just repeated ah so we got merging data sometimes you have data in one table that refers to Sami code in another table and you're interested in in what that code means so if you've used sequel before or SQL there's a lot of those same types of rich joining operations are made a lot easier with deep liar and base are you have just like the simple merge function these in our it's just a little more clear what all the joint functions are but again just going back to this example I got all these average delays with all these codes and I didn't know what the codes are it just so happens that in this same data case the NYC flights 13 that you can download there's also a table called airlines that gives these two digit codes to some sort of human readable format so now what I can do is I again up to these first four lines of the exact same code what we used before and now I can left join Airlines and now it's going to essentially add this name into the output and when it does when you just do left join without any options it just looks for matching column names so in both cases I go back again this Airlines table had a column called carrier the summary had a column called carrier so it just implicitly matches on to all maps and column names and now I get this information so oh yeah so a a is American Airlines a s Alaska Airlines information like that so left join is just one of the joint options so in case you haven't done a lot of joining before just to give some visualizations of what all these different types of joins look like for example I'll talk about there's the for simple join types are an inner join a full join a left join and a right join and to illustrate I'll be using this sample X&Y so let's say that there's this key column this numbered column and then there's these values X 1 X 2 X 3 y 1 y 2 y 3 so what's gonna happen is if I do an inner join it's gonna look at essentially the key column find that only the ones that match and return those matching rows and keep them together so because there's no 3 and Y and there's no 4 and X those kind of disappear so the inner join matches things up exactly so we get a little subset back left and right joins actually matter which data is on the left and which ones on the right so if you say left it preserves all the values that are on the left side of the operator essentially that whatever parameter you pass in first or if you're chaining it which everything has been piped in to you so in this case because we do a left join and X is listed first I keep other rows from EXO despite the fact that there's no value for three and why I still get a row for three and the output and right would just flip that so that means I want to keep everything on the right so there's no four in X but I get a four in the output and values in are just kind of inserted as na value becomes the default missing value and a full joint now keeps any row that was missing from either of the two so it just keeps all the rows matches them up when it can I mean if it can't preserves the values it does no and just sticks in and aids for those so different useful joint types available to you there's also kind of non merging joints which are very useful so semi join basically allows you to filter one table with the values of another so instead of like merging in new columns it just allows you to subset the original table of interest so if you have you know a multi you have them maybe three different fields and you want to match them on three different fields here and only keeping the subset you know if it's genetic data maybe you have chromosome position graph or something in two tables and you only want to keep this subset of those positions you can do a semi joint and it'll subset that full table that maybe has all the information to that smaller table that you have an anti joint Anthony just does the opposite instead of keeping the rows in your smaller list it just deletes those rows in the smaller list so it does a lot of the things like merge but doesn't actually change the columns I'm so useful for a subset ignored filtering so by default it looks for matching column names and just teach those so in most cases if your columns are nicely named that's that's wonderful and exactly what you want but sometimes that's not exactly what you want in the case of the flight information there's a I guess yeah I maybe I should pull it up a second just to just to show a little example so if I now pull up deep liar just an R I'm gonna load up our NYC flights 13 type over your back okay so now I help my table so I got my plates information which again has all of our plates and we also have the plane's information so the planes give some information about essentially what type of airplane was used on the flight so each of these airplanes have a tail number with a year and a manufacturer and model so this this year is actually like the year the plane was manufactured or put into I can't actually put into service but if I look at the flight stable I also have a column called year and this is actually the year that the flight took place so but it also has a tail number column here to show what plane we actually went on that day so if I do a join between those two I'll do an inner join flights so I get a little note that it's actually joining by year and tail number and in the result I'm actually only getting the planes that were put into service in 2013 so I'm getting four thousand six hundred and thirty rows in the output which isn't the type of join that I wanted because that year means two different things in those two different tables so that you can do is actually specify what column that you actually want to do the joining by in this case we only want to join on tail number so if I put that in it does the join but this time I now get two hundred and eighty four thousand rows so it's ignoring that and well all the flights happened in thirteen yeah unfortunately the the year of the why so that this year column gets merged in it gets merged in with the suffix of like that X&Y that it remembers so it still preserved that other year value but now yeah there's there's values that aren't 2013 in there so just keep that in mind when doing merging sometimes the default behavior street and sometimes you need to overwrite it so there's a lot of options for specifying the the two different column names there so you can specify the column names if they're not the same name yes I don't know if it has example but it's going to look like is it uses a I said sale is called Tian and the other data thing so what's this going to look like is you basically give it the X name and then the Y name and match them up it uses named vectors it's an unfortunate kind of site in fact it's not great syntactically when you're trying to program on it but it uses kind of these named vectors where you give it the name of the vector is actually the table and then the value of that named vector is the name and the other table and you can link them up and put them all together there so it is possible yeah so there are D Peyer again is made for data mangling and wrestling so it has some other kind of just useful functions kind of in addition to the primary manipulation verbs there's a distinct so if you want to filter out duplicates you just tell it which two values you are interested in or which columns you're interested in and it only returns the unique combinations that actually appear in your data for those columns you can use a count which basically kind of does like a table in base R it just looks at all the carriers and counts the number of rows in your table for each of those it creates a new column called n for you I can command a second sister like it's just oh that just gives the overall counts of rows if I wanted to maybe Oh group count by or the carrier then I can just get a little n for each of those so you know nice distal summation you can randomly sample a certain number of rows kind of from each group so if you want to randomly grab three rows from the flight's table you can do sample n and you know get three random rows so in addition to just kind of summarize and mutate where you specify all the columns sometimes you want to do the same thing to a bunch of columns and so there's a three kind of different options summarized all mutate all will apply the same function to all the columns so if you want the mean of every column in your data frame you can get that summarized out allows you to specify which columns you want and you do that in a little bears with so I could summarize all the variables that end with time and get the mean of them so flights is actually getting piped in its first parameter I'm specifying all the columns I want telling it which function to apply to those you can apply you can pass in additional parameters to this function as well in this case because some of the times have missing values I tell mean just to ignore missing values just to drop them so here I can get the the average time for every one of those columns and then summarizing you take if allows you to just kind of do conditional you know do a test over the column itself and decide whether or not you want to summarize the mutate it so if I were to you know summarize all and take the mean well there's some character columns it doesn't make sense with to take the mean of a character column so in this case I can actually say only if it is numeric do I want to summarize it and additionally I don't want to supply one function so I can use this funds operator to specify more than one function I want the mean and variance and also please ignore all the missing values so it's very expressive in that sense so you can you know only fill do certain things for maybe numeric columns or categorical variables things like that and the two functions the two helper functions here are Bauer's which you use when you want to specify more than one thing because if you put a bunch of commas in it's going to kind of interpret it as extra parameters and it needs to know that these are all columns that you're interested in and same with functions if you put extra commas without not inside the functions is returned those extra parameters to summarize it and not just kind of extra functions that you interested in running other useful functions it has a lead-in lag to get a value before or a value after kind of just shifts your array one to the left or one to the right if you're trying to match up with a value that came before or after it has a useful coalesced function which is the you sequel it's just like the coalesce operator there you can pass in these lists of vectors and for each row that it goes across it'll return the first non-missing value so if you have different columns some have missing some don't have missing and you need basically just the first non-missing value and even these call you can use the coalesce operator for that I'd mentioned before and and distinct useful for counting especially in like the group by scenario so if you're interested in the number of total number of flights by each plane you can get the total number of flights and if you're looking for the unique route sino to some planes by the same flight number of multiple times you can get the number of distinct routes versus the number of total it's just like they took another useful function is recode allows you to easily change values in lists if you just have one value that you want to change to a different value so in this case letters is a built in vector and our one through five just returns ABCD but in this ABCDE in this case I just want changed the value B to the word boo and basically it does that instead of doing a bunch of kind of like ifs and and sub settings recode can be very useful for changing one or more values just to some other value case when is a is a great alternative to maybe if else if you have a bunch of conditions that you want to apply it's basically like a switch statement in other languages it does have somewhat unusual syntax when you're looking at it the idea is you put some expression that you're testing for so this is before I have a value of x here it's just looking for all the values of X that are evenly divisible by 35 you know this little modulus operator is the double percent sign and basically even these is y 35 it uses the formula syntax so that's where there's Wiggles coming from and it's saying what's the value that you want when that particular case is true so it's gonna go down this list that you apply to case when and it's gonna stop when it finds the first true statement so that's not true it's gonna check is this these evenly divisible by five if so spit out fizz if it's evenly divisible I seven spit out buzz otherwise I kind of have a catch-all here just keep that value the same in this case because I started with numbers it's turning into a character so this case web expression allows you again to do if it's not just a simple recode if you have a bunch of conditions that you're interested in transforming here's what the output that looks like so all those that were divisible by five it could change the fish those reverses y7 get changed a buzz those are divisible by five and seven get changed to fizzbuzz which oh yeah I didn't go up to 35 there but that's that's what the output look like if you looked at the whole 50 so sometimes you want to combine the information well there's two different of combining information we already talked about merging which basically looks at two different data sources and tries to line up columns across them sometimes you want to just stack one data frame on top of another or maybe just stick two side-by-side together stitch them up if they have the same number of rows already and you're sure than the right the right order so there's bind rows and buying columns so vine grows just stacks things on top of each other buying columns you know puts them side-by-side and stitches them together these are much more efficient and then using like C bind or are binds in our it would base our they're just they're much better at growing data sets and not mangling different data types so they're great ways to just again put together things especially bind rows there's also the things like you know intersect Union incentive to look at basically you know again common elements between different data frames you know if you're looking kind of like filtering so these are just kind of maybe alternatives to actually doing a full merge if you're interested in just getting differences between different vectors so that's a lot of the basic verbs in deep liar are there any kind of questions about those that we've talked about so far but the player changed their since so before they used to have like whatever for should they have the function underscores where you could give a string instead of names yes now they abolish that yes they're using our legs yes that's actually yeah that's the next section but we're going to talk about how to program with that because that's very important but yeah just any other questions about just the basic verbs I know you know yeah so the pivot tables actually comes from another package in the tidy verse like I think like tiny R is the one that's better for kind of breaking out values yes so that's one thing maybe deep lie on its own isn't the best out but yeah there's another package and yeah that's it's a little more yeah it's a little more work to explain everything that one can do as well but I think tide er is the better solution for that and apply itself yes call them matching it okay it'll it'll Matt it'll stack them up but it'll it'll match the columns that are named the same so the column should be named the same if the columns are different it's going in Kurt it'll put a value of n A's for the one value of n A's for the other ones that were the columns don't match up but they will match on column e I don't I don't think so yeah it has yeah it's been a while since I've been down that path okay great and then now yeah now we'll talk about so these commands are great if you're just writing them out and maybe you have a little our notebook that you're working on it helps create very readable code but sometimes you want to create functions and that's where getting into deep wire is a little it's a little bit trickier than maybe you would like so the idea is you know I have this I create this little code chunk I want to group by carrier and I want to get the average arrival delay by carrier but let's say I'm also interested in running the same kind of operation for multiple different columns and I want to just group by something different well if I kind of naively write this little function to take in a column now I say flights I want you to group by this X and then calculate the average arrival delay when you go to run like F and just try and pass in carrier like you would here you get this error that column X is unknown and the reason is is that we always pass in column names as basically bare keywords which is exactly what a variable looks like an R so in this case it doesn't know that X is a variable it thinks that that's a column name there's nothing the clue are in that oh hey I'm actually a variable that you need to resolve first before you actually try to run the group by so that's where things get a little bit confusing and in old versions of deep are they're using this underscore but now with this new R Lang syntax they're introducing things called closures into R which is a closure is like a quoted closure it has a symbol but it also has an environment attached to it so here's what here's two options for rewriting your function so it looks like so closures can be created using this qu Oh keyword and basically this is now saying instead of just having the symbol carrier which looks like a variable I'm saying that this is an expression that I'm gonna want you to evaluate at some time later but don't try to like look up what the value of carrier is now because it doesn't exist and how I tell are to expand that later is using this double exclamation point or the bangbang operator so what this does is it takes this closure that you pass into here and it expands it it don't bangs it so now it's basically like you had just typed carrier into that place so this is one way to kind of rewrite that function is you have to create some sort of closure and then you have to expand it at some point later in your expression another way maybe a little cleaner way to write this although it depends on what you like is if you want to be able to just pass the actual name to your function instead of having to explicitly call kuo on it end quote can take whatever was passed to your function and create a closure from that so that's going to create the the closure of again there's this carrier thing by passing it into your function and again you expand it with a double bang to make it that into that X value a you can insert that there so the double bang or bing bang can be used essentially anywhere you're using kind of a single column name you know I could also change the name of the column that I'm taking the mean up by having another parameter I can use a double bang Y there if I want to pass in a second thing but that's now how you kind of insert variables into are the only other catch is that you can only use the normally you can only use the double bang on the right side of an equal sign or where you're not using an equal sign at all the equal sign in R has like this different it's actually naming parameters so it doesn't have the same kind of variable options that you use but deep are are laying certainly has also created this : equals operator that allows you to then rename the left side of an equals operator where you normally camp so if you wanted to in your summarize dynamically create the name of the new column you're created because the deep-fryer rules that house has to be on the left side of an equal sign so we have to do a little bit extra work so here's what we do if I walk through this step basically I'm taking this function H I'm passing in carrier I'm creating a closure from that carrier so I'm kind of capturing that symbol so I can evaluate that later and now I'm creating an out name so I'm taking this closure if I want to get this stream value of it because I want to paste this to create some sort of string name I use quo name so that can actually get this string carrier carrier basically carrier in quotes and I can add that to delay with an underscore in between so that's creating this output name carrier underscore delay and this is all as a string here so and now I'm grouping by that column I'm going to ask that original closure and now I'm using that out name variable that I created here I'm using the double bang to expand that into the expression and again you just need the colon equals for that and then you just continue with the rest of your expression so it get a little more confusing again those underscore functions that you may have used temporarily before have been deprecated or will be but this is kind of how you need to program functions so writing functions it would this tea pyar looks a little bit Messier but it's really a good idea because again if you can create some sort of verb that describes exactly what you're doing you can express that very easily in some sort of pipeline that other people can use so there's yes it is working already for did you block no yes so ggplot is maybe the black sheep of the deep line family it's the oldest one it uses pluses instead of the piping operator to do things and I think they've declared there's no intention to actually change that at any point it does not yet work well but I think closures will be working with ggplot but it's as of today it's not available yet or stream still with a ES underscore or AES yeah cute yeah well there's a variance on the AES you still to use those for ggplot so yeah all these functions I talked about is our own data wrangling cheat sheets this it's a wonderful cheat sheet that our CEO put together I recommend when you're learning to apply are you print it out just put out of your desk if you just search that yeah our CTO data wrangling cheat sheet and it's actually available I think it's right in our studio I think they have the cheat sheets a transformation just to link you right to that again they're very useful summary of all the functions and maybe somebody didn't talk about today that just really helps you kind of again visualize those and remind you what's available to you when you're using deep water so that's basically my talk today thank you very much and I'll be happy to answer any questions yes I do think again when you're writing code it is much easier to read the steps so for that sense and because it also expresses us is what your intention is more clearly instead of trying to understand again the the square braces and the the dollar signs yeah I I do recommend teaching tidy verse first I think it is like if you're in teacher if you only have one day to teach someone are you want to give them useful skills in it I think it's great I mean ultimately if you're gonna be using are for a long time you do need to understand more how the base functions work especially you're gonna be debugging code from other packages yeah using deep layer code in your own package is actually kind of not fun because of the way all the column names look like variable names to the the checker that some verifies your package is good to go and crayon you have to do a lot of kind of weird escaping of things in order to get it work so it makes it really great if you're writing your own code it's not so great if you're writing stuff for a package which is like the only caveat it's like really diving down into deep liar but again I just think it really helps people get productive more quickly especially when you combine that with maybe ggplot2 like if you have those two things down there's just so many things you can do in our I mean you know super fancy date announcements at least the visualization the the steps of exploratory data analysis I made so much easier with the buyer great I mean yeah if you have any other questions or things that come up oh I did push my email address down the slides just em click that umich.edu I'm happy answer uh questions about deep ire as they come up or or anything else I do I feel I learned the most about are when I'm answering other people's questions about stuff I've never thought of before so it's very fun to do that so thank you very much