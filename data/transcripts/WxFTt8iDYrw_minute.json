[
    {
        "start": 4.19,
        "text": "our technical go ahead and get started sorry about that pizza arrived a little late so we're gonna go late starts but so welcome the tools of technology seminar series I think most of you know weekly thank you to share about conversations about tools technologies methodologies so that speakers Peter orchard graduates thanks for going up drunk so today I'll be talking about a tactic which is an assay we use a lot our lab probably a lot of you work with it as well I'll be talking in there about quality control and about our software so for those of you who don't "
    },
    {
        "start": 67.799,
        "text": "do much genomics I could at first explain why it's important so this is the world's most native model of gene regulation basically in each one of your cells you've got two meters of DNA and it's not just kind of free floating around in the nucleus it's actually really tightly packed around these proteins called histone proteins so if your DNA is represented by this kind of string here it's wrapped up around these blue histone proteins and the complex of the two is called chromatin that's the DNA protein complex when the DNA is kind of really tightly compacted like this Gene's can't really do much so you can't have the gene thing read to produce RNA just because you can't have any necessary proteins getting to the gene said that thing is off in order to basically turn editing on and regulate gene expression you need to have unpacking of the DNA "
    },
    {
        "start": 129.989,
        "text": "and so when that happens the DNA becomes a accessible for other non-histone proteins to come and bind these are called transcription factors and this is what allows it needs to be turned on though these regions of open chromatin which i've scattered at the genome and to be important because their areas of DNA sequence that is important for gene regulation you generally see them right in front of genes or you can also see them within genes or just really scattered throughout the entire genome even very far from so because these regions are very important between regulation people would like to know where they are and there's a couple of high-throughput assays to do that ataxia is one of them it's kind of the modern preferred method the general idea is you take your population of input cells you don't actually need that much only like 500 cells even will will do usually "
    },
    {
        "start": 192.199,
        "text": "people use like 50,000 if they have the material and you isolate the nuclei from those cells and you expose the chromatin to this enzyme called tn5 so 10:5 is a transpose ace which basically means it cuts the DNA and it in particular at custodian a where the DNA is unprotected by Pistone's so like in this little cartoon where you have these red arrows the DNA is a little bit more accessible and so you get the TN 5 cutting the DNA and if you have two cuts of the DNA relatively close to one another of course this results in just kind of a free DNA fragment and you can sequence these and just kind of align them back to the genome and so the result is that you end up with these DNA soups and reads that are concentrated in the regions of the genome that have open chromatin so to give you an idea of what that looks like this is an example from "
    },
    {
        "start": 254.389,
        "text": "our data it's just kind of a linear view along the genome going a game called my OD one which is important to muscle development and you see the attack seek signal here you kind of get this big pileup of signal right at the start of the gene which would indicate the gene promoter is is accessible something else that's worth mentioning here is that if you look at the fragments of DNA that come out of this assay you frequently see a very interesting pattern this is from the original attack see paper and you basically see an abundance of short fragments so that represents cases where you have to transpose ace cuts between nucleosomes that would be like those two arrows there then you sometimes see this mono nucleosome cheek and so that represents cases where you get one cut on either "
    },
    {
        "start": 316.039,
        "text": "side of a nucleosome so that's like this kind of non-nuclear zone DNA fragment example here so you get enough DNA to wrap around a nuclear zone that's a little bit of pointing stuff and that's the fragrance and this in a second pump and so on for the kind of third and fourth pump this just represented kind of additional nucleosomes being added so with the dynamo resolution so in terms of like if you do yeah so you do peak going in a taxi as you would in for example chip seek or DNA sequence in where I fit to a taxi I usually you're looking realistically your resolution is going to be like 100 or 200 base pairs or something yeah first birth or be calling just if "
    },
    {
        "start": 378.65,
        "text": "you look people are looking at like where the cuts yeah so you know like exactly where the enzyme cut just from the sequencing read you can infer that but um in terms of like actually calling a peak usually gonna be a lower resolution that relates a little bit to this next slide the common use cases for a taxi really it's primarily just used for mapping regions of open chromatin across the genome unless you're really most of what I've discussed so far but there are additional use cases for it you should at least I wouldn't probably create an attack seek data set specifically to do this but if you have an intoxicated set anyway for your cell type of interest you can use it to map out nucleosomes positions you can use it as Ricardo was referring to to look at "
    },
    {
        "start": 440.97,
        "text": "transcription factor footprinting so that's the case where you kind of want the per base pair resolution you want to know where each cut from the 10 v transpose ice occurred the idea being that you can then use that to infer precise region though transcription factor binding that's what I thought there will be some Michael actually involved in a so that will affect the resolution unbound during the you know oh yeah yeah I mean so yeah there's yeah you definitely like it reads nothing all over the genome You certainly have a background but you know with with P calling of course your your selectively kind of ignoring those regions and if you do something like transcription factor footprinting where you're concentrating on for base power cuts you're going to tend to focus really on the regions where you have and "
    },
    {
        "start": 501.45,
        "text": "of more signal anyway but you certainly get background yeah if anyone is interested in transcription factor footprinting i recommend they talk to Ricardo so now that you know how ataxic works you can think about some of the expected characteristics you would expect to get a taxi data set to show one that everyone always explore is just the enrichment of attack signal around transcription start sites so like in that example Jean I showed you earlier minnijean promoters will be open and therefore you expect much of your signal to come from near gene promoters and so if you that's usually quantified as transcription start site to enrichment more generally kind of related but marginally you'll do peak calling as you do in chip seek and you just expect a high fraction of your reads to land and "
    },
    {
        "start": 564.33,
        "text": "those attacks expect basically concentration of your attacks it reads high concentration in particular regions of the genome people generally look at the fragment length distributions as you expect that to look very different than just like randomly fragmented DNA you often see that and a fire fire fire trimodal distribution like I showed earlier that interesting program length distribution but frequently you just will see like a very short fragment part of the fragment length distribution and those datasets can also be okay but you have some expectations for what the fragrant length distribution could look like so you'll then we'll check that mitochondrial contamination is a common problem in attack seek and so there's some datasets out there where you're getting like 50 to 80 percent of your sequencing reads thing mitochondrial and you tend to filter those out filing through matically so "
    },
    {
        "start": 626.16,
        "text": "ideally you would have low in mitochondrial contamination as well and then really want to check for all of the same stuff you check for and any other NGS assay do you want to make sure you are getting good alignment rates for example you would be interested in your duplication rate really high duplication rate might indicate basically your PC your PCR amplification of the library was kind of too extreme stuff like that so a couple of years ago this is especially the case but but of course you want to do kisi on your data went to look for all those characteristics that I just discussed and so you'd like some tool to do that so there are a couple out there attack you see in particular has been around for a couple of years this is from the encode consortium if any of you "
    },
    {
        "start": 688.11,
        "text": "are familiar with that and this is a this is kind of a built in part of their pipeline so it's not really a separate tool you can install easily but they give you an HTML report and have one report for for example so that's one tool out there there are a couple of other ones that are newer there is at least one that is in our package so it's kind of you need to use AR and you load in your data and you can produce some plots there that the newest one that I'm aware of it's just published this year this is kind of the nicest of these three in my opinion it's just a command-line tool and then you can additionally load some of the output of that tool up into web viewer and it I've generally found it work pretty work pretty well a major shortcoming of all of these is that "
    },
    {
        "start": 748.829,
        "text": "you're really getting one report per sample and so it anyone who's like run fast you see and had 20 samples is aware of that you know that means you're looking through suddenly 40 reports or something like that and it's kind of a pain additionally some of these only work on certain genomes though like in codes will only works for human in mouse so this was a problem that the lab was dealing with a couple of years ago so we set out to figure out what would you want in a QC tool and these are some of the characteristics we came up with you want something that's easy to integrate into any pipeline you don't want it to be built in to some kind of pre-compiled pipe like and codes is for example you'd obviously like compatibility with any genome you want to make it easy to compare across samples so kind of avoiding that you know one report for sample because if you've got a hundred and fifty samples that becomes kind of a "
    },
    {
        "start": 810.93,
        "text": "pain you'd like something that's given readable but also between mutable because you'll often be loading and kind of files into downstream analyses otherwise you just like it to be you know kind of accessible and easy for experimental folks to look at as well and you'd like things to work on a per read group basis to this is important because a single nuclei attack has actually come online now this is something we're doing in the Parker Lab as well and so being able to run it on a single BAM file with all of your single self data in there is nice so we developed a tool to do this in particular I was John Hensley did the vast majority of the software development he was a software developer previous in the lab since moved on but this tool is available on our on our lab github that's the first link there there's also "
    },
    {
        "start": 872.58,
        "text": "a demo which I'll go over in a minute in case you want to try it out before loading and your own data so the idea of attack UV is it's it's kind of as modular as possible again so you can fit it into an existing pipeline so you have you have great of your samples BAM file which is just kind of a file of a line reads as a standard file you see in genomic analyses you additionally need to know the organism from which it came just because there's a little bit of chromosome metadata that is related to that different organisms of different from naming schemes they needed to tell it which organism is from kind of a metadata for all of the common organisms it's built into the software but you can also provide metadata for your genome of interest and then there a couple of "
    },
    {
        "start": 935.16,
        "text": "optional files that you would generally want to provide so you would usually provide a file at the taxi Peaks so that you can collect statistics like the fraction of reads and Peaks on a concentration of reads and in those attacks see Peaks you could additionally provide a transcription start site file so that can calculate things like you can start site and Richmond technically those fuel those last two things are optional but yeah so you just run it through a tacky be attacking use a basic command line tool and at the output of that is a human readable text file but additionally you get a JSON file so that's kind of the machine readable component and then actually when if you have multiple JSON files because you've run it on multiple samples you pass it to another part of attack UV which is this little make our command and that "
    },
    {
        "start": 997.58,
        "text": "combines the JSON files from all of your samples and creates a single HTML you are though is to give you an idea of what that looks like this is the demo from our lab website so you get a report that looks like this you have your samples across the top the naming scheme in this case is I'm very pressing of course you would give your samples more informative names I'm sure so you see the fragment length distributions for each each sample again you and you'll see that their typical XD fragment length distribution so you can there's some scatter plots if you change the waxes in particular to look at different alignment alignment metrics you have this plot of so again I "
    },
    {
        "start": 1059.51,
        "text": "said you would expect the quality toxic library have good PSS and recommend an herb like this where if what this is doing is you're basically aggregating all of your data across the genome with the transcription start sites at position zero and it's looking at the signal out of near the TSS relative to the signal and a further away from the TSS and background regions so it's not plot there's a couple of additional pods which I won't go into detail on you also get a bunch of tables so you get information about the percentage of reads that pass filtering statistics you can sort on all of these tables so you can quickly see just what's the range of your metric information about the total number of reads you have various mapping "
    },
    {
        "start": 1120.53,
        "text": "statistics do something with your money duplication information a little bit of information on other reads that didn't map why didn't they map and a breakdown of basically what percentage of URIs were autosomal or mitochondrial and for each of those my other zone velour mitochondrial reads right down at what the duplication rate is because the duplication rate is often very different for the mitochondrial reads than it is for others onwards you get a little bit of information about your cleats balls as well so demo is available on our lab github in case you want to play around with it yourself to give you an idea of what it "
    },
    {
        "start": 1184.99,
        "text": "takes to run it we haven't done any really super benchmarking but when John was putting it together he did do some basic specs of resource use so he created one bit BAM file that was basically an aggregate of all of the data and the report I just showed you so for those of you who don't work a lot with BAM files this is a big one 1.1 billion alignments normally for a single library in our lab we might be looking at like 50 to 100 million alignments so this is a sizable file if you don't give it a file of Peaks that can run that in 20 minutes with only two gigs of memory the same file with Peaks but some additional statistics and does some additional computing so it takes a little bit longer 40 minutes in this case still uses only two gigabytes of memory so basically you can run this even on a very large file even on your laptop yeah it's also nice though as I "
    },
    {
        "start": 1249.55,
        "text": "said we do single nuclei data in our lab and so it's nice to have a tool that comes very quickly on all of that data so that's the tool I'm frequently asked by people who use it of what you see thresholds did I use and my advice is always well take a look at some of the public data that's out there take a look at the distribution of your your own QC statistics but basically it is hard to give really precise values we found for example TSS enrichment can change radically depending on the list of transcription start sites that you use um you also might expect different cell types will throw different energy gnome wide chromatin accessibility patterns so something like embryonic stem cells I just have more accessibility in general than a more differentiated stuff I'll type so I'd expect different you "
    },
    {
        "start": 1312.02,
        "text": "see metrics from those lines naturally simulate yeah just the purpose of the data should be taken into account so in general it's good to look at the distribution of all of your metrics and compare it to public data from similar cell lines there is so the encode consortium does about their own attack seek standards and so kind of creating a big public resource you know they have very very set standards for each of the genomes that they use so you can look there to get a general idea of what you might like but also kind of on a related note where we're pushing attack TV through review right now so we've got a man's manuscript before it it's under review as part of that review we actually did a survey of of the public data that we could find for human and "
    },
    {
        "start": 1372.22,
        "text": "this was back in December 2017 so it's a little bit out of date at this point but nevertheless it's got hundreds of libraries in there including some single celled data and stuff you want to know kind of compare your data to dissing public data this is a resource for that it's also if you're looking for a public data set to use are you interested in a paper that there's a taxi and you want to kind of look just an idea of what their data looks like in terms of the quality of it you can also have a look in it it will hopefully be helpful in that respect Oh so as part of that manuscript we wanted to do a couple of experiments look at things that we thought might bias tax seek results so I'm going to run through those pretty quickly now it's saying why "
    },
    {
        "start": 1437.2,
        "text": "each one of these is interesting in turn so the first thing that we looked at was the ratio of 10 5 to DNA so as I said with the tax seek you kind of isolate your nuclei and you expose the chromatin to 10 5 enzyme and one thing that we do in our lab is of course you always use the same amount of 10 5 enzyme but we additionally count nuclei when we did this experiment on that's not always done but but we felt it was important just because if you perform nuclear isolation on you know in kind of multiple times you're not always going to get the same efficiency and so even though if your performance in the taxi protocol you're using the same amount of tm5 the amount of DNA going into your experiment may vary and so you're kind of changing the ratio of your material to DNA or your material to the enzyme "
    },
    {
        "start": 1497.7,
        "text": "and to demonstrate that we asked the rotation student in the lab to perform a number of nuclear isolations and we kind of scored the efficiency of each this based on how many input cells do you have and then how many nuclei do you get out and so this is over 10 different nuclear isolations same cell line same day same reagents presumably basically everything the same but you nevertheless see you know and in one case for example you get a supposed 20% efficiency whereas in others you're getting like 55 percent efficiency so there's a two to threefold range in your efficiency which means that the number of nuclei if you're just counting cells and then you do your nuclear isolation and use that as input for your experiment the number of nuclei you have going into each one and very several and the several-fold and so we are wondering like how much does this matter how robust are ataxic results "
    },
    {
        "start": 1559.41,
        "text": "changing the ratio of enzyme to input material and so for that we set up this experiment this was done by a previous postdoc in the lab doechigi oh no some of you probably know him we we started with Jim went white seven eight cells and on the one dish or what flask or whatever it was I really hold on too much white seven eight cells in you perform nuclear isolation and you get you count out them three hundred and fifty thousand nuclei and then you split this 350,000 nuclei into seven pools and which with each one of those pools you perform a TAC seek with a different concentration of 10-5 so it's just again changing the ratio of a-- enzyme to DNA and so you're getting seven libraries out of each nuclear isolation and we did this six times so then you have a kind "
    },
    {
        "start": 1620.05,
        "text": "of 6 by 7 or 42 libraries we just wanted to see you know how does QC change if you do this and your downstream analyses important note here is for this one we held PCR cycles constant because we find that the number of PCR cycles that you would generally do under the protocol and very Co berries with the amount of T and v that you're putting in but we actually replicated the experiment and many of the findings in a second experiment where we did not hold PCR cycles constant but that is a caveat prism of them yeah so you end up saying actually the drastic results in some cases so this is an example of that on the left here I'm showing for one of the replicates the fragment length distribution under three different concentrations of tm5 so this black "
    },
    {
        "start": 1680.71,
        "text": "distribution is the fragment length distribution kind of under our normal two in five concentration if you reduce the amount tn5 you add in you the a shift towards longer fragments in the fragrant link distribution which intuitively makes sense because you know that enzyme cuts DNA and you're putting less of the enzyme and therefore you expect a lower density of cuts and longer fragments and indeed if you double the tn5 instead you get shorter fragments do you kind of see the shift in the fragment length distribution that you would naively expect to see you also see a shift in other metrics as well so this is for these same three libraries the TSS enrichment and so you can see that in this case if you reduce the amount of enzyme you have going in its twofold you you see a drop of a couple of points in your CSS enrichment if you double the amount of tn5 you see a move in the other direction you couldn't increase in kiss Elser "
    },
    {
        "start": 1742.18,
        "text": "enrichment and to show that I'm not cherry picking this this was like highly highly replicable this was highly replicable across all 42 of our libraries so there's all six replicas it's just plotting the TM five concentration against the median fragment length are you getting further pregnancy to increase fans I'm and we consistently saw an increase in PSS enrichment we increased the TN 5 as well the the relationships don't have aren't as clean if you allow the PCR cycles to vary so you kind of especially for a fragment length you see a similar trend but it's definitely dirtier another example of this this is just looking at the fraction of reads and Peaks they're kind of a quantification of signal-to-noise in some sense and you "
    },
    {
        "start": 1805.78,
        "text": "again see a very striking relationship with the amount enzyme and this is very very visually apparent as well so if any of you are familiar with the UCSC genome browser some screenshots from that this is just visualizing at two different genomic loci but it's the attack seek signal look like nonetheless pitchers a promoter you kind of see as you increase the amount of T and v moving up you clearly see that the signal becomes much stronger similarly on the right it's the same pattern on the further away from a gene though if you just quantify where in the genome reads our landing you're going to see some interesting patterns so because people who do a taxi are usually looking for these genomic regulatory elements these regions of "
    },
    {
        "start": 1866.38,
        "text": "open chromatin which and to signify enhancers or promoters that's the orange or the red line we wanted to know using increased concentration of reads in those regions and indeed as you increase the amount of the enzyme even five times over what we usually use you continue to see an increase of the concentration of reads and these regions and you get substantially fewer reads and these regions of the genome that's one isn't really interested in and then kind of one last interesting one that we found is you as you increase the amount of enzyme yada and you substantially change the mitochondrial content of the our sequencing reads so in this case we dropped from 60 percent at the kind of lowest concentration of the enzyme and you can get it down to 30 percent by like maxing out in under the enzyme that "
    },
    {
        "start": 1927.669,
        "text": "that you use yeah so caveat here is the first read I only say that those findings hold over the parameter space that we tested so presumably if you increase the amount of enzyme you're adding in enough you basically just obliterate everything in your your results get worse but in general in the range that we tested we saw that increasing the enzyme I really should suffer grow length distribution and you see kind of an increase and SS enrichment productions of reeds and Peaks fractions of reeds falling into enhancers and promoters and a decrease in mitochondrial contamination as well there a number of other QC metrics that correlate as well and so if you have any interest you can look at the manuscript and review and that comes out so the "
    },
    {
        "start": 1988.73,
        "text": "second thing the second kind of bias that we wanted to take a look at was also related to the fragment length distribution so so if you think that's different parts of the fragment length distribution are kind of enriched for different regions of the genome so you could say promoters for example tend to be over-represented and the very short fragments and enhancers or other type of genomic elements and to be relatively enriched in the wrong longer fragrance we were wondering if you kind of stub sample from the fragment length distribution how does that affect your results and so one way that this occurs in real life is actually related to the way in which DNA is sequence so when you perform on a modern Illumina sequencing you're taking your DNA fragments you add "
    },
    {
        "start": 2048.79,
        "text": "on your sequencing adapters and when they go into the Machine they're binding to this thing called a flow cell so the DNA of fix to the flow cell with one end and in the end when you do your sequencing you're actually not sequencing just that molecule you're sequencing a bunch of copies of that molecule late don't down here on the left and so as intermediate steps you know you add in your DNA at six to the flow cell then you do a bunch of PCR amplification basically within the sequencing machine in order to get these clusters representing a bunch of copies of the same molecule and the way that this is done is you have your your your molecules actually bind over it's called bridge amplification the molecules kind of make this bridge and then you have amplification and you get another copy and you just repeat this procedure again and again interestingly you know "
    },
    {
        "start": 2113.56,
        "text": "you end up with these clusters but throughout the amplification process clusters kind of compete with one another or real estate on the flow cell so like the blue and the green are kind of close to each other in this case and so you know if they're bending over but they're kind of trying to bend over to the same spot you end up with these clusters competing with one another for for amplification and that actually introduces a bias because for DNA fragments and to kind of bend over and make that connection easier if you have two clusters near each other then the whichever cluster has the shorter DNA fragment will tends to be preferentially amplified to the end result of that is that is that if you increase the kind of amount increase the concentration of DNA going into this interesting machine you get you know an increase in the number of clusters and you get more competition between clusters not results and in "
    },
    {
        "start": 2174.73,
        "text": "theory kind of a shorter fragrant length distribution we were looking to kind of test this in our data and and see is this effect actually in measurable in real life so we did a second experiment for this this was very much like the first experiment actually but the important point here is that we created 21 libraries and we sequence the same exact libraries White's onto different sequencing runs and on one sequencing run we kind of loaded loaded loaded the DNA kind of at a higher concentration do we got like 500 million of those little clusters in a second sequencing run we again there in those same exact you know DNA libraries but we only ended up with like 400 million of those clusters so you're kind of you're changing the density by about 25% we're wondering okay so what effect does "
    },
    {
        "start": 2237.67,
        "text": "this have on the data if any and you do actually see an effect so this is a plot of the median fragment length for each library each point there's one library and on the x-axis is showing the median fragment length of that library basically according to the sequencing reads from the low cluster density run and on the y-axis it's the same but from the high singing Lane cluster density run and so you see this shift basically off of the diagonal such that if you take the same library and you sequence it at a lower cluster density you see a shift in this case of like 10 ish base pairs and the median fragment length and this actually ends up affecting I mean basically what this means is they're kind of subsampling the fragment length distribution right you're you have a true fragment length distribution for "
    },
    {
        "start": 2298.569,
        "text": "your toxic library but when you sequence it at a higher a really high cluster density you're preferentially people in saying the left part of that distribution they're kind of being the library from a slightly different angle yeah and as a result T changes and other UC metrics as well so this is same as the previous plot except instead of showing median fragment length showing TSS enrichment and so you can see if you sequence at high cluster density for your selectively sequencing shorter fragments the same exact Brahe looks like it has IRP assessment checked out in some cases like two or more points in this case yeah so I think we're just right on timing let's have a preview of attack EBE including some of "
    },
    {
        "start": 2359.979,
        "text": "the stuff we did for the manuscript that's currently interview so hopefully some times in the next couple of months it will be available if you know in this particular interest I imagine it would be okay agreed and I've shared with you what we have now as well though whose by the work I'll in the left we do this usually kind of as we're submitting it unless we have a grant that we really want what I have a DUI for yeah but generally when we submit door shortly before or after we post on by our archive this is in review this has actually not yet been posted kind of because we've been busy with other things yeah so actually something "
    },
    {
        "start": 2432.319,
        "text": "pointed out by one of one of our reviewers here was like well how much much does it matter if you say an effect due to sequencing and cluster density guess everyone's just trying to maximize the number of reads they get anyway right which means you kind of load your DNA as high of a concentration as you can that you know allows you to just and it still get reasonable data out um so generally people aren't going to be thinking about it but still it's something that you should kind of be aware of and you do actually you can see this effect times in public data so you'll see the same library thing sequence across multiple flow cells so kind of having in the SSRI system there's different accessions or if you're running like the same library across different runs and you can begin sometime take this effect out let's nevertheless something that would be aware of I think comparisons of hearing "
    },
    {
        "start": 2502.309,
        "text": "lip distribution Cena to the thinking of Eileen Weiser thing so I know that we look at bioanalyzer before I know you generally if you have a bad bioanalyzer reading the results the attacks because those after sequencing are predictably bad we haven't done anything really systematic to try to like you know if you attempted to quantify the bioanalyzer pregnant length distribution and compare it to the final results out of sequencing we haven't really done that but anecdotally there's certainly some relationship between the two Thanks "
    }
]