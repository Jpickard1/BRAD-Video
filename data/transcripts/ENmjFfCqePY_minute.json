[
    {
        "start": 0.84,
        "text": "all right uh so thank you so much Marcy for the introduction um like like you said I'm hoj and today I'll be presenting my ongoing work on predicting neuromorphology from single cell gene expression using deep drer models um Matt and Crystal I know you're in lab and have my heard my lab meeting uh recently but this is actually different content so so good on you thanks for coming uh so I'm going to put everybody on a slightly I'm comfortable position I'm going to put people on the spot here before I I jump in so you know sorry to interrupt your eating uh can I ask how many people may have attended Josh's um dcmb Talk maybe a fair number yeah um can I ask like uh who Masters maybe Masters few Masters pre-candidate one pre candidate everybody else is candidate or above okay sounds "
    },
    {
        "start": 62.359,
        "text": "everybody yeah so um just like a little disclaimer if you have attended Josh's talk there is going to be a slight overlap but not too much I Tred to differentiate it as much as I could um it's particularly I'll I'll try to focus on the the tools and Technology portion so that you can uh use the of the techniques here have better understanding of the inner workings of the techniques and also U help you think about how you might want to apply to your own project um and I'm always welcome to to talk about like different different ideas and different ways to apply this um so feel free to come talk to me afterwards with your own ideas and um yeah so without further Ado I'm going to jump straight right into it so the goal of this project is to predict the shape and structure of neurons based on their gene expression so why might we want to do this well first neuromorphology um is a key component of neural circuitries that is responsible for information information processing in the brain uh predicting from gene expression is particularly interesting because now "
    },
    {
        "start": 123.799,
        "text": "we're kind of explicitly creating a a model to study the relationship between genes and morphology and this can be especially interesting in if you're studying disease models like Alzheimer's or Parkinson's we can now start to kind of investigate in silico the effect of of gene expression on morphology um and historically morphology has always been a key component in determining neuron cell type um and one of the goals go of the the brain initiative is to try to create a comprehensive compendium of all the cell types and um uh and it's not going to be just achieved by transomics alone it's going to be some combination transomics morphology electrophysiology Etc and I mentioned this in in L meeting but I like to give like a little historical fun fact um uh on my presentation so this uh picture on the right is the firstand like reconstruction uh is some drawings of neurons by Santiago Ramon EOL I hope I'm "
    },
    {
        "start": 184.4,
        "text": "pronouncing it somewhat correctly um uh so he he is definitely one of the first person to have done hand reconstructions of neurons now it's mostly done kind of digitally so you can kind of see the the the extreme kind of skill that went in here and actually this is a perfect week to present this because as you may know there's the Nobel prizes are being given out or awarded this week um and Cal along with uh Camila GGI won the Nobel Nobel Prize for physiology and Medicine back in 1906 for their work in um elucidating the the nervous system so yeah a very kind of broad overview of how we're going to achieve this is so we are going to use some deep generative models to predict uh condition on single gene expression to predict neur morphology so um there are several types of deep DED models including Gans vaes and diffusion in this talk I'm going to "
    },
    {
        "start": 245.599,
        "text": "mostly focus on Gans and vaes so this is where I'm going to diverge from Lab meeting a little bit uh and uh if you're curious about all these or any of these three U Josh's course Josh and GS course by matics 593 will soon delve into this topic and I'll mention that a little bit later uh in my talk um and this is a nice time to talk about the generative models just because there's a lot of public awareness and interest in it uh so you may have heard of examples like mid Journey or dolly or Chach uh I madean a joke if if you have not used Chach or have not heard of it like you should probably go there now instead of listening to this talk just I will not be offended so feel free to to tune out if that is the case uh but these these um these two particular deep Jour models are really good at taking like a text information like a photograph of an Astron riding a horse um and somehow using that that information to create an image that incorporates um the semantic "
    },
    {
        "start": 307.96,
        "text": "meaning of the words into image so in our in my project instead of thinking text to image um you can kind of think of the problem as how can we utilize information in the Gene and create morphology based on that so that that's um kind of a simple analogy to think about uh what we're trying to do here here's a brief list of what we're going to be talking about um I'll just give you straight up the the overview of uh the model that we uh developed for Gene to morphology prediction called morphet uh I'll talk a little bit about the patch data set which we use to train the model um I'll talk on both the singles R portion and also the morphology portion I'll spend quite a bit of time on maybe not quite but at least a little bit of time on Gans and also sty Gans which is what more fit is it's primarily based on uh some results and summary and also feel free to stop stop me at any point as well so here is the Ora "
    },
    {
        "start": 370.639,
        "text": "mornet we so this this model combines actually two generative models uh one vae and one Gan and I'll go into each of them more deeply to to take uh gene expression information and um and predict uh morphology so the vae which is on the the red box is uh so their purposes are a little bit different the VA is used to obtain meaningful lat and Vector representation and I'll explain what that is in a few slides uh the generative aell Network which is on in the the green box here is used to transform or to generate the image um usually there's a starting image of noise um and then it will um take that noise and also the gene expression uh to generate morphological images Okay so so um much more detail of of both of these components will will come soon as far as the data set um I used a really unique kind of data called patch she which is a tri modal um data "
    },
    {
        "start": 434.0,
        "text": "that combines patch clap recordings which uh I don't actually use in this project but U that's where the patch patch SE comes from uh also the single sequencing and neuron tracing SL reconstruction all from the same cell so uh this gives us the paired gene expression and morphology data so compared to I guess other data set there is a ground truth morphology here uh from the same cell there so there's a uh gene expression and the the ground truth corresponding morphology uh this is a very very brief schematic of what Pat is collecting so either starting from uh slice of the brain or neural culture you can do some staining to um to to get like a morphological reconstruction uh you can also poke in some probes into the cells it's very hard I haven't done it myself but ha is very hard uh to get um uh like recordings like action potentials not "
    },
    {
        "start": 494.08,
        "text": "exactly but something so much to that um and afterwards you can suck off the nucleus from each of the cell to to do the um single cell sequencing so as you can imagine this is quite hard to do uh and so compared to other kind of single cell meth this is quite low throughput so it's um I am using like two of the large largest publicly available patch data sets that combined together have like just over 1,000 cells um and I'm just mentioning this um because you know it become it's one of the considerations when you're developing um because I guess any kind of deep learning models just in general they require a lot of training data so we do need to think a little bit about how we're going to deal with this um limited training data and if anybody's interested in this kind of morphology data set um neurom Morpho is an excellent repository um that started in 2006 and I think it has just about quarter million quarter million morphologies but but not "
    },
    {
        "start": 554.6,
        "text": "all the morphologies will have uh single cell components so this is more um morphology focused uh uh data repository site so I am going to also assume that many people here are probably familiar with single seek data or what it looks like at least um I know that's not usually the case in other audiences but in general you know like we're starting out with this you know cell by Gene Matrix or Gene by cell depending on who you are um in my in my world s by Jan where the the individual elements are non- negative integers so there these are count datas uh I'm going to say that these are you know quote unquote High dimensional U uh especially if you're collecting data from the whole transcripton they can be you know maybe if you open one of these files it can have like maybe up to 30,000 genes or so um what we did in this project is that we we fed this through a variation all encoder that I'll go into detail uh "
    },
    {
        "start": 617.04,
        "text": "to get a Cell by Gene latent representation so compared to the original data this is much more lower dimensional uh in fact we set it to 10 so instead of 30,000 we're we're kind of compressing all the information um into a 10 dimensional Vector using a variation Auto encoder called um sdvi so um the the VA portion we're building off of this work called single cell varal inference the paper has been published already in nature methods I think the author is now also professor in BIOS maybe or in set I forget exactly um but he's also here if you want to actually talk to him is what I know um so sdpi which stands for single cell variational inference um let's see how to explain this um so ve it's a little bit confusing because VA itself actually is made up of two different neural networks one called encoder and one called the "
    },
    {
        "start": 678.12,
        "text": "decoder so the encoder portion um what this does is it takes a high dimensional and and make uh and learns a low dimensional Vector U now and then the decoder is taking low dimensional vector and trying to reconstruct original data so um I I've taken this really big and kind of information dense figure um I I tried to kind of segment it out to the the relevant part so in the in their encoder basically they have you know two really important neural networks uh that will learn the mean and the standard deviation of a multivariate gan I've written that out here kind of um and then what the decoder does does is that it actually it assumes that the gene expression data is coming from uh this so-called zero inflated negative binomial or zinb distribution so it uses information from the multivariate um from the the compressed data so you can see like this this data "
    },
    {
        "start": 739.12,
        "text": "is actually used in this uh parameter for like expect frequency and expected Dropout that that's kind of so this this is their model of where the the gene expression is Created from to to actually reconstruct original data um and as you can imagine um you can train this model by you know comparing the original with the reconstructed obviously the goal is to have the match um and through this process of trying to match that it's going to try to learn a latent representation that's that's um that's compact so that so that the decoder can uh reconstruct properly U so that that's kind of a Chell of what what's happening here um in the end once the VA is trained uh we only use it encoder part to get the latent Vector representation um unless you are interested in some other you know depending on the application you can use your decoder or not in my case um I just want to train the vae and use the encoder to get a lower dimensional representation so that I can feed that into again uh the neur morphology data set "
    },
    {
        "start": 801.36,
        "text": "probably not many are familiar or less familiar so these are actually um the data is not actually given in images themselves they're already digitally reconstructed by the data producing lab um and they actually come in this tabular format called s swc files which contain uh seven is it seven 1 two 3 four five yeah seven columns ID type XYZ radius parent so each row is representing like a point in space or node um the type is indicating whether that that point is part of of the Soma or the axon or dendr right so it's only a few values in there um and you can use your favorite you know pandas or r r tools to you know read this data data frame uh uh to create you know and plot them to get like a 3D view or in my case in this project I focus actually on the 2D view something like this so if you were to look at it from the up down "
    },
    {
        "start": 865.36,
        "text": "you'll get this kind of like flattened image um and um uh so the goal of of morphet was to try to predict the 2D images of neur morphologies and I just want to also say that this is like one way to think about neuromorphology there's I'm thinking of it of like the neuron structure as like a set of 2D images that you can know possibly combine together to make a 3D structure but uh there are many actually there are many other ways to approaches that can change the underlying technique a lot so you can think about neurons as like a a bag of branches that you put together or you can think about them as graphs um a particular like a tree graph or yeah and depending on kind of how you represent your neuron uh kind of as a mathematical object you kind of change underlying um method anyway but but for the purposes of morphet we obviously chose the image representation because Gans have been so successful in generating high quality uh "
    },
    {
        "start": 925.839,
        "text": "and High Fidelity realistic images okay any questions so far don't give yes yeah so the question was how do we transform to a 2D image I literally ploted this on M plot live and then saved it as an image without the axis so without the the bounding you know like the you know if your plot in M plot live you get the xaxis yis um so you can just turn those off um and and you want and so all the kind of coordinate positions are kind of lost in that sense and we're just thinking of neurons this 2D as just like a pure pixel representation so like if if you were thinking about this as like a like a square image you know there will be a lot of white pixels like 255 255 255 and there will be some pixels that represent red black for Soma Etc just um so the "
    },
    {
        "start": 986.0,
        "text": "the model doesn't have any idea but but the the the points or um uh the connectivity information all right I'm going to move on for now so uh background on on generative models um broadly speaking kind of regardless of the generative model that you're talking about whether it's scans or vas or or diffusions or um normalizing flows uh their broad goal is to learn the underlying data distribution of the real real samples so they generally categorize or one way to categorize them is is whether they learn an explicit density model or an implicit density model um an example of explicit density model is like vaes or probably the PCA but who who is taking Josh's class right now if any okay yeah yeah yeah I think he has "
    },
    {
        "start": 1046.48,
        "text": "maybe just gone over or like just probably PCA lecture recently uh and so the goals of these models is to learn this um blue probability distribution and you can imagine if you have this distribution you can sample from the distribution to create new samples uh one very one dominant example of an impl sensity one is Gans so Gans doesn't actually learn a prob distribution model but it will learn to generate or learn samples that kind of that that if you were to draw the prob distribution for the data points and alth also the model samples that you know if you were to draw the curves and they will actually match um but it will actually not lure the curve itself okay um so getting into Gant a little bit more uh like the vae this also consists of two models inside uh one called the generator one called theator um they have they all have different names very "
    },
    {
        "start": 1107.0,
        "text": "confusing um and and so a little bit historical perspective as well so this was published back in 2014 kind of the early days of like the new kind of Spring hot summer of AI I don't know out of the AI winter um so if you remember or um I think we have just recently gain like a new interest in AI after Alex Ned did very very well in the ad missionary classification back in 2012 uh and it's not that and the the authors here um were interested in how we can generate good good images not just classify them but this generation process has always been quite hard so the inspiration was how can we kind of utilize this success and kind of powerful discriminator models like classifiers so that you know how can we use this kind of as like a teacher to teach good gener uh to to teach good generator networks uh so that's that's partially "
    },
    {
        "start": 1168.44,
        "text": "the inspiration if you look at the original paper I think it actually said like how can we utilize the success of Alex net to you know like create good generator networks um again in a nutshell um these two networks are going to play this uh mini Maps game uh where they're they're competing with each other one the generator is going to try to generate realistic looking data the discriminator is going to try to um it's going to do a binary classification whether for a given image whether this image is really so it's not a complicated classification it's not like classifying an image as like dog cat and thousand other classes um it's just you know real or fake um and actually the information from the discriminator so whether it's real or fake is actually going to U Back propagate to to motivate the generator to do better and actually this uh competition is actually going to make both of them better at their jobs the generator is going to get better at generating images the the is going to get better at telling the "
    },
    {
        "start": 1230.6,
        "text": "difference pictorially what's happening uh is I'm going try to explain this clearly clearly as I can uh let's see so these black dots represent the distribution of the real data so that's the real data that we want to mimic at the end uh the the green is a distribution of the fake and the blue is the just a decision boundary of the generator this is for a simple wanty example so you know first thing that's going to happen the generator is going to sample from this zspace so let's say this is some noise um it seems like it's sampling kind of uniformly you know generator like any other deeping models is just a function like it's just going to transform one input to another right so it's going to transform the Z into this xace let's say images or morphology or whatever so you can see that it's kind of concentrating uh the outputs here which makes this you know Green distribution uh so once the generator um creates that we can now take the "
    },
    {
        "start": 1291.279,
        "text": "discriminator to train which whether it's a um whether a given image is real or fake so uh in the beginning it it doesn't do very well say all the squ lines but in the once you train the disc you'll see that oh like points coming from this end on the left is is most likely real points coming from this end is most likely uh fake and you can see there's a like a little slope here so this gradient um in multi-dimensional term is going to you can almost think of as an invisible force trying to pull the the the green curve over to the left I don't know if you can kind of I can feel it from the picture but think about like there's information here there's a gradient here and it's going to push the the green towards the black black dotted lines so you can see once that updates you know the green has come a little bit closer and we're going to read this process um until eventually the the green very closely matches with the black which is the original goal that we wanted we wanted the generator aka the "
    },
    {
        "start": 1352.88,
        "text": "green line to match as closely with the black the real distribution okay so that's pictorially uh this is well mathematically um trained using so Gans are trained using so-called adversarial loss um this one I feel like it looks kind of scary in the beginning but actually it's very very very very simple um so this left term here is lock probability that the discriminator correctly predicts the real data as real uh if you drill it down a little further you can see X is being sampled from the real distribution P ofx that's a real distribution so and that's going to go into discriminator the discriminator is going to say it's going to give some probability of whether it's real or not so it's going to give some value between 0 to one um this value is maximized so log of one is zero right and the log of zero is minus infinity so if the discriminator wants to maximize this value it will want to try to classify this as real right uh on the flip side this is the log prob that "
    },
    {
        "start": 1413.4,
        "text": "that the discriminat correctly predicts generated data as generated again the same process if we sample some noise from pz so let's say pz is some uniform or gaussian doesn't matter it's going to the generator is going to take that noise and generate fake data that's G ofz uh the discriminate is going to see that and again it's going to Output some value between 0 to one um again if the discriminator wants to Maxim imize it then you want this this value to be close to zero right because log of one is zero again if this value is close to one then it's going to be log close to zero which is very negative Infinity um and the E here is we going to average this that's that's a simple way to think about it so you can already kind of there's competing interest here between the the generator and discriminator that's a main takeaway so disor goal is to maximize the prediction accuracy the the generator's goal is to try to fool the the discriminator because it has the opposite goal here it wants to make this as negative as "
    },
    {
        "start": 1473.919,
        "text": "possible and um you can actually solve this optimization problem uh not shown here a 10 biomatics 593 um but you know after after the math shenanigan the the optimal value is when the generated distribution PG of X matches the real distribution PR ofx um you know once this holds you know obviously the the the Optimum value for discriminator is that's perfectly confused it will just be unsure whether it's real or fake um and the the loss the value of the loss which is actually not important um but if you're interested the value of the loss will come out to be negative2 L too anyway um skipping a lot of details here about derivation but we're going to move on to to bigger and better things okay so the original again like I mentioned I actually took the screenshot now like it's been three years ago so maybe like 20189 uh so it's going only from 2014 to 2018 a lot of things have happened since "
    },
    {
        "start": 1535.799,
        "text": "then as well but this is just to give like a little context so the original again was um only 32 by 32 and since then we have gotten higher resolution and higher quality uh this is obviously not to scale 1024 x 1024 is much larger than 32x 32 um and you probably um I always like give an example of like this website called like this person design ex this which if you go there and refresh every time you refresh it will give you like a picture of realistic looking images but not real um so feel free to to play around with that if you're interested it's really cool um again in in class will I do go over like all the intermediate ones before I get to styan but for the interest of this talk I'm going to just jump right into styan so uh the major Innovation for this paper um was this humongous uh generate generator design so it's not just your I guess um convolutional layers "
    },
    {
        "start": 1598.32,
        "text": "stack on top of each other uh so they actually separated at the generator to this two networks underneath called one called the mapping lay mapping Network which is all this uh FC fully connected layers um stacked here uh and then um the synthesis Network which is responsible for taking the noise image uh and generating the image so so since the synthesis is kind of like your traditional generator that we have talked about before um uh yeah and the mapping Network I guess is is more the novel part um so the and also like another Innovation was that instead of just taking your initial like Lattin or gene expression in our case and and going through um a series of of of convolutional network convolutional layers San actually tried to introduce the latence at every single layer of the senses Network so you're kind of putting information across every single layer of "
    },
    {
        "start": 1660.96,
        "text": "um the gener generator yeah um so that's kind of a expansion architectural kind of expansion of what happened and mentioned about training Gans with limited data I think in general you probably want on the order of 10 through five or 10 through six like up to a million images to train well at least for natural images like faces um it's I guess it's a little bit unknown for non-natural images but um that's simply what's cited on on literature I would see is is what I would see um but so the same authors who develop San one tackle this problem of how we can generate good images maybe not uh the best quality but good images with limited data and you know one of the things that we do when we uh when we have a a classifier that is overfitted is to use data augmentation I me there's many other methods to to prevent overfitting but "
    },
    {
        "start": 1722.279,
        "text": "you know one one thing is the augmentation um a little bit tricky part with generative models is that you don't want to have the generator creating augmented images like for example I have some like pictures of um a painting that is let's say you do some kind of color color augmentation and you generate some blue faces but you don't want the gener generator to make blue faces unless that's your application for some reason um we we still want to generate like normal things uh so you know brilliant idea we're just going to augment the discriminator only and not tou a generator uh it's a little bit more complicated than that but but that that is essentially um we're going to leave the generator alone and only augment the descript minator and in uh this method is called adaptive discriminator augmentation um and intuitively what is happening is uh with limited data the discriminator gets too good too quickly so it becomes too good at discriminating whether it's real or "
    },
    {
        "start": 1783.159,
        "text": "fake it saturates its performance really quickly and once that happens you no longer have that information to propagate back to the generator so it's kind of saying like you're fake with like uh without any kind of um it's kind of like a teacher who says like you're doing good or you're doing bad without any other kind of feedback and if it consist in saying that you're doing bad even though the generator is improving then the generator kind of in some sense it gives up and doesn't generate any good information so you want to kind of balance the performance of the generator discriminator uh when training Gans that's one of the more difficult part of training Gans as well um and and doing this augmentation helps with slowing down the discriminator so that the generator has the time to catch up and um make better images and and this has been shown to uh generate pretty good images as low as um uh 1,000 which is perfect for our case did you have a question do I think I saw hand but maybe not okay yes you said that you need like roughly a million images to get a good G "
    },
    {
        "start": 1843.76,
        "text": "yeah What proportion of those images can be augmented it's not a good model What proportion can be augmented so if you have just one one 1 million generated images I think you typically people form like horizontal flips or like some kind of rotation or cropping uh but nothing like crazy has to change the color pixel or whatever because um again you don't want a differently colored images generated uh if you have as low like if you have only 1,000 images like this then that data augmentation is applied to all images but not at every step um so the adapted portion actually that's a great question the adap portion means that we're going to apply the augmentation whether it's color or whatever at a certain percentage of that time so in the beginning um I forget what it work um so for example if we set uh P equals the the "
    },
    {
        "start": 1904.519,
        "text": "probability of applying the augmentation itself as you know 0.1 then 0.1% of the time we will augment it and then other times we will not and this probability will actually change while training hence adaptive um so I think it's actually we want to do low augmentation in the beginning uh when the discriminator is still not good in the beginning discriminator needs to train so we don't need high probability to um augment but at towards the end of the training when the discriminator is getting too good we want to make the task harder for a discriminator so we will augment more so we will increase the P up to you know P equals 0.9 something like that um yeah and the augmentation is kind of done automatically I guess um they have fig out how right to do this yes how is it like um like how would this perform you know cont because that 10 to the thir 10 to the third images with like you know at the end of the day 90% being a is crazy like how how like what if you just "
    },
    {
        "start": 1967.039,
        "text": "like had an analing turn in front of the discriminator even the loss and you just kind of like you know made it not so hard begin that sort of do the same thing yeah so there's um so I guess with the adversarial loss there's like um like yeah the mathematically so what it's doing is like it's minimizing the kale or gens and Shannon Divergence between the um and one of the properties of the gens and Shannon Divergence that unless it's matching it's all harsh um like you said and putting a nailing term works but there's also other kinds of losses like in the elro I'll talk about was seene distance and that one um instead of being like all or none if it's like a little bit off then the loss will be actually be lower than being if it's far off then the loss will be higher so it will actually scale by how good it will actually give a grade instead of grade of ABCD you know F why is he skin ABCD F instead of like 100% "
    },
    {
        "start": 2029.32,
        "text": "or 0% kind of yeah so um yeah there are ways to I think even then I think you I think the the Washington G actually one of the earlier ones back in like 2016 or so um so these are I guess addition even more techniques on top of that yes yes for the um augmentations oftentimes you want to pick in variance of your data yeah did you look at at different projections of your 3D as a augmentation that would have been better yeah I mean um uh I I didn't necessarily um let's see so one of the reason why I stuck with this projection is was that you could see more information about the neuron um depending on which an XY X XC or YC you look at like if you look at y "
    },
    {
        "start": 2091.159,
        "text": "it just looks like a clump of strings in some sense and not at least in my eyes which is not a neuroscientist I is not super informative and and the XY so um is the informative axis in the sense that um people um I know in your I think there's a way that you can kind of use a a 2d view to try to classify self TI but something like they have a a density plot they make a density plot of the axon branches and that's one of the ways to classify like a calculate some of the morphological properties so that's one of the reasons why I chose that but yes I could have technically also increased the the train data set by by three but by by have by considering all three projections XY YZ XC I think the reason why I didn't use that was um I still wanted the generator to produce only the XY only and if I increase um I guess in the end like the generator needs to I want the generator to produce one image and "
    },
    {
        "start": 2152.319,
        "text": "um I didn't know how to control for how it can generate how it will choose one of the three projections I guess that makes sense yeah but yeah all right I will move on for now so I guess we definitely talk more these are all excellent questions that I haven't thought of um okay so kind moving on from the nitty-gritty style yet I also want to focus on kind know what has been the goal of these generative AI folks in some sense from before diffusion and trach it's like it's not just about trying to generate realistic looking images but how we can make how we can do do creative work in some sense so um the the literature on Gan is not just about oh we're making the the most realistic image ever uh there's actually a lot more uh research on how we can control the generation process so that we can make whatever we want to um "
    },
    {
        "start": 2214.119,
        "text": "instead of just what already exists out there in Google Images and whatnot so um you know I'm going to show you like three examples this is one of them you know this is trying to mix socalled styles for two different images so let's say I have this real image like Source a here and also some real images Source B here this with faces let's say if I um you input The Source a and add in the style information from Source B early on uh then after the generator will generate something like Source a in terms of let's say you know lighting or background but you can see that the gender has changed and the person has glasses so now like you know so you can think of cases like oh like I have these like two images that have components of things that I want and I want something in between or something novel out of them then you can you know one way is to like mix two different styles um so you can see you can change let's see gender uh post see it's this like this woman is "
    },
    {
        "start": 2277.24,
        "text": "facing towards whatever this woman is facing and also like put you know facial facial hair uh you can see if you add in the style kind of later on in the c network it doesn't affect the original image as much so you can all all the images here have the same post like all the all the uh people here are looking face forward um but you can see like it takes some other like Inspirations from SCE B so this one this one always kind of makes me a little bit laugh because it's it's a little bit bizarre uh to me but um and and so like so you have you can choose like a different sources and you can kind of decide when you want to mix these information to kind of get different outputs uh in this example it's like a fine fine grain taining right so you have an image of a woman you know maybe you're maybe you created this in Photoshop and you're you're happy with this but you want to change just like her her hair color or something then maybe you can take another image with the right hair color and apply that here so so I mean these "
    },
    {
        "start": 2337.56,
        "text": "are all kind of cool examples from computer vision um but again I want to emphasize like you know our latent is a gene expression and now we can think about okay can I take components of one gene expression and another and mix them and like what what what kind of neuromorphology will that come out like so I guess um trying to like apply to to whatever your problem is um I know this is like very fun to look at but yeah some other examples um that people have have tried is um is trying to create intermediate images so in this particular one um the authors found some images of of faces kind of looking on One Direction um and faces looking in another Direction and maybe you want this pH to look sort of towards the center U then you can try to like uh take the latent for these and then find the average you feel like um the weighted average and generate the corresponding image you can get some interview images at Le not all of them "
    },
    {
        "start": 2399.44,
        "text": "are perfect you know but um you know this one has like a part of the pce missing you know it it uh but I would also prefess that this was back in 2015 and we can do much better than this another Super very uh very fun example and I will have examples for this in the results section as well I'm not just showing this just because it's uh another example is for example is um you have some take some images man with glasses a certain property so that you uh so all the images of man with glasses um you will know the corresponding like latent vectors uh you find the latent vectors of Man Without Glasses you can do the vector subtraction um like you learned in linear algebra you know add in women without glasses and if you take that vector and generate the corresponding images you'll get woman with glasses so all the women with glasses are generated images but um plausible right so yeah and um I'll will show you examples of how we utilize this technique um in the results right um for the sake of time I "
    },
    {
        "start": 2460.64,
        "text": "will skip this real quick of classes I think I'll be getting ganss and diffusion yeah soon so um I think the class is in Dental School uh you can ask ywan who is a GSI on where it is but yeah okay so jumping into the morphet um I think I've shown this slide before so Moret uses V and ganss to under relationship uh what trained we dro the decoder and we dro the discriminator and just use encoder to get the meaningful latent representation of the gene expression and then we feed that into the generator to get more posable information um yeah obligatory you know this works well slide um so here more uh so we train Moran on the patake data set as I mentioned before uh they seem to retain cell type one they generate uh pretty realistic looking neuron images and they also retain cell typ morphological properties um by that I mean if you take the generated images "
    },
    {
        "start": 2521.0,
        "text": "and try to classify them by cell type um then uh the classifier can reliably um pretty reliably uh classify them to the right right cell type so uh that wouldn't be possible if the morphology um didn't retain any of the cell type kind of information uh when we tested it on the you know validation set you know with the um adapted discriminator augmentation technique uh thankfully we didn't have any like um not not any but uh we we were able to Simply reduce overfitting so the um generated images on the validation set still look pretty realistic but not um memor but not memorized so you can see like in the L five case you know this neuron looks quite different from what is the ground truth but you can look look at this and say like oh but this does still look like a five neuron like this does still look like a VIP even if not if it's not exact um so with that we have you know "
    },
    {
        "start": 2583.88,
        "text": "applied morphet to try to predict morphologies for other parts of uh of the brain region so um with a single cell data set we can actually like I can combine Patek and some the Single Cell AR from patch and other single cell data sets which doesn't have morphological information um and then predict from those uni modal data sets so again they don't have ground truth so these the middle column here are showing the predicted images uh they don't have ground truth because obviously this was just single cell on a data um on the right I just provided like examples of what these cell types look like and again um although it's not possible to know like oh this cell like I'm saying that we we think that this cell would might look like this if we were you know if um but obviously we don't have like a like nobody has done an experiment to to go and see um well we we can kind of say is so like okay it is still generating something like that looks like other cells of this cell type so that that's "
    },
    {
        "start": 2645.88,
        "text": "what this two two different columns are showing here here's one image of the kind of application or like the use cases of um this this is kind of an example of the the face faces turning from left to right I did the same thing except I I took a lamp five cell and then um kind of Step through some of the intermediate Gene Expressions to get all the way to VIP VIP type cell um this might be easier to understand so like in the beginning this is the classification probabilities of so in the beginning in Step One the classifier really thought that this was lamp five there's a high probability there um and obviously at the end the classifier thought that this was VIP as you progress through uh the lamp Fess goes down and the the VIP if if if goes up there there's an interesting thing where like in the middle the classifier is like not sure if this is p valve or VIP um this is natural like this is not something that you would see in a "
    },
    {
        "start": 2706.92,
        "text": "biological experiment unless you're trying to like really capture the transitioning cells uh so these are just showing like plausible morphologies you know um um that that may exist in in very like transitory States uh same uh kind of application uh here we have taken differentially expressed change from all from lamp five set that remove all of them so set set all the gene count to zero um and added more uh different values for the differential Express genes for VIP um and if we take that and generate the corresponding um neuron that the end so this is a the real example of lamb five if we just manipulate the genes and and ask it to produce a a VIP then it looks something again not perfect but it does look like a bipolar neuron which is kind of characteristic of of VIP neurons again um this is not perfect because there's probably no cell that has like zero expression of all the lamb five genes that's probably not super real in "
    },
    {
        "start": 2768.68,
        "text": "some sense but you can kind of see the um kind of the manipulation that we can do uh in gene expression to uh and see its effect on mology using more met okay we are almost at the end here um so that was kind of the 2D project yes we are working on 3D uh it is a uh and um we are actually using diffusion networks for this and and hence um I might try to give another Tools in Tech maybe maybe in a year or so um but here's some like preliminary results I I know it looks quite similar to the 2D but uh these are actually all 3D points just for visualization purposes I'm just only showing a 2d portion yes there's a question in chat yeah thank you uh is there a possibility to generate the tree graphs of the morphologies instead of 2G images with the Le yes I'm working on it right now yeah you should if you're interested please talk to me I guess who is this is "
    },
    {
        "start": 2831.559,
        "text": "it I'm sorry to put put you on the sad name RI okay all right uh please select me my my you ID is Ho Lee all right um and uh so I'm going to leave that for a future talk here and then yeah so the key takeaways um morphology is key determin of circuits and self identity uh we we develop morphet to predict s morphology from gene expression they seem to be doing pretty well if I may say so in terms of FID let's let's put it that way um FID and just qualitative inspection uh we can we have also played around with trying to manipulate gene expression to generate novel morphologies or kind of see what the effect of manipulating gene expression would be and yeah um Mr or Mrs Ry or Dr Dr Ry I am working on extending worknet "
    },
    {
        "start": 2894.24,
        "text": "to generate pre graphs or 3D theologies not just images all right yeah happy to take any questions or talk afterwards I think sorry um oh yeah so do you have a available for this um yes I will send that link to Marcy after updating it I I already know that there's like some issues I need to get to on GitHub um it's just I haven't op of them so I want to get to the issues first P yeah um you I I'm not super familiar with Style again I guess but like how important is it to do if you go back to the to the Moret um to the morphet model um computation graph yeah like right there how um like if you were just to encode some "
    },
    {
        "start": 2956.04,
        "text": "gene expression and then you were just to like sample of the M Sigma that you get there and just feed that directly into the gener as the noise like how important is it to have the to have that noise Source there in addition to you know the sample the sample un Sigma from the encoder okay actually um turns out pretty important because actually the middle portion here is generated with direct from just trying to transform the noise into like an image um I think there's a little bit of a you know if you you think about the the gene expression Vector it's we're only taking a 10 dimensional vector and we're trying to create this humongous image of 52 x 5 Follow by three um I don't think there's like enough um information there to just transform directly from gene expression to image and another key reason is that um gene "
    },
    {
        "start": 3017.839,
        "text": "expression is not the entire determinant of mology there's other influences so having the noise actually gives us stochasticity so actually I could have generated multiple variations of morphologies from a single gene expression I'm just showing one example from one gene expression um in the paper and and um that's a good point like it it gives the impression that like okay this is a morphology for that gene expression but that's that's not really the case in in biology right like there could be some flexibility there there the Gen expression only puts a constraint and the noise actually gives that flexibility to generate um um different variations yeah and that that would be actually a really interesting thing to study like how much kind of within cell variation can can that how much can it exist within a given like gene expression yeah yeah I mean well yeah I mean like you could MLP the the sample from the whatever you want it I mean also I was just wondering like what so when you "
    },
    {
        "start": 3078.44,
        "text": "do your interpolation where are the what lat vectors are being interp are you just doing that are you interpolating between some sort of like conditioned Gan noises or between the like how do you get the C yeah yeah so um each cell will have the Lum representation 10 dimensional right so um and I'm interpolating in that 10 dimensional space so I have a uh lat V 10 dimensional latent Vector for a lamp five cell I have a latent Vector for a VIP and then literally taking a linear interpolation in that and then you're using that DET G yeah yeah and then they're using that to to feed the again to generate the corresponding apology yeah yeah yes images that you're generating are just gorgeous they're really really cool it's fun to look at them all day but I'm curious of um how people typically quantify these images and whether or not the generated images have similar quantification distributions as the real Quantified uh "
    },
    {
        "start": 3141.4,
        "text": "images yeah that's that's exactly what my reviewers have said so um that's why that's also partially why we're U kind of moving on to the 3D model where um the the 2D so I think the only kind of traditional morphometric that you can calculate is maybe sh profile which is uh you start from the Soma and draw some circles around it and and see how many branches are intersecting and that kind of gives you the uh if you draw that profile it gives you kind of the comp complexity of the neuron um based on distance to the Soma but there there's other many other morphometrics like a branch length or um oh my goodness like a tapering ratio there's literally you know like almost hundreds of them and they're not really a minimal for calculation from 2D images which was one of the kind of things I were flag for um so so yeah which is why we're going to the model as well yeah so for the SCH "
    },
    {
        "start": 3202.48,
        "text": "yeah uh how close are your generated ones to have not computed that so I I will let you know yeah what of the um yeah I I've have not explicitly calculated that for for the most part I've only kind of Quantified how good they were based on the FID metric only and not the I guess in some sense biological metrics and I guess if the cell type is determined from these quantifications yes why not just predict those directly um it's um that's an excellent question so the cell type that was given by Patek I think was from gene expression not morphology so I think they have gotten the Single Cell a sa cluster then you know label the cluster and that's where they have gotten the and that's partially the reason why we I don't get perfect classification accuracy when I classify the generated neurons um I don't think that's a satisfactory "
    },
    {
        "start": 3262.92,
        "text": "answer but holistically I'm thinking that like cell type cannot just be from morphology or transomics alone need to be some kind of combination of the two I don't know how yet does that I don't does that help I guess at least or we can talk more yeah Crystal I don't know um you have covered this but maybe I over this so um you did a very nice work in which that you make yourself gen information to generate this mological data um but thing although like gene expression doesn't always equal to mological information but I'm sure there are some like a share in that's how you manage to transer expression information through morphology I wonder whether you also try to see whether you can use morphological images that you generate to reverse generate this gion that will the original "
    },
    {
        "start": 3324.0,
        "text": "dision I think this is a common question I I haven't done that for my like for these images but I know there's even like a recent paper that came out like a three days ago that there's several papers that deals with for example trying to go from histological images to gene expression something like that um I [Music] haven't this Pap um generate certain learning output from one modality they could also using the to reverse original input so I wonder so I mean we'll have to probably have another if I were to do that like right now um I would probably have another Network that goes from images to to to jeans maybe I'll you know copy and paste again and then just flip the order "
    },
    {
        "start": 3386.44,
        "text": "maybe I'll start from that um what what you mentioned actually there's a um think she has done this work on like um invertible neural networks like I think Josh has mentioned this very briefly c i NN is I don't know what the C stands for maybe conditional conditional invertible neural networks where they had invertible ones and tried to match the latents together after inverting so that was one of the training methods so that you know you have one thing to encode and another thing to kind of like having two baes and trying to have the two legs match each other yeah sorry I could keep yeah thank you foration my question is a really good question of yours about the noise yeah said that this introducing noise will help us account for other reasons other factors that uh affect the mor of herself so is there any way to kind "
    },
    {
        "start": 3449.319,
        "text": "of control like for example like in style G again maybe normalization uh to kind of control this noise and understand other reasons as well other factors what affects uh the morphology yeah so that that's actually really really that's actually a really deep question that we talk about like an hour um yeah so I I have not I included this slide and then took it out but I have looked at what morphet is learning in some sense like what are the the weights and then how changing that weights affect morphology as well U and that's kind of closely associated with the noise as well um in in general um when you ch change let's say you know let's say noise is like a 10 dimensional Vector as well you know just random uh there's a "
    },
    {
        "start": 3513.319,
        "text": "whole slew of research on if we change one dimension can we change one aspect that we want to control and this is called disentanglement and but vaes usually do better on this so Josh will give a talk uh his lecture there's lecture on disentanglement basically uh for for example for the faces I'll just make the analogy um let's say the these are all coming from 10 dimensional Vector can we change the First Dimension let's say from 0 to 50 and then change the age of that person you know from young to old um and most of the time um vaes or Gans they change multiple aspects so if you change one dimension it will change the gender it will change the age it will change the hair color like all at the same time um and so these properties are entangled together uh but there are ways to make it so that the properties are separate out that and that way we can also kind of control like can just change one aspect of the noise so that I make neurons that are bigger or longer or more brancher something like that yeah it's yeah yeah "
    },
    {
        "start": 3574.079,
        "text": "how you pronounce San yeah second question is one of the main struggles hardships through the doing 3D uh 3D I guess it's just um um in some sense it's a different problem we're not generating IM anymore so what what deep learning architectures can do very well with um handling tabular data that's that's has that's been the first um kind of challenge like what can we use to generate points I know there's like things like Point Nets or like using Point clouds but they are not as in some sense mainstream as Gans or S Gans uh the other thing is uh we can generate points but we need to connect them together into a tree so how do we connect them together that's another question um how um so we've actually approached it in multiple different ways in the beginning I Tred to use graph networks because you can think of them as you know so I I can predict both points and the edges that "
    },
    {
        "start": 3635.68,
        "text": "connect the points together uh that did not turn out very well so now I'm using a different approach which is um modification of a diffusion model um yeah yes there's two questions on my um and so I'm going to ask those questions and then we are over the hour so we'll have to wrap up after full more pizza leave go to class I don't know do do whatever you need to do so the first question is from Cedar who said I noticed that the F1 scores and ACC are ratio to real scores what is the real scores on real data set and generated dat yeah yeah EXC I I I don't know if you finish or yeah I think the question yeah yeah yeah so so uh classifying these kind of images even on real pretty hard problem you can probably write a paper about that one I try to make the best classifier that I "
    },
    {
        "start": 3695.92,
        "text": "can which could have been a paper on its own but it's about like 70% or so so um you know when I say like in relation to the real that means that you know if the real classifies this accurately like 70% of the time then you know the the generator will classify like a little bit less than that maybe 60% of the time that's why yeah even even though it's just like six way there there were six classes in this even though it's like six six way classification um it is hard to classify thank you and then I'm gonna try to read the second question so Arvin R asked said nice work it's cool you can subtract gen expression selectively if you subtracted the yamaka SC factors from the neuron would you get a pent SC and then if you add back can you regenerate a differential neuron St that is um I haven't tried that like in particular so I can try to try to do that let you "
    },
    {
        "start": 3758.079,
        "text": "know honestly I'm kind of curious now but but that that's the whole point kind of the application of this like right right we want to try to see like which genes we can knock out and add back in and and see how that affects morphology um the only thing I guess I know is that I can't just knock out one gene there's no like one you know Silver Bullet Gene that will like destroy the neuron um or not like usually I have to knock out like several kind of classes of genes kind of uh to to have a significant imp morphology um don't like I mean they it's like it's a Cascade yeah yeah yeah so yeah so I don't know I I I don't know if the question was like knocking out one particular or a class but if it's a class then yes that we will definitely see some effects I will have to actually do it to see the effects if it's like one gene probably they'll have no effect or follow up there are about 20 yamaka "
    },
    {
        "start": 3818.52,
        "text": "stem cell differentiation factors okay and think that should be enough yeah um yeah but uh that's that's simple thing simple thing for me to run just I haven't done it that's probably not a good answer so real quickly the cedar did also ask how to evaluate the 3D images uh I because with 3D we can calculate a lot of the um morphological metrics like the like I said like Branch length like total area total s like uh volume uh so we can actually compare those the 3D on um on the biological metrics and uh I still need to look into what is a good metric for like something like a FID but for 3D that um sure exists but again I I think it's um still under research what what that might be yeah all right well that thank you so "
    },
    {
        "start": 3883.88,
        "text": "much to see everyone that's hey "
    }
]