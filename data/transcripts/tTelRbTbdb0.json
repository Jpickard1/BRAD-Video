[
    {
        "text": "hi everyone",
        "start": 0.659,
        "duration": 3.481
    },
    {
        "text": "um thank you so much for having me so",
        "start": 2.22,
        "duration": 4.74
    },
    {
        "text": "today I'm going to be presenting on my",
        "start": 4.14,
        "duration": 5.1
    },
    {
        "text": "work called Amaze which stands for a",
        "start": 6.96,
        "duration": 3.719
    },
    {
        "text": "machine learning approach to index",
        "start": 9.24,
        "duration": 3.6
    },
    {
        "text": "resequence enrichment this work was done",
        "start": 10.679,
        "duration": 4.261
    },
    {
        "text": "jointly with piyush Ron John ARP",
        "start": 12.84,
        "duration": 4.08
    },
    {
        "text": "downward Robert Dixon and my advisor",
        "start": 14.94,
        "duration": 3.9
    },
    {
        "text": "Jenna Williams and it was published in",
        "start": 16.92,
        "duration": 4.26
    },
    {
        "text": "nature Communications biology in June of",
        "start": 18.84,
        "duration": 4.98
    },
    {
        "text": "2022.",
        "start": 21.18,
        "duration": 4.92
    },
    {
        "text": "okay so first I'm going to be getting",
        "start": 23.82,
        "duration": 4.619
    },
    {
        "text": "into some background related work",
        "start": 26.1,
        "duration": 5.4
    },
    {
        "text": "related to a maze",
        "start": 28.439,
        "duration": 6.181
    },
    {
        "text": "so the ultimate goal of our work is to",
        "start": 31.5,
        "duration": 5.76
    },
    {
        "text": "improve infectious disease diagnosis by",
        "start": 34.62,
        "duration": 4.56
    },
    {
        "text": "developing a pathogen identification",
        "start": 37.26,
        "duration": 4.319
    },
    {
        "text": "tool that is accurate to ensure that",
        "start": 39.18,
        "duration": 4.74
    },
    {
        "text": "correct treatment can be given fast to",
        "start": 41.579,
        "duration": 3.781
    },
    {
        "text": "ensure that the treatment can be given",
        "start": 43.92,
        "duration": 3.6
    },
    {
        "text": "in a timely manner and cheap and",
        "start": 45.36,
        "duration": 4.32
    },
    {
        "text": "efficient to ensure the accessibility of",
        "start": 47.52,
        "duration": 4.019
    },
    {
        "text": "the method and the ability of it to be",
        "start": 49.68,
        "duration": 5.059
    },
    {
        "text": "used at the bedside",
        "start": 51.539,
        "duration": 3.2
    },
    {
        "text": "so traditionally to diagnose infectious",
        "start": 54.899,
        "duration": 3.781
    },
    {
        "text": "diseases clinicians have used",
        "start": 57.18,
        "duration": 3.78
    },
    {
        "text": "culture-based methods which involves",
        "start": 58.68,
        "duration": 3.96
    },
    {
        "text": "taking a sample from a patient either",
        "start": 60.96,
        "duration": 4.44
    },
    {
        "text": "School saliva or blood mixing the sample",
        "start": 62.64,
        "duration": 4.38
    },
    {
        "text": "with culture media and waiting for",
        "start": 65.4,
        "duration": 3.42
    },
    {
        "text": "growth and then doing pathogen",
        "start": 67.02,
        "duration": 4.44
    },
    {
        "text": "identification via biological tests",
        "start": 68.82,
        "duration": 4.74
    },
    {
        "text": "there are a couple drawbacks to using",
        "start": 71.46,
        "duration": 4.14
    },
    {
        "text": "these culture-based methods first they",
        "start": 73.56,
        "duration": 4.08
    },
    {
        "text": "can be inaccurate because not all",
        "start": 75.6,
        "duration": 3.839
    },
    {
        "text": "pathogens can be detected using this",
        "start": 77.64,
        "duration": 3.54
    },
    {
        "text": "method and pathogen detection is",
        "start": 79.439,
        "duration": 3.54
    },
    {
        "text": "necessary for treatment and this is",
        "start": 81.18,
        "duration": 3.66
    },
    {
        "text": "because not all pathogens can grow when",
        "start": 82.979,
        "duration": 3.661
    },
    {
        "text": "mixed with the culture media",
        "start": 84.84,
        "duration": 4.08
    },
    {
        "text": "these methods can also be slow because",
        "start": 86.64,
        "duration": 4.08
    },
    {
        "text": "it can take several days to detect",
        "start": 88.92,
        "duration": 4.26
    },
    {
        "text": "growth and this slowness can negatively",
        "start": 90.72,
        "duration": 6.259
    },
    {
        "text": "affect a patient's ability to recover",
        "start": 93.18,
        "duration": 3.799
    },
    {
        "text": "so to alleviate some of these issues",
        "start": 97.68,
        "duration": 5.34
    },
    {
        "text": "people have started to use metagenomics",
        "start": 100.28,
        "duration": 5.44
    },
    {
        "text": "for disease diagnosis so metagenomics is",
        "start": 103.02,
        "duration": 4.62
    },
    {
        "text": "the study of the metagenome which is the",
        "start": 105.72,
        "duration": 3.78
    },
    {
        "text": "collective DNA from a clinical sample",
        "start": 107.64,
        "duration": 3.6
    },
    {
        "text": "and the way that people will use",
        "start": 109.5,
        "duration": 4.079
    },
    {
        "text": "metagenomics for disease diagnosis are",
        "start": 111.24,
        "duration": 3.72
    },
    {
        "text": "that they would take the same sample",
        "start": 113.579,
        "duration": 3.72
    },
    {
        "text": "from a patient the stool saliva or blood",
        "start": 114.96,
        "duration": 4.019
    },
    {
        "text": "but instead of mixing it with culture",
        "start": 117.299,
        "duration": 3.481
    },
    {
        "text": "media they would input it into a DNA",
        "start": 118.979,
        "duration": 4.081
    },
    {
        "text": "sequencer and get metagenomic sequencing",
        "start": 120.78,
        "duration": 4.26
    },
    {
        "text": "output which is all of the DNA in the",
        "start": 123.06,
        "duration": 5.039
    },
    {
        "text": "sample and then they would use a genomic",
        "start": 125.04,
        "duration": 4.98
    },
    {
        "text": "classification method to do the pathogen",
        "start": 128.099,
        "duration": 3.901
    },
    {
        "text": "classification and metagenomic",
        "start": 130.02,
        "duration": 4.02
    },
    {
        "text": "classification Maps DNA to a",
        "start": 132.0,
        "duration": 3.9
    },
    {
        "text": "classification label and existing",
        "start": 134.04,
        "duration": 3.9
    },
    {
        "text": "metagenomic classification methods do",
        "start": 135.9,
        "duration": 4.38
    },
    {
        "text": "this using reference databases so as you",
        "start": 137.94,
        "duration": 3.84
    },
    {
        "text": "can see here we have the metagenomic",
        "start": 140.28,
        "duration": 3.0
    },
    {
        "text": "sequencing output that we input into",
        "start": 141.78,
        "duration": 3.36
    },
    {
        "text": "this metagenomic classification method",
        "start": 143.28,
        "duration": 4.26
    },
    {
        "text": "that uses a reference database to do the",
        "start": 145.14,
        "duration": 5.099
    },
    {
        "text": "pathogen classification",
        "start": 147.54,
        "duration": 4.98
    },
    {
        "text": "so the problem with using metagenomics",
        "start": 150.239,
        "duration": 4.621
    },
    {
        "text": "for disease diagnosis are that there can",
        "start": 152.52,
        "duration": 4.5
    },
    {
        "text": "be copious host derived sequences in a",
        "start": 154.86,
        "duration": 4.08
    },
    {
        "text": "sample and here I have a couple of",
        "start": 157.02,
        "duration": 4.26
    },
    {
        "text": "examples of microbiome compositions from",
        "start": 158.94,
        "duration": 4.5
    },
    {
        "text": "a human where the Pike in the pie chart",
        "start": 161.28,
        "duration": 4.86
    },
    {
        "text": "the red indicates the percentage of the",
        "start": 163.44,
        "duration": 4.379
    },
    {
        "text": "sequences in the microbiome that are",
        "start": 166.14,
        "duration": 3.179
    },
    {
        "text": "from post and in blue we have the",
        "start": 167.819,
        "duration": 2.941
    },
    {
        "text": "percentage of sequences that are from a",
        "start": 169.319,
        "duration": 3.721
    },
    {
        "text": "microbe so the gut as you can see here",
        "start": 170.76,
        "duration": 4.38
    },
    {
        "text": "is evenly split there are 50 host",
        "start": 173.04,
        "duration": 4.74
    },
    {
        "text": "sequences and 50 microbial sequences in",
        "start": 175.14,
        "duration": 6.36
    },
    {
        "text": "the microbiome but the lung can be very",
        "start": 177.78,
        "duration": 6.3
    },
    {
        "text": "um can contain copious host derived",
        "start": 181.5,
        "duration": 4.019
    },
    {
        "text": "sequences compared to the microbial",
        "start": 184.08,
        "duration": 4.1
    },
    {
        "text": "sequences",
        "start": 185.519,
        "duration": 2.661
    },
    {
        "text": "um and here's an example of what um a",
        "start": 188.819,
        "duration": 3.84
    },
    {
        "text": "lung microbiome could look like with the",
        "start": 191.04,
        "duration": 3.96
    },
    {
        "text": "copious host derived sequences and so",
        "start": 192.659,
        "duration": 4.44
    },
    {
        "text": "microbial sequence formative for",
        "start": 195.0,
        "duration": 3.659
    },
    {
        "text": "pathogen detection because they could",
        "start": 197.099,
        "duration": 3.601
    },
    {
        "text": "contain the pathogen derived sequences",
        "start": 198.659,
        "duration": 4.08
    },
    {
        "text": "but the host sequences are not",
        "start": 200.7,
        "duration": 3.899
    },
    {
        "text": "informative for pathogen detection and",
        "start": 202.739,
        "duration": 3.601
    },
    {
        "text": "in this case host is the patient from",
        "start": 204.599,
        "duration": 5.241
    },
    {
        "text": "which the sample was collected",
        "start": 206.34,
        "duration": 3.5
    },
    {
        "text": "so copious host derived sequences can",
        "start": 211.68,
        "duration": 4.559
    },
    {
        "text": "cause Downstream classification methods",
        "start": 214.14,
        "duration": 4.519
    },
    {
        "text": "to be inaccurate slow and costly",
        "start": 216.239,
        "duration": 4.86
    },
    {
        "text": "inaccurate because these methods are not",
        "start": 218.659,
        "duration": 4.3
    },
    {
        "text": "especially sensitive to noisy host",
        "start": 221.099,
        "duration": 3.78
    },
    {
        "text": "sequences so they can be inaccurate",
        "start": 222.959,
        "duration": 4.021
    },
    {
        "text": "classifying those sequences",
        "start": 224.879,
        "duration": 4.321
    },
    {
        "text": "slow because it causes these methods to",
        "start": 226.98,
        "duration": 4.08
    },
    {
        "text": "classify a lot of uninformative",
        "start": 229.2,
        "duration": 3.539
    },
    {
        "text": "sequences the host sequences as you",
        "start": 231.06,
        "duration": 3.0
    },
    {
        "text": "remember are not informative to doing",
        "start": 232.739,
        "duration": 3.78
    },
    {
        "text": "the pathogen identification and also it",
        "start": 234.06,
        "duration": 4.02
    },
    {
        "text": "causes these methods to be costly",
        "start": 236.519,
        "duration": 3.481
    },
    {
        "text": "because they have to store large amounts",
        "start": 238.08,
        "duration": 3.54
    },
    {
        "text": "of post genomes to classify the host",
        "start": 240.0,
        "duration": 3.9
    },
    {
        "text": "sequences and typically host genomes are",
        "start": 241.62,
        "duration": 4.259
    },
    {
        "text": "much larger than microbial genomes so",
        "start": 243.9,
        "duration": 4.339
    },
    {
        "text": "this can add a lot of storage and Rams",
        "start": 245.879,
        "duration": 6.14
    },
    {
        "text": "requirements to these methods",
        "start": 248.239,
        "duration": 3.78
    },
    {
        "text": "so to alleviate the aforementioned",
        "start": 256.62,
        "duration": 3.959
    },
    {
        "text": "problem of copious host derived",
        "start": 258.66,
        "duration": 4.319
    },
    {
        "text": "sequences",
        "start": 260.579,
        "duration": 4.56
    },
    {
        "text": "um fire investigators have employed host",
        "start": 262.979,
        "duration": 4.741
    },
    {
        "text": "depletion staffs and host depletion is a",
        "start": 265.139,
        "duration": 4.081
    },
    {
        "text": "binary classification task of",
        "start": 267.72,
        "duration": 4.08
    },
    {
        "text": "determining whether a sequence is from a",
        "start": 269.22,
        "duration": 5.34
    },
    {
        "text": "host or not from a host so instead of",
        "start": 271.8,
        "duration": 4.32
    },
    {
        "text": "this existing pipeline that I had shown",
        "start": 274.56,
        "duration": 3.48
    },
    {
        "text": "before of taking the metagenomic",
        "start": 276.12,
        "duration": 4.26
    },
    {
        "text": "sequencing output and inputting it into",
        "start": 278.04,
        "duration": 4.92
    },
    {
        "text": "a metagenomic classification method that",
        "start": 280.38,
        "duration": 4.74
    },
    {
        "text": "uses a reference database with both host",
        "start": 282.96,
        "duration": 4.44
    },
    {
        "text": "and microbial DNA to perform the",
        "start": 285.12,
        "duration": 4.139
    },
    {
        "text": "classification",
        "start": 287.4,
        "duration": 4.079
    },
    {
        "text": "we would use the following pipeline",
        "start": 289.259,
        "duration": 4.38
    },
    {
        "text": "where before inputting the sequences",
        "start": 291.479,
        "duration": 4.321
    },
    {
        "text": "into a metagenomic classification method",
        "start": 293.639,
        "duration": 4.201
    },
    {
        "text": "we would input those sequences into a",
        "start": 295.8,
        "duration": 4.14
    },
    {
        "text": "host depletion method that removes the",
        "start": 297.84,
        "duration": 3.96
    },
    {
        "text": "host sequences and then takes those",
        "start": 299.94,
        "duration": 3.96
    },
    {
        "text": "microbial sequences and it inputs them",
        "start": 301.8,
        "duration": 4.14
    },
    {
        "text": "into a metagenomic classification method",
        "start": 303.9,
        "duration": 4.38
    },
    {
        "text": "and in this pipeline the metagenomic",
        "start": 305.94,
        "duration": 4.199
    },
    {
        "text": "classification method would only need",
        "start": 308.28,
        "duration": 3.9
    },
    {
        "text": "microbial DNA in the reference database",
        "start": 310.139,
        "duration": 4.081
    },
    {
        "text": "because all of those host sequences have",
        "start": 312.18,
        "duration": 4.68
    },
    {
        "text": "been removed",
        "start": 314.22,
        "duration": 5.1
    },
    {
        "text": "so the benefits of using host depletion",
        "start": 316.86,
        "duration": 4.5
    },
    {
        "text": "for Downstream methods are it allows",
        "start": 319.32,
        "duration": 4.14
    },
    {
        "text": "them to be more accurate faster and",
        "start": 321.36,
        "duration": 4.2
    },
    {
        "text": "cheaper more accurate because it gives",
        "start": 323.46,
        "duration": 4.019
    },
    {
        "text": "Downstream classification methods a",
        "start": 325.56,
        "duration": 3.96
    },
    {
        "text": "slightly easier classification task it",
        "start": 327.479,
        "duration": 3.841
    },
    {
        "text": "removes one class that they would need",
        "start": 329.52,
        "duration": 4.019
    },
    {
        "text": "to do the classification on it also",
        "start": 331.32,
        "duration": 4.08
    },
    {
        "text": "allow these methods to be faster because",
        "start": 333.539,
        "duration": 3.961
    },
    {
        "text": "Downstream methods seem to classify less",
        "start": 335.4,
        "duration": 4.26
    },
    {
        "text": "sequences and it allows them to be",
        "start": 337.5,
        "duration": 3.9
    },
    {
        "text": "cheaper because Downstream methods don't",
        "start": 339.66,
        "duration": 5.24
    },
    {
        "text": "need to store those genomes",
        "start": 341.4,
        "duration": 3.5
    },
    {
        "text": "okay so previous work in computational",
        "start": 347.34,
        "duration": 4.98
    },
    {
        "text": "host depletion can be broken up into two",
        "start": 350.1,
        "duration": 4.2
    },
    {
        "text": "different categories the first category",
        "start": 352.32,
        "duration": 4.26
    },
    {
        "text": "are pairwise alignment based methods and",
        "start": 354.3,
        "duration": 4.92
    },
    {
        "text": "an example of this is mini-map2 the way",
        "start": 356.58,
        "duration": 4.26
    },
    {
        "text": "that these types of methods work are",
        "start": 359.22,
        "duration": 3.6
    },
    {
        "text": "that they get a query sequence and they",
        "start": 360.84,
        "duration": 3.54
    },
    {
        "text": "align it to the reference Genome of",
        "start": 362.82,
        "duration": 3.84
    },
    {
        "text": "interest and in this case we want to",
        "start": 364.38,
        "duration": 4.02
    },
    {
        "text": "save the query sequences from a human so",
        "start": 366.66,
        "duration": 3.24
    },
    {
        "text": "we align that prayer sequence to the",
        "start": 368.4,
        "duration": 3.54
    },
    {
        "text": "human reference genome in this case we",
        "start": 369.9,
        "duration": 3.66
    },
    {
        "text": "see there's perfect alignment so we",
        "start": 371.94,
        "duration": 4.14
    },
    {
        "text": "would output that the sequence is from a",
        "start": 373.56,
        "duration": 4.32
    },
    {
        "text": "human or the human classification label",
        "start": 376.08,
        "duration": 3.6
    },
    {
        "text": "and if there wasn't perfect alignment we",
        "start": 377.88,
        "duration": 5.539
    },
    {
        "text": "would output that it wasn't from a human",
        "start": 379.68,
        "duration": 3.739
    },
    {
        "text": "the other class of methods in",
        "start": 383.46,
        "duration": 3.54
    },
    {
        "text": "computational host depletion are lookup",
        "start": 385.319,
        "duration": 3.781
    },
    {
        "text": "table based methods and examples of this",
        "start": 387.0,
        "duration": 5.84
    },
    {
        "text": "are cracking chew and centrifuge",
        "start": 389.1,
        "duration": 3.74
    },
    {
        "text": "and the way that these methods work are",
        "start": 393.06,
        "duration": 3.78
    },
    {
        "text": "they take that same query sequence but",
        "start": 394.86,
        "duration": 4.38
    },
    {
        "text": "instead of directly aligning it to the",
        "start": 396.84,
        "duration": 4.38
    },
    {
        "text": "human reference genome they break the",
        "start": 399.24,
        "duration": 3.959
    },
    {
        "text": "query sequence up into Capers or",
        "start": 401.22,
        "duration": 4.259
    },
    {
        "text": "subsequences of length K and in this",
        "start": 403.199,
        "duration": 3.72
    },
    {
        "text": "case we are breaking up the sequence",
        "start": 405.479,
        "duration": 3.541
    },
    {
        "text": "into subsequences of blank three or",
        "start": 406.919,
        "duration": 3.301
    },
    {
        "text": "primers",
        "start": 409.02,
        "duration": 5.399
    },
    {
        "text": "um TCG cgc and GCC and then we look for",
        "start": 410.22,
        "duration": 6.78
    },
    {
        "text": "direct matches between those trimers and",
        "start": 414.419,
        "duration": 4.021
    },
    {
        "text": "the trimers that exist in the human",
        "start": 417.0,
        "duration": 3.36
    },
    {
        "text": "reference genome so in this lookup table",
        "start": 418.44,
        "duration": 4.259
    },
    {
        "text": "we have all of the trimers that exist in",
        "start": 420.36,
        "duration": 4.14
    },
    {
        "text": "the human reference genome in this case",
        "start": 422.699,
        "duration": 3.72
    },
    {
        "text": "we see that these timers perfectly match",
        "start": 424.5,
        "duration": 4.38
    },
    {
        "text": "these trimers and so we can output that",
        "start": 426.419,
        "duration": 4.5
    },
    {
        "text": "this query sequence has the human",
        "start": 428.88,
        "duration": 5.3
    },
    {
        "text": "classification label",
        "start": 430.919,
        "duration": 3.261
    },
    {
        "text": "um so the issues with these existing",
        "start": 434.94,
        "duration": 3.9
    },
    {
        "text": "computational host depletion methods are",
        "start": 436.62,
        "duration": 4.26
    },
    {
        "text": "that they can be inaccurate on sequences",
        "start": 438.84,
        "duration": 4.32
    },
    {
        "text": "from error-prone Technologies and this",
        "start": 440.88,
        "duration": 3.659
    },
    {
        "text": "is because they build their reference",
        "start": 443.16,
        "duration": 3.539
    },
    {
        "text": "databases using reference genomes which",
        "start": 444.539,
        "duration": 4.021
    },
    {
        "text": "are very curated and have very few",
        "start": 446.699,
        "duration": 3.601
    },
    {
        "text": "errors so when we're doing this direct",
        "start": 448.56,
        "duration": 3.96
    },
    {
        "text": "matching we're unable to account for a",
        "start": 450.3,
        "duration": 4.08
    },
    {
        "text": "lot of the errors that could appear in",
        "start": 452.52,
        "duration": 4.56
    },
    {
        "text": "error from sequences and these methods",
        "start": 454.38,
        "duration": 4.259
    },
    {
        "text": "are also costly because they require",
        "start": 457.08,
        "duration": 3.239
    },
    {
        "text": "storage and memory to store the",
        "start": 458.639,
        "duration": 4.701
    },
    {
        "text": "reference databases",
        "start": 460.319,
        "duration": 3.021
    },
    {
        "text": "so why do we think that machine learning",
        "start": 464.46,
        "duration": 3.78
    },
    {
        "text": "would help so we hypothesized that",
        "start": 466.38,
        "duration": 4.08
    },
    {
        "text": "machine learning based approach would be",
        "start": 468.24,
        "duration": 3.899
    },
    {
        "text": "more accurate and cheaper than existing",
        "start": 470.46,
        "duration": 3.78
    },
    {
        "text": "approaches more accurate because we",
        "start": 472.139,
        "duration": 4.201
    },
    {
        "text": "hypothesized than an ml-based approach",
        "start": 474.24,
        "duration": 3.959
    },
    {
        "text": "would be more robust to sequences from",
        "start": 476.34,
        "duration": 3.72
    },
    {
        "text": "error-prone Technologies because we're",
        "start": 478.199,
        "duration": 3.661
    },
    {
        "text": "not directly aligning sequences or",
        "start": 480.06,
        "duration": 3.66
    },
    {
        "text": "cameras to a reference genome we can do",
        "start": 481.86,
        "duration": 4.8
    },
    {
        "text": "something a little bit more complicated",
        "start": 483.72,
        "duration": 5.34
    },
    {
        "text": "and we hypothesized an ml based approach",
        "start": 486.66,
        "duration": 3.599
    },
    {
        "text": "would be cheaper than existing",
        "start": 489.06,
        "duration": 3.78
    },
    {
        "text": "approaches because they can use Less",
        "start": 490.259,
        "duration": 4.081
    },
    {
        "text": "storage and brand than existing",
        "start": 492.84,
        "duration": 3.299
    },
    {
        "text": "post-depletion methods and this is",
        "start": 494.34,
        "duration": 3.479
    },
    {
        "text": "because an ml-based approach can learn",
        "start": 496.139,
        "duration": 3.9
    },
    {
        "text": "patterns from raw DNA sequences without",
        "start": 497.819,
        "duration": 6.201
    },
    {
        "text": "the Reliance on an external database",
        "start": 500.039,
        "duration": 3.981
    },
    {
        "text": "but why is DNA classification",
        "start": 504.72,
        "duration": 4.44
    },
    {
        "text": "challenging for machine learning so ml",
        "start": 506.639,
        "duration": 4.381
    },
    {
        "text": "hasn't been applied to host depletion in",
        "start": 509.16,
        "duration": 3.78
    },
    {
        "text": "past work but it has been applied to",
        "start": 511.02,
        "duration": 3.899
    },
    {
        "text": "multi-class metagenomic classification",
        "start": 512.94,
        "duration": 4.5
    },
    {
        "text": "and novel path and connection and",
        "start": 514.919,
        "duration": 4.261
    },
    {
        "text": "current approaches in those areas have",
        "start": 517.44,
        "duration": 4.5
    },
    {
        "text": "two issues first they can be inaccurate",
        "start": 519.18,
        "duration": 4.739
    },
    {
        "text": "and slow at performing variable length",
        "start": 521.94,
        "duration": 3.899
    },
    {
        "text": "sequence classification and sequences",
        "start": 523.919,
        "duration": 3.721
    },
    {
        "text": "from aeroprone Technologies happen to be",
        "start": 525.839,
        "duration": 3.421
    },
    {
        "text": "variable length they can range from",
        "start": 527.64,
        "duration": 4.199
    },
    {
        "text": "length 100 to over a thousand and the",
        "start": 529.26,
        "duration": 3.9
    },
    {
        "text": "second issue is that they typically",
        "start": 531.839,
        "duration": 3.541
    },
    {
        "text": "don't build diverse training sets and",
        "start": 533.16,
        "duration": 4.02
    },
    {
        "text": "they can be inaccurate at classifying",
        "start": 535.38,
        "duration": 3.959
    },
    {
        "text": "sequences that differ from those in its",
        "start": 537.18,
        "duration": 4.64
    },
    {
        "text": "training set",
        "start": 539.339,
        "duration": 2.481
    },
    {
        "text": "so our contributions are that we",
        "start": 544.08,
        "duration": 4.14
    },
    {
        "text": "developed a novel machine learning based",
        "start": 546.12,
        "duration": 4.44
    },
    {
        "text": "host depletion method a maze that can",
        "start": 548.22,
        "duration": 3.72
    },
    {
        "text": "perform variable links sequence",
        "start": 550.56,
        "duration": 3.839
    },
    {
        "text": "classification accurately and quickly on",
        "start": 551.94,
        "duration": 5.579
    },
    {
        "text": "a diverse set of input data",
        "start": 554.399,
        "duration": 5.581
    },
    {
        "text": "so we first leverage global average",
        "start": 557.519,
        "duration": 4.38
    },
    {
        "text": "pooling to handle the variable length",
        "start": 559.98,
        "duration": 4.26
    },
    {
        "text": "sequences",
        "start": 561.899,
        "duration": 4.861
    },
    {
        "text": "and we use new training data sources to",
        "start": 564.24,
        "duration": 4.2
    },
    {
        "text": "improve the ability of our model to",
        "start": 566.76,
        "duration": 6.199
    },
    {
        "text": "classify a diverse set of input data",
        "start": 568.44,
        "duration": 4.519
    },
    {
        "text": "we also rigorously evaluated our",
        "start": 573.54,
        "duration": 4.56
    },
    {
        "text": "approach by providing a comprehensive",
        "start": 575.94,
        "duration": 4.26
    },
    {
        "text": "comparison of our approach to existing",
        "start": 578.1,
        "duration": 4.44
    },
    {
        "text": "alignment and classification methods in",
        "start": 580.2,
        "duration": 4.259
    },
    {
        "text": "their ability to perform host completion",
        "start": 582.54,
        "duration": 4.56
    },
    {
        "text": "and we also evaluated our approach as a",
        "start": 584.459,
        "duration": 4.681
    },
    {
        "text": "pre-processing tool applied before",
        "start": 587.1,
        "duration": 4.08
    },
    {
        "text": "Downstream microbial taxonomic",
        "start": 589.14,
        "duration": 4.639
    },
    {
        "text": "classification",
        "start": 591.18,
        "duration": 2.599
    },
    {
        "text": "okay so now I'm going to be getting into",
        "start": 595.44,
        "duration": 5.7
    },
    {
        "text": "details of our method",
        "start": 597.6,
        "duration": 6.02
    },
    {
        "text": "first starting with amazes architecture",
        "start": 601.14,
        "duration": 5.819
    },
    {
        "text": "we start with our input to amaze a DNA",
        "start": 603.62,
        "duration": 4.36
    },
    {
        "text": "read",
        "start": 606.959,
        "duration": 3.361
    },
    {
        "text": "that DNA read first passes through four",
        "start": 607.98,
        "duration": 4.5
    },
    {
        "text": "convolutional layers and these",
        "start": 610.32,
        "duration": 3.72
    },
    {
        "text": "convolutional layers learn a rich",
        "start": 612.48,
        "duration": 4.919
    },
    {
        "text": "feature representation of the DNA read",
        "start": 614.04,
        "duration": 5.64
    },
    {
        "text": "the next step is passing that feature",
        "start": 617.399,
        "duration": 3.841
    },
    {
        "text": "representation through global average",
        "start": 619.68,
        "duration": 3.24
    },
    {
        "text": "pooling layer and a fully connected",
        "start": 621.24,
        "duration": 3.96
    },
    {
        "text": "layer to get the probability that a DNA",
        "start": 622.92,
        "duration": 3.78
    },
    {
        "text": "reads from a host",
        "start": 625.2,
        "duration": 3.18
    },
    {
        "text": "and these global average pooling and",
        "start": 626.7,
        "duration": 3.3
    },
    {
        "text": "fully connected layer aggregate the",
        "start": 628.38,
        "duration": 4.8
    },
    {
        "text": "Learned features into that probability",
        "start": 630.0,
        "duration": 5.399
    },
    {
        "text": "and then the last step is thresholding",
        "start": 633.18,
        "duration": 3.42
    },
    {
        "text": "that probability for the final",
        "start": 635.399,
        "duration": 3.361
    },
    {
        "text": "classification decision if the",
        "start": 636.6,
        "duration": 4.44
    },
    {
        "text": "probability is below the threshold we",
        "start": 638.76,
        "duration": 4.74
    },
    {
        "text": "state that the DNA read is from a",
        "start": 641.04,
        "duration": 4.32
    },
    {
        "text": "microbe if the probability is above a",
        "start": 643.5,
        "duration": 3.66
    },
    {
        "text": "threshold we state that the DNA read is",
        "start": 645.36,
        "duration": 4.219
    },
    {
        "text": "from a host",
        "start": 647.16,
        "duration": 2.419
    },
    {
        "text": "okay so going back to the issue with",
        "start": 651.36,
        "duration": 4.8
    },
    {
        "text": "existing ml-based approaches for DNA",
        "start": 654.0,
        "duration": 4.2
    },
    {
        "text": "classification the first issue is",
        "start": 656.16,
        "duration": 4.14
    },
    {
        "text": "existing methods are inaccurate or slow",
        "start": 658.2,
        "duration": 3.84
    },
    {
        "text": "at performing variable length sequence",
        "start": 660.3,
        "duration": 3.96
    },
    {
        "text": "classification existing methods either",
        "start": 662.04,
        "duration": 5.22
    },
    {
        "text": "truncate the input or pad the input",
        "start": 664.26,
        "duration": 5.28
    },
    {
        "text": "and truncation can cause inaccuracy",
        "start": 667.26,
        "duration": 5.1
    },
    {
        "text": "because this they remove important parts",
        "start": 669.54,
        "duration": 5.039
    },
    {
        "text": "of the sequence while padding causes",
        "start": 672.36,
        "duration": 4.2
    },
    {
        "text": "methods to be slow because it causes an",
        "start": 674.579,
        "duration": 3.841
    },
    {
        "text": "increase in classification time since",
        "start": 676.56,
        "duration": 4.32
    },
    {
        "text": "we're adding additional aspects of the",
        "start": 678.42,
        "duration": 5.479
    },
    {
        "text": "input to be classified",
        "start": 680.88,
        "duration": 3.019
    },
    {
        "text": "to solve these issues with existing",
        "start": 684.36,
        "duration": 3.659
    },
    {
        "text": "methods we leverage global average",
        "start": 686.399,
        "duration": 3.361
    },
    {
        "text": "pooling to handle the variable length",
        "start": 688.019,
        "duration": 4.5
    },
    {
        "text": "sequence and this leverage pooling",
        "start": 689.76,
        "duration": 4.5
    },
    {
        "text": "averages the learn features over the",
        "start": 692.519,
        "duration": 3.421
    },
    {
        "text": "sequence Dimension allowing our method",
        "start": 694.26,
        "duration": 3.48
    },
    {
        "text": "to be agnostic to the length of the",
        "start": 695.94,
        "duration": 4.16
    },
    {
        "text": "sequence",
        "start": 697.74,
        "duration": 2.36
    },
    {
        "text": "so if you remember from our architecture",
        "start": 700.68,
        "duration": 3.779
    },
    {
        "text": "diagram the global average pooling",
        "start": 702.66,
        "duration": 3.96
    },
    {
        "text": "occurs after we learn a feature",
        "start": 704.459,
        "duration": 4.201
    },
    {
        "text": "representation of our DNA read via the",
        "start": 706.62,
        "duration": 4.02
    },
    {
        "text": "convolutional layers and it allows our",
        "start": 708.66,
        "duration": 6.02
    },
    {
        "text": "method to be agnostic to sequence length",
        "start": 710.64,
        "duration": 4.04
    },
    {
        "text": "so the second issue with existing",
        "start": 715.92,
        "duration": 3.659
    },
    {
        "text": "ml-based approaches are that they don't",
        "start": 717.6,
        "duration": 4.14
    },
    {
        "text": "build diverse training sets and they can",
        "start": 719.579,
        "duration": 4.26
    },
    {
        "text": "be inaccurate at classifying sequences",
        "start": 721.74,
        "duration": 4.14
    },
    {
        "text": "that differ from those in its training",
        "start": 723.839,
        "duration": 4.981
    },
    {
        "text": "set existing methods like existing",
        "start": 725.88,
        "duration": 4.62
    },
    {
        "text": "computational host depletion methods",
        "start": 728.82,
        "duration": 3.959
    },
    {
        "text": "train models on sequences from reference",
        "start": 730.5,
        "duration": 5.1
    },
    {
        "text": "genomes and the issue with this is that",
        "start": 732.779,
        "duration": 4.74
    },
    {
        "text": "these methods are not able to accurately",
        "start": 735.6,
        "duration": 3.9
    },
    {
        "text": "classify sequences from error from",
        "start": 737.519,
        "duration": 5.121
    },
    {
        "text": "sequencing Technologies",
        "start": 739.5,
        "duration": 3.14
    },
    {
        "text": "so to solve this we use new training",
        "start": 742.74,
        "duration": 4.26
    },
    {
        "text": "data sources to improve our learned",
        "start": 745.2,
        "duration": 3.72
    },
    {
        "text": "representations and instead of just",
        "start": 747.0,
        "duration": 3.66
    },
    {
        "text": "training our model on sequences sampled",
        "start": 748.92,
        "duration": 3.72
    },
    {
        "text": "from reference genomes we also sampled",
        "start": 750.66,
        "duration": 3.72
    },
    {
        "text": "sequences from sequencing Technologies",
        "start": 752.64,
        "duration": 3.78
    },
    {
        "text": "allowing our method to be more robust to",
        "start": 754.38,
        "duration": 5.84
    },
    {
        "text": "sequences from airplane Technologies",
        "start": 756.42,
        "duration": 3.8
    },
    {
        "text": "okay now I'm going to be getting into",
        "start": 762.12,
        "duration": 5.58
    },
    {
        "text": "the evaluation setup of our method",
        "start": 763.74,
        "duration": 6.18
    },
    {
        "text": "we had three different classes of",
        "start": 767.7,
        "duration": 3.78
    },
    {
        "text": "evaluation metrics that we were looking",
        "start": 769.92,
        "duration": 5.28
    },
    {
        "text": "at accuracy speed and cost efficiency",
        "start": 771.48,
        "duration": 5.58
    },
    {
        "text": "um as I had said before accuracy is",
        "start": 775.2,
        "duration": 3.24
    },
    {
        "text": "important to ensure that the correct",
        "start": 777.06,
        "duration": 3.839
    },
    {
        "text": "treatment can be assigned and for our ml",
        "start": 778.44,
        "duration": 4.62
    },
    {
        "text": "method and host depletion comparison we",
        "start": 780.899,
        "duration": 4.141
    },
    {
        "text": "measured accuracy using classification",
        "start": 783.06,
        "duration": 4.7
    },
    {
        "text": "accuracy sensitivity and specificity",
        "start": 785.04,
        "duration": 4.799
    },
    {
        "text": "sensitivity is the percentage of",
        "start": 787.76,
        "duration": 4.12
    },
    {
        "text": "microbes or sorry sensitivity is the",
        "start": 789.839,
        "duration": 3.481
    },
    {
        "text": "percentage of hosts that were correctly",
        "start": 791.88,
        "duration": 3.42
    },
    {
        "text": "identified and specificity is the",
        "start": 793.32,
        "duration": 3.6
    },
    {
        "text": "percentage of macros that were correctly",
        "start": 795.3,
        "duration": 3.599
    },
    {
        "text": "identified and then for our",
        "start": 796.92,
        "duration": 3.479
    },
    {
        "text": "pre-processing or metagenomic",
        "start": 798.899,
        "duration": 3.541
    },
    {
        "text": "classification comparison we looked at",
        "start": 800.399,
        "duration": 4.38
    },
    {
        "text": "overall accuracy on the host data and",
        "start": 802.44,
        "duration": 5.28
    },
    {
        "text": "overall accuracy on the microbial data",
        "start": 804.779,
        "duration": 5.401
    },
    {
        "text": "then to measure speed which is important",
        "start": 807.72,
        "duration": 3.84
    },
    {
        "text": "to ensure that the treatment can be",
        "start": 810.18,
        "duration": 3.48
    },
    {
        "text": "given in a timely manner we measure that",
        "start": 811.56,
        "duration": 4.86
    },
    {
        "text": "using wall clock time and then for cost",
        "start": 813.66,
        "duration": 4.739
    },
    {
        "text": "and efficiency which is important to",
        "start": 816.42,
        "duration": 3.84
    },
    {
        "text": "ensure the accessibility of the method",
        "start": 818.399,
        "duration": 3.481
    },
    {
        "text": "and ability of it to be used at the",
        "start": 820.26,
        "duration": 4.16
    },
    {
        "text": "bedside we measured this using storage",
        "start": 821.88,
        "duration": 6.74
    },
    {
        "text": "RAM and dram usage",
        "start": 824.42,
        "duration": 4.2
    },
    {
        "text": "and the test sets that we used for our",
        "start": 829.2,
        "duration": 4.439
    },
    {
        "text": "evaluation contain nanopore reads and",
        "start": 831.06,
        "duration": 4.2
    },
    {
        "text": "this is because nanopore sequencing",
        "start": 833.639,
        "duration": 3.961
    },
    {
        "text": "currently produces the longest reads and",
        "start": 835.26,
        "duration": 3.96
    },
    {
        "text": "is the only platform that produces",
        "start": 837.6,
        "duration": 3.66
    },
    {
        "text": "real-time sequencing data both of which",
        "start": 839.22,
        "duration": 4.5
    },
    {
        "text": "are useful for clinical Diagnostics and",
        "start": 841.26,
        "duration": 4.139
    },
    {
        "text": "all of our test sets contain human in",
        "start": 843.72,
        "duration": 3.84
    },
    {
        "text": "the host fraction and bacteria and fungi",
        "start": 845.399,
        "duration": 5.24
    },
    {
        "text": "in the microbial fraction",
        "start": 847.56,
        "duration": 3.079
    },
    {
        "text": "okay now I'm going to be getting into",
        "start": 852.06,
        "duration": 5.219
    },
    {
        "text": "our ml model comparison results uh which",
        "start": 854.7,
        "duration": 4.8
    },
    {
        "text": "presents a comparison of a maze to other",
        "start": 857.279,
        "duration": 3.961
    },
    {
        "text": "machine learning based solutions that",
        "start": 859.5,
        "duration": 3.6
    },
    {
        "text": "use other architectures and training",
        "start": 861.24,
        "duration": 4.279
    },
    {
        "text": "schemes",
        "start": 863.1,
        "duration": 2.419
    },
    {
        "text": "and our hypotheses here are that",
        "start": 865.7,
        "duration": 5.319
    },
    {
        "text": "existing methods that concatenate or pad",
        "start": 868.68,
        "duration": 4.44
    },
    {
        "text": "outputs would be improved by using",
        "start": 871.019,
        "duration": 4.201
    },
    {
        "text": "global average pooling and existing",
        "start": 873.12,
        "duration": 3.899
    },
    {
        "text": "methods that use a single training data",
        "start": 875.22,
        "duration": 3.419
    },
    {
        "text": "source like just sampling sequences from",
        "start": 877.019,
        "duration": 3.661
    },
    {
        "text": "reference genomes would be improved by",
        "start": 878.639,
        "duration": 5.841
    },
    {
        "text": "using multiple training data sources",
        "start": 880.68,
        "duration": 3.8
    },
    {
        "text": "okay and for this comparison we looked",
        "start": 886.5,
        "duration": 4.32
    },
    {
        "text": "at one test set which contained a human",
        "start": 888.959,
        "duration": 4.861
    },
    {
        "text": "host percentage of 50 we found that",
        "start": 890.82,
        "duration": 5.34
    },
    {
        "text": "machine learning methods did not um",
        "start": 893.82,
        "duration": 3.959
    },
    {
        "text": "their performance did not change based",
        "start": 896.16,
        "duration": 3.359
    },
    {
        "text": "on the percentage of host DNA and the",
        "start": 897.779,
        "duration": 4.081
    },
    {
        "text": "test set but non-ml host depletion",
        "start": 899.519,
        "duration": 4.32
    },
    {
        "text": "methods performance did change so when I",
        "start": 901.86,
        "duration": 3.96
    },
    {
        "text": "show you results from that comparison we",
        "start": 903.839,
        "duration": 3.601
    },
    {
        "text": "looked at a variety of test sets with",
        "start": 905.82,
        "duration": 3.9
    },
    {
        "text": "different percentages of host in the",
        "start": 907.44,
        "duration": 4.88
    },
    {
        "text": "sample",
        "start": 909.72,
        "duration": 2.6
    },
    {
        "text": "okay so for the first issue of existing",
        "start": 913.68,
        "duration": 4.98
    },
    {
        "text": "methods being inaccurate or slow at",
        "start": 916.5,
        "duration": 3.66
    },
    {
        "text": "performing variable length sequence",
        "start": 918.66,
        "duration": 3.419
    },
    {
        "text": "classification",
        "start": 920.16,
        "duration": 4.919
    },
    {
        "text": "where um you see sensitivity and",
        "start": 922.079,
        "duration": 4.801
    },
    {
        "text": "specificity we want to be high in",
        "start": 925.079,
        "duration": 4.44
    },
    {
        "text": "classification time we want to be low uh",
        "start": 926.88,
        "duration": 5.04
    },
    {
        "text": "we see that when we pad the inputs we",
        "start": 929.519,
        "duration": 4.32
    },
    {
        "text": "have a high accuracy sensitivity and",
        "start": 931.92,
        "duration": 4.08
    },
    {
        "text": "specificity but a high classification",
        "start": 933.839,
        "duration": 4.021
    },
    {
        "text": "time where we want a low classification",
        "start": 936.0,
        "duration": 4.68
    },
    {
        "text": "time when we concatenate the input that",
        "start": 937.86,
        "duration": 4.919
    },
    {
        "text": "we have a low classification time but",
        "start": 940.68,
        "duration": 3.779
    },
    {
        "text": "that comes at the expense of a lower",
        "start": 942.779,
        "duration": 5.161
    },
    {
        "text": "specificity sensitivity and accuracy and",
        "start": 944.459,
        "duration": 4.981
    },
    {
        "text": "in this case we have Peak membrane and",
        "start": 947.94,
        "duration": 3.12
    },
    {
        "text": "storage usage held constant so I don't",
        "start": 949.44,
        "duration": 4.019
    },
    {
        "text": "include that in the table",
        "start": 951.06,
        "duration": 5.279
    },
    {
        "text": "when we global average pool we can",
        "start": 953.459,
        "duration": 4.801
    },
    {
        "text": "maintain the high accuracy sensitivity",
        "start": 956.339,
        "duration": 4.141
    },
    {
        "text": "and specificity of padding the inputs",
        "start": 958.26,
        "duration": 5.939
    },
    {
        "text": "but we have a lower classification time",
        "start": 960.48,
        "duration": 5.94
    },
    {
        "text": "so a maze was faster than a model that",
        "start": 964.199,
        "duration": 4.2
    },
    {
        "text": "pads inputs to the maximum length with",
        "start": 966.42,
        "duration": 3.539
    },
    {
        "text": "no decrease in sensitivity and",
        "start": 968.399,
        "duration": 4.021
    },
    {
        "text": "specificity and a maze at a higher",
        "start": 969.959,
        "duration": 4.32
    },
    {
        "text": "sensitivity and specificity than a model",
        "start": 972.42,
        "duration": 3.9
    },
    {
        "text": "that truncate sequences to the minimum",
        "start": 974.279,
        "duration": 4.521
    },
    {
        "text": "length",
        "start": 976.32,
        "duration": 2.48
    },
    {
        "text": "so for the second issue of existing",
        "start": 979.38,
        "duration": 4.259
    },
    {
        "text": "methods not building a diverse training",
        "start": 981.36,
        "duration": 4.5
    },
    {
        "text": "set and being inaccurate at classifying",
        "start": 983.639,
        "duration": 4.56
    },
    {
        "text": "sequences that differ from those in its",
        "start": 985.86,
        "duration": 3.419
    },
    {
        "text": "training set",
        "start": 988.199,
        "duration": 3.721
    },
    {
        "text": "we have here models that were trained",
        "start": 989.279,
        "duration": 4.92
    },
    {
        "text": "just on nanopore sequences and just on",
        "start": 991.92,
        "duration": 4.68
    },
    {
        "text": "reference genomes and sequences sample",
        "start": 994.199,
        "duration": 4.38
    },
    {
        "text": "just from reference genomes and we see",
        "start": 996.6,
        "duration": 4.14
    },
    {
        "text": "here that both of these methods have a",
        "start": 998.579,
        "duration": 4.921
    },
    {
        "text": "low accuracy when we train on just",
        "start": 1000.74,
        "duration": 4.74
    },
    {
        "text": "nanopore sequences we have a high",
        "start": 1003.5,
        "duration": 4.86
    },
    {
        "text": "specificity but a low sensitivity this",
        "start": 1005.48,
        "duration": 4.74
    },
    {
        "text": "flips when we train on reference genomes",
        "start": 1008.36,
        "duration": 4.08
    },
    {
        "text": "we have a high sensitivity but a low",
        "start": 1010.22,
        "duration": 4.619
    },
    {
        "text": "specificity and we want all of these",
        "start": 1012.44,
        "duration": 4.92
    },
    {
        "text": "metrics to be high",
        "start": 1014.839,
        "duration": 4.74
    },
    {
        "text": "when we train on both nanopore and",
        "start": 1017.36,
        "duration": 4.14
    },
    {
        "text": "reference genome sequences we have a",
        "start": 1019.579,
        "duration": 3.601
    },
    {
        "text": "high accuracy sensitivity and",
        "start": 1021.5,
        "duration": 3.6
    },
    {
        "text": "specificity so we're able to achieve the",
        "start": 1023.18,
        "duration": 3.84
    },
    {
        "text": "best of both worlds",
        "start": 1025.1,
        "duration": 3.959
    },
    {
        "text": "so training on only reference genomes",
        "start": 1027.02,
        "duration": 3.539
    },
    {
        "text": "are only data from a sequencing",
        "start": 1029.059,
        "duration": 3.78
    },
    {
        "text": "technology results in lower sensitivity",
        "start": 1030.559,
        "duration": 4.441
    },
    {
        "text": "and specificity compared to training on",
        "start": 1032.839,
        "duration": 6.261
    },
    {
        "text": "both record genomes and nanopard data",
        "start": 1035.0,
        "duration": 4.1
    },
    {
        "text": "okay so takeaways from this section we",
        "start": 1040.699,
        "duration": 4.62
    },
    {
        "text": "developed a novel machine learning based",
        "start": 1043.28,
        "duration": 4.019
    },
    {
        "text": "host depletion method a maze that can",
        "start": 1045.319,
        "duration": 3.36
    },
    {
        "text": "perform variable length sequence",
        "start": 1047.299,
        "duration": 3.781
    },
    {
        "text": "classification accurately and quickly on",
        "start": 1048.679,
        "duration": 4.981
    },
    {
        "text": "a diverse set of input data",
        "start": 1051.08,
        "duration": 4.8
    },
    {
        "text": "we leverage global average schooling to",
        "start": 1053.66,
        "duration": 4.62
    },
    {
        "text": "handle variable length sequences",
        "start": 1055.88,
        "duration": 4.74
    },
    {
        "text": "and we use new training data sources to",
        "start": 1058.28,
        "duration": 3.96
    },
    {
        "text": "improve the ability of our model to",
        "start": 1060.62,
        "duration": 5.96
    },
    {
        "text": "classify a diverse set of open data",
        "start": 1062.24,
        "duration": 4.34
    },
    {
        "text": "okay now I'm going to be getting into a",
        "start": 1068.299,
        "duration": 5.581
    },
    {
        "text": "comparison of a maze um to other non-ml",
        "start": 1070.88,
        "duration": 5.159
    },
    {
        "text": "based host depletion methods as well as",
        "start": 1073.88,
        "duration": 4.919
    },
    {
        "text": "a comparison of a maze plus metagenomic",
        "start": 1076.039,
        "duration": 4.5
    },
    {
        "text": "classification methods compared to those",
        "start": 1078.799,
        "duration": 3.901
    },
    {
        "text": "methods alone so first for our host",
        "start": 1080.539,
        "duration": 4.201
    },
    {
        "text": "depletion comparison we're comparing a",
        "start": 1082.7,
        "duration": 4.08
    },
    {
        "text": "maze's ability to perform host depletion",
        "start": 1084.74,
        "duration": 3.84
    },
    {
        "text": "to other computational host depletion",
        "start": 1086.78,
        "duration": 3.779
    },
    {
        "text": "methods and this is a binary task of",
        "start": 1088.58,
        "duration": 3.66
    },
    {
        "text": "determining whether a sequence is from a",
        "start": 1090.559,
        "duration": 4.441
    },
    {
        "text": "host or not from a host then we have our",
        "start": 1092.24,
        "duration": 4.559
    },
    {
        "text": "metagenomic classification comparison",
        "start": 1095.0,
        "duration": 3.84
    },
    {
        "text": "where we're comparing the metagenomic",
        "start": 1096.799,
        "duration": 3.781
    },
    {
        "text": "classification pipelines with and",
        "start": 1098.84,
        "duration": 3.719
    },
    {
        "text": "without a maze and this is a multi-class",
        "start": 1100.58,
        "duration": 4.219
    },
    {
        "text": "task",
        "start": 1102.559,
        "duration": 2.24
    },
    {
        "text": "so our hypotheses here are that first a",
        "start": 1106.46,
        "duration": 4.56
    },
    {
        "text": "maze will be more accurate and cheaper",
        "start": 1109.16,
        "duration": 3.36
    },
    {
        "text": "than k-mer and alignment-based",
        "start": 1111.02,
        "duration": 3.48
    },
    {
        "text": "approaches at performing host depletion",
        "start": 1112.52,
        "duration": 4.32
    },
    {
        "text": "and our second hypothesis is that Amaze",
        "start": 1114.5,
        "duration": 4.32
    },
    {
        "text": "will improve the accuracy and efficiency",
        "start": 1116.84,
        "duration": 6.38
    },
    {
        "text": "of genomic classification methods",
        "start": 1118.82,
        "duration": 4.4
    },
    {
        "text": "we have five test sets that we're",
        "start": 1125.299,
        "duration": 4.321
    },
    {
        "text": "looking at for this evaluation and each",
        "start": 1127.16,
        "duration": 4.019
    },
    {
        "text": "test set varied in the percentage of",
        "start": 1129.62,
        "duration": 3.36
    },
    {
        "text": "breeds of the sample that pertained to",
        "start": 1131.179,
        "duration": 4.081
    },
    {
        "text": "host in our first test set we have one",
        "start": 1132.98,
        "duration": 4.8
    },
    {
        "text": "percent host data at 99 microbial data",
        "start": 1135.26,
        "duration": 5.52
    },
    {
        "text": "the second one has 25 host data 75",
        "start": 1137.78,
        "duration": 5.58
    },
    {
        "text": "microbial data the fifth one resembles a",
        "start": 1140.78,
        "duration": 5.04
    },
    {
        "text": "gut microbiome with 50 host data 50",
        "start": 1143.36,
        "duration": 4.98
    },
    {
        "text": "microbial data the fourth one we have 75",
        "start": 1145.82,
        "duration": 6.18
    },
    {
        "text": "host uh 25 microbial data and our last",
        "start": 1148.34,
        "duration": 5.52
    },
    {
        "text": "one the most copious amount of host",
        "start": 1152.0,
        "duration": 3.84
    },
    {
        "text": "sequences resembles the lung microbiome",
        "start": 1153.86,
        "duration": 4.439
    },
    {
        "text": "with 99 host data and one percent",
        "start": 1155.84,
        "duration": 5.6
    },
    {
        "text": "microbial data",
        "start": 1158.299,
        "duration": 3.141
    },
    {
        "text": "and so we use two different environments",
        "start": 1161.48,
        "duration": 4.8
    },
    {
        "text": "for our evaluation we evaluated a maze",
        "start": 1163.82,
        "duration": 4.56
    },
    {
        "text": "on a laptop-like environment since this",
        "start": 1166.28,
        "duration": 4.019
    },
    {
        "text": "applies broadly in resource constrained",
        "start": 1168.38,
        "duration": 3.9
    },
    {
        "text": "settings but some of our existing",
        "start": 1170.299,
        "duration": 4.201
    },
    {
        "text": "approaches minimap 2 and Kraken 2 were",
        "start": 1172.28,
        "duration": 4.139
    },
    {
        "text": "not able to run successfully on a laptop",
        "start": 1174.5,
        "duration": 3.96
    },
    {
        "text": "environment due to memory and storage",
        "start": 1176.419,
        "duration": 4.441
    },
    {
        "text": "constraints so we also evaluated all",
        "start": 1178.46,
        "duration": 4.02
    },
    {
        "text": "methods on a server for a fair",
        "start": 1180.86,
        "duration": 3.72
    },
    {
        "text": "comparison and the only evaluation",
        "start": 1182.48,
        "duration": 3.66
    },
    {
        "text": "metric that changed based on",
        "start": 1184.58,
        "duration": 3.18
    },
    {
        "text": "computational environment was the speed",
        "start": 1186.14,
        "duration": 3.48
    },
    {
        "text": "so when I present the results first I'm",
        "start": 1187.76,
        "duration": 3.299
    },
    {
        "text": "going to be delving into our server",
        "start": 1189.62,
        "duration": 3.36
    },
    {
        "text": "results with all the methods and then",
        "start": 1191.059,
        "duration": 3.661
    },
    {
        "text": "showing you how the speed changed when",
        "start": 1192.98,
        "duration": 5.54
    },
    {
        "text": "we moved to laptop like environment",
        "start": 1194.72,
        "duration": 3.8
    },
    {
        "text": "so first for our host depletion",
        "start": 1200.12,
        "duration": 3.6
    },
    {
        "text": "comparison where we were comparing",
        "start": 1202.22,
        "duration": 2.76
    },
    {
        "text": "amazing's ability to perform",
        "start": 1203.72,
        "duration": 3.24
    },
    {
        "text": "post-depletion to other computational",
        "start": 1204.98,
        "duration": 4.38
    },
    {
        "text": "host depletion methods our hypothesis",
        "start": 1206.96,
        "duration": 4.2
    },
    {
        "text": "here is that a maze will be more",
        "start": 1209.36,
        "duration": 3.48
    },
    {
        "text": "accurate and cheaper than camera and",
        "start": 1211.16,
        "duration": 3.66
    },
    {
        "text": "alignment-based approaches at performing",
        "start": 1212.84,
        "duration": 4.82
    },
    {
        "text": "host depletion",
        "start": 1214.82,
        "duration": 2.84
    },
    {
        "text": "and just as a reminder of the host",
        "start": 1218.9,
        "duration": 4.019
    },
    {
        "text": "depletion schematic workflow we have our",
        "start": 1220.64,
        "duration": 4.98
    },
    {
        "text": "of the metagenomic sequencing output of",
        "start": 1222.919,
        "duration": 5.101
    },
    {
        "text": "a sample or all of the DNA in that",
        "start": 1225.62,
        "duration": 5.22
    },
    {
        "text": "sample the host depletion method removes",
        "start": 1228.02,
        "duration": 4.68
    },
    {
        "text": "the host sequences and outputs the",
        "start": 1230.84,
        "duration": 3.719
    },
    {
        "text": "microbial sequences to be used for",
        "start": 1232.7,
        "duration": 4.14
    },
    {
        "text": "Downstream methods and the three methods",
        "start": 1234.559,
        "duration": 3.901
    },
    {
        "text": "that we're comparing out to amaze are",
        "start": 1236.84,
        "duration": 4.079
    },
    {
        "text": "Kraken 2 centrifuge and minimap2 or if",
        "start": 1238.46,
        "duration": 3.959
    },
    {
        "text": "you remember cracking two and centrifuge",
        "start": 1240.919,
        "duration": 3.301
    },
    {
        "text": "are the lookup table-based methods and",
        "start": 1242.419,
        "duration": 6.021
    },
    {
        "text": "minimap2 is the alignment based method",
        "start": 1244.22,
        "duration": 4.22
    },
    {
        "text": "okay so here are the results of our host",
        "start": 1249.62,
        "duration": 4.559
    },
    {
        "text": "depletion comparison first I'm going to",
        "start": 1252.38,
        "duration": 3.419
    },
    {
        "text": "be talking about our accuracy",
        "start": 1254.179,
        "duration": 3.12
    },
    {
        "text": "sensitivity and specificity results",
        "start": 1255.799,
        "duration": 3.601
    },
    {
        "text": "where we all want all of these metrics",
        "start": 1257.299,
        "duration": 4.981
    },
    {
        "text": "to be high on the y-axis of all of these",
        "start": 1259.4,
        "duration": 4.62
    },
    {
        "text": "graphs we have accuracy sensitivity and",
        "start": 1262.28,
        "duration": 3.96
    },
    {
        "text": "specificity and on the x-axis we have",
        "start": 1264.02,
        "duration": 4.019
    },
    {
        "text": "the host fraction varied from one",
        "start": 1266.24,
        "duration": 5.1
    },
    {
        "text": "percent to 99 and amazes performance is",
        "start": 1268.039,
        "duration": 5.88
    },
    {
        "text": "in purple and our baselines are in red",
        "start": 1271.34,
        "duration": 4.32
    },
    {
        "text": "blue and green",
        "start": 1273.919,
        "duration": 4.38
    },
    {
        "text": "so we see here across all host fractions",
        "start": 1275.66,
        "duration": 4.98
    },
    {
        "text": "Amaze consistently achieves a higher",
        "start": 1278.299,
        "duration": 4.981
    },
    {
        "text": "accuracy here and sensitivity as well as",
        "start": 1280.64,
        "duration": 4.74
    },
    {
        "text": "a comparable specificity compared to the",
        "start": 1283.28,
        "duration": 4.38
    },
    {
        "text": "baselines and it's especially notable",
        "start": 1285.38,
        "duration": 4.26
    },
    {
        "text": "that as we increase the host fraction",
        "start": 1287.66,
        "duration": 3.96
    },
    {
        "text": "all of our Baseline methods start to",
        "start": 1289.64,
        "duration": 4.56
    },
    {
        "text": "decrease in accuracy while Amaze as",
        "start": 1291.62,
        "duration": 6.14
    },
    {
        "text": "performance remains pretty consistent",
        "start": 1294.2,
        "duration": 3.56
    },
    {
        "text": "next looking at storage where we want",
        "start": 1298.64,
        "duration": 4.38
    },
    {
        "text": "all of these metrics to be low a maze is",
        "start": 1300.679,
        "duration": 3.48
    },
    {
        "text": "still in purple compared to our",
        "start": 1303.02,
        "duration": 3.24
    },
    {
        "text": "baselines in the other colors a maze",
        "start": 1304.159,
        "duration": 3.961
    },
    {
        "text": "requires Less storage compared to all of",
        "start": 1306.26,
        "duration": 4.08
    },
    {
        "text": "our methods and remains competitive with",
        "start": 1308.12,
        "duration": 4.559
    },
    {
        "text": "respect to Peak memory usage compared to",
        "start": 1310.34,
        "duration": 4.5
    },
    {
        "text": "our baselines so a maze is the lowest",
        "start": 1312.679,
        "duration": 4.441
    },
    {
        "text": "storage requirements here and has lower",
        "start": 1314.84,
        "duration": 4.8
    },
    {
        "text": "Peak memory requirements than minimap 2",
        "start": 1317.12,
        "duration": 4.439
    },
    {
        "text": "which has significantly High deep memory",
        "start": 1319.64,
        "duration": 3.779
    },
    {
        "text": "usage and remains competitive with",
        "start": 1321.559,
        "duration": 2.821
    },
    {
        "text": "respective",
        "start": 1323.419,
        "duration": 3.801
    },
    {
        "text": "and centrifugal",
        "start": 1324.38,
        "duration": 2.84
    },
    {
        "text": "field for our final evaluation metric of",
        "start": 1327.26,
        "duration": 4.5
    },
    {
        "text": "classification time where we also want",
        "start": 1330.08,
        "duration": 3.959
    },
    {
        "text": "this to be low we see that amaze and",
        "start": 1331.76,
        "duration": 4.02
    },
    {
        "text": "purple it remains competitive with",
        "start": 1334.039,
        "duration": 3.301
    },
    {
        "text": "respect to speed compared to our",
        "start": 1335.78,
        "duration": 3.779
    },
    {
        "text": "baselines and is especially faster than",
        "start": 1337.34,
        "duration": 4.14
    },
    {
        "text": "centrifuge we see here that centrifuge",
        "start": 1339.559,
        "duration": 5.161
    },
    {
        "text": "starts to get more and more slow as the",
        "start": 1341.48,
        "duration": 5.939
    },
    {
        "text": "host fraction the percentage of host uh",
        "start": 1344.72,
        "duration": 5.459
    },
    {
        "text": "DNA in the sample increases while amazes",
        "start": 1347.419,
        "duration": 4.38
    },
    {
        "text": "performance remains consistent and we",
        "start": 1350.179,
        "duration": 3.181
    },
    {
        "text": "see the same thing happening for minimap",
        "start": 1351.799,
        "duration": 3.74
    },
    {
        "text": "too",
        "start": 1353.36,
        "duration": 2.179
    },
    {
        "text": "okay now um for uh the change in",
        "start": 1357.44,
        "duration": 4.56
    },
    {
        "text": "performance on a laptop-like environment",
        "start": 1360.14,
        "duration": 3.84
    },
    {
        "text": "as I had said before the only evaluation",
        "start": 1362.0,
        "duration": 4.559
    },
    {
        "text": "metric that changed was speed",
        "start": 1363.98,
        "duration": 4.439
    },
    {
        "text": "um here on the x-axis we have our",
        "start": 1366.559,
        "duration": 3.661
    },
    {
        "text": "methods and on the y-axis classification",
        "start": 1368.419,
        "duration": 3.781
    },
    {
        "text": "time and each of these different graphs",
        "start": 1370.22,
        "duration": 3.54
    },
    {
        "text": "represents the performance on a",
        "start": 1372.2,
        "duration": 3.719
    },
    {
        "text": "different percentage of hosts compared",
        "start": 1373.76,
        "duration": 4.5
    },
    {
        "text": "to microbial data in the sample",
        "start": 1375.919,
        "duration": 4.861
    },
    {
        "text": "we see here that across the board all",
        "start": 1378.26,
        "duration": 4.56
    },
    {
        "text": "methods were slower on the laptop-like",
        "start": 1380.78,
        "duration": 4.019
    },
    {
        "text": "environment than on the server we have",
        "start": 1382.82,
        "duration": 4.32
    },
    {
        "text": "in red these bars are the speed on a",
        "start": 1384.799,
        "duration": 4.801
    },
    {
        "text": "laptop-like environment in blue we have",
        "start": 1387.14,
        "duration": 5.039
    },
    {
        "text": "the speed on the server and we see that",
        "start": 1389.6,
        "duration": 4.74
    },
    {
        "text": "classification time increases the red",
        "start": 1392.179,
        "duration": 3.48
    },
    {
        "text": "bars are always bigger than the blue",
        "start": 1394.34,
        "duration": 3.36
    },
    {
        "text": "bars meeting that our classification",
        "start": 1395.659,
        "duration": 4.921
    },
    {
        "text": "time increased on the laptop compared to",
        "start": 1397.7,
        "duration": 5.28
    },
    {
        "text": "the server however a maze still remain",
        "start": 1400.58,
        "duration": 4.74
    },
    {
        "text": "faster than centrifuge on all test sets",
        "start": 1402.98,
        "duration": 3.96
    },
    {
        "text": "with the host fraction greater than one",
        "start": 1405.32,
        "duration": 3.599
    },
    {
        "text": "percent so when we have one percent host",
        "start": 1406.94,
        "duration": 4.14
    },
    {
        "text": "data a maze is the slowest method on the",
        "start": 1408.919,
        "duration": 4.26
    },
    {
        "text": "laptop but as we increase the percentage",
        "start": 1411.08,
        "duration": 4.62
    },
    {
        "text": "of host data in our sample a maze starts",
        "start": 1413.179,
        "duration": 5.48
    },
    {
        "text": "to yes lower or faster than centrifuge",
        "start": 1415.7,
        "duration": 5.4
    },
    {
        "text": "classification time continues to",
        "start": 1418.659,
        "duration": 4.0
    },
    {
        "text": "increase as we increase the amount of",
        "start": 1421.1,
        "duration": 4.98
    },
    {
        "text": "host data in our sample",
        "start": 1422.659,
        "duration": 6.201
    },
    {
        "text": "foreign",
        "start": 1426.08,
        "duration": 2.78
    },
    {
        "text": "metagenomic classification comparison",
        "start": 1430.539,
        "duration": 4.781
    },
    {
        "text": "which is a comparison of our metagenomic",
        "start": 1432.74,
        "duration": 4.439
    },
    {
        "text": "classification pipelines with and",
        "start": 1435.32,
        "duration": 3.239
    },
    {
        "text": "without a maze",
        "start": 1437.179,
        "duration": 3.541
    },
    {
        "text": "and a hypothesis here is that a maze",
        "start": 1438.559,
        "duration": 4.921
    },
    {
        "text": "improves the accuracy and efficiency of",
        "start": 1440.72,
        "duration": 6.62
    },
    {
        "text": "metagenomic classification methods",
        "start": 1443.48,
        "duration": 3.86
    },
    {
        "text": "okay just as a reminder of the",
        "start": 1453.559,
        "duration": 4.381
    },
    {
        "text": "metagenomic classification and schematic",
        "start": 1456.08,
        "duration": 3.719
    },
    {
        "text": "workflow we're comparing two different",
        "start": 1457.94,
        "duration": 4.26
    },
    {
        "text": "pipelines here the first is in",
        "start": 1459.799,
        "duration": 4.62
    },
    {
        "text": "highlighted in Orange where we have our",
        "start": 1462.2,
        "duration": 4.32
    },
    {
        "text": "metagenomic sequencing output that we",
        "start": 1464.419,
        "duration": 3.901
    },
    {
        "text": "feed into a metagenomic classification",
        "start": 1466.52,
        "duration": 3.84
    },
    {
        "text": "method that needs both host and",
        "start": 1468.32,
        "duration": 4.02
    },
    {
        "text": "microbial DNA in the reference database",
        "start": 1470.36,
        "duration": 4.439
    },
    {
        "text": "to do classification we're comparing",
        "start": 1472.34,
        "duration": 4.44
    },
    {
        "text": "that to this pipeline here where we",
        "start": 1474.799,
        "duration": 3.721
    },
    {
        "text": "input the metagenomic sequencing output",
        "start": 1476.78,
        "duration": 3.779
    },
    {
        "text": "into a host depletion method that",
        "start": 1478.52,
        "duration": 3.779
    },
    {
        "text": "removes the host sequences and then",
        "start": 1480.559,
        "duration": 3.961
    },
    {
        "text": "inputs microbial sequences into a",
        "start": 1482.299,
        "duration": 4.321
    },
    {
        "text": "metagenomic classification method that",
        "start": 1484.52,
        "duration": 3.84
    },
    {
        "text": "only needs microbial DNA in the",
        "start": 1486.62,
        "duration": 3.059
    },
    {
        "text": "reference database to do the",
        "start": 1488.36,
        "duration": 3.48
    },
    {
        "text": "classification and the methods that",
        "start": 1489.679,
        "duration": 4.5
    },
    {
        "text": "we're comparing here are centrifuge with",
        "start": 1491.84,
        "duration": 4.199
    },
    {
        "text": "host and microbial DNA in the reference",
        "start": 1494.179,
        "duration": 4.321
    },
    {
        "text": "database as our Baseline compared to a",
        "start": 1496.039,
        "duration": 4.561
    },
    {
        "text": "maze plus centrifuge so a maze plus",
        "start": 1498.5,
        "duration": 4.5
    },
    {
        "text": "centrifuge with just microbial DNA in",
        "start": 1500.6,
        "duration": 4.559
    },
    {
        "text": "the reference database and we focus our",
        "start": 1503.0,
        "duration": 3.9
    },
    {
        "text": "comparison on centrifuge which and",
        "start": 1505.159,
        "duration": 3.421
    },
    {
        "text": "without a maze since centrifuge",
        "start": 1506.9,
        "duration": 3.72
    },
    {
        "text": "outperformed Kraken 2 on every metric",
        "start": 1508.58,
        "duration": 4.32
    },
    {
        "text": "except for classification time but I",
        "start": 1510.62,
        "duration": 4.559
    },
    {
        "text": "have the results for cracking to in an",
        "start": 1512.9,
        "duration": 5.72
    },
    {
        "text": "appendix if anyone is interested",
        "start": 1515.179,
        "duration": 3.441
    },
    {
        "text": "okay so first I'm going to be showing",
        "start": 1520.82,
        "duration": 4.92
    },
    {
        "text": "you the results of host accuracy where",
        "start": 1523.76,
        "duration": 3.899
    },
    {
        "text": "we want higher to be better and we have",
        "start": 1525.74,
        "duration": 3.679
    },
    {
        "text": "a maze plus centrifuge in purple",
        "start": 1527.659,
        "duration": 4.5
    },
    {
        "text": "centrifuge in bread we see here that the",
        "start": 1529.419,
        "duration": 4.181
    },
    {
        "text": "pipeline that included a maze",
        "start": 1532.159,
        "duration": 3.241
    },
    {
        "text": "consistently achieved a higher host",
        "start": 1533.6,
        "duration": 3.78
    },
    {
        "text": "accuracy compared to the pipeline",
        "start": 1535.4,
        "duration": 4.62
    },
    {
        "text": "without a maze and this is a cross hose",
        "start": 1537.38,
        "duration": 4.62
    },
    {
        "text": "fraction again on the x-axis host",
        "start": 1540.02,
        "duration": 4.38
    },
    {
        "text": "accuracy here on the y-axis",
        "start": 1542.0,
        "duration": 4.559
    },
    {
        "text": "when we look at Cost where we want that",
        "start": 1544.4,
        "duration": 4.44
    },
    {
        "text": "to be lower Peak memory usage",
        "start": 1546.559,
        "duration": 4.5
    },
    {
        "text": "specifically a maze reduces the peak",
        "start": 1548.84,
        "duration": 4.319
    },
    {
        "text": "memory usage requirements for centrifuge",
        "start": 1551.059,
        "duration": 3.72
    },
    {
        "text": "the pipeline with the Maze and",
        "start": 1553.159,
        "duration": 3.661
    },
    {
        "text": "centrifuge had a lower Peak memory usage",
        "start": 1554.779,
        "duration": 5.041
    },
    {
        "text": "than centrifugal which is what we want",
        "start": 1556.82,
        "duration": 4.979
    },
    {
        "text": "and then finally speed where we also",
        "start": 1559.82,
        "duration": 5.099
    },
    {
        "text": "want classification time to be lower we",
        "start": 1561.799,
        "duration": 4.801
    },
    {
        "text": "see that the pipeline with amazes",
        "start": 1564.919,
        "duration": 4.14
    },
    {
        "text": "classification time decreases as the",
        "start": 1566.6,
        "duration": 4.26
    },
    {
        "text": "percentage of host data in the test set",
        "start": 1569.059,
        "duration": 3.901
    },
    {
        "text": "increases while the pipeline without",
        "start": 1570.86,
        "duration": 4.74
    },
    {
        "text": "amazes classification time increased so",
        "start": 1572.96,
        "duration": 5.4
    },
    {
        "text": "when we have one percent post DNA in the",
        "start": 1575.6,
        "duration": 5.1
    },
    {
        "text": "sample a maze plus centrifuge is slower",
        "start": 1578.36,
        "duration": 4.14
    },
    {
        "text": "than centrifuge but as we start to",
        "start": 1580.7,
        "duration": 4.02
    },
    {
        "text": "increase the percentage of host data in",
        "start": 1582.5,
        "duration": 4.74
    },
    {
        "text": "the sample amazeball centrifuge becomes",
        "start": 1584.72,
        "duration": 4.439
    },
    {
        "text": "faster than centrifuges classification",
        "start": 1587.24,
        "duration": 5.299
    },
    {
        "text": "time continues to increase",
        "start": 1589.159,
        "duration": 3.38
    },
    {
        "text": "okay so um looking at our comparisons on",
        "start": 1594.32,
        "duration": 5.52
    },
    {
        "text": "a laptop-like environment we're again",
        "start": 1598.22,
        "duration": 3.959
    },
    {
        "text": "the only evaluation metric that um",
        "start": 1599.84,
        "duration": 4.74
    },
    {
        "text": "changed with speed we have here this",
        "start": 1602.179,
        "duration": 5.1
    },
    {
        "text": "classification time of our methods on a",
        "start": 1604.58,
        "duration": 5.4
    },
    {
        "text": "laptop-like environment in red and then",
        "start": 1607.279,
        "duration": 4.981
    },
    {
        "text": "the classification times of our methods",
        "start": 1609.98,
        "duration": 5.28
    },
    {
        "text": "on a server in blue again like on the",
        "start": 1612.26,
        "duration": 4.68
    },
    {
        "text": "host depletion comparison results that I",
        "start": 1615.26,
        "duration": 2.94
    },
    {
        "text": "had shown before",
        "start": 1616.94,
        "duration": 2.88
    },
    {
        "text": "um the red bars are always bigger than",
        "start": 1618.2,
        "duration": 3.42
    },
    {
        "text": "the blue bars so all methods ended up",
        "start": 1619.82,
        "duration": 3.239
    },
    {
        "text": "being slower on the laptop-like",
        "start": 1621.62,
        "duration": 3.72
    },
    {
        "text": "environment than on the server",
        "start": 1623.059,
        "duration": 4.5
    },
    {
        "text": "but a maze plus centrifuge remained",
        "start": 1625.34,
        "duration": 4.38
    },
    {
        "text": "faster than centrifuge on all test sets",
        "start": 1627.559,
        "duration": 5.161
    },
    {
        "text": "with a host fraction above 25 so if we",
        "start": 1629.72,
        "duration": 5.339
    },
    {
        "text": "look at these two um",
        "start": 1632.72,
        "duration": 4.62
    },
    {
        "text": "data sets we see the Amaze placentrifuge",
        "start": 1635.059,
        "duration": 4.381
    },
    {
        "text": "ends up being slower than centrifuge but",
        "start": 1637.34,
        "duration": 4.199
    },
    {
        "text": "as we increase the amount of host data",
        "start": 1639.44,
        "duration": 4.68
    },
    {
        "text": "in our sample a mazebo centrifuge starts",
        "start": 1641.539,
        "duration": 4.62
    },
    {
        "text": "to become faster than centrifuge ending",
        "start": 1644.12,
        "duration": 4.32
    },
    {
        "text": "here with 99 host data or a baseball",
        "start": 1646.159,
        "duration": 3.841
    },
    {
        "text": "centrifuge each of us faster than",
        "start": 1648.44,
        "duration": 4.04
    },
    {
        "text": "centrifuge",
        "start": 1650.0,
        "duration": 2.48
    },
    {
        "text": "okay so our takeaways from this section",
        "start": 1654.38,
        "duration": 4.74
    },
    {
        "text": "we developed a novel machine learning",
        "start": 1656.659,
        "duration": 4.441
    },
    {
        "text": "based host depletion method a maze that",
        "start": 1659.12,
        "duration": 3.419
    },
    {
        "text": "can perform variable length sequence",
        "start": 1661.1,
        "duration": 3.9
    },
    {
        "text": "classification accurately and quickly on",
        "start": 1662.539,
        "duration": 4.681
    },
    {
        "text": "a diverse set of input data and we",
        "start": 1665.0,
        "duration": 4.26
    },
    {
        "text": "rigorously evaluated our approach and",
        "start": 1667.22,
        "duration": 3.959
    },
    {
        "text": "found that it had higher accuracy and",
        "start": 1669.26,
        "duration": 3.48
    },
    {
        "text": "lower storage requirements than other",
        "start": 1671.179,
        "duration": 3.841
    },
    {
        "text": "computational depletion methods and it",
        "start": 1672.74,
        "duration": 3.72
    },
    {
        "text": "improved the accuracy and cost",
        "start": 1675.02,
        "duration": 3.72
    },
    {
        "text": "effectiveness of Downstream metagenomic",
        "start": 1676.46,
        "duration": 5.42
    },
    {
        "text": "classification methods",
        "start": 1678.74,
        "duration": 3.14
    },
    {
        "text": "finally I'm going to end with some",
        "start": 1684.38,
        "duration": 4.26
    },
    {
        "text": "results related to interpreting our",
        "start": 1686.659,
        "duration": 4.76
    },
    {
        "text": "machine learning model",
        "start": 1688.64,
        "duration": 2.779
    },
    {
        "text": "so specifically the question that I'm",
        "start": 1692.9,
        "duration": 4.32
    },
    {
        "text": "want to answer in this section are what",
        "start": 1695.0,
        "duration": 4.5
    },
    {
        "text": "cameras are the most important by a maze",
        "start": 1697.22,
        "duration": 4.439
    },
    {
        "text": "for classification and the camera as I",
        "start": 1699.5,
        "duration": 4.02
    },
    {
        "text": "said in the background section are",
        "start": 1701.659,
        "duration": 4.38
    },
    {
        "text": "substrings of length k for example with",
        "start": 1703.52,
        "duration": 6.36
    },
    {
        "text": "this sequence AGC TCC the formers are",
        "start": 1706.039,
        "duration": 5.52
    },
    {
        "text": "the first for",
        "start": 1709.88,
        "duration": 4.5
    },
    {
        "text": "um nucleotides in this sequence agct",
        "start": 1711.559,
        "duration": 7.021
    },
    {
        "text": "then gctc and then finally ctcc",
        "start": 1714.38,
        "duration": 6.179
    },
    {
        "text": "and the interpretability method that",
        "start": 1718.58,
        "duration": 3.959
    },
    {
        "text": "we're using to examine the gamers that",
        "start": 1720.559,
        "duration": 3.48
    },
    {
        "text": "are deemed most important by amazing",
        "start": 1722.539,
        "duration": 3.721
    },
    {
        "text": "classification is called deep lift and",
        "start": 1724.039,
        "duration": 4.321
    },
    {
        "text": "this method identifies the importance of",
        "start": 1726.26,
        "duration": 3.659
    },
    {
        "text": "input features on a machine learning",
        "start": 1728.36,
        "duration": 4.02
    },
    {
        "text": "model's classification and specifically",
        "start": 1729.919,
        "duration": 4.5
    },
    {
        "text": "on a randomly selected subset of",
        "start": 1732.38,
        "duration": 3.96
    },
    {
        "text": "sequences in our test set we were",
        "start": 1734.419,
        "duration": 3.721
    },
    {
        "text": "determining the 15 words that",
        "start": 1736.34,
        "duration": 3.54
    },
    {
        "text": "contributed to amaze's classification",
        "start": 1738.14,
        "duration": 3.659
    },
    {
        "text": "decision and we looked at 15 words",
        "start": 1739.88,
        "duration": 3.36
    },
    {
        "text": "because this is the length of",
        "start": 1741.799,
        "duration": 3.48
    },
    {
        "text": "subsequence that Kraken 2 uses to",
        "start": 1743.24,
        "duration": 5.24
    },
    {
        "text": "perform its classification",
        "start": 1745.279,
        "duration": 3.201
    },
    {
        "text": "so first I examined the 15 verse that",
        "start": 1749.0,
        "duration": 4.08
    },
    {
        "text": "most contributed to a microbial",
        "start": 1751.52,
        "duration": 3.6
    },
    {
        "text": "classification or the way to interpret",
        "start": 1753.08,
        "duration": 4.38
    },
    {
        "text": "this histogram is they least contributed",
        "start": 1755.12,
        "duration": 4.38
    },
    {
        "text": "to a host classification so we see the",
        "start": 1757.46,
        "duration": 3.54
    },
    {
        "text": "contribution to a host classification",
        "start": 1759.5,
        "duration": 3.48
    },
    {
        "text": "label that's negative which means these",
        "start": 1761.0,
        "duration": 3.6
    },
    {
        "text": "sequences contributed to a microbial",
        "start": 1762.98,
        "duration": 3.72
    },
    {
        "text": "classification label so the way to",
        "start": 1764.6,
        "duration": 4.02
    },
    {
        "text": "interpret this graph is the histogram",
        "start": 1766.7,
        "duration": 5.099
    },
    {
        "text": "shows you how much this entire 15 Mark",
        "start": 1768.62,
        "duration": 5.279
    },
    {
        "text": "contributed to a microbial",
        "start": 1771.799,
        "duration": 4.441
    },
    {
        "text": "classification label and then this is",
        "start": 1773.899,
        "duration": 4.801
    },
    {
        "text": "these are the five the top five 15 words",
        "start": 1776.24,
        "duration": 4.5
    },
    {
        "text": "that contributed most to a microbial",
        "start": 1778.7,
        "duration": 4.44
    },
    {
        "text": "classification label and the nucleotides",
        "start": 1780.74,
        "duration": 5.64
    },
    {
        "text": "here are the color around them is dark",
        "start": 1783.14,
        "duration": 4.86
    },
    {
        "text": "based on how much they individually",
        "start": 1786.38,
        "duration": 5.659
    },
    {
        "text": "contributed to this final score",
        "start": 1788.0,
        "duration": 4.039
    },
    {
        "text": "um",
        "start": 1792.08,
        "duration": 2.94
    },
    {
        "text": "so the main takeaway that we found from",
        "start": 1792.679,
        "duration": 5.281
    },
    {
        "text": "these five 15 words in terms of how much",
        "start": 1795.02,
        "duration": 4.2
    },
    {
        "text": "they contributed to the microbial",
        "start": 1797.96,
        "duration": 3.959
    },
    {
        "text": "classification label is that four out of",
        "start": 1799.22,
        "duration": 4.079
    },
    {
        "text": "the five of them contain a",
        "start": 1801.919,
        "duration": 4.38
    },
    {
        "text": "cg-diducleotide",
        "start": 1803.299,
        "duration": 3.0
    },
    {
        "text": "and this is in comparison to when we",
        "start": 1807.62,
        "duration": 3.84
    },
    {
        "text": "look at the 15 verse that most",
        "start": 1809.6,
        "duration": 3.42
    },
    {
        "text": "contributed to a host classification",
        "start": 1811.46,
        "duration": 4.26
    },
    {
        "text": "label none of them contain that CG",
        "start": 1813.02,
        "duration": 4.86
    },
    {
        "text": "dinucleotide",
        "start": 1815.72,
        "duration": 4.079
    },
    {
        "text": "uh so they all they all had an absence",
        "start": 1817.88,
        "duration": 4.019
    },
    {
        "text": "of the CG dinucleotide and this is a",
        "start": 1819.799,
        "duration": 4.38
    },
    {
        "text": "phenomenon known as CG suppression and",
        "start": 1821.899,
        "duration": 3.601
    },
    {
        "text": "this is a phenomenon that CG",
        "start": 1824.179,
        "duration": 3.841
    },
    {
        "text": "dinucleotides are uncommon in vertebrate",
        "start": 1825.5,
        "duration": 5.0
    },
    {
        "text": "genomes",
        "start": 1828.02,
        "duration": 2.48
    },
    {
        "text": "um so it is encouraging that Amaze",
        "start": 1832.22,
        "duration": 4.319
    },
    {
        "text": "captures known biological phenomena and",
        "start": 1834.02,
        "duration": 4.019
    },
    {
        "text": "this indicates that a maze can",
        "start": 1836.539,
        "duration": 3.601
    },
    {
        "text": "generalize to classify data from species",
        "start": 1838.039,
        "duration": 4.38
    },
    {
        "text": "not present in the training set we try",
        "start": 1840.14,
        "duration": 4.919
    },
    {
        "text": "to include a variety of species in our",
        "start": 1842.419,
        "duration": 4.801
    },
    {
        "text": "training set but the fact that Amaze was",
        "start": 1845.059,
        "duration": 3.36
    },
    {
        "text": "able to pick up on this General",
        "start": 1847.22,
        "duration": 3.48
    },
    {
        "text": "biological phenomena is an indication",
        "start": 1848.419,
        "duration": 5.101
    },
    {
        "text": "that a maze can generalize to unseen",
        "start": 1850.7,
        "duration": 6.38
    },
    {
        "text": "data from what it was trained on",
        "start": 1853.52,
        "duration": 3.56
    },
    {
        "text": "however this might lead some of you to",
        "start": 1857.36,
        "duration": 4.199
    },
    {
        "text": "think that Amaze is solely relying on CG",
        "start": 1859.399,
        "duration": 4.321
    },
    {
        "text": "to classify our inputs which we found",
        "start": 1861.559,
        "duration": 4.74
    },
    {
        "text": "that it's not compared to a classifier",
        "start": 1863.72,
        "duration": 4.98
    },
    {
        "text": "that only uses the percent of CG in a",
        "start": 1866.299,
        "duration": 3.841
    },
    {
        "text": "sequence to make its classification",
        "start": 1868.7,
        "duration": 3.42
    },
    {
        "text": "decision a maze had a much higher",
        "start": 1870.14,
        "duration": 5.899
    },
    {
        "text": "accuracy than that method",
        "start": 1872.12,
        "duration": 3.919
    },
    {
        "text": "we also found that existing camera and",
        "start": 1877.88,
        "duration": 5.039
    },
    {
        "text": "alignment-based methods rely on CG",
        "start": 1880.88,
        "duration": 4.38
    },
    {
        "text": "content to a much larger extent than a",
        "start": 1882.919,
        "duration": 4.14
    },
    {
        "text": "maze so these graphs here we show",
        "start": 1885.26,
        "duration": 4.86
    },
    {
        "text": "accuracy sensitivity and specificity",
        "start": 1887.059,
        "duration": 4.921
    },
    {
        "text": "um compared to on the x-axis the percent",
        "start": 1890.12,
        "duration": 4.62
    },
    {
        "text": "of CG in our sequences and looking at",
        "start": 1891.98,
        "duration": 4.559
    },
    {
        "text": "sensitivity and specified activity is a",
        "start": 1894.74,
        "duration": 3.059
    },
    {
        "text": "little bit more interpretable than the",
        "start": 1896.539,
        "duration": 3.061
    },
    {
        "text": "accuracy plots if we look at our",
        "start": 1897.799,
        "duration": 4.201
    },
    {
        "text": "sensitivity plot here we see that as the",
        "start": 1899.6,
        "duration": 4.62
    },
    {
        "text": "percent of CG in sequences increases",
        "start": 1902.0,
        "duration": 4.38
    },
    {
        "text": "crack and centrifuge and mini-map2's",
        "start": 1904.22,
        "duration": 4.079
    },
    {
        "text": "performance significantly drops while",
        "start": 1906.38,
        "duration": 4.08
    },
    {
        "text": "amazes performance remains stable and",
        "start": 1908.299,
        "duration": 3.24
    },
    {
        "text": "this makes sense because they're",
        "start": 1910.46,
        "duration": 2.819
    },
    {
        "text": "supposed to be CG suppression in",
        "start": 1911.539,
        "duration": 3.841
    },
    {
        "text": "vertebrates so as there's more percent",
        "start": 1913.279,
        "duration": 5.041
    },
    {
        "text": "lcg in sequences existing",
        "start": 1915.38,
        "duration": 3.799
    },
    {
        "text": "um",
        "start": 1918.32,
        "duration": 2.82
    },
    {
        "text": "gamer and Alignment based methods",
        "start": 1919.179,
        "duration": 3.641
    },
    {
        "text": "struggle to classify those sequences",
        "start": 1921.14,
        "duration": 3.659
    },
    {
        "text": "while Amaze is able to classify them",
        "start": 1922.82,
        "duration": 3.719
    },
    {
        "text": "because it doesn't rely on the percent",
        "start": 1924.799,
        "duration": 3.841
    },
    {
        "text": "of CG as much as these methods and then",
        "start": 1926.539,
        "duration": 5.161
    },
    {
        "text": "when we look at specificity we see that",
        "start": 1928.64,
        "duration": 5.7
    },
    {
        "text": "uh Kraken 2 and centrifuge struggle to",
        "start": 1931.7,
        "duration": 4.8
    },
    {
        "text": "classify sequences with a small amount",
        "start": 1934.34,
        "duration": 4.199
    },
    {
        "text": "of CG because there isn't supposed to be",
        "start": 1936.5,
        "duration": 3.96
    },
    {
        "text": "CPU suppression in microbes and",
        "start": 1938.539,
        "duration": 3.901
    },
    {
        "text": "specificity measures the percent of",
        "start": 1940.46,
        "duration": 3.54
    },
    {
        "text": "microbes that were correctly identified",
        "start": 1942.44,
        "duration": 3.839
    },
    {
        "text": "but a maze is better able to classify",
        "start": 1944.0,
        "duration": 4.44
    },
    {
        "text": "those sequences so camera and Alignment",
        "start": 1946.279,
        "duration": 4.38
    },
    {
        "text": "based methods rely on CG content to a",
        "start": 1948.44,
        "duration": 5.839
    },
    {
        "text": "much larger extent than a maze",
        "start": 1950.659,
        "duration": 3.62
    },
    {
        "text": "so looking ahead accuracy speed and",
        "start": 1955.58,
        "duration": 5.16
    },
    {
        "text": "memory efficiency are all important in",
        "start": 1958.52,
        "duration": 4.08
    },
    {
        "text": "developing bedside clinical diagnostic",
        "start": 1960.74,
        "duration": 4.14
    },
    {
        "text": "Technologies high accuracy is important",
        "start": 1962.6,
        "duration": 4.5
    },
    {
        "text": "to ensure that appropriate treatments",
        "start": 1964.88,
        "duration": 4.2
    },
    {
        "text": "are selected speed is important to",
        "start": 1967.1,
        "duration": 3.6
    },
    {
        "text": "ensure the treatment can be given in a",
        "start": 1969.08,
        "duration": 3.959
    },
    {
        "text": "timely manner and memory efficiency is",
        "start": 1970.7,
        "duration": 4.199
    },
    {
        "text": "important to ensure the technology is",
        "start": 1973.039,
        "duration": 3.421
    },
    {
        "text": "broadly accessible",
        "start": 1974.899,
        "duration": 3.361
    },
    {
        "text": "given the improvements provided by",
        "start": 1976.46,
        "duration": 3.599
    },
    {
        "text": "adding a maze to the current metagenomic",
        "start": 1978.26,
        "duration": 4.139
    },
    {
        "text": "classification pipeline we believe that",
        "start": 1980.059,
        "duration": 4.261
    },
    {
        "text": "this work brings us one step closer to",
        "start": 1982.399,
        "duration": 4.26
    },
    {
        "text": "clinical Diagnostics via DNA sequencing",
        "start": 1984.32,
        "duration": 5.9
    },
    {
        "text": "Technologies at the bedside",
        "start": 1986.659,
        "duration": 3.561
    },
    {
        "text": "so here are some final takeaways a link",
        "start": 1990.919,
        "duration": 5.1
    },
    {
        "text": "to my paper my contact information if",
        "start": 1993.2,
        "duration": 4.64
    },
    {
        "text": "you would like to ask me any questions",
        "start": 1996.019,
        "duration": 4.5
    },
    {
        "text": "via email as well as the funding",
        "start": 1997.84,
        "duration": 4.42
    },
    {
        "text": "acknowledgments for this project thank",
        "start": 2000.519,
        "duration": 3.861
    },
    {
        "text": "you",
        "start": 2002.26,
        "duration": 2.12
    },
    {
        "text": "so if anyone online",
        "start": 2007.12,
        "duration": 3.02
    },
    {
        "text": "on the questions uh feel free to put",
        "start": 2010.32,
        "duration": 4.479
    },
    {
        "text": "them in the chat box or raise your zoom",
        "start": 2013.12,
        "duration": 3.72
    },
    {
        "text": "in and uh one of the room those",
        "start": 2014.799,
        "duration": 4.201
    },
    {
        "text": "questions feel free to ask almost",
        "start": 2016.84,
        "duration": 6.54
    },
    {
        "text": "nervous yeah uh great talk very much",
        "start": 2019.0,
        "duration": 6.96
    },
    {
        "text": "um so just to clarify do you guys used",
        "start": 2023.38,
        "duration": 5.519
    },
    {
        "text": "uh not of course sequence data to like",
        "start": 2025.96,
        "duration": 5.819
    },
    {
        "text": "for the model right so how like would",
        "start": 2028.899,
        "duration": 4.5
    },
    {
        "text": "you be able to apply other sequencing",
        "start": 2031.779,
        "duration": 5.161
    },
    {
        "text": "Technologies like shortly like the model",
        "start": 2033.399,
        "duration": 6.541
    },
    {
        "text": "as well yeah so since um Amaze was",
        "start": 2036.94,
        "duration": 5.04
    },
    {
        "text": "trained on base called reads it applies",
        "start": 2039.94,
        "duration": 5.219
    },
    {
        "text": "broadly to any input sequence uh I think",
        "start": 2041.98,
        "duration": 6.54
    },
    {
        "text": "to ensure that it would be I guess the",
        "start": 2045.159,
        "duration": 4.74
    },
    {
        "text": "most accurate",
        "start": 2048.52,
        "duration": 3.78
    },
    {
        "text": "um I would recommend retraining a maze",
        "start": 2049.899,
        "duration": 5.22
    },
    {
        "text": "to include I guess whatever specific",
        "start": 2052.3,
        "duration": 4.319
    },
    {
        "text": "sequence technology that you want to",
        "start": 2055.119,
        "duration": 3.841
    },
    {
        "text": "apply to but the fact that Amaze was",
        "start": 2056.619,
        "duration": 5.341
    },
    {
        "text": "able to learn I guess the presence of CG",
        "start": 2058.96,
        "duration": 5.1
    },
    {
        "text": "is indication that it could potentially",
        "start": 2061.96,
        "duration": 4.379
    },
    {
        "text": "apply broadly to other sequences from",
        "start": 2064.06,
        "duration": 3.779
    },
    {
        "text": "other sequencing Technologies but to",
        "start": 2066.339,
        "duration": 2.76
    },
    {
        "text": "ensure highest accuracy I would",
        "start": 2067.839,
        "duration": 3.241
    },
    {
        "text": "recommend retraining or adding those",
        "start": 2069.099,
        "duration": 4.52
    },
    {
        "text": "sequencies",
        "start": 2071.08,
        "duration": 2.539
    },
    {
        "text": "so",
        "start": 2076.119,
        "duration": 3.0
    },
    {
        "text": "um",
        "start": 2084.159,
        "duration": 2.121
    },
    {
        "text": "that was already labeled by like a some",
        "start": 2098.46,
        "duration": 7.06
    },
    {
        "text": "earlier ml method that that people with",
        "start": 2102.52,
        "duration": 4.74
    },
    {
        "text": "a sometimes there's kind of training on",
        "start": 2105.52,
        "duration": 3.24
    },
    {
        "text": "something that was already machine",
        "start": 2107.26,
        "duration": 2.839
    },
    {
        "text": "generated",
        "start": 2108.76,
        "duration": 5.4
    },
    {
        "text": "so you need to know it's better if a",
        "start": 2110.099,
        "duration": 5.861
    },
    {
        "text": "human can actually say like oh this cell",
        "start": 2114.16,
        "duration": 4.439
    },
    {
        "text": "was actually some type ABC or whatever",
        "start": 2115.96,
        "duration": 5.76
    },
    {
        "text": "so here like the labels must have come",
        "start": 2118.599,
        "duration": 6.421
    },
    {
        "text": "from somewhere for you to train a base",
        "start": 2121.72,
        "duration": 6.48
    },
    {
        "text": "algebra what that process was yes yeah",
        "start": 2125.02,
        "duration": 5.7
    },
    {
        "text": "so um the test sets that I presented",
        "start": 2128.2,
        "duration": 5.22
    },
    {
        "text": "here um are were synthetic microbiomes",
        "start": 2130.72,
        "duration": 5.399
    },
    {
        "text": "that we created so we got the",
        "start": 2133.42,
        "duration": 4.32
    },
    {
        "text": "um I think there's a human reference",
        "start": 2136.119,
        "duration": 4.921
    },
    {
        "text": "standard that was created in 2018",
        "start": 2137.74,
        "duration": 6.359
    },
    {
        "text": "um by some research group where uh I",
        "start": 2141.04,
        "duration": 4.799
    },
    {
        "text": "guess they had confirmed that all of the",
        "start": 2144.099,
        "duration": 4.561
    },
    {
        "text": "sequences in our in the um data that",
        "start": 2145.839,
        "duration": 4.561
    },
    {
        "text": "they provided were from a human so we",
        "start": 2148.66,
        "duration": 4.199
    },
    {
        "text": "used that and then we got our um",
        "start": 2150.4,
        "duration": 5.16
    },
    {
        "text": "bacterian fungal DNA in the same way so",
        "start": 2152.859,
        "duration": 4.26
    },
    {
        "text": "these were artificially created",
        "start": 2155.56,
        "duration": 3.66
    },
    {
        "text": "microbiomes based on sequences that were",
        "start": 2157.119,
        "duration": 4.441
    },
    {
        "text": "already confirmed to have that label in",
        "start": 2159.22,
        "duration": 4.2
    },
    {
        "text": "our paper we have results on a real",
        "start": 2161.56,
        "duration": 3.96
    },
    {
        "text": "microbiome where we got the labels I",
        "start": 2163.42,
        "duration": 4.56
    },
    {
        "text": "think using minimap um but for all of",
        "start": 2165.52,
        "duration": 4.02
    },
    {
        "text": "the results that I showed here they were",
        "start": 2167.98,
        "duration": 3.119
    },
    {
        "text": "artificially created microbiomes based",
        "start": 2169.54,
        "duration": 3.48
    },
    {
        "text": "on sequences words we knew what the true",
        "start": 2171.099,
        "duration": 3.0
    },
    {
        "text": "label was",
        "start": 2173.02,
        "duration": 4.079
    },
    {
        "text": "foreign",
        "start": 2174.099,
        "duration": 3.0
    },
    {
        "text": "[Music]",
        "start": 2188.77,
        "duration": 3.139
    },
    {
        "text": "host 50 microbial DNA in it but I think",
        "start": 2218.88,
        "duration": 6.94
    },
    {
        "text": "what why amnes was able to succeed so",
        "start": 2223.119,
        "duration": 4.561
    },
    {
        "text": "much more on the test sets with a large",
        "start": 2225.82,
        "duration": 5.22
    },
    {
        "text": "human fraction is that we included uh um",
        "start": 2227.68,
        "duration": 5.46
    },
    {
        "text": "the reference standard that we train on",
        "start": 2231.04,
        "duration": 3.78
    },
    {
        "text": "from is from a nanoper sequence",
        "start": 2233.14,
        "duration": 3.719
    },
    {
        "text": "technology I think allowed to generalize",
        "start": 2234.82,
        "duration": 3.66
    },
    {
        "text": "much more than existing methods I think",
        "start": 2236.859,
        "duration": 4.441
    },
    {
        "text": "that our crack into centrifuge mini Maps",
        "start": 2238.48,
        "duration": 4.44
    },
    {
        "text": "struggled much more on the noisy host",
        "start": 2241.3,
        "duration": 3.96
    },
    {
        "text": "sequences specifically and I think it's",
        "start": 2242.92,
        "duration": 5.1
    },
    {
        "text": "because a lot of them contained a lot of",
        "start": 2245.26,
        "duration": 5.22
    },
    {
        "text": "CG as you can see like existing methods",
        "start": 2248.02,
        "duration": 4.02
    },
    {
        "text": "tank significantly more in terms of",
        "start": 2250.48,
        "duration": 3.06
    },
    {
        "text": "sensitivity when the percent of CG",
        "start": 2252.04,
        "duration": 3.539
    },
    {
        "text": "increases and this measures our accuracy",
        "start": 2253.54,
        "duration": 4.079
    },
    {
        "text": "on the host sequences",
        "start": 2255.579,
        "duration": 3.601
    },
    {
        "text": "um so I think for some reason I think",
        "start": 2257.619,
        "duration": 3.181
    },
    {
        "text": "because the host sequences look so",
        "start": 2259.18,
        "duration": 3.54
    },
    {
        "text": "different from what existing methods",
        "start": 2260.8,
        "duration": 4.74
    },
    {
        "text": "were expecting enemies was able to deal",
        "start": 2262.72,
        "duration": 4.26
    },
    {
        "text": "with that because we were able to train",
        "start": 2265.54,
        "duration": 3.72
    },
    {
        "text": "on nanopore sequences directly that's",
        "start": 2266.98,
        "duration": 3.96
    },
    {
        "text": "what led to success more than class and",
        "start": 2269.26,
        "duration": 2.64
    },
    {
        "text": "balance",
        "start": 2270.94,
        "duration": 3.12
    },
    {
        "text": "yeah so there are a couple of questions",
        "start": 2271.9,
        "duration": 3.84
    },
    {
        "text": "that have come in online",
        "start": 2274.06,
        "duration": 3.66
    },
    {
        "text": "um the first is from Travis who said it",
        "start": 2275.74,
        "duration": 4.14
    },
    {
        "text": "seems that current method trunciating or",
        "start": 2277.72,
        "duration": 4.02
    },
    {
        "text": "synthetic to equal blood input",
        "start": 2279.88,
        "duration": 4.979
    },
    {
        "text": "Dimensions before inputting into CNN in",
        "start": 2281.74,
        "duration": 5.16
    },
    {
        "text": "your architecture diagram has seen the",
        "start": 2284.859,
        "duration": 5.581
    },
    {
        "text": "global average cooling happening am I",
        "start": 2286.9,
        "duration": 5.76
    },
    {
        "text": "understanding that correctly in your CNN",
        "start": 2290.44,
        "duration": 4.2
    },
    {
        "text": "he's input to the non-equal dimensions",
        "start": 2292.66,
        "duration": 3.959
    },
    {
        "text": "yes yeah",
        "start": 2294.64,
        "duration": 3.36
    },
    {
        "text": "I think",
        "start": 2296.619,
        "duration": 4.74
    },
    {
        "text": "yeah so I guess the way that we handled",
        "start": 2298.0,
        "duration": 6.18
    },
    {
        "text": "that was that we I guess so the way that",
        "start": 2301.359,
        "duration": 4.26
    },
    {
        "text": "you could handle that was input each",
        "start": 2304.18,
        "duration": 3.899
    },
    {
        "text": "sequence individually",
        "start": 2305.619,
        "duration": 4.621
    },
    {
        "text": "um so that because I think if you input",
        "start": 2308.079,
        "duration": 4.201
    },
    {
        "text": "sequences in a batch they have to be the",
        "start": 2310.24,
        "duration": 3.72
    },
    {
        "text": "same length in order for I guess you to",
        "start": 2312.28,
        "duration": 3.48
    },
    {
        "text": "input it as a matrix but inputting",
        "start": 2313.96,
        "duration": 3.96
    },
    {
        "text": "sequences um one by one amazed can",
        "start": 2315.76,
        "duration": 4.38
    },
    {
        "text": "handle any sequence anyway",
        "start": 2317.92,
        "duration": 4.199
    },
    {
        "text": "and then the second question that came",
        "start": 2320.14,
        "duration": 3.54
    },
    {
        "text": "on and then we can go back to questions",
        "start": 2322.119,
        "duration": 3.661
    },
    {
        "text": "in the room uh this is from Patricia I",
        "start": 2323.68,
        "duration": 3.899
    },
    {
        "text": "said excellent presentation good job",
        "start": 2325.78,
        "duration": 4.02
    },
    {
        "text": "making this clear and logical could you",
        "start": 2327.579,
        "duration": 3.961
    },
    {
        "text": "say a little more about the choice of",
        "start": 2329.8,
        "duration": 3.539
    },
    {
        "text": "deep lift and the Alternatives that were",
        "start": 2331.54,
        "duration": 4.44
    },
    {
        "text": "considered yeah um so the reason that we",
        "start": 2333.339,
        "duration": 5.221
    },
    {
        "text": "selected deep lift is because it was",
        "start": 2335.98,
        "duration": 5.06
    },
    {
        "text": "designed with DNA sequences in mind",
        "start": 2338.56,
        "duration": 4.2
    },
    {
        "text": "specifically I think a lot of other",
        "start": 2341.04,
        "duration": 3.819
    },
    {
        "text": "interpretability based methods are for",
        "start": 2342.76,
        "duration": 4.26
    },
    {
        "text": "images and for other inputs um the fact",
        "start": 2344.859,
        "duration": 6.301
    },
    {
        "text": "that deep lift was designed to interpret",
        "start": 2347.02,
        "duration": 7.26
    },
    {
        "text": "DNA sequences already and some existing",
        "start": 2351.16,
        "duration": 4.439
    },
    {
        "text": "work could already be done in selecting",
        "start": 2354.28,
        "duration": 2.88
    },
    {
        "text": "so the way the deep lift works is that",
        "start": 2355.599,
        "duration": 5.041
    },
    {
        "text": "it compares the output of your method to",
        "start": 2357.16,
        "duration": 6.0
    },
    {
        "text": "the output related to a reference input",
        "start": 2360.64,
        "duration": 4.92
    },
    {
        "text": "and it there were a lot of experiments",
        "start": 2363.16,
        "duration": 4.5
    },
    {
        "text": "done on the appropriate reference to use",
        "start": 2365.56,
        "duration": 3.779
    },
    {
        "text": "for dna-based methods so that's why we",
        "start": 2367.66,
        "duration": 3.419
    },
    {
        "text": "chose to use duplic I think there are a",
        "start": 2369.339,
        "duration": 3.24
    },
    {
        "text": "ton of different interpretability based",
        "start": 2371.079,
        "duration": 4.861
    },
    {
        "text": "methods that could be used to analyze a",
        "start": 2372.579,
        "duration": 5.401
    },
    {
        "text": "maze but because deep lift had already",
        "start": 2375.94,
        "duration": 3.899
    },
    {
        "text": "been looked at in the context of DNA",
        "start": 2377.98,
        "duration": 4.379
    },
    {
        "text": "that's why we chose it",
        "start": 2379.839,
        "duration": 5.0
    },
    {
        "text": "yeah",
        "start": 2382.359,
        "duration": 2.48
    },
    {
        "text": "big time for the microbial group",
        "start": 2385.0,
        "duration": 7.14
    },
    {
        "text": "together bacteria and managera but Andre",
        "start": 2388.599,
        "duration": 6.361
    },
    {
        "text": "are eukaryotic and I would make sure",
        "start": 2392.14,
        "duration": 4.8
    },
    {
        "text": "that they might be more similar than",
        "start": 2394.96,
        "duration": 4.44
    },
    {
        "text": "those in bacteria I was curious with you",
        "start": 2396.94,
        "duration": 4.02
    },
    {
        "text": "that the",
        "start": 2399.4,
        "duration": 3.719
    },
    {
        "text": "um the bias or the predictive actors can",
        "start": 2400.96,
        "duration": 5.1
    },
    {
        "text": "be separated out between the bacteria",
        "start": 2403.119,
        "duration": 5.121
    },
    {
        "text": "and the microbes",
        "start": 2406.06,
        "duration": 4.14
    },
    {
        "text": "that's a great question I don't have",
        "start": 2408.24,
        "duration": 3.52
    },
    {
        "text": "those results but I think I remember",
        "start": 2410.2,
        "duration": 4.379
    },
    {
        "text": "qualitatively looking at our output and",
        "start": 2411.76,
        "duration": 4.98
    },
    {
        "text": "we struggled more on fungi so I think",
        "start": 2414.579,
        "duration": 3.481
    },
    {
        "text": "and I think that was kind of across the",
        "start": 2416.74,
        "duration": 2.4
    },
    {
        "text": "board for all methods I don't know",
        "start": 2418.06,
        "duration": 3.72
    },
    {
        "text": "particularly which methods struggled",
        "start": 2419.14,
        "duration": 4.08
    },
    {
        "text": "more or less that would be something",
        "start": 2421.78,
        "duration": 4.1
    },
    {
        "text": "I should look into",
        "start": 2423.22,
        "duration": 2.66
    },
    {
        "text": "it",
        "start": 2427.24,
        "duration": 2.0
    },
    {
        "text": "for the reason",
        "start": 2429.3,
        "duration": 4.14
    },
    {
        "text": "um",
        "start": 2431.44,
        "duration": 2.0
    },
    {
        "text": "specifically they look at this global",
        "start": 2434.64,
        "duration": 5.04
    },
    {
        "text": "average",
        "start": 2437.44,
        "duration": 5.82
    },
    {
        "text": "so they elaborate more out of that",
        "start": 2439.68,
        "duration": 6.46
    },
    {
        "text": "yeah um so it's not I think something",
        "start": 2443.26,
        "duration": 6.72
    },
    {
        "text": "that's typically done this sort of",
        "start": 2446.14,
        "duration": 5.939
    },
    {
        "text": "um I guess pooling over the entire",
        "start": 2449.98,
        "duration": 3.599
    },
    {
        "text": "sequencing Dimension and I think it's",
        "start": 2452.079,
        "duration": 4.921
    },
    {
        "text": "because in most cases machine learning",
        "start": 2453.579,
        "duration": 6.121
    },
    {
        "text": "inputs are fixed in size",
        "start": 2457.0,
        "duration": 4.8
    },
    {
        "text": "um and so I think that just just like",
        "start": 2459.7,
        "duration": 4.919
    },
    {
        "text": "the I guess there's this um",
        "start": 2461.8,
        "duration": 4.86
    },
    {
        "text": "thought that you know why would you need",
        "start": 2464.619,
        "duration": 4.441
    },
    {
        "text": "to be agnostic to size because all of",
        "start": 2466.66,
        "duration": 3.36
    },
    {
        "text": "your inputs are going to be the same",
        "start": 2469.06,
        "duration": 1.98
    },
    {
        "text": "size I don't think that this is a",
        "start": 2470.02,
        "duration": 2.76
    },
    {
        "text": "problem that comes up much in machine",
        "start": 2471.04,
        "duration": 2.819
    },
    {
        "text": "learning",
        "start": 2472.78,
        "duration": 3.0
    },
    {
        "text": "um but I think we found that",
        "start": 2473.859,
        "duration": 4.861
    },
    {
        "text": "I guess being agnostic to sequencing",
        "start": 2475.78,
        "duration": 5.339
    },
    {
        "text": "size allowed us to I guess the biggest",
        "start": 2478.72,
        "duration": 4.56
    },
    {
        "text": "issue with truncation is that you're",
        "start": 2481.119,
        "duration": 4.861
    },
    {
        "text": "losing out on valuable parts of the",
        "start": 2483.28,
        "duration": 4.079
    },
    {
        "text": "sequence that could be important for",
        "start": 2485.98,
        "duration": 3.78
    },
    {
        "text": "accuracy and the other fix for that was",
        "start": 2487.359,
        "duration": 4.801
    },
    {
        "text": "to use padding but the issue is is that",
        "start": 2489.76,
        "duration": 4.319
    },
    {
        "text": "nanopore sequence is particularly can",
        "start": 2492.16,
        "duration": 3.6
    },
    {
        "text": "range in lengths so significantly that",
        "start": 2494.079,
        "duration": 3.601
    },
    {
        "text": "if you pad to the maximum length you're",
        "start": 2495.76,
        "duration": 3.66
    },
    {
        "text": "increasing your classification time a",
        "start": 2497.68,
        "duration": 3.24
    },
    {
        "text": "lot so we found that doing this global",
        "start": 2499.42,
        "duration": 3.6
    },
    {
        "text": "average pooling allowed us to have kind",
        "start": 2500.92,
        "duration": 3.84
    },
    {
        "text": "of The Best of Both Worlds of using all",
        "start": 2503.02,
        "duration": 3.78
    },
    {
        "text": "the input but not being significantly",
        "start": 2504.76,
        "duration": 5.46
    },
    {
        "text": "slower on smaller inputs",
        "start": 2506.8,
        "duration": 4.98
    },
    {
        "text": "yeah",
        "start": 2510.22,
        "duration": 3.96
    },
    {
        "text": "um I forgot which slide it was but you",
        "start": 2511.78,
        "duration": 4.92
    },
    {
        "text": "had one where you were looking at the",
        "start": 2514.18,
        "duration": 4.32
    },
    {
        "text": "time performance of the different",
        "start": 2516.7,
        "duration": 4.379
    },
    {
        "text": "proportions of like posts and",
        "start": 2518.5,
        "duration": 6.0
    },
    {
        "text": "um microbials uh sequences",
        "start": 2521.079,
        "duration": 6.181
    },
    {
        "text": "um I was wondering",
        "start": 2524.5,
        "duration": 5.94
    },
    {
        "text": "oh yeah actually this one or no the one",
        "start": 2527.26,
        "duration": 6.26
    },
    {
        "text": "before okay actually yeah",
        "start": 2530.44,
        "duration": 5.82
    },
    {
        "text": "I was just going to ask like if you",
        "start": 2533.52,
        "duration": 5.5
    },
    {
        "text": "could talk a bit more about sort of the",
        "start": 2536.26,
        "duration": 5.579
    },
    {
        "text": "variation between like model performance",
        "start": 2539.02,
        "duration": 5.46
    },
    {
        "text": "of like different Fashions at an equator",
        "start": 2541.839,
        "duration": 5.941
    },
    {
        "text": "because I I know the sort of big um like",
        "start": 2544.48,
        "duration": 4.92
    },
    {
        "text": "the main example of you again at the",
        "start": 2547.78,
        "duration": 4.559
    },
    {
        "text": "beginning of the cycle a sample that is",
        "start": 2549.4,
        "duration": 6.12
    },
    {
        "text": "like mostly hosts you know and only part",
        "start": 2552.339,
        "duration": 6.121
    },
    {
        "text": "are really a small bit microbial",
        "start": 2555.52,
        "duration": 4.44
    },
    {
        "text": "um it's just wondering about the inverse",
        "start": 2558.46,
        "duration": 2.879
    },
    {
        "text": "of that because I know that's another",
        "start": 2559.96,
        "duration": 3.78
    },
    {
        "text": "thing for a lot of like like microbial",
        "start": 2561.339,
        "duration": 4.681
    },
    {
        "text": "like service yeah so I think so I guess",
        "start": 2563.74,
        "duration": 5.04
    },
    {
        "text": "the the reason that",
        "start": 2566.02,
        "duration": 4.44
    },
    {
        "text": "um non-ml based approaches and",
        "start": 2568.78,
        "duration": 3.0
    },
    {
        "text": "specifically I guess centrifuge and",
        "start": 2570.46,
        "duration": 3.18
    },
    {
        "text": "minimap here struggle when there's a lot",
        "start": 2571.78,
        "duration": 4.38
    },
    {
        "text": "of host DNA in the sample compared to",
        "start": 2573.64,
        "duration": 4.8
    },
    {
        "text": "microbial is that host reference genomes",
        "start": 2576.16,
        "duration": 3.48
    },
    {
        "text": "are a lot bigger than microbial",
        "start": 2578.44,
        "duration": 3.06
    },
    {
        "text": "reference genomes so pulling that into",
        "start": 2579.64,
        "duration": 4.62
    },
    {
        "text": "memory and looking over the host",
        "start": 2581.5,
        "duration": 4.02
    },
    {
        "text": "reference genomes to perform the",
        "start": 2584.26,
        "duration": 3.359
    },
    {
        "text": "classification takes longer so if there",
        "start": 2585.52,
        "duration": 3.599
    },
    {
        "text": "are more host sequences you have to do",
        "start": 2587.619,
        "duration": 3.661
    },
    {
        "text": "that more often and so those methods can",
        "start": 2589.119,
        "duration": 3.781
    },
    {
        "text": "struggle versus the inverse of when",
        "start": 2591.28,
        "duration": 3.12
    },
    {
        "text": "there's a lot of microbial sequences",
        "start": 2592.9,
        "duration": 3.24
    },
    {
        "text": "relative to the host you've the",
        "start": 2594.4,
        "duration": 3.66
    },
    {
        "text": "reference genomes you have to pull into",
        "start": 2596.14,
        "duration": 4.14
    },
    {
        "text": "memory are much smaller",
        "start": 2598.06,
        "duration": 5.16
    },
    {
        "text": "um so that takes less time so I think",
        "start": 2600.28,
        "duration": 6.6
    },
    {
        "text": "that existing methods are optimized on a",
        "start": 2603.22,
        "duration": 6.48
    },
    {
        "text": "I guess a speed basis for kind of the",
        "start": 2606.88,
        "duration": 4.86
    },
    {
        "text": "ins of a lot of host sequence or a lot",
        "start": 2609.7,
        "duration": 4.2
    },
    {
        "text": "of microbial is relative to the host",
        "start": 2611.74,
        "duration": 4.68
    },
    {
        "text": "sequences but as the host fraction",
        "start": 2613.9,
        "duration": 4.5
    },
    {
        "text": "increases those methods start to break",
        "start": 2616.42,
        "duration": 4.14
    },
    {
        "text": "down and so we see that a maze is",
        "start": 2618.4,
        "duration": 4.14
    },
    {
        "text": "probably the most useful in cases where",
        "start": 2620.56,
        "duration": 4.08
    },
    {
        "text": "you're analyzing a micro a microbiome",
        "start": 2622.54,
        "duration": 3.539
    },
    {
        "text": "like the long microbiome with a",
        "start": 2624.64,
        "duration": 2.88
    },
    {
        "text": "significant number of host sequences",
        "start": 2626.079,
        "duration": 3.301
    },
    {
        "text": "when you have the inverse of a lot of",
        "start": 2627.52,
        "duration": 3.66
    },
    {
        "text": "microbial sequence as well to the host",
        "start": 2629.38,
        "duration": 4.02
    },
    {
        "text": "uh if you're if all you care about is",
        "start": 2631.18,
        "duration": 5.58
    },
    {
        "text": "speed I think that existing non-ml based",
        "start": 2633.4,
        "duration": 5.4
    },
    {
        "text": "approaches are also good except for even",
        "start": 2636.76,
        "duration": 3.18
    },
    {
        "text": "though Center features a little bit",
        "start": 2638.8,
        "duration": 3.539
    },
    {
        "text": "slower than amazing",
        "start": 2639.94,
        "duration": 5.639
    },
    {
        "text": "thank you that your GC analysis was",
        "start": 2642.339,
        "duration": 4.861
    },
    {
        "text": "really interesting",
        "start": 2645.579,
        "duration": 4.02
    },
    {
        "text": "um it got me thinking that perhaps there",
        "start": 2647.2,
        "duration": 5.58
    },
    {
        "text": "is this reasonably identified patterns",
        "start": 2649.599,
        "duration": 6.121
    },
    {
        "text": "that separates them and so the",
        "start": 2652.78,
        "duration": 6.0
    },
    {
        "text": "model would be very compact like it",
        "start": 2655.72,
        "duration": 4.44
    },
    {
        "text": "doesn't need to look at very much to",
        "start": 2658.78,
        "duration": 3.299
    },
    {
        "text": "take one of themselves but I guess sort",
        "start": 2660.16,
        "duration": 3.959
    },
    {
        "text": "of on the other end you can picture gosh",
        "start": 2662.079,
        "duration": 3.301
    },
    {
        "text": "you know they're virtually",
        "start": 2664.119,
        "duration": 3.661
    },
    {
        "text": "indistinguishable memorize all the",
        "start": 2665.38,
        "duration": 4.439
    },
    {
        "text": "sequences and go back to the reference",
        "start": 2667.78,
        "duration": 3.839
    },
    {
        "text": "genome",
        "start": 2669.819,
        "duration": 4.621
    },
    {
        "text": "experience if you had thought about sort",
        "start": 2671.619,
        "duration": 5.281
    },
    {
        "text": "of assessing where you're up in that",
        "start": 2674.44,
        "duration": 5.399
    },
    {
        "text": "spectrum of memorizing versus like",
        "start": 2676.9,
        "duration": 6.84
    },
    {
        "text": "having really crisp uh lines and maybe",
        "start": 2679.839,
        "duration": 6.721
    },
    {
        "text": "in terms of like model capacity like how",
        "start": 2683.74,
        "duration": 4.44
    },
    {
        "text": "does your performance be great as you",
        "start": 2686.56,
        "duration": 3.6
    },
    {
        "text": "get smaller and smaller models and then",
        "start": 2688.18,
        "duration": 3.419
    },
    {
        "text": "also maybe you're thinking about trying",
        "start": 2690.16,
        "duration": 3.84
    },
    {
        "text": "to not just distinguish humans from",
        "start": 2691.599,
        "duration": 5.041
    },
    {
        "text": "microbes but like microbes or microbes",
        "start": 2694.0,
        "duration": 4.619
    },
    {
        "text": "or or other sort of more challenging",
        "start": 2696.64,
        "duration": 4.08
    },
    {
        "text": "types of discrimination paths totally",
        "start": 2698.619,
        "duration": 3.541
    },
    {
        "text": "yeah so we actually started this project",
        "start": 2700.72,
        "duration": 3.96
    },
    {
        "text": "as a trying to replace the entire",
        "start": 2702.16,
        "duration": 4.32
    },
    {
        "text": "pipeline of multi-plus metagenomic",
        "start": 2704.68,
        "duration": 3.899
    },
    {
        "text": "classification and we found that",
        "start": 2706.48,
        "duration": 5.099
    },
    {
        "text": "existing methods are so successful",
        "start": 2708.579,
        "duration": 4.981
    },
    {
        "text": "because I think when you get to these",
        "start": 2711.579,
        "duration": 3.901
    },
    {
        "text": "fine grain differences a lot you have to",
        "start": 2713.56,
        "duration": 4.38
    },
    {
        "text": "do exact matching and it's not as easy",
        "start": 2715.48,
        "duration": 4.44
    },
    {
        "text": "to extrapolate patterns as it is with",
        "start": 2717.94,
        "duration": 3.96
    },
    {
        "text": "this kind of simpler host versus not",
        "start": 2719.92,
        "duration": 3.36
    },
    {
        "text": "host test so you totally hit the nail of",
        "start": 2721.9,
        "duration": 2.52
    },
    {
        "text": "the head and I think we found that",
        "start": 2723.28,
        "duration": 4.14
    },
    {
        "text": "machine learning at right now in terms",
        "start": 2724.42,
        "duration": 5.22
    },
    {
        "text": "of speed accuracy and efficiency",
        "start": 2727.42,
        "duration": 5.1
    },
    {
        "text": "perspective works best as sort this kind",
        "start": 2729.64,
        "duration": 6.12
    },
    {
        "text": "of sort of higher level separation and",
        "start": 2732.52,
        "duration": 4.86
    },
    {
        "text": "existing methods I think are still",
        "start": 2735.76,
        "duration": 4.44
    },
    {
        "text": "Superior when we do more fine grain",
        "start": 2737.38,
        "duration": 5.54
    },
    {
        "text": "differences yeah",
        "start": 2740.2,
        "duration": 2.72
    },
    {
        "text": "any other questions",
        "start": 2748.06,
        "duration": 3.14
    },
    {
        "text": "yeah so when you build up your training",
        "start": 2753.099,
        "duration": 5.821
    },
    {
        "text": "deals that um how did you construct your",
        "start": 2756.52,
        "duration": 5.22
    },
    {
        "text": "host plans meaning like",
        "start": 2758.92,
        "duration": 4.8
    },
    {
        "text": "I know that it's not from a real person",
        "start": 2761.74,
        "duration": 6.06
    },
    {
        "text": "but like do you have any background on",
        "start": 2763.72,
        "duration": 6.3
    },
    {
        "text": "what type of people are those like",
        "start": 2767.8,
        "duration": 5.16
    },
    {
        "text": "Geniuses are from this is currently",
        "start": 2770.02,
        "duration": 5.52
    },
    {
        "text": "enough like diversity to represents the",
        "start": 2772.96,
        "duration": 4.26
    },
    {
        "text": "entire population that you know",
        "start": 2775.54,
        "duration": 5.76
    },
    {
        "text": "introduce any bias or resistance right",
        "start": 2777.22,
        "duration": 7.32
    },
    {
        "text": "so we included three host genomes in our",
        "start": 2781.3,
        "duration": 4.44
    },
    {
        "text": "host fraction",
        "start": 2784.54,
        "duration": 3.36
    },
    {
        "text": "um or sample sequences from three",
        "start": 2785.74,
        "duration": 4.2
    },
    {
        "text": "different hosts we did",
        "start": 2787.9,
        "duration": 5.64
    },
    {
        "text": "um human pig and mouse and we included",
        "start": 2789.94,
        "duration": 6.24
    },
    {
        "text": "some human nanopore sequences but we",
        "start": 2793.54,
        "duration": 6.24
    },
    {
        "text": "didn't include any pig or Mouse nanopore",
        "start": 2796.18,
        "duration": 5.88
    },
    {
        "text": "sequences and I have results in the full",
        "start": 2799.78,
        "duration": 3.539
    },
    {
        "text": "paper if you're interested on",
        "start": 2802.06,
        "duration": 3.96
    },
    {
        "text": "performance with nanopore pig and mouse",
        "start": 2803.319,
        "duration": 4.5
    },
    {
        "text": "sequences and we found that we could do",
        "start": 2806.02,
        "duration": 3.78
    },
    {
        "text": "well on those sequences so we were able",
        "start": 2807.819,
        "duration": 4.861
    },
    {
        "text": "to extrapolate from the human nanopore",
        "start": 2809.8,
        "duration": 4.74
    },
    {
        "text": "data patterns that exist in nanopore",
        "start": 2812.68,
        "duration": 5.159
    },
    {
        "text": "data but were able to do well on um",
        "start": 2814.54,
        "duration": 5.579
    },
    {
        "text": "Pagan Mouse because we uh included that",
        "start": 2817.839,
        "duration": 6.201
    },
    {
        "text": "in the reference genome aspective",
        "start": 2820.119,
        "duration": 3.921
    },
    {
        "text": "foreign",
        "start": 2832.38,
        "duration": 5.439
    },
    {
        "text": "has a very new feature which is like",
        "start": 2834.72,
        "duration": 5.44
    },
    {
        "text": "technology allows it to read in a",
        "start": 2837.819,
        "duration": 4.5
    },
    {
        "text": "sequence and determine if it's what it's",
        "start": 2840.16,
        "duration": 5.659
    },
    {
        "text": "looking for and if not exactly out yes",
        "start": 2842.319,
        "duration": 6.961
    },
    {
        "text": "so it's possible to apply or by like",
        "start": 2845.819,
        "duration": 5.981
    },
    {
        "text": "real time and labeling in the sequence",
        "start": 2849.28,
        "duration": 5.46
    },
    {
        "text": "while it's getting and deciding lower",
        "start": 2851.8,
        "duration": 5.76
    },
    {
        "text": "country or no so I guess the the issue",
        "start": 2854.74,
        "duration": 4.74
    },
    {
        "text": "is that we have like the additional step",
        "start": 2857.56,
        "duration": 3.84
    },
    {
        "text": "we would need to do is be base calling",
        "start": 2859.48,
        "duration": 4.32
    },
    {
        "text": "in real time because um I think a lot of",
        "start": 2861.4,
        "duration": 4.5
    },
    {
        "text": "existing nanopore specific approaches",
        "start": 2863.8,
        "duration": 4.799
    },
    {
        "text": "work on the on base called electric",
        "start": 2865.9,
        "duration": 5.58
    },
    {
        "text": "signal we work on baseball signals so if",
        "start": 2868.599,
        "duration": 4.561
    },
    {
        "text": "you could base call in real time we can",
        "start": 2871.48,
        "duration": 3.859
    },
    {
        "text": "work in real time",
        "start": 2873.16,
        "duration": 4.919
    },
    {
        "text": "yeah I guess but the issue um with",
        "start": 2875.339,
        "duration": 4.0
    },
    {
        "text": "methods that work on the electrical",
        "start": 2878.079,
        "duration": 2.941
    },
    {
        "text": "signal is that they're not",
        "start": 2879.339,
        "duration": 3.181
    },
    {
        "text": "um accessible to other sequence",
        "start": 2881.02,
        "duration": 3.599
    },
    {
        "text": "Technologies we see sort of a maze kind",
        "start": 2882.52,
        "duration": 3.599
    },
    {
        "text": "of the framework of a maze could work",
        "start": 2884.619,
        "duration": 7.641
    },
    {
        "text": "right on Pac bio on illuminum yes yeah",
        "start": 2886.119,
        "duration": 6.141
    },
    {
        "text": "Chronicles back to my first question",
        "start": 2894.099,
        "duration": 5.041
    },
    {
        "text": "that gives me a seamless technology but",
        "start": 2895.66,
        "duration": 4.919
    },
    {
        "text": "um I was wearing",
        "start": 2899.14,
        "duration": 5.88
    },
    {
        "text": "if it would be possible to train on like",
        "start": 2900.579,
        "duration": 6.78
    },
    {
        "text": "80 like instead of just like focusing on",
        "start": 2905.02,
        "duration": 4.52
    },
    {
        "text": "like one sequence technology",
        "start": 2907.359,
        "duration": 4.381
    },
    {
        "text": "having like demand for a specific model",
        "start": 2909.54,
        "duration": 4.36
    },
    {
        "text": "of doing a specific model if there would",
        "start": 2911.74,
        "duration": 4.5
    },
    {
        "text": "be any complications with just using a",
        "start": 2913.9,
        "duration": 4.26
    },
    {
        "text": "variety of sequence Technologies to",
        "start": 2916.24,
        "duration": 5.4
    },
    {
        "text": "things like the model was better yeah um",
        "start": 2918.16,
        "duration": 4.74
    },
    {
        "text": "I guess I I don't know what the",
        "start": 2921.64,
        "duration": 2.88
    },
    {
        "text": "trade-off would be in terms of accuracy",
        "start": 2922.9,
        "duration": 3.12
    },
    {
        "text": "on each individual sequence of",
        "start": 2924.52,
        "duration": 4.02
    },
    {
        "text": "Technology compared to overall",
        "start": 2926.02,
        "duration": 4.98
    },
    {
        "text": "um we tried to do that with",
        "start": 2928.54,
        "duration": 3.84
    },
    {
        "text": "um I guess we started this project",
        "start": 2931.0,
        "duration": 3.24
    },
    {
        "text": "thinking of applying the maze to both",
        "start": 2932.38,
        "duration": 4.62
    },
    {
        "text": "short and uh long rates I think the",
        "start": 2934.24,
        "duration": 5.099
    },
    {
        "text": "issue with short reads is because they",
        "start": 2937.0,
        "duration": 4.68
    },
    {
        "text": "have very low error",
        "start": 2939.339,
        "duration": 4.02
    },
    {
        "text": "um and they're very short",
        "start": 2941.68,
        "duration": 3.659
    },
    {
        "text": "um existing approaches crack and",
        "start": 2943.359,
        "duration": 3.661
    },
    {
        "text": "centrifuge minimap are designed to",
        "start": 2945.339,
        "duration": 4.621
    },
    {
        "text": "operate well on short reads that have",
        "start": 2947.02,
        "duration": 6.42
    },
    {
        "text": "very low errors so we weren't able to do",
        "start": 2949.96,
        "duration": 5.76
    },
    {
        "text": "better than them I think that a machine",
        "start": 2953.44,
        "duration": 4.919
    },
    {
        "text": "learning based approach works is kind of",
        "start": 2955.72,
        "duration": 4.08
    },
    {
        "text": "the best in comparison to existing",
        "start": 2958.359,
        "duration": 3.301
    },
    {
        "text": "approaches on ingredients",
        "start": 2959.8,
        "duration": 3.779
    },
    {
        "text": "um so I think actually I I mean we",
        "start": 2961.66,
        "duration": 3.3
    },
    {
        "text": "haven't done any experience on this but",
        "start": 2963.579,
        "duration": 3.121
    },
    {
        "text": "I think Amaze would probably work well",
        "start": 2964.96,
        "duration": 4.139
    },
    {
        "text": "kind of out of the box on sequences but",
        "start": 2966.7,
        "duration": 4.08
    },
    {
        "text": "I think when you look to apply it on",
        "start": 2969.099,
        "duration": 3.901
    },
    {
        "text": "short reads I think machine learning",
        "start": 2970.78,
        "duration": 5.039
    },
    {
        "text": "might not be okay most optimal to handle",
        "start": 2973.0,
        "duration": 5.839
    },
    {
        "text": "that yes",
        "start": 2975.819,
        "duration": 3.02
    }
]