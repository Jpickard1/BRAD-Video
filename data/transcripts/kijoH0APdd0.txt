today i will describe cumulus this is a cloud-based single cell and single nucleus genomics analysis framework my lab has developed in the past uh two years uh i will start my talk with motivation and then introduce the cumulative system next i will benchmark cumulus with alternatives on large large datasets and demonstrate cumulus uh interactive visualization and analysis capabilities which are super useful and then i will show you how awesome our cumulus team is we keep developing new features rapidly and in particular i will discuss three recently updates in details last but not least i will discuss the cumulus roadmap what we plan to do in the next five years so we all know that human immune system is super important because immune cells are actually presented in all human tissues and they are likely to be involved in all diseases and actually they are next generation therapeutic targets for wide range of diseases for example cancer immunotherapy thus at the broad institute we have initialized several immune cell atlas efforts these include the efforts of human hematopoiesis as well as across humanized mouse and different organs as a computational lead i am in charge of the atlases of human hematopoiesis system which includes cells from bone marrow cord blood and peripheral blood for this dataset we have profiled around 1.5 million single cells using single cell rna-seq to be representative of the human immune system for each tissue type we actually collected samples from multiple donors with equal gender representation this is so far still the largest single cell transcriptomics data in the world for the human immune system although you know two years later earlier uh uh i i'll claim this is the largest uh single cell data set in the world but now it's not but still uh is the largest uh uh transcriptomic date singles or transcriptomic data for the human immune system in particular so for 1.5 million single cells we obtained over five terabytes of sequencing data you know although like for big tech like google and facebook five terabytes is not that big but for you know biologists this is really a gigantic number and our data actually posed serious problem for the analysis first there are two problems first computational computing resources are not enough and second most existing two at least at that time could not scale up therefore together with my team including e-min young and josh scott we developed cumulus this is a the first comprehensive cloud-based framework to address the about-two problems before i introduce cumulus let me first briefly describe the workflow of single cell rna signature analysis we first prepare single cell cdn libraries from either droplet-based or plate-based protocols we then send these libraries for sequencing and after sequencing we start the analysis flow we first trigger this is called the make fastq step this step extracts raw sequencing risk from the sequencer the next step is a count step and in this step we align the risk to a genome and generate this gene by cut matrix for each sample lastly we trigger the analysis step to discuss to discover new biology this step pulls gene count matrices from all samples find cell clusters based on expression profiles annotate these clusters with putative cell types and visualize them in say for example 2d space so the make fast q and con steps they are easily paralyzable if we have enough computing resources thus we implemented cumulus based on broad institute's terror platform and the underlying google cloud platform so that cumulus can utilize these hundreds of thousands of cpus and now also gpus on cloud to run these two steps in parallel and in particular for text genomics data we have a cloud-based wrapper of cell ranger for the concept um so because you know i mentioned like cumulus is built on broad institute's terror platform and also google cloud platform uh you may ask you know if i can use it say for example in a local big cluster or other alternative cloud providers so here i want to say although cumulus is built on top of terran google cloud it is readily adapted to alternative platforms because cumulus only depends on darker images and workflow description language files and cumulus can run on any backend chrome well this is a widow uh execution engine uh chrome oil supports this include amazon web services google cloud platform uh local computing servers and a variety of computing cluster back-ends and we can make running cumulus jobs even easier by using capper this is a tool developed by encode dcc and it's a python command line tool uh it's a python command line wrapper for the chrome well and uh this will uh make uh you know a command line and this will make uh running like jobs uh in command line much easier however i want i have to warn you like for alternative platforms we only have this command line tools provided which makes it a challenge for biologists without a programming background to run cumulus so uh for the next step the analysis step this step is much harder to parallelize across different servers therefore we develop a ultra fast python analysis module and we call it pegasus which can run on cloud or local computer pegasus covers most common analysis tasks it can filter low-quality cells and genes select highly available genes perform batch correction uh conduct pca build nearest neighbor graph and find colostrum using community detection measures such as the low-end enlightened algorithms and visualize data using either disney or umap for developmental data we can estimate diffusion maps and visualize the the data enforce direct layout embeddings lastly this pexus package can perform differential expression analysis detect cluster specific markers and annotate putative cell types based on known markers we have actually made several algorithmic and implementation improvements in order to make pegasus scalable and here is one of the improvements we have made i just want to show as a demonstration this technique in theory can speed up the calculation of any two-dimensional visualization and the motivation is you know we know that large data sets are often redundant therefore we might be able to capture the global structure using only a fraction of the cells to speed up the visualization thus we propose the following algorithm the first step we downsample a subset of cells inversely proportional to each cell's local density this is mirrored by its median 10 years neighbor distance and the goal here is we can with this like non-uniform sampling we can sample more cells in the sparse regions which might represent rare cell types and sample less frequent from the dense regions which you know most of cells may like represent the same cell type and then the second step we project the sampled cells using an embedded algorithm you you of your choice for example you can do tcm you can do umap you can do false direct layout and then we train a deep learning regressor using the embedded coordinates as a ground truth once we have this regressor we instead of running the embedding algorithm that can be time consuming we directly predict the coordinates using this regressor for all other cells and actually this idea is inspired by uh cho at our cell systems paper and lastly uh because in most of cases this regressor uh does an okay job for prediction for the coordinate prediction but not 100 accurate we need a last adjustment step in this step we basically adjust the predicted coordinates by running the same embedding algorithm for only a small number of iterations and let's see this algorithm in action for speeding up the umap and we call the you know resulting visualization as netview map so as a first step we generate a umap by say subsampling 10 of the cells here here different colors represent different cell types annotated separately using known markers and then using these umap coordinates we can trim a regressor and use this regressor to predict the other 90 percent of the cell and here you can see this umap actually is blurred and in the last step we just ran the umap for say 10 iterations to make the umap crystal clear again and our algorithm actually can speed up the visualization of umap like disney and force directly laid out uh by more than two-fold change uh by more than two-fold will keep the quality roughly the same uh so by the way any questions so far about this algorithm or or like other things before we move to the benchmarking section uh if there's no question i'll just move on sir i have a quick question have you basically done a similar analysis but with like let's say an organoid where you kind of have a constrained set of cells and you have sort of intercept intra or intercellular sort of interactions that might actually perturb their kind of representation within your visualization here uh sorry can you repeat your question again uh why is uh org noise uh uh like player factor here well i well that's that's precisely a question that i'm interested in um kind of looking at myself so i'm curious if basically you had a multi-dimensional sort of tissue structure if you would actually see a difference in sort of how these cells end up separating on these signals maybe this is about i might be misunderstanding something maybe this is a better question for later okay okay so uh this algorithm the basic is like uh uh like like you know in big big data field there's there's all this kind of sketching algorithm but other assumption is you know because once you have large enough data points by like non-uniform or uniform sampling of this data point you can capture the global structure without lose much accuracy and then like you just sampling a small subset of cells build a skeleton of your visualization and then basically uh you fill in the other datasets to make uh the details much clearer that's that's the concept ah got it thank you can i ask a question quickly as well yeah sure of course um does this um net umap or net pc um have similar performance characteristics in 3d versus 2d projections uh that's actually a great question we have never tested in 3d but i suspect we should do a similar good job yeah but i never tested it cool thank you okay so uh in the benchmark section we will first benchmark pegasus which is a python analysis module with cerrad and scanpi and these are basically because pegasus perform similar functionalities than this uh to these uh surrounding scan packages and we'll do the benchmark on two data sets one is uh bone marrow data sets from our immune cell atlas project this data set consists of around 300 thousand cells the other datasets is 10x genomics 1.3 million more spring cell uh most brain datasets uh this is just used to test the limits of each software and after that we will benchmark cumulus and this is our cloud solution with a traditional single server solution that runs cell ranger plus either serat or scampi on the bone marrow datasets and here i listed the software versions i use for benchmarking so for bone marrow data set we benchmark 10 key analysis tasks using a single server with 28 threads and 256 gigabytes of memory and we highlighted the bytes performer for each task in both and here you can see that pegasus performed best for all 10 tasks and we have similar results for the 1.3 million more spring cell data set note that sarat even failed to load the whole data matrix into memory and this is emitted in this comparison and another note is uh here basically i just show you uh this the speed of pegasus is really awesome maybe you have concerns about if they produce um results of comparable quality or not uh i did not uh into the slides here but if you're interested uh feel free to uh find the comparation in my cumulus paper this is a nature measure paper and you can find the results in supplementary figures so and this table shows that the analysis supported by each package are actually similar although each one has its unique features and the red check marks are actually uh analysis we recently supported in this table compare running cumulus on cloud with a single server solution as you can see here cumulus successfully reduce the analysis time from 10 to 9 days to 15 hours and in addition the computational cost is modest for analyzing one sample of around four thousand single cells cumulus costed less than two dollars well the experimental cost can be as high as one thousand and five hundred [Music] besides fast and cost effective cumulus also offers a comprehensive set of features it processes both droplet-based and place-based data in addition it supports sideseek which mirrors the transcriptome and epitope abundances simultaneously and perturb sig which is designed for put crispr screens cumulus also supports a variety of sample pooling and multiplexing strategies these include pooling by donor-specific genetic information cell hashing and nucleus harshes and then you may ask um great cumulus uh basically uh for the constant run cell ranger but uh we also recently we also have this development of uh like new cont matrix generation tools such as human cell atlas optimus workflow this is cloud-based workflow for generating the cog matrix and all these living this is a salmon team developed this for a single cell rnc and kalisto bus tools and star solo so you may wonder how are these new tools compared with cell ranger so to answer this question we did this benchmarking uh we basically run a 5000 pbmc data set this is 10x genomics v3 chemistry publicly available and this dataset can consist of around 400 million risk and we benchmark each of the two on cloud for their execution time and cost and uh we give them 32 cp uh we give each tool uh a google cloud virtual machine of 33 uh cpus gigabytes of memory 500 gigabytes of disk space and here is the results you can see that both the new tools allowing crystal bus tools and star solo they run much faster than sell ranger and as a result of like spending less time they also cost less however we can see the best performer actually are the star solo and crystal bus tools they all finish within one hour and the cost is less than 30 cents um but there's uh one caves here uh for callisto bus tools this aligns to the transcriptome reference instead of the genome reference but the star solo aligns to the genome directly any questions so far okay so the next section i want to discuss about cumulus interactive data visualization and analysis capabilities once users finish their cumulus jobs they can instantly visualize the results interactively using cell cumulus this is a cloud-based serverless visualizer we have developed here alternatively they can download the analysis results say in h5ad format locally and visualize them using third-party tools such as a cell x gene or ucsc cell browser and if you using uh the tera platform you can also conduct post-hoc analysis interactively using tera notebooks without the need of downloading any data objects locally lastly once you finish your analysis you can deposit your results to the single cell portal seamlessly for publication purpose because cumulus actually generates single cell portal compatible files and here is a demo of the serocumulus visualizer in action to import the data you just need to provide to import the data you just need to provide the dataset name and link and the result location cloud you can share your data by typing with your collaborators by typing their email address and then you click save if you load in the data using cumulus you can visualize either categorical features like the cluster like the cell types shown here or or continuous types such as gene expressions shown here you can also select a subset of cells and observe it across multiple features as demonstrated here and you can also visualize the dot plot interactively lastly if you want to share some visualization results with your collaborators you can easily click the copy link button and send them with an email of their link of the link serial cumulus now also supports uh spatial transcriptomics data visualization and here is a demo of the 10x wisdom data each dot here is colored by the cluster it belongs to entire users can interactively analyze their data using pegasus on cloud here is an example of generating beautiful heat maps and dot plots using pegasus and for more examples you can visit the cumulus featured workspace listed here and here is a summary of the cumulus highlights cumulus paper is published in nature masters we already have a large used user base the python package has already over uh 22 000 downloads and major sell atlas projects there are several major cell artist projects that either used or decided to use cumulus this include the human immune cell atlas the human tumor atlas pilot project uh the human cell atlas data coordination platform uh internal investigation and the long map too and there are other consortium that are actively evaluating cumulus for their use these include uh the human tumor atlas network funded by uh nci and bring initiative cell census network so um here i just want to say our team is really excellent at rapid development of new features and here i'll show you uh the cumulus development timeline since it's paper submission we released a python implementation of the harmony data integration algorithm in january we added a new algorithm to calculate the gene module score in may we deployed the customized cumulus for the pam boston code 19 autopsy and blood research efforts in early june and incorporate another data integration to uh scannerama uh in late june and our paper is published uh in late july and we basically rewrote our plotting library so that we can generate all these nice figures for publication in early august and we speed up the differential expression analysis by 26-fold change uh uh vote in september and provided a preliminary nanostring spatial transcriptomic data support this is in late october this is not published public available yet however and we actually work closely with users who help us to gear cumulus towards the right direction and in the following i will discuss three of these recent updates the harmony python implementation module score calculation and the differential expression analysis speed up so harm harmony pertage is a pitoch implementation of the harmony algorithm published in nature measures and the original implementation is originally r and the reason we do this uh pi touch reimplementation is uh python this real implementation actually is more scalable and allows us to do computation on gpus and here i will benchmark the harmony pi touch on three datasets one is more one is medium-sized and one is large first this plot shows the pearson correlations between batch corrected principal components computed using the original harmony and harmony by touch and this figure just suggests harmony python faithfully recapitulates the original harmony algorithm and this table shows the this table shows a harmony uh pie touch is more scalable on large data sets and in particular uh for the large data set we can see the cpu version uh is 7.5 uh times faster and the gpu version is 14.6 times fast faster the error bars here were calculated based on 10 independent ranks the next thing is we will discuss how to calculate g module scores given a list of genes describing say one gene module or one pathway biologists always want us to calculate a summarized score so that they can know which cells are expressing this gene module or not and in addition uh when we calculate this geomodule score we also need to remove technical noise related to gene abandons and here uh i show the cell type annotated umap of our bone marrow data set on the left and on the right side i just show the b cell module score based on these 10 b cell markers and here we can observe that the b cell scores are high in b cells and low in all other cells which means this is a like working module score the traditional measures uh for calculating g module score as once used in both serat and scanpi they approximate the module score by sampling and instead we found a closed form solution that can compute the exact module score and as shown here for the b cell module score on our bone marrow data set we show on the y-axis the experiment rank correlation between scan height and sera's module scores at different at different sampling size with our exact module scores and we can observe that both scan high and cirrhot scores approached our scores when the sampling size is increasing in addition uh it seems sarah's module score is better than scan price because uh sarah's curl is dominates a scan price curve note that the sampling size actually stops at 500 for sarat because syrah basically crashed on sampling size about 500. besides accurate our calculation is also 20 times and eight times faster than the surrogate and skyingpie uh computation uh thanks uh to like the exact formula we found our last uh improvement is the speed of speed up of differential expression analysis inspired by presto we redesigned our differential expression module which significantly speed up the main whitney u test and area and the curve calculation this mw test is also called a wilcoxon rexxam test it is a nonparametric test that is more robust and thus preferable than the t-test and these euroc values is also very useful based on feedbacks from our biology collaborators for select cluster-specific gene markers and we tested our redesigned module on a subset of bone marrow cells of a consisting of a 35 000 cells and we achieve a 62 times speed up compared to our original implementation and because it's speed up now pakistan's calculate uh differential expression using these mw tests and calculate aolc values for all genes and if you are familiar with either cerrado scan high uh you know that they can they can also calculate differential expression uh for all genes but by default they only calculate differential expression for highly variable genes basically because of the computational bottleneck but because they speed up basically we can do all differential express we can do differential expression gene for all the analysis for all the genes so any questions so far before i go to the last section of cumulus yield map okay so uh here is what we plan to do for the cumulus uh we plan to extend cumulus for single cell multimodal omics this includes support of large-scale data analysis of single cell ataxic single cell immunoraptor sequencing spatial transcriptomics and proteomics mass cytometry and also support multi-modal analysis this means joint analysis of single-cell toxic iron expression and maybe side-sig for protein expression so we'll discuss each aspect separately for single cell ataxic uh currently uh cumulus supports cell ranger ataxic surrender attack on cloud however in the future we plan to extend pegasus for single cell ataxic downstream analysis and in particular we want to address a big data challenge for the single cell attacks field as we know the feature size here for single cell ataxic each feature is not a gene's expression but a separate peak or a separate genomic bins the feature size for singles are ataxic is 10 to 20 times larger than the size of single cell rna-seq and this will cause big troubles for both generating the feature by cell matrix and downstream analysis for for generating the feature by cell matrix uh i will collaborate with dr hanley's lab on incorporating their newly developed tool called chrome map which can speed up the computation by 60 times compared to cell ranger attack and for the downstream analysis [Music] we often need to actually pull matrices from multiple samples together and then it is possible even we even cannot load the full data set into memory uh thus we will design novel online learning algorithm uh to address this memory challenge um you know josh also have these similar online learning algorithms uh uh for the uh uh his uh awesome uh liger to online uh non-active matrix factorization and uh the good thing about this online algorithm is uh you do not need to load all the data into the memory and it also enjoy a very fast convergence rate for the single cell immunorapture analysis currently cumulus supports cell ranger vdg on cloud and our planned development include evaluating alternative vdj assemblers such as trust4 developed by shirley liu's lab this is very important because actually cell ranger has its own vdj assembler that is never peer reviewed or published and actually between their versions say sell ranger three and sell ranger four and now they have cell render five they keep changing their algorithm so uh you know for users it's just like a black box you you do not know uh you know what what they give you as output so it's very important we can have a systematic benchmark of these two and other available tools and we also try to extend pegasus to support more downstream analysis for example based on both rna single cell rna-seq and the t-cell receptors we can detect types in single cell clusters our next reaction is spatial data analysis for spatial data analysis this is still in its infancy for here i'm aiming at developing a standard operation procedure for spatial analysis for example ideally users only need to provide type some inputs tell tell the machine where the data is and click the run analysis button then for different type of the spatial data for example include slide seek to ask whism nanostring geo mx and morpheus data it will trigger different data processing workflows for different data type and then generate a unifying unified format data for the gene expression and spatial information and then for this unified uh format data we can put them into pegasus to do uh analysis such as colossian differential expression analysis this actually shared with a single cell rna significant analysis or like a spatial data specific analysis like cell type deconvolution and detecting spatially variable genes and uh last but not least uh we also need an efficient data structure for organizing single cell multimodal omix data and data is a very good example for efficient data structure but this data structure is only designed for one modality for example if you have both single cell rna seq and single cell toxic you need to store them in two-ended objects which is not a very clean solution uh therefore we developed what car a new data structure called pegasus io and uh in this uh state structure users access a multi-modal data object which can contains a list of unimodal data objects and the uni and the unimodal data object basically resembles and data but it can specialize to a variety of modalities such as a toxic vdj flow set mastotometry on under string data and for example uh and and then each of these specialization have like functionalities to process the specific data type for example for the uh cytometry data uh we it has ability to are processing my cytometry data uh in a specific format they called flow cytometry standard format um yeah and last i want to say uh both cumulus and bro's terror platform are free to public but you still need to pay a cloud pay google cloud for computation storage uh and here we have the uh and cumulus is open source and the bsd three uh license and the pegasus actually is a python package you can run on your laptop if you're interested please give it a try and we also have this uh harmony pod pitoch as a separate uh python package for you uh in the end i like to thank for my colleagues and collaborators and in particular uh i'd like to thank the cumulus team i mean young and josh god and my collaborators at the raghav live uh vilanilab and and thank you no i'm good for questions okay so thank you both for this wonderful talk so do we have any questions from the audience uh please feel free to unmute yourself and ask the question directly to paul well that was a great talk thanks um i i wanted to ask about the pytorch harmony implementation um did you change the algorithm at all um like for example converting it to a mini batch optimization instead of using all the data points at once or was it simply just rewriting it in the pi torch uh it's just a simple rewrite in python yeah yeah yeah that's interesting i i was curious why just rewriting in pytorch gave such a big speed up oh um let me share the screen uh harmony yep so there's a couple of reasons uh i think one of the reason is uh the original r implementation you know although for uh say the time consuming matrix multiplication is implemented in c or c plus plus but uh but i think uh it does not utilize multi-thread very well however uh as part of the pi touch implementation uh uh you know python basically depends on this torch implementation uh they did specific optimization for uh matrix multiplication and can automatically do parallel computation when do these uh matrix uh operations and i think this is a reason why the cpu uh implementation is much faster actually um we also have a python implementation using numpy and yeah just using numpy and that version if you benchmark it with a harmony r they basically perform the same you do not see a big speed up got it so are you using multiple cores on your cpu for this comparison oh yes i see okay so it's really the multi-core that makes the difference yes the multi-core uh well so if we do single core is still faster but for this dramatic uh speed up yes it's a multicore i think we benchmark it on a 20 core cpu yeah a server something like that yeah okay great thanks so but i have another question oh i think it's really great many of these singles our consortium use uh community uh cumulus uh to host their data so i wonder if i want to use uh this consortium data like human cell idol state or can i just use the data from your platform or i have to download somewhere to like a bucket and run it myself so can you give me some like instructions on how to use oh is that like you want to reanalyze the data or oh um say it's a bit complicated for example the human cell atlas i think they hosted their data uh like uh in a website created by sanger institute in uk and then you can download these bam files or all these uh conf matrices directly and i i believe you can also import the data to the terror platform directly i see great yeah and if you do the para route uh then you can run like all these workflows uh like available in this uh uh environment yeah and another question is if i want to for example i want to like build a gang like uh adversarial like generative model over this large scale like uh like cell cohorts so what can i still use your platform to do that oh i have to do like this type of gun learning or generative model case right on your platform or not oh cumulus basically is uh is a way we try to standardize uh a single cell genomics analysis for biologists um but but actually it's several layers so for for all these kind of things and the bottom layer actually is google cloud platform and this is basically the same as you use either amazon or microsoft it's just cloud platform you you just pay it and you use it and then what tera is actually is a scene at the application layer that handles uh a workflow execution and uh for you and give you a very nice user interface for example uh like like say uh if for some reason uh one of your cloud note uh crashed and you want the ability of uh automatically uh retry it or run it from the cash results uh tara can help you with you and then uh like for you say if you want to do again or whatever you can just write your own tools and import it to terror and to analyze all of your data and then cumulus basically is a set of uh standard standard tools like we set up to like make analysis uh more automatic yeah i see so basically i can still write new deep learning model of course okay i think yeah yeah and and uh and uh um and i think your lab also have like uh gpu servers right right yeah so in that case like uh for just uh benchmarking or testing you can just run on your uh own server but say if you really need a large computation uh you can just do this cloud things and you can ask unlimited gpus but uh i have to warn you it costs a lot okay i see oh and so what you haven't worked on like singles or high c data for you for the like data frame or the object right uh not yet but uh i'm actually very interested in like uh working on this maybe we can talk more more about it if you have news and whatever okay great uh do we have additional questions from the audience