hi everyone um thank you so much for having me so today I'm going to be presenting on my work called Amaze which stands for a machine learning approach to index resequence enrichment this work was done jointly with piyush Ron John ARP downward Robert Dixon and my advisor Jenna Williams and it was published in nature Communications biology in June of 2022. okay so first I'm going to be getting into some background related work related to a maze so the ultimate goal of our work is to improve infectious disease diagnosis by developing a pathogen identification tool that is accurate to ensure that correct treatment can be given fast to ensure that the treatment can be given in a timely manner and cheap and efficient to ensure the accessibility of the method and the ability of it to be used at the bedside so traditionally to diagnose infectious diseases clinicians have used culture-based methods which involves taking a sample from a patient either School saliva or blood mixing the sample with culture media and waiting for growth and then doing pathogen identification via biological tests there are a couple drawbacks to using these culture-based methods first they can be inaccurate because not all pathogens can be detected using this method and pathogen detection is necessary for treatment and this is because not all pathogens can grow when mixed with the culture media these methods can also be slow because it can take several days to detect growth and this slowness can negatively affect a patient's ability to recover so to alleviate some of these issues people have started to use metagenomics for disease diagnosis so metagenomics is the study of the metagenome which is the collective DNA from a clinical sample and the way that people will use metagenomics for disease diagnosis are that they would take the same sample from a patient the stool saliva or blood but instead of mixing it with culture media they would input it into a DNA sequencer and get metagenomic sequencing output which is all of the DNA in the sample and then they would use a genomic classification method to do the pathogen classification and metagenomic classification Maps DNA to a classification label and existing metagenomic classification methods do this using reference databases so as you can see here we have the metagenomic sequencing output that we input into this metagenomic classification method that uses a reference database to do the pathogen classification so the problem with using metagenomics for disease diagnosis are that there can be copious host derived sequences in a sample and here I have a couple of examples of microbiome compositions from a human where the Pike in the pie chart the red indicates the percentage of the sequences in the microbiome that are from post and in blue we have the percentage of sequences that are from a microbe so the gut as you can see here is evenly split there are 50 host sequences and 50 microbial sequences in the microbiome but the lung can be very um can contain copious host derived sequences compared to the microbial sequences um and here's an example of what um a lung microbiome could look like with the copious host derived sequences and so microbial sequence formative for pathogen detection because they could contain the pathogen derived sequences but the host sequences are not informative for pathogen detection and in this case host is the patient from which the sample was collected so copious host derived sequences can cause Downstream classification methods to be inaccurate slow and costly inaccurate because these methods are not especially sensitive to noisy host sequences so they can be inaccurate classifying those sequences slow because it causes these methods to classify a lot of uninformative sequences the host sequences as you remember are not informative to doing the pathogen identification and also it causes these methods to be costly because they have to store large amounts of post genomes to classify the host sequences and typically host genomes are much larger than microbial genomes so this can add a lot of storage and Rams requirements to these methods so to alleviate the aforementioned problem of copious host derived sequences um fire investigators have employed host depletion staffs and host depletion is a binary classification task of determining whether a sequence is from a host or not from a host so instead of this existing pipeline that I had shown before of taking the metagenomic sequencing output and inputting it into a metagenomic classification method that uses a reference database with both host and microbial DNA to perform the classification we would use the following pipeline where before inputting the sequences into a metagenomic classification method we would input those sequences into a host depletion method that removes the host sequences and then takes those microbial sequences and it inputs them into a metagenomic classification method and in this pipeline the metagenomic classification method would only need microbial DNA in the reference database because all of those host sequences have been removed so the benefits of using host depletion for Downstream methods are it allows them to be more accurate faster and cheaper more accurate because it gives Downstream classification methods a slightly easier classification task it removes one class that they would need to do the classification on it also allow these methods to be faster because Downstream methods seem to classify less sequences and it allows them to be cheaper because Downstream methods don't need to store those genomes okay so previous work in computational host depletion can be broken up into two different categories the first category are pairwise alignment based methods and an example of this is mini-map2 the way that these types of methods work are that they get a query sequence and they align it to the reference Genome of interest and in this case we want to save the query sequences from a human so we align that prayer sequence to the human reference genome in this case we see there's perfect alignment so we would output that the sequence is from a human or the human classification label and if there wasn't perfect alignment we would output that it wasn't from a human the other class of methods in computational host depletion are lookup table based methods and examples of this are cracking chew and centrifuge and the way that these methods work are they take that same query sequence but instead of directly aligning it to the human reference genome they break the query sequence up into Capers or subsequences of length K and in this case we are breaking up the sequence into subsequences of blank three or primers um TCG cgc and GCC and then we look for direct matches between those trimers and the trimers that exist in the human reference genome so in this lookup table we have all of the trimers that exist in the human reference genome in this case we see that these timers perfectly match these trimers and so we can output that this query sequence has the human classification label um so the issues with these existing computational host depletion methods are that they can be inaccurate on sequences from error-prone Technologies and this is because they build their reference databases using reference genomes which are very curated and have very few errors so when we're doing this direct matching we're unable to account for a lot of the errors that could appear in error from sequences and these methods are also costly because they require storage and memory to store the reference databases so why do we think that machine learning would help so we hypothesized that machine learning based approach would be more accurate and cheaper than existing approaches more accurate because we hypothesized than an ml-based approach would be more robust to sequences from error-prone Technologies because we're not directly aligning sequences or cameras to a reference genome we can do something a little bit more complicated and we hypothesized an ml based approach would be cheaper than existing approaches because they can use Less storage and brand than existing post-depletion methods and this is because an ml-based approach can learn patterns from raw DNA sequences without the Reliance on an external database but why is DNA classification challenging for machine learning so ml hasn't been applied to host depletion in past work but it has been applied to multi-class metagenomic classification and novel path and connection and current approaches in those areas have two issues first they can be inaccurate and slow at performing variable length sequence classification and sequences from aeroprone Technologies happen to be variable length they can range from length 100 to over a thousand and the second issue is that they typically don't build diverse training sets and they can be inaccurate at classifying sequences that differ from those in its training set so our contributions are that we developed a novel machine learning based host depletion method a maze that can perform variable links sequence classification accurately and quickly on a diverse set of input data so we first leverage global average pooling to handle the variable length sequences and we use new training data sources to improve the ability of our model to classify a diverse set of input data we also rigorously evaluated our approach by providing a comprehensive comparison of our approach to existing alignment and classification methods in their ability to perform host completion and we also evaluated our approach as a pre-processing tool applied before Downstream microbial taxonomic classification okay so now I'm going to be getting into details of our method first starting with amazes architecture we start with our input to amaze a DNA read that DNA read first passes through four convolutional layers and these convolutional layers learn a rich feature representation of the DNA read the next step is passing that feature representation through global average pooling layer and a fully connected layer to get the probability that a DNA reads from a host and these global average pooling and fully connected layer aggregate the Learned features into that probability and then the last step is thresholding that probability for the final classification decision if the probability is below the threshold we state that the DNA read is from a microbe if the probability is above a threshold we state that the DNA read is from a host okay so going back to the issue with existing ml-based approaches for DNA classification the first issue is existing methods are inaccurate or slow at performing variable length sequence classification existing methods either truncate the input or pad the input and truncation can cause inaccuracy because this they remove important parts of the sequence while padding causes methods to be slow because it causes an increase in classification time since we're adding additional aspects of the input to be classified to solve these issues with existing methods we leverage global average pooling to handle the variable length sequence and this leverage pooling averages the learn features over the sequence Dimension allowing our method to be agnostic to the length of the sequence so if you remember from our architecture diagram the global average pooling occurs after we learn a feature representation of our DNA read via the convolutional layers and it allows our method to be agnostic to sequence length so the second issue with existing ml-based approaches are that they don't build diverse training sets and they can be inaccurate at classifying sequences that differ from those in its training set existing methods like existing computational host depletion methods train models on sequences from reference genomes and the issue with this is that these methods are not able to accurately classify sequences from error from sequencing Technologies so to solve this we use new training data sources to improve our learned representations and instead of just training our model on sequences sampled from reference genomes we also sampled sequences from sequencing Technologies allowing our method to be more robust to sequences from airplane Technologies okay now I'm going to be getting into the evaluation setup of our method we had three different classes of evaluation metrics that we were looking at accuracy speed and cost efficiency um as I had said before accuracy is important to ensure that the correct treatment can be assigned and for our ml method and host depletion comparison we measured accuracy using classification accuracy sensitivity and specificity sensitivity is the percentage of microbes or sorry sensitivity is the percentage of hosts that were correctly identified and specificity is the percentage of macros that were correctly identified and then for our pre-processing or metagenomic classification comparison we looked at overall accuracy on the host data and overall accuracy on the microbial data then to measure speed which is important to ensure that the treatment can be given in a timely manner we measure that using wall clock time and then for cost and efficiency which is important to ensure the accessibility of the method and ability of it to be used at the bedside we measured this using storage RAM and dram usage and the test sets that we used for our evaluation contain nanopore reads and this is because nanopore sequencing currently produces the longest reads and is the only platform that produces real-time sequencing data both of which are useful for clinical Diagnostics and all of our test sets contain human in the host fraction and bacteria and fungi in the microbial fraction okay now I'm going to be getting into our ml model comparison results uh which presents a comparison of a maze to other machine learning based solutions that use other architectures and training schemes and our hypotheses here are that existing methods that concatenate or pad outputs would be improved by using global average pooling and existing methods that use a single training data source like just sampling sequences from reference genomes would be improved by using multiple training data sources okay and for this comparison we looked at one test set which contained a human host percentage of 50 we found that machine learning methods did not um their performance did not change based on the percentage of host DNA and the test set but non-ml host depletion methods performance did change so when I show you results from that comparison we looked at a variety of test sets with different percentages of host in the sample okay so for the first issue of existing methods being inaccurate or slow at performing variable length sequence classification where um you see sensitivity and specificity we want to be high in classification time we want to be low uh we see that when we pad the inputs we have a high accuracy sensitivity and specificity but a high classification time where we want a low classification time when we concatenate the input that we have a low classification time but that comes at the expense of a lower specificity sensitivity and accuracy and in this case we have Peak membrane and storage usage held constant so I don't include that in the table when we global average pool we can maintain the high accuracy sensitivity and specificity of padding the inputs but we have a lower classification time so a maze was faster than a model that pads inputs to the maximum length with no decrease in sensitivity and specificity and a maze at a higher sensitivity and specificity than a model that truncate sequences to the minimum length so for the second issue of existing methods not building a diverse training set and being inaccurate at classifying sequences that differ from those in its training set we have here models that were trained just on nanopore sequences and just on reference genomes and sequences sample just from reference genomes and we see here that both of these methods have a low accuracy when we train on just nanopore sequences we have a high specificity but a low sensitivity this flips when we train on reference genomes we have a high sensitivity but a low specificity and we want all of these metrics to be high when we train on both nanopore and reference genome sequences we have a high accuracy sensitivity and specificity so we're able to achieve the best of both worlds so training on only reference genomes are only data from a sequencing technology results in lower sensitivity and specificity compared to training on both record genomes and nanopard data okay so takeaways from this section we developed a novel machine learning based host depletion method a maze that can perform variable length sequence classification accurately and quickly on a diverse set of input data we leverage global average schooling to handle variable length sequences and we use new training data sources to improve the ability of our model to classify a diverse set of open data okay now I'm going to be getting into a comparison of a maze um to other non-ml based host depletion methods as well as a comparison of a maze plus metagenomic classification methods compared to those methods alone so first for our host depletion comparison we're comparing a maze's ability to perform host depletion to other computational host depletion methods and this is a binary task of determining whether a sequence is from a host or not from a host then we have our metagenomic classification comparison where we're comparing the metagenomic classification pipelines with and without a maze and this is a multi-class task so our hypotheses here are that first a maze will be more accurate and cheaper than k-mer and alignment-based approaches at performing host depletion and our second hypothesis is that Amaze will improve the accuracy and efficiency of genomic classification methods we have five test sets that we're looking at for this evaluation and each test set varied in the percentage of breeds of the sample that pertained to host in our first test set we have one percent host data at 99 microbial data the second one has 25 host data 75 microbial data the fifth one resembles a gut microbiome with 50 host data 50 microbial data the fourth one we have 75 host uh 25 microbial data and our last one the most copious amount of host sequences resembles the lung microbiome with 99 host data and one percent microbial data and so we use two different environments for our evaluation we evaluated a maze on a laptop-like environment since this applies broadly in resource constrained settings but some of our existing approaches minimap 2 and Kraken 2 were not able to run successfully on a laptop environment due to memory and storage constraints so we also evaluated all methods on a server for a fair comparison and the only evaluation metric that changed based on computational environment was the speed so when I present the results first I'm going to be delving into our server results with all the methods and then showing you how the speed changed when we moved to laptop like environment so first for our host depletion comparison where we were comparing amazing's ability to perform post-depletion to other computational host depletion methods our hypothesis here is that a maze will be more accurate and cheaper than camera and alignment-based approaches at performing host depletion and just as a reminder of the host depletion schematic workflow we have our of the metagenomic sequencing output of a sample or all of the DNA in that sample the host depletion method removes the host sequences and outputs the microbial sequences to be used for Downstream methods and the three methods that we're comparing out to amaze are Kraken 2 centrifuge and minimap2 or if you remember cracking two and centrifuge are the lookup table-based methods and minimap2 is the alignment based method okay so here are the results of our host depletion comparison first I'm going to be talking about our accuracy sensitivity and specificity results where we all want all of these metrics to be high on the y-axis of all of these graphs we have accuracy sensitivity and specificity and on the x-axis we have the host fraction varied from one percent to 99 and amazes performance is in purple and our baselines are in red blue and green so we see here across all host fractions Amaze consistently achieves a higher accuracy here and sensitivity as well as a comparable specificity compared to the baselines and it's especially notable that as we increase the host fraction all of our Baseline methods start to decrease in accuracy while Amaze as performance remains pretty consistent next looking at storage where we want all of these metrics to be low a maze is still in purple compared to our baselines in the other colors a maze requires Less storage compared to all of our methods and remains competitive with respect to Peak memory usage compared to our baselines so a maze is the lowest storage requirements here and has lower Peak memory requirements than minimap 2 which has significantly High deep memory usage and remains competitive with respective and centrifugal field for our final evaluation metric of classification time where we also want this to be low we see that amaze and purple it remains competitive with respect to speed compared to our baselines and is especially faster than centrifuge we see here that centrifuge starts to get more and more slow as the host fraction the percentage of host uh DNA in the sample increases while amazes performance remains consistent and we see the same thing happening for minimap too okay now um for uh the change in performance on a laptop-like environment as I had said before the only evaluation metric that changed was speed um here on the x-axis we have our methods and on the y-axis classification time and each of these different graphs represents the performance on a different percentage of hosts compared to microbial data in the sample we see here that across the board all methods were slower on the laptop-like environment than on the server we have in red these bars are the speed on a laptop-like environment in blue we have the speed on the server and we see that classification time increases the red bars are always bigger than the blue bars meeting that our classification time increased on the laptop compared to the server however a maze still remain faster than centrifuge on all test sets with the host fraction greater than one percent so when we have one percent host data a maze is the slowest method on the laptop but as we increase the percentage of host data in our sample a maze starts to yes lower or faster than centrifuge classification time continues to increase as we increase the amount of host data in our sample foreign metagenomic classification comparison which is a comparison of our metagenomic classification pipelines with and without a maze and a hypothesis here is that a maze improves the accuracy and efficiency of metagenomic classification methods okay just as a reminder of the metagenomic classification and schematic workflow we're comparing two different pipelines here the first is in highlighted in Orange where we have our metagenomic sequencing output that we feed into a metagenomic classification method that needs both host and microbial DNA in the reference database to do classification we're comparing that to this pipeline here where we input the metagenomic sequencing output into a host depletion method that removes the host sequences and then inputs microbial sequences into a metagenomic classification method that only needs microbial DNA in the reference database to do the classification and the methods that we're comparing here are centrifuge with host and microbial DNA in the reference database as our Baseline compared to a maze plus centrifuge so a maze plus centrifuge with just microbial DNA in the reference database and we focus our comparison on centrifuge which and without a maze since centrifuge outperformed Kraken 2 on every metric except for classification time but I have the results for cracking to in an appendix if anyone is interested okay so first I'm going to be showing you the results of host accuracy where we want higher to be better and we have a maze plus centrifuge in purple centrifuge in bread we see here that the pipeline that included a maze consistently achieved a higher host accuracy compared to the pipeline without a maze and this is a cross hose fraction again on the x-axis host accuracy here on the y-axis when we look at Cost where we want that to be lower Peak memory usage specifically a maze reduces the peak memory usage requirements for centrifuge the pipeline with the Maze and centrifuge had a lower Peak memory usage than centrifugal which is what we want and then finally speed where we also want classification time to be lower we see that the pipeline with amazes classification time decreases as the percentage of host data in the test set increases while the pipeline without amazes classification time increased so when we have one percent post DNA in the sample a maze plus centrifuge is slower than centrifuge but as we start to increase the percentage of host data in the sample amazeball centrifuge becomes faster than centrifuges classification time continues to increase okay so um looking at our comparisons on a laptop-like environment we're again the only evaluation metric that um changed with speed we have here this classification time of our methods on a laptop-like environment in red and then the classification times of our methods on a server in blue again like on the host depletion comparison results that I had shown before um the red bars are always bigger than the blue bars so all methods ended up being slower on the laptop-like environment than on the server but a maze plus centrifuge remained faster than centrifuge on all test sets with a host fraction above 25 so if we look at these two um data sets we see the Amaze placentrifuge ends up being slower than centrifuge but as we increase the amount of host data in our sample a mazebo centrifuge starts to become faster than centrifuge ending here with 99 host data or a baseball centrifuge each of us faster than centrifuge okay so our takeaways from this section we developed a novel machine learning based host depletion method a maze that can perform variable length sequence classification accurately and quickly on a diverse set of input data and we rigorously evaluated our approach and found that it had higher accuracy and lower storage requirements than other computational depletion methods and it improved the accuracy and cost effectiveness of Downstream metagenomic classification methods finally I'm going to end with some results related to interpreting our machine learning model so specifically the question that I'm want to answer in this section are what cameras are the most important by a maze for classification and the camera as I said in the background section are substrings of length k for example with this sequence AGC TCC the formers are the first for um nucleotides in this sequence agct then gctc and then finally ctcc and the interpretability method that we're using to examine the gamers that are deemed most important by amazing classification is called deep lift and this method identifies the importance of input features on a machine learning model's classification and specifically on a randomly selected subset of sequences in our test set we were determining the 15 words that contributed to amaze's classification decision and we looked at 15 words because this is the length of subsequence that Kraken 2 uses to perform its classification so first I examined the 15 verse that most contributed to a microbial classification or the way to interpret this histogram is they least contributed to a host classification so we see the contribution to a host classification label that's negative which means these sequences contributed to a microbial classification label so the way to interpret this graph is the histogram shows you how much this entire 15 Mark contributed to a microbial classification label and then this is these are the five the top five 15 words that contributed most to a microbial classification label and the nucleotides here are the color around them is dark based on how much they individually contributed to this final score um so the main takeaway that we found from these five 15 words in terms of how much they contributed to the microbial classification label is that four out of the five of them contain a cg-diducleotide and this is in comparison to when we look at the 15 verse that most contributed to a host classification label none of them contain that CG dinucleotide uh so they all they all had an absence of the CG dinucleotide and this is a phenomenon known as CG suppression and this is a phenomenon that CG dinucleotides are uncommon in vertebrate genomes um so it is encouraging that Amaze captures known biological phenomena and this indicates that a maze can generalize to classify data from species not present in the training set we try to include a variety of species in our training set but the fact that Amaze was able to pick up on this General biological phenomena is an indication that a maze can generalize to unseen data from what it was trained on however this might lead some of you to think that Amaze is solely relying on CG to classify our inputs which we found that it's not compared to a classifier that only uses the percent of CG in a sequence to make its classification decision a maze had a much higher accuracy than that method we also found that existing camera and alignment-based methods rely on CG content to a much larger extent than a maze so these graphs here we show accuracy sensitivity and specificity um compared to on the x-axis the percent of CG in our sequences and looking at sensitivity and specified activity is a little bit more interpretable than the accuracy plots if we look at our sensitivity plot here we see that as the percent of CG in sequences increases crack and centrifuge and mini-map2's performance significantly drops while amazes performance remains stable and this makes sense because they're supposed to be CG suppression in vertebrates so as there's more percent lcg in sequences existing um gamer and Alignment based methods struggle to classify those sequences while Amaze is able to classify them because it doesn't rely on the percent of CG as much as these methods and then when we look at specificity we see that uh Kraken 2 and centrifuge struggle to classify sequences with a small amount of CG because there isn't supposed to be CPU suppression in microbes and specificity measures the percent of microbes that were correctly identified but a maze is better able to classify those sequences so camera and Alignment based methods rely on CG content to a much larger extent than a maze so looking ahead accuracy speed and memory efficiency are all important in developing bedside clinical diagnostic Technologies high accuracy is important to ensure that appropriate treatments are selected speed is important to ensure the treatment can be given in a timely manner and memory efficiency is important to ensure the technology is broadly accessible given the improvements provided by adding a maze to the current metagenomic classification pipeline we believe that this work brings us one step closer to clinical Diagnostics via DNA sequencing Technologies at the bedside so here are some final takeaways a link to my paper my contact information if you would like to ask me any questions via email as well as the funding acknowledgments for this project thank you so if anyone online on the questions uh feel free to put them in the chat box or raise your zoom in and uh one of the room those questions feel free to ask almost nervous yeah uh great talk very much um so just to clarify do you guys used uh not of course sequence data to like for the model right so how like would you be able to apply other sequencing Technologies like shortly like the model as well yeah so since um Amaze was trained on base called reads it applies broadly to any input sequence uh I think to ensure that it would be I guess the most accurate um I would recommend retraining a maze to include I guess whatever specific sequence technology that you want to apply to but the fact that Amaze was able to learn I guess the presence of CG is indication that it could potentially apply broadly to other sequences from other sequencing Technologies but to ensure highest accuracy I would recommend retraining or adding those sequencies so um that was already labeled by like a some earlier ml method that that people with a sometimes there's kind of training on something that was already machine generated so you need to know it's better if a human can actually say like oh this cell was actually some type ABC or whatever so here like the labels must have come from somewhere for you to train a base algebra what that process was yes yeah so um the test sets that I presented here um are were synthetic microbiomes that we created so we got the um I think there's a human reference standard that was created in 2018 um by some research group where uh I guess they had confirmed that all of the sequences in our in the um data that they provided were from a human so we used that and then we got our um bacterian fungal DNA in the same way so these were artificially created microbiomes based on sequences that were already confirmed to have that label in our paper we have results on a real microbiome where we got the labels I think using minimap um but for all of the results that I showed here they were artificially created microbiomes based on sequences words we knew what the true label was foreign [Music] host 50 microbial DNA in it but I think what why amnes was able to succeed so much more on the test sets with a large human fraction is that we included uh um the reference standard that we train on from is from a nanoper sequence technology I think allowed to generalize much more than existing methods I think that our crack into centrifuge mini Maps struggled much more on the noisy host sequences specifically and I think it's because a lot of them contained a lot of CG as you can see like existing methods tank significantly more in terms of sensitivity when the percent of CG increases and this measures our accuracy on the host sequences um so I think for some reason I think because the host sequences look so different from what existing methods were expecting enemies was able to deal with that because we were able to train on nanopore sequences directly that's what led to success more than class and balance yeah so there are a couple of questions that have come in online um the first is from Travis who said it seems that current method trunciating or synthetic to equal blood input Dimensions before inputting into CNN in your architecture diagram has seen the global average cooling happening am I understanding that correctly in your CNN he's input to the non-equal dimensions yes yeah I think yeah so I guess the way that we handled that was that we I guess so the way that you could handle that was input each sequence individually um so that because I think if you input sequences in a batch they have to be the same length in order for I guess you to input it as a matrix but inputting sequences um one by one amazed can handle any sequence anyway and then the second question that came on and then we can go back to questions in the room uh this is from Patricia I said excellent presentation good job making this clear and logical could you say a little more about the choice of deep lift and the Alternatives that were considered yeah um so the reason that we selected deep lift is because it was designed with DNA sequences in mind specifically I think a lot of other interpretability based methods are for images and for other inputs um the fact that deep lift was designed to interpret DNA sequences already and some existing work could already be done in selecting so the way the deep lift works is that it compares the output of your method to the output related to a reference input and it there were a lot of experiments done on the appropriate reference to use for dna-based methods so that's why we chose to use duplic I think there are a ton of different interpretability based methods that could be used to analyze a maze but because deep lift had already been looked at in the context of DNA that's why we chose it yeah big time for the microbial group together bacteria and managera but Andre are eukaryotic and I would make sure that they might be more similar than those in bacteria I was curious with you that the um the bias or the predictive actors can be separated out between the bacteria and the microbes that's a great question I don't have those results but I think I remember qualitatively looking at our output and we struggled more on fungi so I think and I think that was kind of across the board for all methods I don't know particularly which methods struggled more or less that would be something I should look into it for the reason um specifically they look at this global average so they elaborate more out of that yeah um so it's not I think something that's typically done this sort of um I guess pooling over the entire sequencing Dimension and I think it's because in most cases machine learning inputs are fixed in size um and so I think that just just like the I guess there's this um thought that you know why would you need to be agnostic to size because all of your inputs are going to be the same size I don't think that this is a problem that comes up much in machine learning um but I think we found that I guess being agnostic to sequencing size allowed us to I guess the biggest issue with truncation is that you're losing out on valuable parts of the sequence that could be important for accuracy and the other fix for that was to use padding but the issue is is that nanopore sequence is particularly can range in lengths so significantly that if you pad to the maximum length you're increasing your classification time a lot so we found that doing this global average pooling allowed us to have kind of The Best of Both Worlds of using all the input but not being significantly slower on smaller inputs yeah um I forgot which slide it was but you had one where you were looking at the time performance of the different proportions of like posts and um microbials uh sequences um I was wondering oh yeah actually this one or no the one before okay actually yeah I was just going to ask like if you could talk a bit more about sort of the variation between like model performance of like different Fashions at an equator because I I know the sort of big um like the main example of you again at the beginning of the cycle a sample that is like mostly hosts you know and only part are really a small bit microbial um it's just wondering about the inverse of that because I know that's another thing for a lot of like like microbial like service yeah so I think so I guess the the reason that um non-ml based approaches and specifically I guess centrifuge and minimap here struggle when there's a lot of host DNA in the sample compared to microbial is that host reference genomes are a lot bigger than microbial reference genomes so pulling that into memory and looking over the host reference genomes to perform the classification takes longer so if there are more host sequences you have to do that more often and so those methods can struggle versus the inverse of when there's a lot of microbial sequences relative to the host you've the reference genomes you have to pull into memory are much smaller um so that takes less time so I think that existing methods are optimized on a I guess a speed basis for kind of the ins of a lot of host sequence or a lot of microbial is relative to the host sequences but as the host fraction increases those methods start to break down and so we see that a maze is probably the most useful in cases where you're analyzing a micro a microbiome like the long microbiome with a significant number of host sequences when you have the inverse of a lot of microbial sequence as well to the host uh if you're if all you care about is speed I think that existing non-ml based approaches are also good except for even though Center features a little bit slower than amazing thank you that your GC analysis was really interesting um it got me thinking that perhaps there is this reasonably identified patterns that separates them and so the model would be very compact like it doesn't need to look at very much to take one of themselves but I guess sort of on the other end you can picture gosh you know they're virtually indistinguishable memorize all the sequences and go back to the reference genome experience if you had thought about sort of assessing where you're up in that spectrum of memorizing versus like having really crisp uh lines and maybe in terms of like model capacity like how does your performance be great as you get smaller and smaller models and then also maybe you're thinking about trying to not just distinguish humans from microbes but like microbes or microbes or or other sort of more challenging types of discrimination paths totally yeah so we actually started this project as a trying to replace the entire pipeline of multi-plus metagenomic classification and we found that existing methods are so successful because I think when you get to these fine grain differences a lot you have to do exact matching and it's not as easy to extrapolate patterns as it is with this kind of simpler host versus not host test so you totally hit the nail of the head and I think we found that machine learning at right now in terms of speed accuracy and efficiency perspective works best as sort this kind of sort of higher level separation and existing methods I think are still Superior when we do more fine grain differences yeah any other questions yeah so when you build up your training deals that um how did you construct your host plans meaning like I know that it's not from a real person but like do you have any background on what type of people are those like Geniuses are from this is currently enough like diversity to represents the entire population that you know introduce any bias or resistance right so we included three host genomes in our host fraction um or sample sequences from three different hosts we did um human pig and mouse and we included some human nanopore sequences but we didn't include any pig or Mouse nanopore sequences and I have results in the full paper if you're interested on performance with nanopore pig and mouse sequences and we found that we could do well on those sequences so we were able to extrapolate from the human nanopore data patterns that exist in nanopore data but were able to do well on um Pagan Mouse because we uh included that in the reference genome aspective foreign has a very new feature which is like technology allows it to read in a sequence and determine if it's what it's looking for and if not exactly out yes so it's possible to apply or by like real time and labeling in the sequence while it's getting and deciding lower country or no so I guess the the issue is that we have like the additional step we would need to do is be base calling in real time because um I think a lot of existing nanopore specific approaches work on the on base called electric signal we work on baseball signals so if you could base call in real time we can work in real time yeah I guess but the issue um with methods that work on the electrical signal is that they're not um accessible to other sequence Technologies we see sort of a maze kind of the framework of a maze could work right on Pac bio on illuminum yes yeah Chronicles back to my first question that gives me a seamless technology but um I was wearing if it would be possible to train on like 80 like instead of just like focusing on like one sequence technology having like demand for a specific model of doing a specific model if there would be any complications with just using a variety of sequence Technologies to things like the model was better yeah um I guess I I don't know what the trade-off would be in terms of accuracy on each individual sequence of Technology compared to overall um we tried to do that with um I guess we started this project thinking of applying the maze to both short and uh long rates I think the issue with short reads is because they have very low error um and they're very short um existing approaches crack and centrifuge minimap are designed to operate well on short reads that have very low errors so we weren't able to do better than them I think that a machine learning based approach works is kind of the best in comparison to existing approaches on ingredients um so I think actually I I mean we haven't done any experience on this but I think Amaze would probably work well kind of out of the box on sequences but I think when you look to apply it on short reads I think machine learning might not be okay most optimal to handle that yes