[
    {
        "start": 0.68,
        "text": "thank you very much this is a very well organized seminar Series so thanks to Marc Aon I uploaded my slides like an hour ago and I show up here and they're magically ready to go and everything I think that's that's fantastic um and then Marcy emailed me about a talk title and I was like a month late in responding to her so that's uh if it was delayed that was because of me I'm going to talk about metabolic models is sort of the tool or technology uh we use a lot in our lab uh and I want to start by saying why we use the metabolic models I won't focus too much on the biological question that we're going to ask and then I'll give you sort of the outline of what we're going to talk about today in terms of models but here's the here's the general idea in C all right the big problem is that despite the explosion of data everyone says there's big data and we have so much data we don't know what to do with the data I argue the opposite so in my "
    },
    {
        "start": 62.0,
        "text": "corner of the scientific world we study bacteria uh we have a tiny data problem in fact we we don't have any data um Big Data would be nice we just don't have it this is a a analysis that our lab did I took every single Paper that's ever been published on bacteria and then we map them out to all the different species of bacteria that we know about so we know about 46,000 different species of bacteria if you see how many papers are published on every species in the history of microbiology you find out that about half of all papers only talk about 13 of the 46,000 species of bacteria and 90% of papers talk about less than 5% of all those species so the vast majority over three qus of every bacterial species although we know it exists we have its genome in a lot of cases no one has ever studied that bacteria we don't have any information other than there's this thing out there somewhere that's the species of bacteria and you might think well this problem is going to go away because we're all "
    },
    {
        "start": 123.079,
        "text": "drowning in the literature if you take the number of papers that are published every year and you correct it by the number of species that we're discovering in microbiology it's actually going the opposite way so we're publishing about 30% fewer papers per species now than we were a decade ago because while the papers are going up the number of species we're discovering is exploding a lot faster so we're going backwards in terms of data we don't really we know less and less about more and more things in microbiology it's called it's an ignorance explosion uh to quote James baffing way so these are the bacteria that we study um there's four of them that I'm going to talk about uh today these are strepto oxide the only place in the entire world they live is on the surface of your teeth and that's all negative they appeared as species about when humans invented agriculture which was about the time we put enough carbohydrates in our mouth that we could sustain these bacteria and they've been passed along human to human ever since then that you probably have these "
    },
    {
        "start": 183.72,
        "text": "bacteria in your mouth uh you usually get them from your mother so you know little kids I have little kids they put their hands in your mouth and you're holding them and then they put it back in their mouth and that's how the transfer of this bacteria occurs because they only live on your teeth and everyone's born without teeth so at some point when your teeth show up uh these have to arrive and they do so within about 48 hours now everything's fine and dandy until one of the bacteria um starts to overtake this nice healthy community that lives on your teeth usually it's streptococus mutants it ferments sugar into acid it really concentrated acid uh it makes a bofilm that we call plaque uh that concentrates the acid and eventually you get so much acid that it kills off all the rest of the bacteria the acid is so strong that it demineralizes your teeth and we call this a cavity so the reason you have cavi is because these bacteria if you took these bacteria away you can eat all the sugar that you want and you would never have a cavity you might have other problems but cavities would not be one "
    },
    {
        "start": 244.439,
        "text": "of them there's another bacterium too that does this we're not really sure its role this is the one that our lab is really interested in esus uh but for the most part we know that these cause uh cause tooth decay that cause cavities but we don't know a whole lot about these bacteria especially some of the Lesser studied ones I guess salivarius or or esconi right so today we're going to ask the question can we predict what these bacteria need to grow because if we can get the good ones to grow and not the bad ones to grow we could in theory eliminate tooth decay because this is what causes the tooth gate collateral damage from them making all this acid from the sugar that we and the tool we're going to use we're going to talk about metabolic models I'm going to show you that we can build some models for the oral stupic oxide I'm going to show you where the models break so where this is a good tool and where this is not a good tool and then we're going to fix the models uh we're going to show the process that we go through and doing it and the very end we'll ask well should we is should we even need a model maybe "
    },
    {
        "start": 305.759,
        "text": "there's ways to do this without a model in general now I'm going to structure this with a brief history of AI particularly AI That's used to play games because I think this is a fascinating topic and the development of gameplay in AI exactly mirrors the evolution of how we've been doing this type of modeling in our lab and I got really into reading about the history of AI I read the 750 page book on uh AI playing checkers it's a history of doing that my wife thought this was silly that I was reading so much about Checkers uh I'm also terrible at Checkers I I I'm fascinated by these AI I can't play any of these games my eight-year-old daughter beats me we play checkers or chess or something and she always wins and uh in an innocent way that only an eight-year-old can a couple weeks ago she asked me Daddy how come you're the one that reads all these books but I'm always the one that wins so there the books are on history not on strategy is my excuse so let's go back in time this is 1994 it's when IBM's deep blue beat the "
    },
    {
        "start": 367.52,
        "text": "chess Grandmaster Gary kasperon and so so the IBM deep blue team will will claim that this is the first time in artificial intelligence has beaten a Grandmaster uh a world champion at a board game it's not really true because the the Checker book will say that they beat the checkers world champion uh which is a thing I didn't know about either before I read the book a couple years before so the the chess thing came after Checkers it l later on now how this worked it was something called a rule engine so there wasn't any learning that happened here people programmed in and said you know this is good this is bad this is how we value the pieces a rook is worth this many points a pawn is worth this many points um there was a a rematch that uh caspero this was a rematch casprov originally won uh they played before and he won there was a big negotiation with IBM to say we're going to play again and the second one caspero lost um Casper wasn't too happy about this um "
    },
    {
        "start": 430.24,
        "text": "when he actually resigned uh he made an illegal move to resign and that illegal move was talking to his mother who was in the audience that how he all of a sudden started talking to her and then he sort of left and stormed out of the Arena he right afterwards said well he thinks that there were chess Grand Masters who were hired by IBM to help with the programming that were actually influencing the game and making moves later on he sort of went back on that and and admitted that this was an actual win for AI because while it was a close game with deep blue there would be no close Mash now in all chess okay so these were rule engines and the way they work is they combine two things knowledge and search so we hardcode in what we think humans know about Chess and then we use the computer and deep bles case specialized Hardware that's designed to look ahead and play ahead in the game and figure out if this is a good move or a bad so to still human knowledge it's hardcoded in by engineers "
    },
    {
        "start": 490.56,
        "text": "at IBM and then search so um we have to somehow translate computer to computers what's good in chess there are whole journals academic journals dedicated to computer chess that have debates over how we should encode the knowledge and then we have this this heris search that goes forward and said well this is a good move or not now there's a trade-off here because it's very difficult to distill human knowledge into a computer so everyone agreed that the computer's knowledge was worse than a grand Master's knowledge but the computer was much better at searching than Grand Masters were it could test out more Physicians and look farther ahead so the they viewed this as an inevitability that eventually computers would get fast enough that with their inferior knowledge their better search would overcome it and that's that inflection point happened between the two casprov games the first game it wasn't looking far enough ahead in the second game it was and they were able to beat the grand champion so when we started building "
    },
    {
        "start": 552.24,
        "text": "models of bacteria we did it exactly the same way right so we decided let's take all of the human knowledge everything that we know about a bacterium's metabolism and let's write out the rules let's hardcode the information into a model we use this technique called flux balance analysis where we view the cell as a factory this square box is the inside of the cell and it takes certain inputs uh in its environment and then it produces outputs like biomass or energetic phosphates or something and in between this conversion happens because of all these rules that we've programmed in that if you bring in a molecule of glucose you can turn it into fructose and fructose six phosphate and so on that's all pre-programmed um we have rules about what reac action are available about which way the reactions go about the stri ometry the thermodynamics whatever we can uh take from humans and encode we try and stick it into the model and then we can do simulations and say can you grow is it possible to make biomass "
    },
    {
        "start": 614.24,
        "text": "given these inputs to the factor and we solve it using optimization techniques like linear program and so that that's our first that's like our deep blue our rule engine now where do these come from there are wonderful systems where you can put in an annotated genome and it will look at the enzymes it will find the rules out of the database and then it will give you back the rule set say here is the rules for your particular uh organism it gives you a a draft model so we did this we took our oral strepto oxide they have sequence genomes and we put them in and said tell me what's going on and what we found in our experience that these aren't good at generating strepto coxal models you either get EOL or you get basilla subtl so the the gram negative model bacterium or the gram positive model bacterium the model you kind of get one or the other just a slightly different flavor based on your organism strepto oxide look very different um an example strepto oxide "
    },
    {
        "start": 674.399,
        "text": "don't have a TCA cycle they can't do oxidative respiration they're missing a couple enzymes but the the model annotator that automatically put that in because that's the easiest way to make sure that the model grows and you know that that isn't case so the graduate student working on this key ninja joley uh said all right I'm going to do it myself and he threw out the draft model and he went uh enzyme by enzyme in the genome during the entire thing and manually pulled out the rules from a biochemical database and added it to the bottle it took him a year of doing this he went through all these different steps it's different if you're looking at metabolic enzymes or Transporters you have to go in and fix all the gaps he did it all entirely by hand just like the people uh programming in rules about Chess uh for deep blue in the end the the model is about 656 reactions total uh the genome for these stopic oxy is about 2,000 genes so they're less than "
    },
    {
        "start": 734.76,
        "text": "half the size of the POI this is compared to the automatic generated model so that's the kbase one for the system of biology knowledge base is the acronym that had about 700 reactions but uh his model had far fewer gaps there's a much higher quality one we liked it a lot uh the model covers all sorts of different uh subsystems in metabolism it was the best that we could really do in terms of this is everything I think that's going on when the bacteria eats and tries to divide this is the the picture of the model this was also drawn by hand this took Keenan about a month to get all there's a you can use side escape and things to make the models but they don't look like the biochemical Pathways which are done by hand so he went in and placed every reaction action and every component on the model this is what the inside of of smut looks like the downside of generating this by hand is that when you make changes to the model you have to go and fix the map as well and and as you can imagine those'll stay in perfect agreement in our lab all "
    },
    {
        "start": 795.24,
        "text": "the time they never just like the documentation in the software they never drift whatsoever that was sarcastic or it didn't come through on the thing okay so we we had to test the model so you want to play some people in chess we got to try the model out so stupic oxy are very finicky they need a lot of stuff to grow and that's because they live in our MTH so they're like uh kids that lived at home their whole life and then they go to college and their parents always cook for them why would they learn how to cook for themselves when food is just there we put food in our mouth three times a day they don't need to they don't need to learn how to make rival flaven because if you ever stop eating rival flaven you're in trouble and it's an evolutionary dead end so they forgot how to make rival so uh the media that we grow them in has about 40 different ingredients and we uh pulled every ingredient out of the media one at a time this is a list of all of them and then we compared uh how the model predicts it grows versus the experimental data came and went in the lab and actually did all these "
    },
    {
        "start": 855.88,
        "text": "experiments and you see that the model works pretty well so the the orange the experiment and the blue dots the model line up pretty well so it's quite predictive there are exceptions some where the model is a little bit off right it seems like our rule engine works inside the model we also have a linkage to the genome so everything that's in the model was there because Keenan found an enzyme for it so we can do different simulations where we say well what if you delete some of these genes in silico can it still grow we can do the same that experiments a microbiologist would do by deleting the gene deleting the corresponding reaction and then resolving the model and when you compare this to Gene knockout data that have been done experimentally these were done in two different ways one by manually knocking out individual genes and another one uh using transpose on mutagenesis you see that the model overall is about 70 to 80% accurate in predicting the function of genes when you delete them right now it's skewed slightly "
    },
    {
        "start": 917.079,
        "text": "because most of the genes have no effect you delete single genes so the organism the largest chunk of them says well it's still gross doesn't do and now we can do all sorts of fun predictions with our tool this is a set of Pathways that's eating rapanos which is a sugar i' be surprised all the different types of sugar that are in your food s mutans can eat about 20 or 30 different types of sugar and obviously we've been eating that otherwise they have no reason to eat them as well so when uh s mutans digest rapanos the model predicts it actually needs some enzymes that are used to process galactose because it takes rapanos and it turns it into galactose and then eats that this all happens inside the cell and that prediction turns out to be correct in the model so when you delete these genes gal K and Galt then all of a sudden it can't uh can't grow as well on raps you get this buildup of intermediates and when you put the genes back then it grows fine as well so the we can make forward predictions too with the model after we "
    },
    {
        "start": 977.319,
        "text": "have so now we have our rule engine and this was so exciting ke said I'm going to build more models of the other strepto oxide so we can start to simulate these community and I said well that's great just take the mutans model and then figure out what's different and then change the enzymes he said' no that would bias the results start over from scratch so he did he went back and said all right enzyme one of the second organism and went through every single enzyme and he built four different models for four closely related bacteria they're all stripc oxide they all live in the mouth and he got models and the models are slightly different they have some big differences in their metabolism some of them can make fol light some of them have an oxidor branch of the pentos phosphate pathway uh but in a lot of cases they're the same and these models work well work well too we did these leave one out experiments we tried to find Gene essentiality data and we can look at it and yeah if you do single perturbations the models seem to hold then the wheels fell off right so "
    },
    {
        "start": 1042.919,
        "text": "this is a whole bunch of growth experiments that were done in the lab I'll tell you in a bit how we did it but this is uh a growth assay each box is one experiment where we have removed two amino acids so the diagonal is the single amino acid removals and then every you know the the top corner there would be Arginine and alanine that are taken right so there 20 amino acids uh this is the combination and you see all these interesting oxit tropies that the bacteria has this is the four different bacteria this is when they're growing with oxygen on the top and without oxygen on the bottom and they look very different right they they for some reason want different amino acids and can't live without different combinations of amino acids some can convert other amino acids to others right even though they all live in the same place they've all been presumably eating the same thing uh in their entire evolutionary history that's interesting what's scary is that the model says they're all "
    },
    {
        "start": 1105.919,
        "text": "identical right Keenan found every enzyme needed to make every amino acid in every Buck the model actually predicts that they have in their genome everything they need to make all 20 amino acids starting from carbon and nitrogen and sulfur so they don't need anything they're just not using the enzymes that they have and it's in a different pattern right so they're all different but the model says no they're actually all the same and if you put the model predictions all of these boxes would be white they would all be no growth defect whatsoever as the model said so this is a problem and the problem is that this doesn't show up until you look at higher order thing until you start taking two out it's actually pretty good at doing the single amino acid at a time predictions it has high accuracy right but the it's the combinations that are bad so we have this issue now where if you looked at all the possible combinations of amino acids the model is "
    },
    {
        "start": 1166.799,
        "text": "right when you say if you give it all the amino acids yes it grows when you take them out one at a time it grows the model agrees with the experiment down on the bottom you take them all the way and it it's dead and the model says it can still grow it because it doesn't need them right so somewhere in between is where the model breaks if we're going to fix it we have to find where the thing breaks the problem is that there's a million experiments in between is 2 to the 20th the number of amino acids is a million right so even if you wanted to start by doing the leave two out that I've shown you each one of these triangles here these assays it was 213,000 pipetting operations to generate one of those trucks right and that's just to get the leave two outs and then you have that's 10,000 a and then you have the leave three outs and the four outs and the common motorics are just not in your favor whatsoever okay but the model's clearly wrong we can't just keep saying this "
    },
    {
        "start": 1227.48,
        "text": "model works just fine and AI went through the same issue right so chess they had beaten caspero go which is another board game which is viewed as more complex this is the engineer who he started at Carnegie Mel and moved to IBM and he was in charge of the deep blue team and he said this is in 2002 that go is the hardest game board game that we know of uh it's not going to be solved we're not going to be a go grandm within the next 20 years this was after his victory in fact this was uh eight years after his victory over cast says go is completely unreachable and he said this because of the complexity so Checkers was solved entirely um we have a deterministic solution Checkers is a draw if the two players play optimally no one can win that was solved in 2008 there's a paper in science called Checkers is solved by a group of the University bur chess has a complexity about 10 to the 46 the be "
    },
    {
        "start": 1288.6,
        "text": "Casper at that Go's complexity is 10 to 170 I said absolutely not we can't solve this not even within 20 years 14 years later um they beat the world champion in go all right this was a team by uh deep mine which is now owned by Google uh they came up with a program called Alpha gold that beat least at all there's a wonderful documentary on this for free on YouTube You'll watch it you'll cry I show it to my class every year student say they teared up at one point on it you should you should do it you need the link send me an email I'll send it to you and and they beat Le adult who was the spoiler alert on the documentary they won they beat leas at all a couple years later leas at all quit the game of G the world's greatest go player says what's the point the computers are far better than humans will ever be and he retired and hasn't played since okay so what happened this wasn't a rule engine this was the next step in AI history they said well we can do "
    },
    {
        "start": 1349.0,
        "text": "a rule engine and we can augment it using uh data so in their case experimental data was taking two engines and putting them next to each other and having them play one another and then based on the data based on that experimental result they updated the parameters inside their model which in their case was the neural number so we thought this is what we need to do the the problem we're not going to find better rules we don't know the rules Beyond met cism because most of these bugs are under study we don't know anything about the regulation we just need to start doing more experiments the problem with that is that experiments are hard so what would be nice is if experiments work like this this is experiments in Python you say for uh all the amino acids and all the other amino acids you take CDM which is the name of the media we have remove this is fake code this doesn't really happen you remove it and then uh you say all right you know run the model and get the result this works on the model we can simulate these pretty quickly this "
    },
    {
        "start": 1409.919,
        "text": "doesn't work quite this way in the real world to say well you just Loop over all the amuno acids and then take them all out uh so it works on the model and what we decided about five years ago is that the only way we're going to get this to work because the only way Alpha go worked is they played millions and millions and millions of times is we have to be able to do this with experiments so uh we had an undergraduate who had just graduated and he became a postback for two years his name was Adam and I sat down with Adam and said all right I want code like this to return a result but the result comes from the laboratory so you send an experiment like this and it's going to kick on a whole bunch of robots in the laboratory that will set up this experiment run the experiment collect the data normalize it process it QC it and return to the computer the result so it's going to have to wait 24 hours while the bacteria grow but the computer should not be able to know the difference between whether this "
    },
    {
        "start": 1470.48,
        "text": "prediction came from a model or whether this actually came out of the lab I said if we can do that then we can run whatever experiment we want and I think we actually have a chance of fixing these models because we can use the same idea that Alpha that Deep Mind did in training alphago uh so Adam did it he pulled it up and we now have this system 14 robots in the lab and they can run all sorts of experiments just at the direction of these computer programs now there's a some issues that come up that I would like to highlight um to give credit to Adam and all the engineering work that he put in so let's say most people think of combinatorial things I think of you know drug screening as the example let's say you wanted to do a pairwise screen of 50 small molecules I do all combinations of 50 different drugs this that's 1,200 or so combinations you need to add the drugs to every well you also need to put the cells in the well but that's just that's an order of one approximation we'll leave it out and we call this a low "
    },
    {
        "start": 1531.08,
        "text": "combinatorial screen it requires 2400 pipetting operation a lot for a human but our robots can handle that when you're leaving stuff out that's a bit of a misnomer you can't take stuff out of the mediate we can't buy the full CDM and say ah take the Arginine out and that that doesn't work we have to make CDM and just not put Arginine in so if you have a 50 ingredient media and you want to take two things out you have to put 48 things in every single one so that's why we get this explosion that the same size screen is now 58,000 combinations and with replicates and controls that explodes to the the 200 and some thousand operations that I mentioned before and you get all sorts of other issues when you add drugs you put in a tiny amount you don't really have to worry about it because you're adding two things to every well when you're doing these screens you have to put in 50 ingredients most of the volume of the final experiment is all stuff "
    },
    {
        "start": 1592.24,
        "text": "that you put in so now you have to worry all sorts of stuff about the ph and what the things are dissolved in then will it actually all fit inside a multi- will plate all these engineering issues Adam had to solve so it for every single experiment that we do it solves about six or seven mixed integer linear programs in order to plan the experiment before it gets sent to the lab and we joke that it's harder to plan the experiments there's more MTH that goes into that then actually goes into the model um in the end it certainly takes less time to plan to run the model the plan experience so this is our system this is some of the robots that we have it's sort of a loose collection so you're not going to walk in and see like a Skylab type thing the instruments are scattered throughout the lab when we first got this up and running we could do 300 experiments a day now we're up to about 10,000 experiments today that we can do all individually requested uh by humans we turns out you don't need that many experiments today we bit overshot on the capacity uh so usually we run in "
    },
    {
        "start": 1655.6,
        "text": "the hundreds to about a thousand experiments every day okay so what can you do we now we have all the data that we want uh we can start to update the rules on our model and learn changes to them that aren't really mechanistic rules but to sort of fit the data Corrections one of the things that we can do is say well when you take out an amuno acid a bacterium either has to eat the amino acid or it has to make it itself so when you remove an amino acid from The Medium you know that the only way it's making amino acid is by producing it on the inside internally so we came up with sort of a simple machine learning technique where we said for every one of the amino acids all 20 we're going to put a throttle on the internal production so we'll say that if we take away the amino acid out of the media right then we're going to put a cap a numerical cap "
    },
    {
        "start": 1715.799,
        "text": "on how much internally it can make and we set that cap to fit The observed data right so if you take alanine away and the organism dies then that cap is zero it can't make any alanine otherwise it would be growing a little bit right if you take alanine away and the organism grows just fine then the cap is very large it can make all the alanine it wants clearly makes enough alamine to be able to grow as fast as it did before so you can set this par this is only 20 parameters that sit on top of the model they're not mechanistic we're just sort of you know making up a transcription factor that shuts down or caps all of the allany production so only 20 parameters but we fit it to a large amount of data and it makes big changes to the model so here is uh 3100 growth experiments and they're sorted and uh we you should probably stop doing that because this looks like a bacterial growth curve but it's not and each one of the Dots here is a single growth assay so how much it grew at the end "
    },
    {
        "start": 1777.279,
        "text": "point and there's 3,100 dots just sorted from no growth to maximum growth so a lot of the conditions this is by taking out amino acids a lot of the times it's dead sometimes it grows just fine and then we have a couple hundred conditions in between where it has sort of intermediate grow all right these are actual experimental results now I'm going to show you the model predictions if the model was perfectly correct all of the model's dots would be right on top of the green line because for every Point says here's the experiment the model prediction would be right on top of it so that's what we're hoping that it should just change color but they should be right on top and now what we see right because this is the model again saying no you're fine you can grow without any amino acids it doesn't matter how many you take away the model was wrong all the red dots are up on top if you just do this throttle just add 20 par to a model that has 700 reactions in it and fit it to the data this is what you get right and these are these are test data these are not data that were used "
    },
    {
        "start": 1838.64,
        "text": "to fit the throttling these are data that we're taken separately right still not perfect at all but for 20 parameters we think that's that's pretty good in the extreme this is some very preliminary work that we're just starting to do now we thought well you know for amino acids the throttling worked we could come up with a way that we need to stick a parameter right here and then adjust it and that will help out the model in general we don't have that because there's all these higher order XS that jump in so U we decided that instead of putting parameters inside the model let's just stick a neural network on the outside of the model and and here's how it works so we have the nutrients these are the inputs to the model those go to the model and we're also going to put those as inputs to the neural network now the output of the neural network are the enzymes the genes that go into the Mel so what this neural "
    },
    {
        "start": 1900.039,
        "text": "network represents is a sort of fake trans transcriptional regulatory network of the cell it gets to see the environment and it gets to go change the gene expression pattern inside the cell it can shut things off it can move things up it can make a change to what enzymes are available based on the environment okay and this neural network is filled with lots of parameters so now we show what training data we have all sorts of experiments where we say here are inputs here's the growth and then we train the neural network by actually propagating the loss back through the model it takes a little trick in order to do it but you can train the neural net now to learn how it should change the patterns of Gene regulation in order to get the model to fit the experimental data right so it basically now has unlimited parameters but the parameters are not at all inside the model they said outside and we're training this transcript form now we don't know what's "
    },
    {
        "start": 1962.0,
        "text": "causing the regulation you can't say what's the transcription factor that regulates this all we can say is that given this metabolic environment what does it predict happens to the genes the metabolic enzymes would say these are up and these are down I don't know how that happens in a Cell the they only that is a black box but we think that's the most consistent way for it to work and if you do that so we're still working on this and we're coming up with better ways to train this neural network now these are the same Data before you get sort of these banded patterns from the model uh the banding is based on whether or not the experiments were Anor robic or aerobic but really the model only predicts three different levels of growth and after you train the model then you start to see patterns like this so now uh this is with heavy heavy regularization because we know could just memorize the data uh but we start now to fit the intermediate grow so it's learning something about oh I can change these enzymes in order to get the model to be more predictive afterwards so this still ongoing we're "
    },
    {
        "start": 2023.84,
        "text": "getting really excited about it if we if we you know want to show it all the data and really back off the regularization we can get the model to predict almost perfectly but we know that that's then we're just overfitting a little bit so this is a balance between between how much data we've collected versus how big we make the neural net the neural net is not big it's about three layers um uh about 128 hidden nodes inside it's a small neur net because we we don't think that this should be a hugely complex logic in order to do this type of Regulation so now we've come a way to correct uh our LS but the nice thing this we can add in that's not even in the model so we can give it a stressor we say well these bacteria respond to fluoride there's there's no fluoride in the model so we can't simulate the effect of fluoride right now but we can train it on data where we give fluoride in experiments and then we can have the model learn how it would modulate the things that are "
    },
    {
        "start": 2084.599,
        "text": "actually in the model of predict fluoride so that that's a another thing we're hoping to do in the future okay the last question you have is the models are great you made this model you're spending all this work fixing it if you wanted to know if the bacteria grow do you really need a model you have virtually unlimited experimental data so we've done about a million experiments now in the lab like at at some point you you can just ask and get the result do you need them all so we decided to explore that Avenue a little bit and this also mirrors what happened in the AI game plan world so uh the same team from Deep Mind now said we're going to train a new neural net that will play go but rather than starting with games of Go played by Grand Masters which they' used before in Alpha go we're going to start from nothing we're just going to make random networks we'll start by "
    },
    {
        "start": 2145.64,
        "text": "making random moves and they're going to learn from each other and we'll see if that works because then we can apply it to places where we don't have training data well this works much better right human knowledge apparently is just a bad idea when you're playing going because if you use human knowledge as a starting point you can train something that will just beat a human but it's kind of limited because it's biased by the way humans play if you start from nothing these models train faster and they end up beating hands down the other previous models that were trained at the humanity so this is the way to do it for gameplay it works using a technique called reinforcement learning where you have an AI agent that requests experiments in the case it makes a move and then it plays a game and it gets some sort of reward did you win or did you lose and they actually wait and only give it a reward on did you win or did you lose they don't try and give it any intermediate reward so we thought can we do this can we just have an agent that says well I can run things in the lab I "
    },
    {
        "start": 2206.92,
        "text": "can do an experimen did I get it right or not and then I update and I can keep on guessing and eventually train a model that can predict the experimental results even though it knows nothing about metabolism it doesn't have any doesn't have genes in it it doesn't have enzymes it doesn't have any of that stuff just all from scrap the issue is that for go you can have two of these things play each other inside a computer and we can't do that with the bacteria so we have to have it requesting experiments from the robots in the lab and then waiting for the results so while they play billions of games against each other to train something to play go uh we have to go a little bit slower because we have to run this in the real world and then at the end scientists are still want to know why why does it grow or why does it not we don't really want an agent that can predict growth we want it to tell us something so we took our automated lab and we hooked it up to a an AI system that would request experiments so now we "
    },
    {
        "start": 2267.68,
        "text": "were done designing experiments and every day the AI system goes in and plans experiments requests them it gets them back and we really don't know what it's doing so we have all these robots in the lab that are running experiments and if you ask me why is it doing that experiment I don't know this the AI is kind of in charge here so every day at 9:00 amm a technician comes in and finishes collecting the data previously the data gets sent back to back AI which is the the name we invented for it and then we couldn't come up with a better name so that name stuck by default uh it gets an hour in order to bid on experiments it has a budget of so many experiments you can do every day and then it has to figure out what's the best one to run it has its own little argument well it searches for those we give it one hour because at 11 o'cl we have to start the robots to do the pipetting so at 11: the robots begin pipetting they get inoculated about 3:00 put in the incubator and then the next morning the cycle will all repeat and the number of technicians Adam with the one leading it Kevin Kim and Daniel Lea "
    },
    {
        "start": 2329.52,
        "text": "were the ones that got the entire system down that we could do this and run this every day to shorten all these all these windows up Adam on the software side and then Kevin and Danielle on the hardware side to get the robot St so here is our non- mechanistic model learning I'm showing you the experiments that it picks every day every Circle here is an experiment and uh the numbers are the number of amino acids that it requested to be removed from the media right so zero is the full media 20 would be a media with no amino acids and then everything between the circles are are filled or not if the agent predicted that it was going to be grow or not grow and the Black versus red says was it right when the answer came back the next day was its prediction correct so on day one it has no idea what it's doing it's requesting random experiments it's decision is should this grow or not is random it's a randomly initialized neural network that's predicting whether "
    },
    {
        "start": 2390.92,
        "text": "or not this grows and it gets about half of them incorrect then we start learning this is on day three I'm showing you every other day here just to speed it up now there's a lot fewer red circles all right so it's learned it's better predicting the next day now we don't let the agent repeat experiments so the easiest way for it to score points would be to see the answer and then say I run that experiment it's not allowed to do that if it if it a request an experiment it's already run it says no go back um and that's part of the computational challenge of scheduling is it keeps on wanting the same experiments because they were informative but we have to tell it tell these are always brand new data predictions get better this is day three now here's day five it's not monotonic sometimes it gets a set of data back and it it predictions actually get get a little worse for the next day you know I'm sure chess players go through the same thing where I started thinking about this new opening and actually lost more games could quite perfected it but by day 13 "
    },
    {
        "start": 2452.16,
        "text": "it can predict uh with 90% accuracy the results of experiments before or they happen so it makes predictions when it schedules them and we compare to the data when they come in the next day and once it's over 90% we say all right you're good we can stop collecting data now inside the agent is where the learning is happening it actually has a neural networ so it's it has a neural net that's not predicting does it grow or does it not it's actually predicting the amount of growth The Continuous value for growth this is what the neural net looks like so the same data but now we have the model predictions in blue and the black dots are the actual experiments after the data come back in so again if it was perfect the black dots would be on top of the blue line at day one it's random there's no correlation between the experimental results and the black dots much more of the media are no grow so with if you look at all million amino acid combinations only about 3% actually grow so it has a hard time picking grow these "
    },
    {
        "start": 2512.359,
        "text": "strings and then here's the same neural that over the 13 days so you can see that very quickly uh it can accurately predict not just if it grows or not you do that binarization at the end but it can tell you exactly how much it's going to grow before the experiment happens so now it knows it can say oh I can predict growth and now we're very jealous of the model because it knows but I want to know can you explain to me and it says well easy there's a billion parameters and on NE and I said no no you got to you got to dumb it down for us measly humans here so we actually make it do something else it finishes running a cycle and then we say all right now we need to do another cycle there's a separate AI agent that tries to extract a logical rule from the first agent so we have a second machine learning cycle where it's trying to dumb this down into something that the humans can understand and it does this by constructing a logical rule about what amino acids it means to grow so this is one of the bacteria esconi and this is the rule "
    },
    {
        "start": 2573.72,
        "text": "that's extracted from the AG afterwards needs Arginine and Lucine and pheno Aline and serin and tyrosine it needs either cysteine or veine and it needs either glutamate or glutamine so it's dumb down but it's still about 85% accurate at predicting growth so if I wanted the prediction I would just ask the neuron net but if I want to understand what amino acids that needs this I can use this one and I can try and design me and say oh that makes sense glutamine and glutamine there's one enzyme that converts between the two that that's logical for we we stopped it and say all right play the whole game again this is on a different bacteria and it ends up with a different Rule and so these rules reflect the differences between uh the oxit tropy patterns right same bug live in the same place but they have differences in what they require even when you simplify it down for the humans for S mutans early on we did a little experiment we ran back to AI for about 2700 experiments and we asked it to give "
    },
    {
        "start": 2635.359,
        "text": "us its rules so this was not its best rule it hadn't even converged at the time and then we had it play against uh a grad student we gave the grad student the leave two out leave one out leave two out data and say Keenan can you come up with a logical Rule and that's what Keenan came up with and that's what backi came up with and uh Keenan's rule had better accuracy it was a win for the humans because this this didn't make any sense until you realized that we were scoring ing it based on the leave one out and leave two out data if you look at all the data fact even data that it didn't use to develop its its rule uh bacteri is right there's this other second oxit tropy between Lucine and proline in s mutants but it doesn't show up until you get to three or higher interactions right so we think we're right oh we're doing better than the machine because we can only hold the small number in her head but if you yeah "
    },
    {
        "start": 2698.16,
        "text": "really Factor eye one uh Indian and then Keenan retired from science and said there's no point no he's he's doing great he works in the Biotech Industry doing machine okay so in summary sort of three different uh tools that we use all about predicting growth so we started with our rule engines the metabolic models and we said we need to fix the rule engines just like alphao did the play go but preserve the human knowledge and make it better and then finally we said do you know maybe the humans just get in the way and we can have robots tell we can have ai systems tell other robots uh how to pick experiments so the amount of human intelligence has decreased in our models over time but the amount of artificial intelligence is ramping up to the end point the limit now where we don't put any human knowledge into our models uh if we just want to know why they grow this was kind of predicted um "
    },
    {
        "start": 2760.48,
        "text": "this is Phil Bourne who is the uh the first head of data science at the National Institutes of Health he's now uh the dean of the school of data science at the University of Virginia he wrote an article in 2021 called is bioinformatics dead which I thought would be an interesting article for this this audience and so this is a quote from this paper which is a fascinating paper he said in 2024 this is Phil Bor now I predicted that by 2020 um computation would be the the big thing experiments would be used to confirm predictive models causation would be determined digitally uh or by bioinformatically guided laboratory robots that maximized experimental insights he wrote this in 2021 and then he admitted he said well my predictions about the timing were off this wasn't going to happen by 2020 but not about the outcome you still believe that this is where everything is going um and I argue he wasn't off very far because you know I've just shown you something that "
    },
    {
        "start": 2821.2,
        "text": "you could say is a bioinformatically guided robot that does its own experiments uh and he was about two or three years off in the prediction so I think it's going to be a a fun challenge to say where is the bioinformatics Stop and where is Pure data stop and then where is the interface between the two what's the value added on both sides uh thank you to everyone that did all this work and and the different funding sources that Adam was the the real leader in a lot of the automation type work Kenan was the one who built the models the the model neural network hybrid was Brandon Brash who was a a master student has just graduated and also now works in the Biotech Industry and uh happy to take any questions and I'll leave you with one of my my favorite quotes which are actually given to me by thank you everyone "
    },
    {
        "start": 2882.96,
        "text": "great talk um I'm curious about the growth is the output um can you say a little bit more about like why is that like the key outcome for understanding the cellular biology yeah so our end goal for this is to try and say there's this community on your teeth and we have ones that we want to win and one that we want to lose and and that's largely a a growth process um so learning their growth rates is actually relevant for the disease because the only way they can grow is by proding the acid so um there there's a direct correlation between how much they're growing and how much acid they make now that doesn't mean that there's a lot of outputs that we should be measuring that influence growth so for example if we eventually mix these together and bacteria a you know promotes or inhibits the growth of the other bacteria we have no clue why that is we're not measuring "
    },
    {
        "start": 2944.72,
        "text": "if they have bacteria s to produce maybe they're making a metabolite that the other one can eat um You' have to switch to sort of a multivariate output model um I think it would work the the there no problem on the modeling side is the experimental side you know we can't be doing 10,000 metabolomics experiments every day and and that's why we can't start so anyone who's interested in doing a 10,000 metal profiles to day I love to talk to you or has the money to do, 10,000 profiles I think that's that's why we yeah thank you for the presentation was amazing my question is can you give an Insight how does the the interpretation model works like how it Crees the this logical Expressions so uh it does it using a "
    },
    {
        "start": 3005.88,
        "text": "genetic algorithm which I usually leave out because that gets very confusing talking about biology stuff so what happens is it uh it makes a candidate rule so kind of use it as a tree of ANS and ores and the different metabolites and then it mutates that tree structure and then evaluates again the data says how accurate was the rule so it makes a whole bunch of these rules and mutates them and recombines them and scores all the rules and over time you evolve one rule that fits the data really well so that was our strategy there's a lot of other strategies that can use logical induction from Rules we were very particular about how complex the rule could be we can get more accurate rules that are you know even more complex we could probably fit it just as well as the network if you did a like a a classification tree or something like that but so we C and said you can only have this many terms in the rule it can only have this many causes inside each "
    },
    {
        "start": 3067.0,
        "text": "other um because we wanted it to be simple that that's the only reason just for interpretive yeah and can you also share your vision on the future development of this so the things we're working on now uh one is we want to get the number of experiments down so like I said we could do 10,000 a day but what it turns out is that in the limit of infinite experiments you don't have to be intelligent at all to pick them just pick random experiments eventually have the data that she need and we're almost at that point so we have so many experiments coming in that we don't have to make really good really strong choices you can't quite train the model in just random data that number Rand data um but it's it's on the borderline so some people are trying to push that down say what's the fewest experiments that we could do because we have hundreds of bacteria that we want to get "
    },
    {
        "start": 3127.64,
        "text": "through and train these models um we have some people are working on doing this directly on community so if we mix these up and just measure the growth of the community can we run that in the same cycle and say now the model doesn't predict growth of the bacteria it predicts the abundances in inside a community one one more student is working on gene expression so we sequence do RNA sequencing as the Endo rather than growth and can we learn to predict inside the cell that that number is much much smaller the number of experiments that we can do every day Matt is helping us out with that he's on the students committee um because that becomes a very very difficult Bean optimization problem because you have to know that this experiment has value before you run no no pressure I might have missed it but "
    },
    {
        "start": 3188.119,
        "text": "what's the model of vector a like it's the same input to the model and get the Gen output and to the model the growth or is like something different in that well it's it's identical so if we were doing the data I showed you was on amino acids so the neural net is just learning the regulatory pattern of the amino acid so it has 20 inputs that are the the the same 20 inputs that go as the bounds on the exchange reaction in the model and then uh to say whether these 20 amino acids are there and then the outputs there's one output for every Gene it gives the upper bound on the gene activity that's that's model at this can only make predictions on whether par AMD is present or not but not the other like Med conditions yeah we have the largest we've done now we we have data and we have models that do with the complete CDM so 40 ingredients all "
    },
    {
        "start": 3249.64,
        "text": "together and we can use the the same strategy then it has 40 inputs and 40 output but yeah everything every time we want to expand more things in the model we also have to run larger experiments it turns out the turns out the scaling is about linear so when you run the thing in a closed loop and ask the AI to learn about it if you double the number of experiments with transfer learning it only takes about twice as long to learn uh the bigger model we were really worried that it was going to explode um and we just hit you know a sweet spot with with 20 but going to 40 takes another five to seven days and then you can learn all the growth patterns for up to 40 so we're we're hopeful on that you're scared for while question "
    },
    {
        "start": 3313.44,
        "text": "thanks "
    }
]