hey everybody this is mike mathis i'm a cardiac anesthesiologist at michigan medicine uh with the research focus on using data science techniques to improve clinical care which is what i'll be speaking about today in this talk in contrast to other talks i've seen given in this forum i'll be focusing on some of the the touchy-feely side of machine learning applied to healthcare the perspectives of clinicians who may not be experts in machine learning or data science techniques and who may have some skepticism as to how useful these algorithms actually are i think this group i know is very well trained with some of the most the smartest most knowledgeable faculty um in this audience and the and um and and certainly are at the cutting edge of developing these algorithms and i think um but i think it's also interesting to hear kind of the implementation strategies uh used in in how to meet uh you know kind of converge on a common language with clinicians on the front line again who may not be experts in in these algorithms so that's what i want to talk about today so we'll be talking about just the challenges to earning clinician trust and and having their um winning their confidence that machine learning algorithms are a credible way to improve care i don't have any personal financial relationships with any vendor but my research is supported by grants through the nih in the department of defense in addition to presenting to you virtually today i have to apologize i'm also presenting to you in a different location in space time i am recorded this lecture on monday of this week since i was required to be in the operating rooms wednesday and so i apologize uh that i'm unable to engage in a discussion during this talk but i definitely don't want to be inaccessible to those who were interested maybe even disagreed with the content of this talk i'd love to touch base with you so feel free to email me at the contacts here or over con or over twitter or however you'd like but i'm very uh interested in staying engaged with this group so in this talk there's a couple different sections the first part of it is just simply setting the stage for what a what we need to do to have a conversation with clinicians who may have a varying level of familiarity with machine learning and i will say varying optimistically many clinicians have basically no familiarity with machine learning algorithms and their strengths and their limitations and many are very skeptical so it is important to make the case to clinicians why they should care and what um you know what you know what steps we need to take to be able to trust that these algorithms may be used safely and for the better of patient care after establishing this problem space i'll then talk about some real examples or near future examples of machine learning or ai applied to my own field anesthesiology and for each example i don't want to go into a ton of detail about the study although i suggest that those who are interested can read further about the study i instead want to use each of the examples as a way to illustrate a few critically important dilemmas in machine learning applied to health care that all clinicians should become acquainted with that we have um that faculty within this group are familiar with but may have haven't considered exactly how to start conversations with clinicians and grapple some of these challenges in interpreting and applying machine learning algorithms appropriately and mitigating against different challenges so we'll start with with the first part of the problem space and the first thing that i've uh the issues that i've had in in having conversations with my own clinical colleagues is that it's important to even talk uh clarify you know what we're even talking about um and just to converge on um what specific type of ai is being is growing in in healthcare applications um and we know that there's four different levels of complexity in ai and there's on the left the simplest the reactive ai which has no no memory is very narrowly defined has very task specific goals and that's an example of that is uh deep blue that the chess program that beat gary kasparov in the 1990s um the next stage is limited memory that's that's really what we're what we have today this is a little bit broader but still task specific ai um you know it has an ability to learn from previous data adapt and and make you use that evolving data to make predictions um that guide clinical decision making or diagnostics or prognoses in the and these are still very vulnerable to edge cases to new healthcare context and that's you know it's important consideration that those are the conversations that we need to have um with clinicians and the the other two the other side of this table the the third and fourth are you know i've i've had collections just kind of jump to these and it's important to emphasize that these are these aren't what we have today these these are not rea this is not reality they the third stage being theory of mind which is a psychology term kind of getting at the notion that um you know you know um that there's there's um human reasoning in in decision making that there is both um you know a objective intelligence and an emotional intelligence and this um you know one of the next major hurdles for machine learning algorithms to overcome is is having a algorithm that mimics this thought process that can learn from fewer examples because it understands a human reasoning and an intent behind decision making and then the last stage on the far right the self level of self-awareness is a level of machine learning where um there's a human level of intelligence that can actually bypass our own intelligence and is physically indistinguishable from from uh uh humans and and that's really important to uh emphasize that we know we're not we're not on that right side of this table we're at the limited memory side um this is this is our focus this is where we're at in in the world today it's also important to frame um a you know frame the goals of machine learning algorithms to clinicians and front line users it's it's important to reiterate that physicians will always have a place in medicine and that machine learning algorithms are great tools but they're no suitable they're no substitute for the judgment the intuition and the care of a thoughtful clinician who understands the full context has all of the data not just the data the algorithm has and can understand the impact of their clinical decision making beyond kind of scoping out the the goals it's important to highlight the strengths and weaknesses to of machine learning to clinicians we know this very well as faculty in this group know this very well but just to reiterate machine learning algorithms they're very quick they're very cheap and they can make accurate they say quote unquote unbiased predictions put that in quotes simply because if the algorithm is trained on data and decision making from humans who are implicitly biased then they will also replicate those biases but you can get some replicable prediction but the disadvantage of machine learning algorithms is that of course they lack transparency and they lack a full understanding of the clinical context the judgment that clinicians have their experiences having taken care of thousands upon thousands of patients and understanding fully why the patient in front of them today is different than the past 1000 patients that they've taken care of beyond the you know the strengths and the weaknesses and the opportunities of machine learning it's it's helpful to motivate clinicians why they should care and the way i do this is i will talk about how you know machine learning and ai's is disrupting every industry and healthcare isn't any different these changes are coming and the best thing that clinicians can do is prepare for them and just like interpreting and trusting um and applying um journal articles that we're reading about in our clinical journals and and having you know being able to understand them demands a literacy in statistics and and study design just you know just like that is demanded when reading a journal article a article on machine learning should also have a should demand for among clinicians a basic literacy in in the methods that they're derived from and um and and one other thing i would mention is that um unlike you know other industries ai machine learning has been extremely slow to be implemented in health care and with good reason and so that's helpful for tempering the hype but also earning trust from skeptics that um you know skeptics in the in the um about the strengths of machine learning and how they may be used or misused in healthcare and things to think about are that mistakes matter in healthcare so you know whereas facebook misclassifies if it misclassifies your face as your twin brothers that's annoying but it's not dangerous um and um and also you know this the mistakes made by a human are preferred to mistakes made by a computer right so so it's not it's not enough for a machine learning algorithm ai to be as good as a human has to be far better if we have an error tolerance and this is the issue that you know that self-driving cars have currently it's not enough to be as good as a human driver and you need to be an order of magnitude better before humans will trust these that are at a broad scale being right isn't enough too so delivering the correct treatment or getting to the right diagnosis in health care isn't enough clinicians need to understand the mechanism and be justified in their decision making so they can anticipate and mitigate against the next problem that a patient might have for which an algorithm might not be available you know we need to truly understand the mechanisms underpinning a specific prognosis diagnosis testing and so that's very important and that's a reason why machine learning has been slow to being adopted in health care and lastly there's this issue of data sharing so um as as we know there's protections around machine learning algorithms a lot of the um ability of a specific biomedical company engineering company or or software company their their financial success might depend on protecting their data protecting their algorithm but beyond that in healthcare this issue of protected health information right so data sharing we can't even do it if we wanted to in many cases just because of this this the issue of patient privacy and so so with that overview we'll jump into the meat of this topic this talk now that being the examples of machine learning algorithms and the different dilemmas that each each example highlights and what we the conversations we need to have with clinicians if we're to make progress and implement these models in healthcare so the first algorithm i want to highlight is a study that was published two years ago in my fields leads journal it's a algorithm that predicts low blood pressure hypotension based on using a waveform the arterial blood pressure waveform and the goal of this study was simple it's to simply use an a line or an arterial line waveform to predict low blood pressure 10 minutes prior to the event actually happening it used a data set that had um three different hospitals two in the uh training data set one in the uh test holdout set and uh these were ic patients in the intensive care unit and the operating rooms and it was developed uh by using many many many more features within the a-line waveform beyond simply the blood pressure so when a clinician uses an a-line it's really only a couple things that they're looking at they're looking at the the systolic blood pressure the diastolic blood pressure the mean arterial pressure and the heart rate whereas a machine learning algorithm can extract much more information than that in this study it actually took the arterial line waveform and broke it down into 3000 different features and using combinations of those features they were able to actually come up with another 2 million combinatorial features to create a total feature set of uh just over two and a half million form features and the performance of this algorithm was very very good so it had a area c statistic of of around 0.96.97 and what and and this this graph just basically shows you how it performs in real time in certain cases this is just one example case where on the top figure you have the patient's blood pressure on the y-axis and on the x-axis you have time in minutes and then in the in you can see the patient's blood pressure slowly decreases over time gets to a medium arterial pressure less than 65 which was the threshold for hypotension on the far right side of this graph and on the lower figure you can see the hypotension prediction index and this was the probability that a patient's blood pressure would get below 65 and you can see that about 15 to 20 minutes before the patient actually had a hypotensive event this hypotension prediction index was pretty close to 100 certain that this was going to happen and so it's pretty pretty interesting and a very accurate algorithm um but you know the question that clinicians are asking the million dollar question is can it actually improve or prevent hypotension and the billion dollar question is can it actually improve outcomes and it turns out that the answer is not obvious earlier this spring jama published a paper where this machine learning algorithm that's now fda approved and it's a medical device that can be used in the ors they showed that it successfully reduced hypotension in a small single center study and just a couple weeks ago a similar study arrived at the opposite conclusion that the use of this in real time by clinicians um who you know were not you know this not data scientist but uh educated on how this this uh tool worked uh they did not uh significantly reduce rates of hypotension when caring for patients undergoing surgical surgeries and so this just highlights that there is a need for reproducibility there's a reproducibility crisis in often in healthcare uh and this is even more accentuated in with machine learning algorithms uh that that research needs to be done in large diverse populations to understand the generalizability and the effect of algorithms on outcomes and so this raises an important issue you know beyond just the success of an algorithm beyond doing a randomized controlled trial to test how well a machine learning algorithm achieves its goal um we need to understand you know will it not lead to major unintended harms and so some of you may know that the fda has taken some discrete steps to evaluate machine learning algorithms by coming up with specific regulations for software as a medical device and those regulations you know are essentially three-fold it needs to demonstrate a association between the algorithm and the clinical condition being diagnosed or predicted we need to validate that we need to understand how the predictions are accurate reliable and precise and then we need to see does do the algorithms work in the real world and to regulate exactly how fast these devices enter the real world the fda has recognized that the potential for harm hinges on how significant the intervention is and how serious the situation is so this table just shows just a regulatory framework for how tightly a specific algorithm needs to be regulated before real world implementation and on the the columns in this table are arranged um from i guess from right to left you have increasing significance so if um you know if your algorithm is simply informing clinical management um that's a less less uh you know that you know just used as a as a clinical decision support that's that's okay but if it's actually diagnosing a specific disease or establishing a specific treatment um that's a much stronger intervention that needs to be much more tightly regulated the rows in this graph um are arranged by increasing criticality so if you have an algorithm you know on the bottom here a non-serious situation let's just say we are using a algorithm to predict um how how long a patient's going to spend in our outpatient clinic and we're trying to optimize our outpatient clinic schedule um that's that's one thing but if we're actually using an algorithm that predicts a patient having a major complication after surgery for example that's a much more critical situation and much more uh there needs to be a much greater regulation around that that type of situation and so just rearranging those cells in that table um the fda has come up with a kind of staged approach for how tightly regulated each specific um a specific machine learning algorithm is before going to market and and clinicians are you know we're we're very risk averse especially anesthesiologists um you know our job is to make safe and otherwise very complex or high-risk procedure and so you know you know i'm we're taking care of very sick patients uh they're undergoing you know potentially one of the biggest physiologic stressors in their life um and so we need to trust that the equipment that is supporting the patient through their surgery is you know we need to be able to trust that that's going to be reliable and and work and so you know spelling out how us your software is a medical device has been reviewed and certified is not just a minimum requirement imposed by the fda it's really an essential component that is needed to build clinician faith that the tool is safe and i don't want to go into the details of this slide i just want to make everyone aware that this is a very important thing that clintons are taking seriously on this this fda approval process um and goes in kind of a cycle here uh starting with um pre-clinical certification uh and then a streamlined review and then an iterative assessment in the real world the performance that feeds back again to the fda review and promoting this reality to clinicians is is useful most are unaware of the fact that there are this is this fda approval process in place in that um that there's plenty of uh software medical devices that are entering the real world um these are just a few the highlight some of the ones more recently as they're uh very important to my own colleagues anesthesiologists uh looking at for example predicting predicting uh atrial fibrillation or detecting that in in patients wearing apple watches or looking at taking ekg waveform and predicting the patient may have heart failure or using a chest x-ray image using image processing to uh arrive at diagnoses within chest x-rays those are all fda-approved algorithms that you know that are important anesthesiologists are important to other questions as well and promoting this you know this awareness of the fda approval process i think is is important for clinicians to earn trust in these algorithms so i'll move on to another example this is an example worked on by a number of clinicians at the university of michigan you may recognize some of the co-authors on this pre-print manuscript but they're all u of m clinicians many with uh expertise in machine learning and the this study was was looking at a um a what was called a deterioration index model for predicting patients with covet 19 who were admitted to the hospital in a non-icu setting predicting their potential to deteriorate and so the goal of the study was to detect in early stages a patient who is deteriorating and deterioration defined as being transferred to an icu being mechanically ventilated so intubated mechanically ventilated or or death so any three of those outcomes we wanted to detect as early as possible the study used a cohort of michigan covet 19 patients admitted to a non-icu setting and collected fairly standard data that is available on most any patient in the hospital demographic data vital signs collected by nurses assessments collected by nurses so their oxygen requirements their glass glaucoma score their ekg rhythm and then lab values that are commonly drawn on on most in patients in the hospital and the model outputs a score from 0 to 100 representing their likelihood of deterioration and it had a modest performance by no means perfect by no means useless but uh modest performance um and so you know we're left with this um understanding that the model performs modestly well but um you know the questions that clinicians will be having before getting any further is they want to know how this works you know why should we trust it why should we not trust it in what situations is this model potentially more trustworthy and than then in other situations and what do we actually do with this information so what if we know that a patient is likely to deteriorate what are we actually going to do differently um had we not had that information and so um you know there's a stress that you know at a minimum the model has to be accurate but that's only a starting point and really to gain clinician faith in machine learning algorithms to actually improve patient care there's a number of different layers to consider beyond just the accuracy and so building up from a base layer of accuracy the next stage is really that a model needs to be transparent so a clinician needs to understand what factors are driving a prediction model we all know about this as as experts in developing these models that transparency is a good thing it's it's really important you know transparency is important in healthcare because mechanisms are important so um just like the causes of um a complication um you know the the causes of low blood pressure or low oxygen levels might imply different treatments you know the same is true for a prediction model if we know what's driving a prediction model that helps us know how to act on it beyond transparency there's this layer of credibility so does the variables or the features that are driving a prediction model fall in line with expert opinion or are they in stark contrast to potentially decades of literature on a particular topic and so we know that experts can be wrong but it's much more rare uh it's much it's it's much less commonly true than the converse and so for a model to be credible it needs to be influenced by features that have plausible uh biologic mechanisms underpinning their association with the outcome so for example if a deterioration model um largely hinged on a patient's age and their vital signs that would be more credible to a critical care physician than a model which seemed to be driven by the day of the week or maybe the patient's height or some obscure lab value and it's not to say that those that useful inferences can't be made by um by the time of day or the or an obscure lab value or the patient's height it just means that it carries less weight than factors um that an intensivist that a critical care physician has come to trust through decades of established research and teaching and so if a model fault if the features driving a model fall in line with expert opinion um those models tend to be more trustworthy than features than models that are drived upon features that really don't fall in line with a expert's way of thinking and then finally at the pinnacle of all this is whether a prediction model is actionable or it's at least informed by modifiable risk factors right so it's one thing if we build a risk model based on age race and gender it's another thing when we build a prediction model based on features that can be modified in real time such as the patient's blood pressure their oxygen levels their hematocrit because these variables can plausibly be tied to interventions and there's at least the potential to inform decisions treatment decisions beyond just risk stratifying a patient and so taking into account these principles of transparency of credibility of actionability let's take a look at the epic deterioration index this is a way that that epic displays machine learning predictions to clinicians who may not necessarily be data scientists so on the on the left side of this you can see this 41.9 so there's there's a 41.9 percent chance that this patient in front of us will have um you know will eventually require a mechanical ventilation or transport to the icu or or death and um you know we need to understand what is driving this 41.9 percent and so not only do clinicians get this probability they get uh transparency into the characteristics that are driving this model we can see all of these listed here um you know at least the most uh important factors contributing to this score the game the machine learning model also gains some credibility by showing um you know how important the features are to the model and we can see that the features that bubble to the top are things that make sense to a clinician you know an elderly patient we know that patients with covid it's it's you're a much higher risk um you know i think if you're elderly compared to a younger patient that falls in line with expert opinion and so seeing that as the major driving factor to this risk score helps improve the credibility of this model to a clinician and then lastly this model embraces some actionability by incorporating at least a few potentially modifiable risk factors right so the oxygen level the blood pressure the ph of the blood these are things that clinicians can actually modify through different pharmacologic physiologic treatments and so if we include these in the model um there's at least although you know all we have is is association we don't have causation we at least have modifiable risk factors that a physician can consider uh when um examining a patient in and trying to understand if this patient is a high-risk patient or a low-risk patient for deteriorating okay the next example i want to focus on is part of my own work it's a machine learning algorithm that uses data collected in the or perioperative data to uh improve the early detection of heart failure um and and i want to go through this very briefly and highlight some issues with clinical actionability that we're grappling with currently so the goal of this project was to use the intraoperative anesthesia record as a stress test so there's this concept of a cardiac stress test you know cardiologists want to make sure that a patient can withstand the stress of a surgery without having any cardiovascular complications we can we can use you know data from a surgery itself to to look at the cardiovascular health of a patient you know grant we want to we hope to have understood the patient's risk before they go to surgery but once they're in the surgery we do have this free data that we can use to further inform our assessment of a patient's overall cardiovascular health and so the algorithm works something like this we had a patient who was undergoing surgery they had a pre-operative evaluation and then they underwent the surgery we used data collected during the pre-op evaluation so medical comorbidities demographic data vital signs in the pre-operative evaluation we combine that with data collected during the surgery physiologic data medication data ventilator data and in each of these stages we computed the probability that a patient might have heart failure and other cardiovascular conditions and we used this as a potential um the high probability patients we we potentially referred uh to a to to first an anesthesiologist to adjudicate uh whether or not this patient was a patient you know the algorithm you know had a high you know deemed this patient had high risk of heart failure but just doesn't all just agree and if if so uh to potentially refer these patients to cardiologists for follow-up and a formal diagnosis of heart failure if it did exist so in this study we took a cohort of michigan medicine patients getting surgery that didn't have a pre-operative they did not have a diagnosis of heart failure and we looked at um we and we divide them into cases and controls and cases where patients that developed heart failure had a diagnosis of heart failure by two years after the surgery within two years after the surgery somebody ultimately diagnosed them as having heart failure and we had the remaining patients healthy control so they didn't have heart failure before the surgery they also didn't have heart failure within two years after the surgery we carefully excluded specific patients that would cause data leakage in this machine learning approach so we excluded any patient that was unlikely to have undiagnosed heart failure so we excluded cardiac surgeries or surgeries that you have because you have heart failure um and and you know those those patients would not be useful for a prediction algorithm the clinician should already be aware as to whether or not that patient has heart failure and we also excluded patients that developed heart failure as a consequence of the surgery or as a consequence of their acute surgical condition so if a patient was in a motor vehicle accident coming in for a trauma surgery and later developed septic shock and developed heart failure as a result of their sepsis those patients were also excluded from this algorithm you know the goal of this algorithm was to detect patients that had insidious you know early stage or impending heart failure that may have been missed during the pre-operative period we wanted to use this the the intraoperative data to help inform a a kind of a post-test probability of the patients having heart failure and so to do this uh we we recognize in the when a patient has surgery there's a couple different cardiovascular stressors that happen a patient comes into the or and before they um before they have the surgery they undergo induction of anesthesia so we give these patients medications that drift them off to sleep that actually have pretty significant cardiovascular depressant effects and patients with heart failure will react differently uh to these drugs than patients uh with that are that are healthy uh and then they're then these patients are intubated and and that's um transition from breathing spontaneously to being put on a breathing machine temporarily for the surgery that's a that's a cardiovascular stressor and and you can see um different responses based on the cardiovascular health of a patient a patient in heart failure may react differently to the stress of mechanical ventilation than a patient that is healthy we did the same thing around incision so when the surgeon makes an incision the patient's asleep and they're unconscious of the decision but their sympathetic nervous system is still intact and can mount a cardiovascular stress response to a pain stimulus and so although a patient's not conscious to experience the pain their sympathetic nervous system is still intact and reacts to the pain and so patients with cardiovascular disease again may mount a different stress response to a surgical incision than a healthy patient so we looked at that time period around surgical incision and then we did the same thing at the at the end of the case just like just like at the beginning of the case when we transitioned the patient from breathing spontaneously to on a breathing machine we wanted to look how that patient did coming off the breathing machine waking up from anesthesia extubated and back to breathing spontaneously so we looked at that time period and with each within each of these time periods we summarized different um we took we collected data from different sources so we looked at physiologic data the blood pressure the heart rate oxygen levels we looked at ventilator data we looked at medications and fluids that we were giving these patients that were charted with high accuracy in the anesthesia record and with each of these data sources we developed different summary statistics different um i guess feature engineering is how i described this but within each segment we looked at different summary stats as well as other more more complex stats like for heart rate for instance we looked at heart rate variability um and we took each of these and and we developed a feature set of over a thousand interoperability features we combined that with all of our pre-operative data and then we used this this combined feature set to train a machine learning algorithm to predict the probability that a patient had undiagnosed heart failure and for more information about the performance of this algorithm i'd refer you to the study but the punch line is that although the algorithm had a reasonably good performance it was limited by a low positive predicted value meaning that the algorithm had an unacceptably high false positive rate to be clinically useful and that's really forever a limitation um to a prediction algorithm focused on rare diagnosis or events that's very common in anesthesia unfortunately for for me you know anesthesiologists are very much focused on preventing the very rare but catastrophic complication and so prediction algorithms have to be very close to being perfect if we want them to be clinically actionable and so this issue of positive predictive value is is very very much a challenge in anesthesiology was a challenge in this study and so the solution to handling this is although our algorithm is has a high sensitivity and a modest performance um you know it would be much more useful and much uh less generative of alert fatigue to clinicians if there was a more specific confirmatory test so we can take these patients who screened positive by the algorithm and we can reduce the false positive rate by getting a more specific confirmatory test there's a specific lab that you can order on a patient that has a high likelihood of having heart failure or a clinical suspicion of heart failure and you can also get imaging you can get a a ultrasound to the patient's heart um you know that's not um it's it's not a it's not a super expensive test but it's not it's not cheap either we don't want to do it on all patients but you can get a ultrasound of a patient's heart and that is certainly much more specific um and can rule out false positives and you can get those patients referred to a cardiologist for further evaluation uh diet a formal diagnosis and management if they do have heart failure um the next example i want to jump to is looking at cpt codes so clinical procedure codes but basically uh taking a um you know a surgery that was performed on a patient and making sure that that it is that the hospital was billing for the and so the goal in this algorithm was to um improve anesthesia billing uh by taking replacing much of the work uh done by a human uh that takes takes time and is expensive and seeing if that can be automated and the issue here is that this this billing process is largely dependent on reading in free text within anesthesia records and surgery notes uh for classifying what type of anesthesia what type of surgery a patient had um and as you can imagine there's all sorts of typos all sorts of misspellings that happen uh when we're trying to classify a specific procedure that's uh um being done on a patient's and so this this is the clinical reality of of many notes is that there's there's lots of typos and so just using um structured data to solve this problem is is is not possible um we did take some structured data um in you know the patient patients uh demographics their their the length of the surgery their comorbidities and that can be used to infer what what type of surgery the patient had but really it's it's the procedure text it's the surgery op node the anesthesia diagnosis and the uh the surgical diagnosis and the surgical procedure text that um needs to be analyzed to be a natural language processing um that can be used that can be used to dramatically improve the performance of a machine learning based classification algorithm and so um the punch line to this study was again that we could with natural language processing techniques we could get the classification accuracy uh for high confidence cases so cases where the the most likely procedure was significantly greater than the second most likely procedure for those very high confidence cases we could get a a very good classification accuracy and you know obviously when we're doing machine learning algorithm you know the turnaround time in these billing codes is is a second whereas in uh this was done by a human the average turnaround time is uh just over a month um and so um beyond you know demonstrating that it has high performance there's and there's this issue of of trying to figure out you know in what instances is it useful for a clinician or is it useful for i guess a billing specialist to be scrutinizing the medical record versus in what instances is it useful for the algorithm to be simply running a you know a classification or just solving a classification problem and so you know we need to bring in we need to revisit this implementation strategy that's um the goal of machine learning algorithms is to improve clinical processes of care it's not to replace humans it's just to enable humans to achieve a better level of care a cheaper level you know more healthcare value than they would have been able to do without the aid of a computer and so you know you know what's uh what we ended up doing is we ended this this is something that actually is applied right now to uh surgical cases at the university of michigan uh we decided to to cla to sort these um procedures into the high confidence cases versus the low confidence cases and so the figure on the left basically shows um we have a you know a pre uh determined confidence parameter on the x-axis which is basically some measure of the most likely um procedure as as as predicted by an algorithm the ratio of of the likelihood that of the likelihood of the most likely procedure to these next most likely procedure and we we recognized that for the ones where the machine learning algorithm was not competent those are the ones that should be scrutinized by a billing specialist whereas the ones that had high confidence on the y-axis you can see the classification accuracy gets above 95 percent for these high confidence cases and since the accuracy of a billing specialist is 95 um we've decided at michigan medicine that these high confidence cases can just be classified by a machine learning algorithm and you know and so you know it looks like it's a minority but it's actually a majority of cases that are classified by this machine learning algorithm on the figure on the right you will see that um the you know the the the confidence interval the confidence parameter on the on the x-axis versus the number of cases included on the y-axis and you'll see that most cases are high confidence cases over 55 percent of cases in this data sets the machine learning algorithm has a high confidence in the classification accuracy so that's that's how we split up the work um we found a role for humans we know they can they're much the billing specialist now can focus on the the more complex cases that require a you know greater scrutinizing of the medical record whereas the machine learning algorithm can very quickly automate and speed up the the cases where there isn't very much critical thinking that it's almost certain it's a specific procedure and so that's greatly uh reduced our billing costs and enabled our billing specialists to focus on um for um for uh more accurately coding that the the more challenging pieces um the last example i want to go into and i think that is the most controversial um is a um is a study that was published in anesthesiology two years ago that looked at machine learning predictive analytics for determining a patient getting a low blood pressure after going under anesthesia so post induction or basically after induction of general anesthesia hypotension or low blood pressure we so the goal of this algorithm was to use data available before induction of anesthesia to predict the likelihood that a patient would get a low blood pressure once under general anesthesia this was a data set of patients at nyu we used they used medical history data comorbidities patients home medications demographics and they used some early surgical data perioperative data so they looked at meds given before the patient underwent general anesthesia and they looked at blood pressure and other vital signs before the patient went under general anesthesia and they used that data to predict the likelihood that a patient would get low blood pressure unsafe levels of dangerously low blood pressure after uh going under general anesthesia and um and again i'll refer you to the um details about how this algorithm was developed but the algorithm performance was again modest like some of these other algorithms we discussed today um and um and and so you know in in some cases um the you know if we had a high likelihood of post-induction hypotension you know the next the next question a clinician will have is is what do we do about that what's what are we actually going to do with that information and the answer to that is like so many other things in healthcare it depends uh depends not only on the nuanced clinical context but it also depends on the shared values of the anesthesiologist in the patient and that's what we can call judgment for purposes of machine learning modeling so when we when a machine learning model takes um you know what we what we're good at right now with um machine learning is taking data taking large amounts of data of complex with complex relationships and making an accurate prediction what we're not very good at yet is inferring or determining the judgment or basically the valuation of different outcomes and actions that we need to take to mitigate those outcomes um we're not very good at quantifying or codifying that judgment that informs our action plan based on a you know the prediction or the likelihood of a specific outcome happening and so what i want to do is i want to give everyone a hypothetical example of a single case where this algorithm might be used we have a elderly gentleman who has carotid disease so they have a risk of having a stroke they have a severe pulmonary disease so they have a risk of pulmonary complications and they have uh chronic kidney disease so they have a chance that they're going to have that a kidney injury from the surgery could be could cause some severe consequences and they're getting a pretty standard abdominal surgery a colectomy and let's just say that we use this prediction algorithm and the algorithm says we have a post-induction hypotension probability of 98 um well great you know so the next thing is you know we're left with is if we trust this um if we believe that number one we believe that hypotension is bad and we need to do something about this and we and we trust the algorithm we need to do something about this in order to mitigate the effects of hypotension that might exacerbate um a complication that might cause a complication as exacerbated by these patients pre-existing comorbidities and there's a couple options that we have you know we can do nothing and if we do nothing this patient will become likely to become hypotensive um they may have a stroke they might they have a one percent chance of having a stroke let's just say for just hypothetically they have a 10 chance of a of a pulmonary complication they have a 10 chance of acute kidney injury or kidney complication and we can mitigate that by giving them some fluid right so we can raise their blood pressure by giving them some volume resuscitation that in that reduces their chances of hypotension and their risk of a stroke but we give them fluid maybe we're adding some fluid to their lungs too and so you have pulmonary edema and you might have a higher chance of a pulmonary complication but on the flip side you you know giving fluid helps blood flow to the kidneys so you might have a lower risk of a a kidney complication the other option we could do instead of giving fluid is we can give a medication called a vasopressor that basically constricts your blood vessels it raises your blood pressure it diverts blood flow away from certain organs but channels blood flow to other organs mainly your brain so when you give a vasopressor you will raise your blood pressure you'll divert blood flow to the brain and you'll mitigate the risk of a stroke probably won't do much in the way of the risk of a pulmonary complication but you are constricting the renal blood vessels diverting blood flow away from the kidneys and so your risk of a kidney complication goes up so you know you know we have three choices of what to do three consequences with clear trade-offs and if we recognize that all complications are not equal that is a stroke you know becoming mentally incapacitated it's probably much worse than having a pulmonary complication or an acute kidney injury then we need to make a judgment call we can't just add up the percentages that uh of these complications from happening we need um you know we need to favor a action plan that mitigates the risk of the most severe complications so the stroke but it's not enough to know that a stroke is worse we need to know exactly how much worse it is than the other complications right and so that's um you know what reinforcement uh reinforcement learning might call a policy that and this is um i don't need to explain this to this this audience um you know that's probably better than i do how reinforcement learning might work you need to um assign a burden or a reward i guess to each complication and then and then this is useful for training the machine learning algorithm to optimize the clinical outcome so if we say a stroke is 100 times worse than and then a kidney injury and maybe 50 times worse than a pulmonary complication we now have a expected value problem we can we can take these relative burdens we can multiply them by the probability that they might happen in these different actions and then we lo and behold find out that giving the vasopressor was the right choice that considering the trade-offs of the different complications we minimize the overall burden of complications to this patient we mitigated that the most by giving a patient a vasopressor but the issue here is who decides these relative burdens and rewards this is something that really is largely unanswered um in clinical medicine and something that um clinicians have an intuition for we in clinicians will do this on a daily basis all the time but haven't bothered to really codify uh in discrete terms these relative risks right and so um that's that's really um you know the challenge that we're faced uh faced with and forgetting machine learning for a second you know we need to understand you know who who should be having these conversations who should be involved should they be possible providers or even even the patient and so you know that that's that's where the dilemma you know it's facing algorithms going forward is although we have we may have a certain level of performance uh using data to make a prediction we don't necessarily have these judgments codified that can inform an action plan that a clinton might take and you know one option to to to um determining judgments is instead of trying to predict the outcome we can predict the action that a clinician might take and you can reverse engineer the judgment that a clinician might have you if you if you predict the judgment using a machine learning algorithm um i'm sorry if you predict the action being taken you can infer the judgment and so that's an option that we can we can look into with machine learning algorithms but the problem is that it propagates our own biases so if a if an action is taken that is made by a biased clinician and a machine learning algorithm is trained biases and we all know about you know the issues of training algorithms on human actions that are inherently biased and we've heard this example time and time again of how amazon had to discard a gender biased hiring toy that tended to favor males over females simply because the hiring process was done by humans and favored uh and and had had an implicit bias favoring males and so take-home points for this talk are that machine learning for health care for anesthesia care is conceptually feasible and the next steps really are to have these conversations with clinicians that machine learning algorithms can be generalizable they can be safe we're aware of the biases and we're aware they need to be clinically actionable and so what we can do today as um as machine learning experts that have a um a you know a understanding of health care uh is there's things that we need to do to help bridge that gap with clinicians who may not have an expert expertise in machine learning and what we need to do is we need to promote this literacy of machine learning and ai to clinicians right so clinicians know they need to be uh aware of classical statistical techniques of study methodology when they're reading a journal article they also need to become aware of classic machine of you know the basics of machine learning algorithms and so it's our job to really explain those to clinicians we need to focus on the right problems to solve and that's getting at that you know that notion of of you know the the low um criticality non-serious event you know that's maybe the starting point for machine learning algorithm before we build up to um algorithms that predict uh treatments or diagnoses that have consequences so you want to start with the algorithm that optimizes your clinic schedule you may not want to start with the algorithm that predicts whether a patient is going to go to the icu you even though we are doing that but it's just a different level of risk and a different level of scrutiny that a machine learning algorithm has to undergo if we want to actually develop that and make it actionable we need to stick the right inputs right so a machine learning algorithm trained on a near infinite amount of irrelevant biased or inaccurate data is never going to mimic the performance of a clinician who has access to the right data we need to sync we need to value transparency and actionability so that's you know getting at the notion of you know clinicians need to understand why they don't need to just be right they need to understand the mechanisms underpinning a specific disease process or treatment process and lastly we need to know our biases we need to make clinicians aware of their biases and we we need to understand how they might impact a machine learning model trained on humans with these implicit biases so making these biases conscious these unconscious biases conscious is a very important thing for improving the performance of an algorithm for earning a clinician's trust that a machine learning algorithm will be usable and actionable and so with that i'll leave you with these references again i apologize that i was unable to give this talk live but um i welcome you to kind email me contact me and i'm very happy to talk about some of the issues um covered in this presentation so thanks again uh looking forward to chatting with you guys sometime soon