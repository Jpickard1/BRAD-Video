[
    {
        "text": "awesome uh thanks so much uh Marcy for",
        "start": 0.56,
        "duration": 5.199
    },
    {
        "text": "the introduction and uh nice to see you",
        "start": 3.08,
        "duration": 5.16
    },
    {
        "text": "all and uh great to be presenting in the",
        "start": 5.759,
        "duration": 4.361
    },
    {
        "text": "tools and Technology",
        "start": 8.24,
        "duration": 4.64
    },
    {
        "text": "seminar um so the topic of my talk is",
        "start": 10.12,
        "duration": 5.0
    },
    {
        "text": "you know ranking and reting improves out",
        "start": 12.88,
        "duration": 5.8
    },
    {
        "text": "of distribution robustness and as you",
        "start": 15.12,
        "duration": 5.84
    },
    {
        "text": "might have seen from the",
        "start": 18.68,
        "duration": 6.48
    },
    {
        "text": "name I do not have a concrete medical",
        "start": 20.96,
        "duration": 6.559
    },
    {
        "text": "application in mind but I think many of",
        "start": 25.16,
        "duration": 4.519
    },
    {
        "text": "the techniques that I present could be",
        "start": 27.519,
        "duration": 5.601
    },
    {
        "text": "used used for uh in medical contexts and",
        "start": 29.679,
        "duration": 6.001
    },
    {
        "text": "I would love to hear from you guys",
        "start": 33.12,
        "duration": 6.48
    },
    {
        "text": "regarding that okay so",
        "start": 35.68,
        "duration": 6.559
    },
    {
        "text": "uh yeah so I think like before I get",
        "start": 39.6,
        "duration": 4.32
    },
    {
        "text": "started I just want to give a little bit",
        "start": 42.239,
        "duration": 4.521
    },
    {
        "text": "of uh overview of my past research to",
        "start": 43.92,
        "duration": 5.92
    },
    {
        "text": "see what kind of work do I do so I know",
        "start": 46.76,
        "duration": 5.319
    },
    {
        "text": "this is the tools and Technology seminar",
        "start": 49.84,
        "duration": 4.16
    },
    {
        "text": "and my research is on people and",
        "start": 52.079,
        "duration": 3.841
    },
    {
        "text": "technology so a little bit related to",
        "start": 54.0,
        "duration": 4.8
    },
    {
        "text": "tools and Technology okay so and",
        "start": 55.92,
        "duration": 5.2
    },
    {
        "text": "especially I built uh machine learning",
        "start": 58.8,
        "duration": 4.12
    },
    {
        "text": "and deep learning methods to understand",
        "start": 61.12,
        "duration": 4.72
    },
    {
        "text": "people and Technology uh so in some of",
        "start": 62.92,
        "duration": 4.68
    },
    {
        "text": "my past research what I've done is I've",
        "start": 65.84,
        "duration": 4.4
    },
    {
        "text": "looked at this large clickstream data of",
        "start": 67.6,
        "duration": 4.72
    },
    {
        "text": "what articles people read how much time",
        "start": 70.24,
        "duration": 5.04
    },
    {
        "text": "they spent reading on it to understand",
        "start": 72.32,
        "duration": 6.2
    },
    {
        "text": "what are uh the stable and the evolving",
        "start": 75.28,
        "duration": 6.56
    },
    {
        "text": "interests of people so that we could uh",
        "start": 78.52,
        "duration": 5.48
    },
    {
        "text": "like do so that we could construct",
        "start": 81.84,
        "duration": 4.76
    },
    {
        "text": "better user profiles and we could",
        "start": 84.0,
        "duration": 5.24
    },
    {
        "text": "personalize uh content for them on like",
        "start": 86.6,
        "duration": 4.64
    },
    {
        "text": "you know New York times or Boston Globe",
        "start": 89.24,
        "duration": 4.879
    },
    {
        "text": "or Wall Street Journal um and so that",
        "start": 91.24,
        "duration": 4.44
    },
    {
        "text": "they have a better better user",
        "start": 94.119,
        "duration": 4.601
    },
    {
        "text": "experience online and recommendations",
        "start": 95.68,
        "duration": 5.119
    },
    {
        "text": "are one part of it",
        "start": 98.72,
        "duration": 6.48
    },
    {
        "text": "okay um and uh yeah so there's some uh",
        "start": 100.799,
        "duration": 6.481
    },
    {
        "text": "like in this particular work like we",
        "start": 105.2,
        "duration": 4.519
    },
    {
        "text": "built a neural network which combine the",
        "start": 107.28,
        "duration": 5.519
    },
    {
        "text": "Simplicity of Matrix factorization uh",
        "start": 109.719,
        "duration": 5.241
    },
    {
        "text": "plus the flexibility of neural network",
        "start": 112.799,
        "duration": 4.36
    },
    {
        "text": "to give to give a stateof the art",
        "start": 114.96,
        "duration": 4.32
    },
    {
        "text": "performance on building this efficient",
        "start": 117.159,
        "duration": 3.721
    },
    {
        "text": "and interpret",
        "start": 119.28,
        "duration": 4.479
    },
    {
        "text": "trajectories",
        "start": 120.88,
        "duration": 6.239
    },
    {
        "text": "um then another work you know uh we did",
        "start": 123.759,
        "duration": 7.28
    },
    {
        "text": "an experiment so here the idea is um",
        "start": 127.119,
        "duration": 6.48
    },
    {
        "text": "that if you want to Target like let's",
        "start": 131.039,
        "duration": 6.2
    },
    {
        "text": "say think about your uh like any online",
        "start": 133.599,
        "duration": 7.241
    },
    {
        "text": "sub online newspaper say uh in this case",
        "start": 137.239,
        "duration": 6.241
    },
    {
        "text": "Boston Globe right and newspapers as you",
        "start": 140.84,
        "duration": 4.72
    },
    {
        "text": "all know like nowadays have subscription",
        "start": 143.48,
        "duration": 4.36
    },
    {
        "text": "based models right so you have to be a",
        "start": 145.56,
        "duration": 4.44
    },
    {
        "text": "subscriber in order to continue reading",
        "start": 147.84,
        "duration": 4.44
    },
    {
        "text": "but what happens is that you know people",
        "start": 150.0,
        "duration": 4.08
    },
    {
        "text": "lose interest and they cancel their",
        "start": 152.28,
        "duration": 4.2
    },
    {
        "text": "subscription so in this experiment what",
        "start": 154.08,
        "duration": 4.2
    },
    {
        "text": "we're trying to see is how to",
        "start": 156.48,
        "duration": 5.52
    },
    {
        "text": "proactively Target discounts to people",
        "start": 158.28,
        "duration": 7.76
    },
    {
        "text": "uh so that they would not cancel their",
        "start": 162.0,
        "duration": 7.04
    },
    {
        "text": "subscription",
        "start": 166.04,
        "duration": 3.0
    },
    {
        "text": "uh okay so",
        "start": 169.4,
        "duration": 8.559
    },
    {
        "text": "now unfortunately the problem is uh that",
        "start": 173.56,
        "duration": 7.759
    },
    {
        "text": "we um that the that whether somebody",
        "start": 177.959,
        "duration": 5.121
    },
    {
        "text": "cancels or not or whether somebody",
        "start": 181.319,
        "duration": 3.961
    },
    {
        "text": "continues to be a subscriber is only",
        "start": 183.08,
        "duration": 5.76
    },
    {
        "text": "observed in the long term right you know",
        "start": 185.28,
        "duration": 5.72
    },
    {
        "text": "uh but you have to Target them discount",
        "start": 188.84,
        "duration": 3.959
    },
    {
        "text": "now so we have to you have to Target an",
        "start": 191.0,
        "duration": 4.64
    },
    {
        "text": "intervention right now with the hope",
        "start": 192.799,
        "duration": 4.761
    },
    {
        "text": "that in the long term maybe year two",
        "start": 195.64,
        "duration": 5.04
    },
    {
        "text": "years five years from now you know uh",
        "start": 197.56,
        "duration": 5.039
    },
    {
        "text": "they they continue to be your subscriber",
        "start": 200.68,
        "duration": 3.8
    },
    {
        "text": "so think about that like a good",
        "start": 202.599,
        "duration": 4.521
    },
    {
        "text": "application of that is also in a medical",
        "start": 204.48,
        "duration": 4.679
    },
    {
        "text": "context where you want to Target the",
        "start": 207.12,
        "duration": 4.679
    },
    {
        "text": "treatment you know like some dose of a",
        "start": 209.159,
        "duration": 4.681
    },
    {
        "text": "medicine right now but the outcome would",
        "start": 211.799,
        "duration": 4.281
    },
    {
        "text": "only be observed 5 years later to see",
        "start": 213.84,
        "duration": 4.28
    },
    {
        "text": "whe the person survived or what's their",
        "start": 216.08,
        "duration": 4.519
    },
    {
        "text": "quality of life right so how could we",
        "start": 218.12,
        "duration": 5.88
    },
    {
        "text": "use shortterm uh information about the",
        "start": 220.599,
        "duration": 6.0
    },
    {
        "text": "person to Target discount to Target",
        "start": 224.0,
        "duration": 4.56
    },
    {
        "text": "discounts in this case that are better",
        "start": 226.599,
        "duration": 4.56
    },
    {
        "text": "in the long term okay that that that",
        "start": 228.56,
        "duration": 4.84
    },
    {
        "text": "improves some long-term outcomes so we",
        "start": 231.159,
        "duration": 5.041
    },
    {
        "text": "developed uh like an approach that uses",
        "start": 233.4,
        "duration": 5.32
    },
    {
        "text": "surrogate variables to Target discounts",
        "start": 236.2,
        "duration": 4.48
    },
    {
        "text": "to people like personalized discount",
        "start": 238.72,
        "duration": 6.439
    },
    {
        "text": "personalized treatments um um so to say",
        "start": 240.68,
        "duration": 6.399
    },
    {
        "text": "and you know we come came up with an",
        "start": 245.159,
        "duration": 3.881
    },
    {
        "text": "optimal policy that is what discount",
        "start": 247.079,
        "duration": 5.88
    },
    {
        "text": "would Target to which person so that uh",
        "start": 249.04,
        "duration": 6.32
    },
    {
        "text": "so that the cancellation of",
        "start": 252.959,
        "duration": 4.56
    },
    {
        "text": "subscriptions of people are minimized",
        "start": 255.36,
        "duration": 4.2
    },
    {
        "text": "over over like a long period of time",
        "start": 257.519,
        "duration": 5.081
    },
    {
        "text": "which in this case was three years",
        "start": 259.56,
        "duration": 6.28
    },
    {
        "text": "okay um so yeah so like this was some of",
        "start": 262.6,
        "duration": 7.599
    },
    {
        "text": "my recent work um uh that I did and and",
        "start": 265.84,
        "duration": 6.84
    },
    {
        "text": "um you know",
        "start": 270.199,
        "duration": 5.72
    },
    {
        "text": "uh there are some key assumptions",
        "start": 272.68,
        "duration": 6.799
    },
    {
        "text": "parried in here",
        "start": 275.919,
        "duration": 3.56
    },
    {
        "text": "right okay so there are some key",
        "start": 279.919,
        "duration": 5.761
    },
    {
        "text": "assumptions bed in my past work on",
        "start": 282.639,
        "duration": 4.201
    },
    {
        "text": "content",
        "start": 285.68,
        "duration": 5.16
    },
    {
        "text": "analytics um so first of all um uh like",
        "start": 286.84,
        "duration": 5.079
    },
    {
        "text": "we assume",
        "start": 290.84,
        "duration": 3.76
    },
    {
        "text": "stationarity we assume that people's",
        "start": 291.919,
        "duration": 4.441
    },
    {
        "text": "preferences and their content",
        "start": 294.6,
        "duration": 4.52
    },
    {
        "text": "consumption patterns uh stay stable over",
        "start": 296.36,
        "duration": 4.2
    },
    {
        "text": "time",
        "start": 299.12,
        "duration": 4.48
    },
    {
        "text": "okay we also assume that the that there",
        "start": 300.56,
        "duration": 6.0
    },
    {
        "text": "is a stationarity in the user panel we",
        "start": 303.6,
        "duration": 5.599
    },
    {
        "text": "track an existing set of users over time",
        "start": 306.56,
        "duration": 5.24
    },
    {
        "text": "and we assume that no new people come uh",
        "start": 309.199,
        "duration": 6.921
    },
    {
        "text": "in our panel over time right and finally",
        "start": 311.8,
        "duration": 6.48
    },
    {
        "text": "a third assumption that we make is the",
        "start": 316.12,
        "duration": 5.4
    },
    {
        "text": "group proportion good group proportion",
        "start": 318.28,
        "duration": 5.52
    },
    {
        "text": "stational that is the relative",
        "start": 321.52,
        "duration": 4.16
    },
    {
        "text": "proportion of people that are in a",
        "start": 323.8,
        "duration": 4.48
    },
    {
        "text": "training set versus in a testing St set",
        "start": 325.68,
        "duration": 5.88
    },
    {
        "text": "this this uh stay more or less constant",
        "start": 328.28,
        "duration": 4.96
    },
    {
        "text": "right so for example the number of",
        "start": 331.56,
        "duration": 4.56
    },
    {
        "text": "people commenting on an article from",
        "start": 333.24,
        "duration": 6.36
    },
    {
        "text": "India or China uh stays the same uh in",
        "start": 336.12,
        "duration": 5.96
    },
    {
        "text": "the training versus the test set",
        "start": 339.6,
        "duration": 6.92
    },
    {
        "text": "right and um so basically all of these",
        "start": 342.08,
        "duration": 6.72
    },
    {
        "text": "three assumptions they are related to",
        "start": 346.52,
        "duration": 5.6
    },
    {
        "text": "this idea of a distribution share and",
        "start": 348.8,
        "duration": 5.119
    },
    {
        "text": "the idea is that we want to build",
        "start": 352.12,
        "duration": 3.96
    },
    {
        "text": "machine learning model that are robust",
        "start": 353.919,
        "duration": 4.12
    },
    {
        "text": "to out of distribution data and in the",
        "start": 356.08,
        "duration": 4.32
    },
    {
        "text": "next few slides I will show like how",
        "start": 358.039,
        "duration": 5.641
    },
    {
        "text": "distribution out of distribution uh data",
        "start": 360.4,
        "duration": 5.4
    },
    {
        "text": "could creep into such a scenario and",
        "start": 363.68,
        "duration": 5.799
    },
    {
        "text": "like how we could mitigate",
        "start": 365.8,
        "duration": 3.679
    },
    {
        "text": "that okay so distributional uh robust uh",
        "start": 374.52,
        "duration": 7.56
    },
    {
        "text": "machine learning is a key uh like I",
        "start": 378.8,
        "duration": 5.44
    },
    {
        "text": "should say a foundation of Equitable",
        "start": 382.08,
        "duration": 4.92
    },
    {
        "text": "machine learning right so what Equitable",
        "start": 384.24,
        "duration": 4.88
    },
    {
        "text": "machine learning says is that we want to",
        "start": 387.0,
        "duration": 4.8
    },
    {
        "text": "ensure fairness in our model outcomes we",
        "start": 389.12,
        "duration": 6.04
    },
    {
        "text": "want that all patients uh receive the",
        "start": 391.8,
        "duration": 5.6
    },
    {
        "text": "same outcome uh receive the same",
        "start": 395.16,
        "duration": 5.159
    },
    {
        "text": "treatment uh like irrespective of their",
        "start": 397.4,
        "duration": 5.88
    },
    {
        "text": "race or gender or the demographics right",
        "start": 400.319,
        "duration": 5.561
    },
    {
        "text": "so we want to ensure a fairness in its",
        "start": 403.28,
        "duration": 4.96
    },
    {
        "text": "outcomes right",
        "start": 405.88,
        "duration": 6.759
    },
    {
        "text": "and um however out of distribution uh uh",
        "start": 408.24,
        "duration": 7.16
    },
    {
        "text": "data could lead the models to perform",
        "start": 412.639,
        "duration": 4.84
    },
    {
        "text": "poorly on under represented people in",
        "start": 415.4,
        "duration": 2.84
    },
    {
        "text": "the",
        "start": 417.479,
        "duration": 3.481
    },
    {
        "text": "data and and uh as I will show some",
        "start": 418.24,
        "duration": 5.16
    },
    {
        "text": "examples what happens is that such",
        "start": 420.96,
        "duration": 5.2
    },
    {
        "text": "models perform poorly from people who",
        "start": 423.4,
        "duration": 5.199
    },
    {
        "text": "are minority groups",
        "start": 426.16,
        "duration": 6.12
    },
    {
        "text": "okay so what we want is that a model",
        "start": 428.599,
        "duration": 6.481
    },
    {
        "text": "which is trained on say patients from an",
        "start": 432.28,
        "duration": 5.4
    },
    {
        "text": "arbor which is mostly white and Asian",
        "start": 435.08,
        "duration": 5.239
    },
    {
        "text": "population uh it should also do well",
        "start": 437.68,
        "duration": 4.76
    },
    {
        "text": "when we deploy that model on patients in",
        "start": 440.319,
        "duration": 5.041
    },
    {
        "text": "Detroit which is mostly black population",
        "start": 442.44,
        "duration": 5.439
    },
    {
        "text": "yeah right so we want to build models",
        "start": 445.36,
        "duration": 4.76
    },
    {
        "text": "that are robust uh across these",
        "start": 447.879,
        "duration": 5.32
    },
    {
        "text": "distribution shifts in the in the",
        "start": 450.12,
        "duration": 7.72
    },
    {
        "text": "populations now let's think about U more",
        "start": 453.199,
        "duration": 8.881
    },
    {
        "text": "conrete um definition of our problem so",
        "start": 457.84,
        "duration": 6.12
    },
    {
        "text": "robust machine learning and Equitable",
        "start": 462.08,
        "duration": 3.799
    },
    {
        "text": "machine learning are very active areas",
        "start": 463.96,
        "duration": 6.16
    },
    {
        "text": "of research and uh there are like",
        "start": 465.879,
        "duration": 7.16
    },
    {
        "text": "several different ways in which the uh",
        "start": 470.12,
        "duration": 4.4
    },
    {
        "text": "like there there could be distribution",
        "start": 473.039,
        "duration": 4.12
    },
    {
        "text": "shifts but for this work you know we",
        "start": 474.52,
        "duration": 5.6
    },
    {
        "text": "focus on what we call group distribution",
        "start": 477.159,
        "duration": 6.88
    },
    {
        "text": "shifts okay and uh even a further subset",
        "start": 480.12,
        "duration": 7.6
    },
    {
        "text": "of that we uh uh like we zero in on two",
        "start": 484.039,
        "duration": 6.28
    },
    {
        "text": "particular types of group distribution",
        "start": 487.72,
        "duration": 6.24
    },
    {
        "text": "shaps so the first uh scenario is like",
        "start": 490.319,
        "duration": 6.361
    },
    {
        "text": "imagine like imagine this example where",
        "start": 493.96,
        "duration": 4.72
    },
    {
        "text": "the training data contains examples of",
        "start": 496.68,
        "duration": 4.6
    },
    {
        "text": "one types of camera uh but on the test",
        "start": 498.68,
        "duration": 4.239
    },
    {
        "text": "data you see a totally new type of",
        "start": 501.28,
        "duration": 3.319
    },
    {
        "text": "camera for which there are no examples",
        "start": 502.919,
        "duration": 5.481
    },
    {
        "text": "in the training data okay the second",
        "start": 504.599,
        "duration": 6.241
    },
    {
        "text": "type is population shift this was the",
        "start": 508.4,
        "duration": 4.759
    },
    {
        "text": "example that I gave earlier uh in which",
        "start": 510.84,
        "duration": 3.8
    },
    {
        "text": "a model is trained on patients in",
        "start": 513.159,
        "duration": 4.081
    },
    {
        "text": "Anarbor which has certain demographic",
        "start": 514.64,
        "duration": 5.92
    },
    {
        "text": "makeup but on but while testing it is",
        "start": 517.24,
        "duration": 4.84
    },
    {
        "text": "deployed in an area which is a",
        "start": 520.56,
        "duration": 3.959
    },
    {
        "text": "completely different demographic makeup",
        "start": 522.08,
        "duration": 5.16
    },
    {
        "text": "so how do we ensure that models uh",
        "start": 524.519,
        "duration": 5.161
    },
    {
        "text": "trained in one place generalize well to",
        "start": 527.24,
        "duration": 6.68
    },
    {
        "text": "other um uh like other like other domain",
        "start": 529.68,
        "duration": 7.0
    },
    {
        "text": "other type of test data or could we fix",
        "start": 533.92,
        "duration": 4.64
    },
    {
        "text": "them like could we train these models",
        "start": 536.68,
        "duration": 4.92
    },
    {
        "text": "better or maybe we could fix them post",
        "start": 538.56,
        "duration": 6.68
    },
    {
        "text": "talk uh to perform better do we have a",
        "start": 541.6,
        "duration": 5.84
    },
    {
        "text": "second yeah so I think like let's try",
        "start": 545.24,
        "duration": 5.48
    },
    {
        "text": "the US let's try sorry everybody hold on",
        "start": 547.44,
        "duration": 6.839
    },
    {
        "text": "one moment having some in room technical",
        "start": 550.72,
        "duration": 7.28
    },
    {
        "text": "difficulties no no so okay so so let's",
        "start": 554.279,
        "duration": 6.8
    },
    {
        "text": "yeah so this was right",
        "start": 558.0,
        "duration": 6.079
    },
    {
        "text": "yeah",
        "start": 561.079,
        "duration": 3.0
    },
    {
        "text": "so",
        "start": 568.12,
        "duration": 3.0
    },
    {
        "text": "let try that oh there we",
        "start": 579.079,
        "duration": 6.601
    },
    {
        "text": "go good job",
        "start": 582.279,
        "duration": 6.881
    },
    {
        "text": "Mark okay so",
        "start": 585.68,
        "duration": 6.2
    },
    {
        "text": "um uh so so this is a high level",
        "start": 589.16,
        "duration": 4.239
    },
    {
        "text": "overview of the problem that we are",
        "start": 591.88,
        "duration": 4.32
    },
    {
        "text": "trying to solve um and I just wanted to",
        "start": 593.399,
        "duration": 4.68
    },
    {
        "text": "narrow down the scope of the problem",
        "start": 596.2,
        "duration": 3.0
    },
    {
        "text": "that we're trying to solve because",
        "start": 598.079,
        "duration": 2.76
    },
    {
        "text": "distribution shifts can be of so many",
        "start": 599.2,
        "duration": 3.759
    },
    {
        "text": "different types so before we proceed",
        "start": 600.839,
        "duration": 4.081
    },
    {
        "text": "further are there any questions about",
        "start": 602.959,
        "duration": 5.32
    },
    {
        "text": "the setup right is this something that",
        "start": 604.92,
        "duration": 6.2
    },
    {
        "text": "you can relate with with your own domain",
        "start": 608.279,
        "duration": 4.081
    },
    {
        "text": "that you're working with like can you",
        "start": 611.12,
        "duration": 4.279
    },
    {
        "text": "see examples of such a case there and",
        "start": 612.36,
        "duration": 5.599
    },
    {
        "text": "does this setup uh like the scope of the",
        "start": 615.399,
        "duration": 5.68
    },
    {
        "text": "setup makes sense to",
        "start": 617.959,
        "duration": 6.641
    },
    {
        "text": "everybody so any any questions any",
        "start": 621.079,
        "duration": 6.76
    },
    {
        "text": "thoughts before we proceed",
        "start": 624.6,
        "duration": 6.44
    },
    {
        "text": "further okay",
        "start": 627.839,
        "duration": 3.201
    },
    {
        "text": "um so uh let's see",
        "start": 631.399,
        "duration": 4.56
    },
    {
        "text": "the let's see the uh like the formal",
        "start": 639.32,
        "duration": 6.319
    },
    {
        "text": "problem definition and setup okay so we",
        "start": 642.48,
        "duration": 6.2
    },
    {
        "text": "assume that we are given data to us uh",
        "start": 645.639,
        "duration": 5.921
    },
    {
        "text": "that we are given uh XS uh like X and Y",
        "start": 648.68,
        "duration": 5.08
    },
    {
        "text": "pairs you know the features and the",
        "start": 651.56,
        "duration": 5.64
    },
    {
        "text": "output labels and we're also given group",
        "start": 653.76,
        "duration": 6.0
    },
    {
        "text": "identities right and let's assume that",
        "start": 657.2,
        "duration": 4.36
    },
    {
        "text": "we are there are some n",
        "start": 659.76,
        "duration": 5.16
    },
    {
        "text": "examples in our data and what we want to",
        "start": 661.56,
        "duration": 5.56
    },
    {
        "text": "do is the statistical inference task is",
        "start": 664.92,
        "duration": 4.479
    },
    {
        "text": "we want to infer the model parameters of",
        "start": 667.12,
        "duration": 5.2
    },
    {
        "text": "some model Theta right and a data is",
        "start": 669.399,
        "duration": 5.321
    },
    {
        "text": "split into a training data you know dra",
        "start": 672.32,
        "duration": 5.079
    },
    {
        "text": "Trin and D test and we only have access",
        "start": 674.72,
        "duration": 6.4
    },
    {
        "text": "to the training data right so just to go",
        "start": 677.399,
        "duration": 5.161
    },
    {
        "text": "back to the earlier example that I gave",
        "start": 681.12,
        "duration": 3.48
    },
    {
        "text": "we do not have access to if our model is",
        "start": 682.56,
        "duration": 3.959
    },
    {
        "text": "trained on Anarbor hospitals we do not",
        "start": 684.6,
        "duration": 4.919
    },
    {
        "text": "have access to Detroit data at all so we",
        "start": 686.519,
        "duration": 6.161
    },
    {
        "text": "cannot even look at 1% of it and change",
        "start": 689.519,
        "duration": 5.681
    },
    {
        "text": "the predictions of our model uh so that",
        "start": 692.68,
        "duration": 4.399
    },
    {
        "text": "it predicts well on that population",
        "start": 695.2,
        "duration": 4.199
    },
    {
        "text": "composition right so we just have access",
        "start": 697.079,
        "duration": 5.961
    },
    {
        "text": "to the data that we have like from an",
        "start": 699.399,
        "duration": 8.521
    },
    {
        "text": "arbor and uh like the models uh uh the",
        "start": 703.04,
        "duration": 7.08
    },
    {
        "text": "model parameters are estimated via the",
        "start": 707.92,
        "duration": 4.32
    },
    {
        "text": "simple ERM simple empirical loss",
        "start": 710.12,
        "duration": 4.32
    },
    {
        "text": "minimization where you assume some loss",
        "start": 712.24,
        "duration": 4.279
    },
    {
        "text": "function you know your favorite model",
        "start": 714.44,
        "duration": 4.959
    },
    {
        "text": "could be uh like a neural or non neural",
        "start": 716.519,
        "duration": 4.961
    },
    {
        "text": "network or what have you that you just",
        "start": 719.399,
        "duration": 4.721
    },
    {
        "text": "want to minimize the loss over all these",
        "start": 721.48,
        "duration": 6.039
    },
    {
        "text": "uh n examples and to estimate to to get",
        "start": 724.12,
        "duration": 5.839
    },
    {
        "text": "the like the maximum likelihood estimate",
        "start": 727.519,
        "duration": 5.481
    },
    {
        "text": "uh of these parameters Theta okay and",
        "start": 729.959,
        "duration": 4.841
    },
    {
        "text": "then you want to make a predictions why",
        "start": 733.0,
        "duration": 4.04
    },
    {
        "text": "had based on these Theta parameters that",
        "start": 734.8,
        "duration": 4.479
    },
    {
        "text": "you've",
        "start": 737.04,
        "duration": 2.239
    },
    {
        "text": "estimated so U uh at least the purpose",
        "start": 743.72,
        "duration": 6.2
    },
    {
        "text": "of the uh models uh for the scope of the",
        "start": 747.24,
        "duration": 5.76
    },
    {
        "text": "things that I would discuss here the the",
        "start": 749.92,
        "duration": 5.76
    },
    {
        "text": "Baseline features or the model that",
        "start": 753.0,
        "duration": 5.959
    },
    {
        "text": "we'll consider is a pre-trained b model",
        "start": 755.68,
        "duration": 6.08
    },
    {
        "text": "so B is a precursor to some of the llms",
        "start": 758.959,
        "duration": 5.161
    },
    {
        "text": "that all of you hear about these days",
        "start": 761.76,
        "duration": 5.36
    },
    {
        "text": "okay so uh B is an encoder model which",
        "start": 764.12,
        "duration": 5.68
    },
    {
        "text": "takes in input text and gets you and",
        "start": 767.12,
        "duration": 6.079
    },
    {
        "text": "outputs uh representations real value",
        "start": 769.8,
        "duration": 6.12
    },
    {
        "text": "representations of uh of those of those",
        "start": 773.199,
        "duration": 4.561
    },
    {
        "text": "Texs you know you could you could use",
        "start": 775.92,
        "duration": 3.919
    },
    {
        "text": "any other model here are like whatever",
        "start": 777.76,
        "duration": 3.72
    },
    {
        "text": "I'm going to say in the next few slides",
        "start": 779.839,
        "duration": 4.44
    },
    {
        "text": "is still applicable to to a different",
        "start": 781.48,
        "duration": 6.32
    },
    {
        "text": "model like you know robota or uh like",
        "start": 784.279,
        "duration": 7.12
    },
    {
        "text": "Excel net and so on so but we just chose",
        "start": 787.8,
        "duration": 6.08
    },
    {
        "text": "bird because like it's probably the most",
        "start": 791.399,
        "duration": 4.88
    },
    {
        "text": "well used model for for for such a",
        "start": 793.88,
        "duration": 4.56
    },
    {
        "text": "context and it's at least parsimonious",
        "start": 796.279,
        "duration": 6.521
    },
    {
        "text": "to uh estimate uh uh like you know B",
        "start": 798.44,
        "duration": 8.36
    },
    {
        "text": "edings for this type of data okay and",
        "start": 802.8,
        "duration": 6.68
    },
    {
        "text": "the model performance okay",
        "start": 806.8,
        "duration": 5.399
    },
    {
        "text": "is evaluated using worst group accuracy",
        "start": 809.48,
        "duration": 4.599
    },
    {
        "text": "right so this is in contrast to standard",
        "start": 812.199,
        "duration": 3.401
    },
    {
        "text": "machine learning where you look at mean",
        "start": 814.079,
        "duration": 3.961
    },
    {
        "text": "squared error or classification error or",
        "start": 815.6,
        "duration": 4.239
    },
    {
        "text": "mean absolute error or something like",
        "start": 818.04,
        "duration": 4.52
    },
    {
        "text": "that so in this case uh so so the mean",
        "start": 819.839,
        "duration": 5.521
    },
    {
        "text": "error hides the worst group accuracy",
        "start": 822.56,
        "duration": 4.399
    },
    {
        "text": "right like so you could still build a",
        "start": 825.36,
        "duration": 4.159
    },
    {
        "text": "model on Anor patients it would do well",
        "start": 826.959,
        "duration": 5.32
    },
    {
        "text": "if you look at the mean uh like uh like",
        "start": 829.519,
        "duration": 4.56
    },
    {
        "text": "the like the average accuracy on",
        "start": 832.279,
        "duration": 4.321
    },
    {
        "text": "patients in Detroit right but what it's",
        "start": 834.079,
        "duration": 4.161
    },
    {
        "text": "hiding under the hood is that it",
        "start": 836.6,
        "duration": 2.72
    },
    {
        "text": "performing",
        "start": 838.24,
        "duration": 5.48
    },
    {
        "text": "like far subar on the uh on the on the",
        "start": 839.32,
        "duration": 6.24
    },
    {
        "text": "people that that belong to the minority",
        "start": 843.72,
        "duration": 4.359
    },
    {
        "text": "group right so we want our our model to",
        "start": 845.56,
        "duration": 6.04
    },
    {
        "text": "do well on the um uh uh like you know on",
        "start": 848.079,
        "duration": 5.081
    },
    {
        "text": "the worst performing DRS you know which",
        "start": 851.6,
        "duration": 3.96
    },
    {
        "text": "are typically uh in most cases are the",
        "start": 853.16,
        "duration": 5.72
    },
    {
        "text": "minority groups also in the",
        "start": 855.56,
        "duration": 3.32
    },
    {
        "text": "data okay so now you know now that I've",
        "start": 859.079,
        "duration": 5.56
    },
    {
        "text": "described the problem uh and like you",
        "start": 862.0,
        "duration": 4.24
    },
    {
        "text": "know this simple empirical risk",
        "start": 864.639,
        "duration": 4.12
    },
    {
        "text": "minimization framework and I've",
        "start": 866.24,
        "duration": 6.039
    },
    {
        "text": "described our uh evaluation metric let's",
        "start": 868.759,
        "duration": 6.0
    },
    {
        "text": "see how is this uh problem currently",
        "start": 872.279,
        "duration": 4.281
    },
    {
        "text": "solved you know what's the state of the",
        "start": 874.759,
        "duration": 3.08
    },
    {
        "text": "art",
        "start": 876.56,
        "duration": 4.36
    },
    {
        "text": "okay so the stateof the art like there's",
        "start": 877.839,
        "duration": 6.521
    },
    {
        "text": "this idea about um you know Minimax",
        "start": 880.92,
        "duration": 5.96
    },
    {
        "text": "robustness right so what people what we",
        "start": 884.36,
        "duration": 5.0
    },
    {
        "text": "want to do is we want to train the model",
        "start": 886.88,
        "duration": 4.72
    },
    {
        "text": "uh to minimize the error of the worst",
        "start": 889.36,
        "duration": 3.56
    },
    {
        "text": "performing",
        "start": 891.6,
        "duration": 5.28
    },
    {
        "text": "growth okay so you want to take a Max",
        "start": 892.92,
        "duration": 6.8
    },
    {
        "text": "over all the groups uh G belonging to",
        "start": 896.88,
        "duration": 6.36
    },
    {
        "text": "capital G so take the max loss of all",
        "start": 899.72,
        "duration": 6.32
    },
    {
        "text": "the groups and find the parameters that",
        "start": 903.24,
        "duration": 5.32
    },
    {
        "text": "minimize the max loss right the simple",
        "start": 906.04,
        "duration": 5.479
    },
    {
        "text": "minia Max loss that you want to do and",
        "start": 908.56,
        "duration": 4.68
    },
    {
        "text": "as I said like our evaluation metric is",
        "start": 911.519,
        "duration": 4.801
    },
    {
        "text": "the worst group accuracy it's a natural",
        "start": 913.24,
        "duration": 6.32
    },
    {
        "text": "um objective to minimize right like and",
        "start": 916.32,
        "duration": 6.16
    },
    {
        "text": "as you know uh most of machine learning",
        "start": 919.56,
        "duration": 5.279
    },
    {
        "text": "uh uh like is about convex learning",
        "start": 922.48,
        "duration": 3.88
    },
    {
        "text": "objectives right or something that could",
        "start": 924.839,
        "duration": 4.0
    },
    {
        "text": "be easily optimized right like so so",
        "start": 926.36,
        "duration": 4.839
    },
    {
        "text": "that's what people thought about you",
        "start": 928.839,
        "duration": 4.601
    },
    {
        "text": "know thinking about convex surrogates of",
        "start": 931.199,
        "duration": 3.161
    },
    {
        "text": "this",
        "start": 933.44,
        "duration": 3.319
    },
    {
        "text": "non-differentiable uh objective function",
        "start": 934.36,
        "duration": 5.0
    },
    {
        "text": "that can be optimized easily",
        "start": 936.759,
        "duration": 4.88
    },
    {
        "text": "okay so and there have been many",
        "start": 939.36,
        "duration": 4.959
    },
    {
        "text": "approaches that people have uh proposed",
        "start": 941.639,
        "duration": 4.521
    },
    {
        "text": "on this Minimax framework to solve the",
        "start": 944.319,
        "duration": 3.161
    },
    {
        "text": "group distributional robustness",
        "start": 946.16,
        "duration": 3.239
    },
    {
        "text": "framework and there are some approaches",
        "start": 947.48,
        "duration": 4.52
    },
    {
        "text": "like you know drro distributional robust",
        "start": 949.399,
        "duration": 4.761
    },
    {
        "text": "uh optimization group Dr and all these",
        "start": 952.0,
        "duration": 3.72
    },
    {
        "text": "approaches at a high level what they try",
        "start": 954.16,
        "duration": 4.0
    },
    {
        "text": "to do is try to find like a convex",
        "start": 955.72,
        "duration": 4.039
    },
    {
        "text": "approxim imation to this objective",
        "start": 958.16,
        "duration": 5.88
    },
    {
        "text": "function and trying to solve that",
        "start": 959.759,
        "duration": 4.281
    },
    {
        "text": "right now a key assumption made by these",
        "start": 964.92,
        "duration": 8.359
    },
    {
        "text": "approaches is that U uh uh that the that",
        "start": 967.8,
        "duration": 8.519
    },
    {
        "text": "the low worst error worst group error on",
        "start": 973.279,
        "duration": 5.601
    },
    {
        "text": "the training data would be would mean",
        "start": 976.319,
        "duration": 5.361
    },
    {
        "text": "would imply that on the test data also",
        "start": 978.88,
        "duration": 6.079
    },
    {
        "text": "we would get low worst group error right",
        "start": 981.68,
        "duration": 4.639
    },
    {
        "text": "which could be a very very strong",
        "start": 984.959,
        "duration": 3.12
    },
    {
        "text": "assumption because implicitly you are",
        "start": 986.319,
        "duration": 3.44
    },
    {
        "text": "assuming that the worst group on",
        "start": 988.079,
        "duration": 3.841
    },
    {
        "text": "training data is similar to the worst",
        "start": 989.759,
        "duration": 6.601
    },
    {
        "text": "group in testing data okay like a priori",
        "start": 991.92,
        "duration": 6.0
    },
    {
        "text": "without any knowledge that's a very",
        "start": 996.36,
        "duration": 4.159
    },
    {
        "text": "strong assumption to make right but the",
        "start": 997.92,
        "duration": 4.08
    },
    {
        "text": "fact that people have been doing these",
        "start": 1000.519,
        "duration": 4.401
    },
    {
        "text": "things is because like most of the",
        "start": 1002.0,
        "duration": 5.04
    },
    {
        "text": "machine learning research proceeds we",
        "start": 1004.92,
        "duration": 3.599
    },
    {
        "text": "have an objective function that we can",
        "start": 1007.04,
        "duration": 3.76
    },
    {
        "text": "easily optimize you know how would you",
        "start": 1008.519,
        "duration": 5.24
    },
    {
        "text": "know what we cannot see on the test data",
        "start": 1010.8,
        "duration": 5.08
    },
    {
        "text": "so why not based on the information that",
        "start": 1013.759,
        "duration": 4.841
    },
    {
        "text": "we have is just uh minimize the the",
        "start": 1015.88,
        "duration": 5.04
    },
    {
        "text": "worst groups accuracy right so that's",
        "start": 1018.6,
        "duration": 4.96
    },
    {
        "text": "why there a justification of what these",
        "start": 1020.92,
        "duration": 4.48
    },
    {
        "text": "people are doing and why these",
        "start": 1023.56,
        "duration": 4.759
    },
    {
        "text": "approaches have been uh popular in this",
        "start": 1025.4,
        "duration": 6.72
    },
    {
        "text": "uh uh in this pafic area",
        "start": 1028.319,
        "duration": 7.6
    },
    {
        "text": "there so uh before I uh describe our",
        "start": 1032.12,
        "duration": 5.559
    },
    {
        "text": "model in detail you know I'm going to",
        "start": 1035.919,
        "duration": 3.52
    },
    {
        "text": "describe a key intuition behind an",
        "start": 1037.679,
        "duration": 4.36
    },
    {
        "text": "improved solution right now what are",
        "start": 1039.439,
        "duration": 4.6
    },
    {
        "text": "what is some of the blueprints of a",
        "start": 1042.039,
        "duration": 4.241
    },
    {
        "text": "better approach uh like approach that",
        "start": 1044.039,
        "duration": 3.961
    },
    {
        "text": "could perform better right and then we",
        "start": 1046.28,
        "duration": 4.8
    },
    {
        "text": "will see on test on like some actual",
        "start": 1048.0,
        "duration": 4.72
    },
    {
        "text": "empirical data whether that approach",
        "start": 1051.08,
        "duration": 4.08
    },
    {
        "text": "actually performs better or not so the",
        "start": 1052.72,
        "duration": 5.319
    },
    {
        "text": "key idea is that instead of focusing",
        "start": 1055.16,
        "duration": 4.639
    },
    {
        "text": "only on the worst performing group at",
        "start": 1058.039,
        "duration": 4.681
    },
    {
        "text": "training time consider several per",
        "start": 1059.799,
        "duration": 6.041
    },
    {
        "text": "several poorly performing groups okay",
        "start": 1062.72,
        "duration": 6.12
    },
    {
        "text": "right so now going back to the previous",
        "start": 1065.84,
        "duration": 5.8
    },
    {
        "text": "slide where I said that these models uh",
        "start": 1068.84,
        "duration": 5.079
    },
    {
        "text": "rigidly assume that the worst group in",
        "start": 1071.64,
        "duration": 4.159
    },
    {
        "text": "training data is similar to the worst",
        "start": 1073.919,
        "duration": 4.0
    },
    {
        "text": "group in testing data what we are seeing",
        "start": 1075.799,
        "duration": 4.161
    },
    {
        "text": "is you know we should relax it a little",
        "start": 1077.919,
        "duration": 4.841
    },
    {
        "text": "you know uh it turns out that we could",
        "start": 1079.96,
        "duration": 4.959
    },
    {
        "text": "take some combination of several poorly",
        "start": 1082.76,
        "duration": 4.64
    },
    {
        "text": "performing groups in training data and",
        "start": 1084.919,
        "duration": 4.281
    },
    {
        "text": "they should be similar to some of the",
        "start": 1087.4,
        "duration": 4.48
    },
    {
        "text": "worst performing groups in test data so",
        "start": 1089.2,
        "duration": 6.2
    },
    {
        "text": "basically moving from one to like uh K",
        "start": 1091.88,
        "duration": 8.2
    },
    {
        "text": "bestest okay so now um why is this a",
        "start": 1095.4,
        "duration": 7.2
    },
    {
        "text": "good idea as I as I just briefly alluded",
        "start": 1100.08,
        "duration": 4.92
    },
    {
        "text": "to you know the worst group might not be",
        "start": 1102.6,
        "duration": 4.52
    },
    {
        "text": "similar to the worst group on the test",
        "start": 1105.0,
        "duration": 5.76
    },
    {
        "text": "data leading to to out of distribution",
        "start": 1107.12,
        "duration": 7.32
    },
    {
        "text": "uh uh generalization problems and uh",
        "start": 1110.76,
        "duration": 6.0
    },
    {
        "text": "like this point is even more Salient for",
        "start": 1114.44,
        "duration": 4.28
    },
    {
        "text": "group distribution shift you know where",
        "start": 1116.76,
        "duration": 4.799
    },
    {
        "text": "unseen groups arrive at test time or",
        "start": 1118.72,
        "duration": 6.8
    },
    {
        "text": "group proportions change",
        "start": 1121.559,
        "duration": 3.961
    },
    {
        "text": "yeah so in terms of uh like you know U",
        "start": 1126.919,
        "duration": 8.76
    },
    {
        "text": "uh like statistical terms what we are",
        "start": 1132.2,
        "duration": 5.32
    },
    {
        "text": "what we are proposing here is to perform",
        "start": 1135.679,
        "duration": 3.281
    },
    {
        "text": "a type of smoothing",
        "start": 1137.52,
        "duration": 4.0
    },
    {
        "text": "a soft minax approach rather than taking",
        "start": 1138.96,
        "duration": 4.839
    },
    {
        "text": "the worst group and you know ensuring",
        "start": 1141.52,
        "duration": 3.6
    },
    {
        "text": "the worst group is similar in the",
        "start": 1143.799,
        "duration": 3.721
    },
    {
        "text": "training and test we just take some kind",
        "start": 1145.12,
        "duration": 4.559
    },
    {
        "text": "of weighted average of several worst",
        "start": 1147.52,
        "duration": 4.279
    },
    {
        "text": "performing groups and hope that that",
        "start": 1149.679,
        "duration": 3.441
    },
    {
        "text": "they are similar to several worst",
        "start": 1151.799,
        "duration": 3.401
    },
    {
        "text": "performing groups in the test data right",
        "start": 1153.12,
        "duration": 3.88
    },
    {
        "text": "so we are quote unquote performing",
        "start": 1155.2,
        "duration": 5.12
    },
    {
        "text": "smoothing okay a tried and tested idea",
        "start": 1157.0,
        "duration": 5.52
    },
    {
        "text": "in statistics and machine learning and",
        "start": 1160.32,
        "duration": 5.56
    },
    {
        "text": "we'll see how this performs uh um on the",
        "start": 1162.52,
        "duration": 7.44
    },
    {
        "text": "several data sets that we have",
        "start": 1165.88,
        "duration": 8.12
    },
    {
        "text": "so now uh sure like this is a that we",
        "start": 1169.96,
        "duration": 5.76
    },
    {
        "text": "should perform smoothing is a high level",
        "start": 1174.0,
        "duration": 4.2
    },
    {
        "text": "Idea Idea okay but how do we",
        "start": 1175.72,
        "duration": 4.12
    },
    {
        "text": "operationalize this how do we come up",
        "start": 1178.2,
        "duration": 3.88
    },
    {
        "text": "with an algorithm that would that would",
        "start": 1179.84,
        "duration": 5.68
    },
    {
        "text": "do this type of smoothing okay and for",
        "start": 1182.08,
        "duration": 4.56
    },
    {
        "text": "that in order to come up with an",
        "start": 1185.52,
        "duration": 3.279
    },
    {
        "text": "algorithm we take inspiration from the",
        "start": 1186.64,
        "duration": 4.519
    },
    {
        "text": "information retriever literature and use",
        "start": 1188.799,
        "duration": 6.521
    },
    {
        "text": "this idea uh uh of discounted cumulative",
        "start": 1191.159,
        "duration": 6.64
    },
    {
        "text": "gain okay so the idea is so so",
        "start": 1195.32,
        "duration": 5.32
    },
    {
        "text": "discounted cumulative gain uh uh to to",
        "start": 1197.799,
        "duration": 5.321
    },
    {
        "text": "differentially rewe the different groups",
        "start": 1200.64,
        "duration": 5.32
    },
    {
        "text": "during the training process okay so",
        "start": 1203.12,
        "duration": 5.84
    },
    {
        "text": "those of you are not um familiar uh with",
        "start": 1205.96,
        "duration": 4.64
    },
    {
        "text": "discounted cumulative gain so it's like",
        "start": 1208.96,
        "duration": 3.88
    },
    {
        "text": "used for ranking search results so the",
        "start": 1210.6,
        "duration": 4.28
    },
    {
        "text": "search results that you get on Google or",
        "start": 1212.84,
        "duration": 5.16
    },
    {
        "text": "Bank uh like there are criteria to to",
        "start": 1214.88,
        "duration": 5.4
    },
    {
        "text": "like wait those results based on",
        "start": 1218.0,
        "duration": 6.44
    },
    {
        "text": "relevance okay and what dcg does is um",
        "start": 1220.28,
        "duration": 5.92
    },
    {
        "text": "it it does the logarithmic waiting of",
        "start": 1224.44,
        "duration": 5.719
    },
    {
        "text": "those results okay",
        "start": 1226.2,
        "duration": 3.959
    },
    {
        "text": "um yeah so uh so our key idea is that we",
        "start": 1230.28,
        "duration": 6.44
    },
    {
        "text": "should uh use like a simple objective",
        "start": 1234.24,
        "duration": 5.12
    },
    {
        "text": "function you know uh like a discounted",
        "start": 1236.72,
        "duration": 5.0
    },
    {
        "text": "cumulated gain to differentially Reade",
        "start": 1239.36,
        "duration": 4.04
    },
    {
        "text": "the various groups during the training",
        "start": 1241.72,
        "duration": 5.52
    },
    {
        "text": "process and then uh like hopefully the",
        "start": 1243.4,
        "duration": 5.519
    },
    {
        "text": "worst performing groups will have higher",
        "start": 1247.24,
        "duration": 4.08
    },
    {
        "text": "say in the model parameters and it and",
        "start": 1248.919,
        "duration": 5.24
    },
    {
        "text": "it would generalize",
        "start": 1251.32,
        "duration": 2.839
    },
    {
        "text": "better um so now now like why did we",
        "start": 1256.28,
        "duration": 7.0
    },
    {
        "text": "choose uh like dcg so the so the idea",
        "start": 1259.799,
        "duration": 5.88
    },
    {
        "text": "the reason why we chose dcg and not any",
        "start": 1263.28,
        "duration": 4.879
    },
    {
        "text": "other functional form is because it's",
        "start": 1265.679,
        "duration": 4.641
    },
    {
        "text": "widely used uh in the information",
        "start": 1268.159,
        "duration": 3.801
    },
    {
        "text": "retrieval literature it has strong",
        "start": 1270.32,
        "duration": 3.92
    },
    {
        "text": "precedents you know people have proven",
        "start": 1271.96,
        "duration": 4.0
    },
    {
        "text": "strong theory about it and it's very",
        "start": 1274.24,
        "duration": 3.72
    },
    {
        "text": "very easy it's very very easy to",
        "start": 1275.96,
        "duration": 4.48
    },
    {
        "text": "understand and also it has a logarithmic",
        "start": 1277.96,
        "duration": 4.959
    },
    {
        "text": "drop off you know from like so it would",
        "start": 1280.44,
        "duration": 4.56
    },
    {
        "text": "wait the worst performing group in a",
        "start": 1282.919,
        "duration": 4.481
    },
    {
        "text": "certain way and the second wor worst",
        "start": 1285.0,
        "duration": 4.72
    },
    {
        "text": "performing group a log of that the third",
        "start": 1287.4,
        "duration": 4.279
    },
    {
        "text": "one log of log of that and so on so it's",
        "start": 1289.72,
        "duration": 4.959
    },
    {
        "text": "like so it has a logarithmic Decay um",
        "start": 1291.679,
        "duration": 8.081
    },
    {
        "text": "and so it ensures that uh we do not uh",
        "start": 1294.679,
        "duration": 6.921
    },
    {
        "text": "like have a very very long tail of",
        "start": 1299.76,
        "duration": 5.519
    },
    {
        "text": "weights right so that we do not uh uh so",
        "start": 1301.6,
        "duration": 6.6
    },
    {
        "text": "that we do not upweight even the best",
        "start": 1305.279,
        "duration": 5.64
    },
    {
        "text": "performing groups so it is a sh drop off",
        "start": 1308.2,
        "duration": 5.16
    },
    {
        "text": "but so it ensures that instead of one we",
        "start": 1310.919,
        "duration": 5.401
    },
    {
        "text": "would um upweight like maybe five or 10",
        "start": 1313.36,
        "duration": 5.4
    },
    {
        "text": "groups but not all of them like if we",
        "start": 1316.32,
        "duration": 5.64
    },
    {
        "text": "have 100 groups",
        "start": 1318.76,
        "duration": 3.2
    },
    {
        "text": "yeah so here is here is our here is our",
        "start": 1322.4,
        "duration": 7.84
    },
    {
        "text": "iterative algorithm okay um basically",
        "start": 1325.679,
        "duration": 7.88
    },
    {
        "text": "you know um uh like as I'm sure all of",
        "start": 1330.24,
        "duration": 6.64
    },
    {
        "text": "you um have uh trained some kind of",
        "start": 1333.559,
        "duration": 5.401
    },
    {
        "text": "neural network model you know so there",
        "start": 1336.88,
        "duration": 4.32
    },
    {
        "text": "is Epoch wise training you know you make",
        "start": 1338.96,
        "duration": 4.0
    },
    {
        "text": "a Passover the data you do gradient",
        "start": 1341.2,
        "duration": 3.32
    },
    {
        "text": "updates and then you move again and so",
        "start": 1342.96,
        "duration": 4.079
    },
    {
        "text": "on right so it's a so we try to",
        "start": 1344.52,
        "duration": 5.48
    },
    {
        "text": "integrate this idea of BCG into this",
        "start": 1347.039,
        "duration": 5.721
    },
    {
        "text": "Epoch wise uh training over the data",
        "start": 1350.0,
        "duration": 4.76
    },
    {
        "text": "okay so we iterate over the training",
        "start": 1352.76,
        "duration": 5.519
    },
    {
        "text": "data and we and uh we compute",
        "start": 1354.76,
        "duration": 6.159
    },
    {
        "text": "accuracy uh of all the groups in our",
        "start": 1358.279,
        "duration": 6.361
    },
    {
        "text": "data right so um in the first Epoch we",
        "start": 1360.919,
        "duration": 5.841
    },
    {
        "text": "rank all the groups based on their",
        "start": 1364.64,
        "duration": 3.96
    },
    {
        "text": "accuracy in the previous Epoch so the",
        "start": 1366.76,
        "duration": 4.08
    },
    {
        "text": "first Epoch sure there is no previous",
        "start": 1368.6,
        "duration": 4.679
    },
    {
        "text": "group but second Epoch converts we rank",
        "start": 1370.84,
        "duration": 4.6
    },
    {
        "text": "the groups based on their accuracy in",
        "start": 1373.279,
        "duration": 3.28
    },
    {
        "text": "the previous",
        "start": 1375.44,
        "duration": 4.2
    },
    {
        "text": "Epoch and then we do this logarithmic",
        "start": 1376.559,
        "duration": 5.841
    },
    {
        "text": "weighting so the groups that perform the",
        "start": 1379.64,
        "duration": 5.36
    },
    {
        "text": "worst you know that will get weighted",
        "start": 1382.4,
        "duration": 5.879
    },
    {
        "text": "the highest and the group that got the",
        "start": 1385.0,
        "duration": 5.52
    },
    {
        "text": "second worst it will get weighted",
        "start": 1388.279,
        "duration": 4.841
    },
    {
        "text": "slightly lower and so on and with a with",
        "start": 1390.52,
        "duration": 5.399
    },
    {
        "text": "a standard logarithmic Decay right and",
        "start": 1393.12,
        "duration": 6.24
    },
    {
        "text": "see uh in the numerator and here is like",
        "start": 1395.919,
        "duration": 6.0
    },
    {
        "text": "is a is a hyper parameter you know that",
        "start": 1399.36,
        "duration": 5.199
    },
    {
        "text": "is chosen by cross validation it just",
        "start": 1401.919,
        "duration": 6.12
    },
    {
        "text": "chooses it just decides uh how much uh",
        "start": 1404.559,
        "duration": 5.48
    },
    {
        "text": "like how many groups we should wait and",
        "start": 1408.039,
        "duration": 3.201
    },
    {
        "text": "what should be the",
        "start": 1410.039,
        "duration": 5.76
    },
    {
        "text": "Decay okay and uh C also decides like",
        "start": 1411.24,
        "duration": 8.28
    },
    {
        "text": "you know as you can see that we only um",
        "start": 1415.799,
        "duration": 7.48
    },
    {
        "text": "um like upweight groups up to up to up",
        "start": 1419.52,
        "duration": 6.68
    },
    {
        "text": "to ranks given by Capital C and so it's",
        "start": 1423.279,
        "duration": 4.801
    },
    {
        "text": "like an implicit threshold also you know",
        "start": 1426.2,
        "duration": 5.2
    },
    {
        "text": "to decide like how many groups we",
        "start": 1428.08,
        "duration": 8.24
    },
    {
        "text": "yeah um so so so what our model does is",
        "start": 1431.4,
        "duration": 7.12
    },
    {
        "text": "like it minimizes the following objetive",
        "start": 1436.32,
        "duration": 5.0
    },
    {
        "text": "function that here is our loss function",
        "start": 1438.52,
        "duration": 5.36
    },
    {
        "text": "like a standard loss function okay and",
        "start": 1441.32,
        "duration": 6.32
    },
    {
        "text": "then uh we uh weit each of the groups",
        "start": 1443.88,
        "duration": 5.52
    },
    {
        "text": "based on that waiting function that I",
        "start": 1447.64,
        "duration": 3.8
    },
    {
        "text": "described on the previous slide right",
        "start": 1449.4,
        "duration": 4.6
    },
    {
        "text": "simple uh discounted cumulative gain",
        "start": 1451.44,
        "duration": 5.119
    },
    {
        "text": "inspired uh waiting",
        "start": 1454.0,
        "duration": 5.44
    },
    {
        "text": "function and we do this uh iterative",
        "start": 1456.559,
        "duration": 5.681
    },
    {
        "text": "training so now this process of like",
        "start": 1459.44,
        "duration": 4.68
    },
    {
        "text": "looking at the model errors and",
        "start": 1462.24,
        "duration": 4.48
    },
    {
        "text": "upweighting certain examples is very",
        "start": 1464.12,
        "duration": 4.96
    },
    {
        "text": "similar so those of you who know about",
        "start": 1466.72,
        "duration": 4.4
    },
    {
        "text": "stage- wise learning method like you",
        "start": 1469.08,
        "duration": 5.079
    },
    {
        "text": "know Ada boost or like its cousins it's",
        "start": 1471.12,
        "duration": 4.84
    },
    {
        "text": "very similar to the idea that boosting",
        "start": 1474.159,
        "duration": 4.601
    },
    {
        "text": "does right so what boosting also does is",
        "start": 1475.96,
        "duration": 4.959
    },
    {
        "text": "like it looks at the errors of certain",
        "start": 1478.76,
        "duration": 4.24
    },
    {
        "text": "examples and upgrate certain errors",
        "start": 1480.919,
        "duration": 4.161
    },
    {
        "text": "right of course it has an exponential",
        "start": 1483.0,
        "duration": 3.64
    },
    {
        "text": "loss function and it has its own",
        "start": 1485.08,
        "duration": 5.0
    },
    {
        "text": "upweighting criteria but at a high level",
        "start": 1486.64,
        "duration": 5.56
    },
    {
        "text": "like you know this reting based idea is",
        "start": 1490.08,
        "duration": 5.12
    },
    {
        "text": "similar to boosting style um boosting",
        "start": 1492.2,
        "duration": 6.24
    },
    {
        "text": "style uh approaches okay",
        "start": 1495.2,
        "duration": 5.04
    },
    {
        "text": "and another key difference is like you",
        "start": 1498.44,
        "duration": 4.08
    },
    {
        "text": "know in our case we do this waiting per",
        "start": 1500.24,
        "duration": 5.88
    },
    {
        "text": "group we upweight all the uh all the",
        "start": 1502.52,
        "duration": 6.72
    },
    {
        "text": "examples all the observations in a group",
        "start": 1506.12,
        "duration": 4.6
    },
    {
        "text": "as opposed to some of these stagewise",
        "start": 1509.24,
        "duration": 2.679
    },
    {
        "text": "learning approaches which are",
        "start": 1510.72,
        "duration": 3.199
    },
    {
        "text": "observation based you know which would",
        "start": 1511.919,
        "duration": 4.521
    },
    {
        "text": "upweight which would compute error of",
        "start": 1513.919,
        "duration": 5.201
    },
    {
        "text": "each observation and it would upweight",
        "start": 1516.44,
        "duration": 6.719
    },
    {
        "text": "uh like each of them by a certain",
        "start": 1519.12,
        "duration": 4.039
    },
    {
        "text": "amount okay so uh like this default idea",
        "start": 1523.52,
        "duration": 5.759
    },
    {
        "text": "that I said said it updates all the",
        "start": 1527.32,
        "duration": 4.16
    },
    {
        "text": "sample in a group but we could we could",
        "start": 1529.279,
        "duration": 4.041
    },
    {
        "text": "be even smarter about this you know we",
        "start": 1531.48,
        "duration": 4.52
    },
    {
        "text": "could only choose uh to update the",
        "start": 1533.32,
        "duration": 5.239
    },
    {
        "text": "misclassified examples from a group",
        "start": 1536.0,
        "duration": 4.799
    },
    {
        "text": "right so if let's say there's a there's",
        "start": 1538.559,
        "duration": 4.201
    },
    {
        "text": "a there's a group containing a certain",
        "start": 1540.799,
        "duration": 4.841
    },
    {
        "text": "demographic Group which is minority and",
        "start": 1542.76,
        "duration": 5.56
    },
    {
        "text": "for which we get very very high errors",
        "start": 1545.64,
        "duration": 6.6
    },
    {
        "text": "um so maybe we should uh uh like why",
        "start": 1548.32,
        "duration": 5.719
    },
    {
        "text": "upate all the examples in that group",
        "start": 1552.24,
        "duration": 3.52
    },
    {
        "text": "maybe we could upate only the",
        "start": 1554.039,
        "duration": 3.801
    },
    {
        "text": "misclassified examples from the group",
        "start": 1555.76,
        "duration": 3.72
    },
    {
        "text": "and the objective function changes",
        "start": 1557.84,
        "duration": 3.48
    },
    {
        "text": "slightly but at a high level the",
        "start": 1559.48,
        "duration": 5.919
    },
    {
        "text": "blueprint of the algorithm uh stays the",
        "start": 1561.32,
        "duration": 7.56
    },
    {
        "text": "same now so that was the algorithm so",
        "start": 1565.399,
        "duration": 6.4
    },
    {
        "text": "now let's try to understand why it works",
        "start": 1568.88,
        "duration": 5.12
    },
    {
        "text": "right like you know why um I've given",
        "start": 1571.799,
        "duration": 4.641
    },
    {
        "text": "you intuition that instead of uh doing",
        "start": 1574.0,
        "duration": 5.279
    },
    {
        "text": "Minimax we are doing soft Mini Max right",
        "start": 1576.44,
        "duration": 5.04
    },
    {
        "text": "so instead of assuming that the worst",
        "start": 1579.279,
        "duration": 3.801
    },
    {
        "text": "group in training is similar to the",
        "start": 1581.48,
        "duration": 4.16
    },
    {
        "text": "worst group in test we are assuming some",
        "start": 1583.08,
        "duration": 5.44
    },
    {
        "text": "weighted combination of worst groups in",
        "start": 1585.64,
        "duration": 5.919
    },
    {
        "text": "training is similar to some uh",
        "start": 1588.52,
        "duration": 5.279
    },
    {
        "text": "combination of worse groups in the test",
        "start": 1591.559,
        "duration": 5.24
    },
    {
        "text": "right but why why does this approach",
        "start": 1593.799,
        "duration": 8.401
    },
    {
        "text": "work so in order to understand um uh",
        "start": 1596.799,
        "duration": 9.201
    },
    {
        "text": "like why some of these models um some of",
        "start": 1602.2,
        "duration": 5.64
    },
    {
        "text": "these Baseline models I should say that",
        "start": 1606.0,
        "duration": 3.6
    },
    {
        "text": "do not are that are not distributionally",
        "start": 1607.84,
        "duration": 4.839
    },
    {
        "text": "robust that they perform well on average",
        "start": 1609.6,
        "duration": 4.84
    },
    {
        "text": "but worse on some these under",
        "start": 1612.679,
        "duration": 4.281
    },
    {
        "text": "represented groups in the data is due to",
        "start": 1614.44,
        "duration": 5.52
    },
    {
        "text": "spous featur features okay so the spous",
        "start": 1616.96,
        "duration": 6.68
    },
    {
        "text": "features are um are are features that",
        "start": 1619.96,
        "duration": 6.079
    },
    {
        "text": "are correlated with the label but their",
        "start": 1623.64,
        "duration": 4.919
    },
    {
        "text": "correlation would switch labels you know",
        "start": 1626.039,
        "duration": 4.201
    },
    {
        "text": "maybe they're positively correlated on",
        "start": 1628.559,
        "duration": 3.84
    },
    {
        "text": "training data but negatively correlated",
        "start": 1630.24,
        "duration": 4.799
    },
    {
        "text": "in test data right so for example in our",
        "start": 1632.399,
        "duration": 6.961
    },
    {
        "text": "case the uh the uh ex uh like the",
        "start": 1635.039,
        "duration": 6.841
    },
    {
        "text": "empirical scenario is we have reviews",
        "start": 1639.36,
        "duration": 4.48
    },
    {
        "text": "from users and we're trying to predict",
        "start": 1641.88,
        "duration": 4.12
    },
    {
        "text": "what rating they would get right like is",
        "start": 1643.84,
        "duration": 4.04
    },
    {
        "text": "it a good is it a festar review or a",
        "start": 1646.0,
        "duration": 4.0
    },
    {
        "text": "fourar review or something so in that",
        "start": 1647.88,
        "duration": 5.519
    },
    {
        "text": "case like an easy spous feature to see",
        "start": 1650.0,
        "duration": 6.96
    },
    {
        "text": "is the writing style uh uh of people",
        "start": 1653.399,
        "duration": 8.041
    },
    {
        "text": "right so so because like a like a",
        "start": 1656.96,
        "duration": 6.319
    },
    {
        "text": "vanilla model like a vanilla off the",
        "start": 1661.44,
        "duration": 5.04
    },
    {
        "text": "shell model it does so well on average",
        "start": 1663.279,
        "duration": 5.28
    },
    {
        "text": "but does poorly on some of these",
        "start": 1666.48,
        "duration": 5.72
    },
    {
        "text": "minority groups is that it has lashed on",
        "start": 1668.559,
        "duration": 6.0
    },
    {
        "text": "to the writing style of people it has",
        "start": 1672.2,
        "duration": 4.52
    },
    {
        "text": "seen that when somebody doesn't have",
        "start": 1674.559,
        "duration": 4.201
    },
    {
        "text": "doesn't form like fully grammatical",
        "start": 1676.72,
        "duration": 4.48
    },
    {
        "text": "sentences uh or like you know uh like",
        "start": 1678.76,
        "duration": 4.799
    },
    {
        "text": "punctuation is bad uh that person also",
        "start": 1681.2,
        "duration": 5.479
    },
    {
        "text": "writes really bad reviews but this is a",
        "start": 1683.559,
        "duration": 4.881
    },
    {
        "text": "feature which is not generalizable",
        "start": 1686.679,
        "duration": 3.72
    },
    {
        "text": "because on the test data that",
        "start": 1688.44,
        "duration": 3.56
    },
    {
        "text": "correlation might not be present like",
        "start": 1690.399,
        "duration": 4.801
    },
    {
        "text": "you know there might be uh like you know",
        "start": 1692.0,
        "duration": 7.0
    },
    {
        "text": "like all well written responses right",
        "start": 1695.2,
        "duration": 5.76
    },
    {
        "text": "now you could you could generalize it to",
        "start": 1699.0,
        "duration": 3.919
    },
    {
        "text": "like other examples you know like in",
        "start": 1700.96,
        "duration": 4.76
    },
    {
        "text": "medical domains where it could be like",
        "start": 1702.919,
        "duration": 4.161
    },
    {
        "text": "where it could be studious features that",
        "start": 1705.72,
        "duration": 3.12
    },
    {
        "text": "would Graphics of people that they are",
        "start": 1707.08,
        "duration": 5.319
    },
    {
        "text": "present with with um One sign in",
        "start": 1708.84,
        "duration": 5.559
    },
    {
        "text": "training data but with the reverse sign",
        "start": 1712.399,
        "duration": 4.28
    },
    {
        "text": "on the test data or like uh like no",
        "start": 1714.399,
        "duration": 5.361
    },
    {
        "text": "correlation of the test",
        "start": 1716.679,
        "duration": 3.081
    },
    {
        "text": "data um so um",
        "start": 1720.799,
        "duration": 7.24
    },
    {
        "text": "um what uh like what our approach you",
        "start": 1724.76,
        "duration": 6.36
    },
    {
        "text": "know uh uh like Dru discounted rank",
        "start": 1728.039,
        "duration": 5.441
    },
    {
        "text": "upating uh like what we are doing is we",
        "start": 1731.12,
        "duration": 5.0
    },
    {
        "text": "are assuming that these spous features",
        "start": 1733.48,
        "duration": 5.0
    },
    {
        "text": "are present in all the groups",
        "start": 1736.12,
        "duration": 4.919
    },
    {
        "text": "right so uh like again like this goes",
        "start": 1738.48,
        "duration": 4.96
    },
    {
        "text": "with the spirit of smoothing uh that we",
        "start": 1741.039,
        "duration": 3.961
    },
    {
        "text": "assume that they are present in all the",
        "start": 1743.44,
        "duration": 5.0
    },
    {
        "text": "groups to varing degrees and hence uh we",
        "start": 1745.0,
        "duration": 5.76
    },
    {
        "text": "Reade all the groups proportional to",
        "start": 1748.44,
        "duration": 4.44
    },
    {
        "text": "their group errors to find robust",
        "start": 1750.76,
        "duration": 4.159
    },
    {
        "text": "features that are invariant to these",
        "start": 1752.88,
        "duration": 5.2
    },
    {
        "text": "previous features right so that's the",
        "start": 1754.919,
        "duration": 6.961
    },
    {
        "text": "Crux of our of our approach you know",
        "start": 1758.08,
        "duration": 6.4
    },
    {
        "text": "that U that that we assume that the",
        "start": 1761.88,
        "duration": 5.08
    },
    {
        "text": "serious features are scattered all over",
        "start": 1764.48,
        "duration": 5.079
    },
    {
        "text": "right and it's just the extent is",
        "start": 1766.96,
        "duration": 5.04
    },
    {
        "text": "different you know the spous features",
        "start": 1769.559,
        "duration": 4.401
    },
    {
        "text": "might be present to a smaller extent in",
        "start": 1772.0,
        "duration": 4.559
    },
    {
        "text": "groups that perform uh like that are",
        "start": 1773.96,
        "duration": 4.24
    },
    {
        "text": "majority groups and for which the model",
        "start": 1776.559,
        "duration": 5.0
    },
    {
        "text": "performs really really well right uh and",
        "start": 1778.2,
        "duration": 5.28
    },
    {
        "text": "we take this agnostic approach that we",
        "start": 1781.559,
        "duration": 4.24
    },
    {
        "text": "do not know which groups have the most",
        "start": 1783.48,
        "duration": 4.72
    },
    {
        "text": "serious features compared to the other",
        "start": 1785.799,
        "duration": 4.081
    },
    {
        "text": "approaches that people have proposed",
        "start": 1788.2,
        "duration": 4.68
    },
    {
        "text": "where they strictly assume that you know",
        "start": 1789.88,
        "duration": 4.48
    },
    {
        "text": "the worst performing group on the",
        "start": 1792.88,
        "duration": 3.56
    },
    {
        "text": "training data has to contain the serious",
        "start": 1794.36,
        "duration": 4.96
    },
    {
        "text": "features",
        "start": 1796.44,
        "duration": 2.88
    },
    {
        "text": "okay so before I proceed further there",
        "start": 1800.08,
        "duration": 5.199
    },
    {
        "text": "any",
        "start": 1803.0,
        "duration": 2.279
    },
    {
        "text": "questions Yeah",
        "start": 1805.919,
        "duration": 5.681
    },
    {
        "text": "question oh okay in your two examples",
        "start": 1807.919,
        "duration": 9.081
    },
    {
        "text": "one you had uh no notion of the um it",
        "start": 1811.6,
        "duration": 8.799
    },
    {
        "text": "was totally out of distribution um like",
        "start": 1817.0,
        "duration": 4.919
    },
    {
        "text": "it was a different camera type Al",
        "start": 1820.399,
        "duration": 3.361
    },
    {
        "text": "together not inter train set in your",
        "start": 1821.919,
        "duration": 3.721
    },
    {
        "text": "second example it was just the",
        "start": 1823.76,
        "duration": 3.639
    },
    {
        "text": "proportion proportion was different but",
        "start": 1825.64,
        "duration": 3.44
    },
    {
        "text": "I'm curious in your method are you",
        "start": 1827.399,
        "duration": 5.041
    },
    {
        "text": "assuming that you have access to the",
        "start": 1829.08,
        "duration": 7.8
    },
    {
        "text": "group label uh at test time can you can",
        "start": 1832.44,
        "duration": 6.359
    },
    {
        "text": "you make decisions based on like the",
        "start": 1836.88,
        "duration": 3.6
    },
    {
        "text": "group that of the person that you're",
        "start": 1838.799,
        "duration": 4.76
    },
    {
        "text": "trying to make predictions for yeah so I",
        "start": 1840.48,
        "duration": 8.079
    },
    {
        "text": "think like you know uh so the so like",
        "start": 1843.559,
        "duration": 7.561
    },
    {
        "text": "the like the results that you will see",
        "start": 1848.559,
        "duration": 4.401
    },
    {
        "text": "so they deal with more of the second",
        "start": 1851.12,
        "duration": 3.919
    },
    {
        "text": "type which is the subpopulation ship",
        "start": 1852.96,
        "duration": 3.76
    },
    {
        "text": "that all the groups are there but their",
        "start": 1855.039,
        "duration": 4.36
    },
    {
        "text": "proportion change right so the first",
        "start": 1856.72,
        "duration": 4.4
    },
    {
        "text": "type of example that I gave the new type",
        "start": 1859.399,
        "duration": 4.0
    },
    {
        "text": "of camera that's like the more extreme",
        "start": 1861.12,
        "duration": 5.0
    },
    {
        "text": "type in that case like you know our",
        "start": 1863.399,
        "duration": 4.481
    },
    {
        "text": "approach could still work but like you",
        "start": 1866.12,
        "duration": 4.08
    },
    {
        "text": "know it's it doesn't work as well",
        "start": 1867.88,
        "duration": 5.159
    },
    {
        "text": "because you know we do not assume that",
        "start": 1870.2,
        "duration": 6.24
    },
    {
        "text": "we have any knowledge of the uh uh of",
        "start": 1873.039,
        "duration": 5.401
    },
    {
        "text": "the of the test group",
        "start": 1876.44,
        "duration": 3.959
    },
    {
        "text": "memberships I guess so then the F",
        "start": 1878.44,
        "duration": 4.16
    },
    {
        "text": "question is um why do you have to have a",
        "start": 1880.399,
        "duration": 5.041
    },
    {
        "text": "single model that is applied to all",
        "start": 1882.6,
        "duration": 4.6
    },
    {
        "text": "instances equally could you train",
        "start": 1885.44,
        "duration": 3.76
    },
    {
        "text": "separate models for each",
        "start": 1887.2,
        "duration": 6.68
    },
    {
        "text": "group separate models for each groups",
        "start": 1889.2,
        "duration": 6.599
    },
    {
        "text": "like the performance on a group you",
        "start": 1893.88,
        "duration": 3.799
    },
    {
        "text": "could pick the model that would be the",
        "start": 1895.799,
        "duration": 3.401
    },
    {
        "text": "most performant for",
        "start": 1897.679,
        "duration": 4.041
    },
    {
        "text": "it I",
        "start": 1899.2,
        "duration": 4.8
    },
    {
        "text": "see so then how would you combine those",
        "start": 1901.72,
        "duration": 4.559
    },
    {
        "text": "models well you're you're given an",
        "start": 1904.0,
        "duration": 4.6
    },
    {
        "text": "instance to score and you pick you know",
        "start": 1906.279,
        "duration": 3.64
    },
    {
        "text": "what group they are so you pick the",
        "start": 1908.6,
        "duration": 3.48
    },
    {
        "text": "model and you score them I don't know",
        "start": 1909.919,
        "duration": 3.36
    },
    {
        "text": "what you mean by",
        "start": 1912.08,
        "duration": 4.079
    },
    {
        "text": "combined okay so you were saying I",
        "start": 1913.279,
        "duration": 4.731
    },
    {
        "text": "see",
        "start": 1916.159,
        "duration": 5.261
    },
    {
        "text": "[Music]",
        "start": 1918.01,
        "duration": 3.41
    },
    {
        "text": "uh yeah I think like okay so such a I",
        "start": 1923.08,
        "duration": 7.319
    },
    {
        "text": "think like it's definitely uh like a",
        "start": 1927.84,
        "duration": 5.319
    },
    {
        "text": "reasonable Baseline to try you know that",
        "start": 1930.399,
        "duration": 4.64
    },
    {
        "text": "that you could learn a separate model",
        "start": 1933.159,
        "duration": 5.041
    },
    {
        "text": "for each group um but I think the",
        "start": 1935.039,
        "duration": 5.24
    },
    {
        "text": "problem with that is you know like in",
        "start": 1938.2,
        "duration": 4.68
    },
    {
        "text": "this case if we have we typically have",
        "start": 1940.279,
        "duration": 5.961
    },
    {
        "text": "500 groups so if especially if you're",
        "start": 1942.88,
        "duration": 6.24
    },
    {
        "text": "training a bird style model to learn and",
        "start": 1946.24,
        "duration": 4.399
    },
    {
        "text": "you learn a separate model for each",
        "start": 1949.12,
        "duration": 4.2
    },
    {
        "text": "group so now you're now you have like a",
        "start": 1950.639,
        "duration": 5.561
    },
    {
        "text": "data uh positive problem you know like",
        "start": 1953.32,
        "duration": 4.839
    },
    {
        "text": "you only have thousand examples to fit a",
        "start": 1956.2,
        "duration": 5.439
    },
    {
        "text": "model right sure uh so you have to be",
        "start": 1958.159,
        "duration": 5.561
    },
    {
        "text": "really careful about how you regularize",
        "start": 1961.639,
        "duration": 4.841
    },
    {
        "text": "the model to ensure that all those 500",
        "start": 1963.72,
        "duration": 4.679
    },
    {
        "text": "models that you train on each of the",
        "start": 1966.48,
        "duration": 4.319
    },
    {
        "text": "groups that they perform uh that they",
        "start": 1968.399,
        "duration": 5.24
    },
    {
        "text": "that they generalize well so now you",
        "start": 1970.799,
        "duration": 5.72
    },
    {
        "text": "like might have circumvented some of the",
        "start": 1973.639,
        "duration": 5.04
    },
    {
        "text": "uh like the distributional shift problem",
        "start": 1976.519,
        "duration": 4.801
    },
    {
        "text": "but there is a problem on how to uh fit",
        "start": 1978.679,
        "duration": 6.561
    },
    {
        "text": "a such a rich model on data which is one",
        "start": 1981.32,
        "duration": 8.0
    },
    {
        "text": "1 divided 500 the size of the of the",
        "start": 1985.24,
        "duration": 7.64
    },
    {
        "text": "actual data okay thank you make sense",
        "start": 1989.32,
        "duration": 6.319
    },
    {
        "text": "yeah yes so I think we are like still",
        "start": 1992.88,
        "duration": 3.919
    },
    {
        "text": "possible",
        "start": 1995.639,
        "duration": 5.841
    },
    {
        "text": "to General model all the available data",
        "start": 1996.799,
        "duration": 7.321
    },
    {
        "text": "and then for each subgroup you five tune",
        "start": 2001.48,
        "duration": 6.199
    },
    {
        "text": "the general model based on a small",
        "start": 2004.12,
        "duration": 7.08
    },
    {
        "text": "said and in that case you know you are",
        "start": 2007.679,
        "duration": 7.88
    },
    {
        "text": "still using kind of using all the data",
        "start": 2011.2,
        "duration": 5.56
    },
    {
        "text": "that small",
        "start": 2015.559,
        "duration": 4.041
    },
    {
        "text": "subset so how would you do that like how",
        "start": 2016.76,
        "duration": 6.12
    },
    {
        "text": "would you so I mean I know uh these days",
        "start": 2019.6,
        "duration": 4.799
    },
    {
        "text": "with large language models you know we",
        "start": 2022.88,
        "duration": 4.519
    },
    {
        "text": "use the word fine tune a lot but uh in",
        "start": 2024.399,
        "duration": 6.0
    },
    {
        "text": "this case like think about 500 groups so",
        "start": 2027.399,
        "duration": 5.441
    },
    {
        "text": "this is not an llm domain that we're",
        "start": 2030.399,
        "duration": 3.88
    },
    {
        "text": "dealing with so we don't have trillions",
        "start": 2032.84,
        "duration": 5.52
    },
    {
        "text": "of examples so we have about 500,000",
        "start": 2034.279,
        "duration": 6.081
    },
    {
        "text": "examples let's say in the training data",
        "start": 2038.36,
        "duration": 5.039
    },
    {
        "text": "and like there are say 10,000 groups so",
        "start": 2040.36,
        "duration": 4.919
    },
    {
        "text": "each group is a user like as I will show",
        "start": 2043.399,
        "duration": 4.081
    },
    {
        "text": "in that example so like people write",
        "start": 2045.279,
        "duration": 4.32
    },
    {
        "text": "reviews on Amazon right like you know",
        "start": 2047.48,
        "duration": 5.119
    },
    {
        "text": "you buy different products uh and all my",
        "start": 2049.599,
        "duration": 6.161
    },
    {
        "text": "reviews would be like I would be a group",
        "start": 2052.599,
        "duration": 6.08
    },
    {
        "text": "right and then in the test data like uh",
        "start": 2055.76,
        "duration": 4.44
    },
    {
        "text": "people are only present either on",
        "start": 2058.679,
        "duration": 4.48
    },
    {
        "text": "training or test so uh my data would",
        "start": 2060.2,
        "duration": 5.0
    },
    {
        "text": "only present in the training data but",
        "start": 2063.159,
        "duration": 4.48
    },
    {
        "text": "there could be a new person in the test",
        "start": 2065.2,
        "duration": 4.36
    },
    {
        "text": "data whom we we would have to perform",
        "start": 2067.639,
        "duration": 6.28
    },
    {
        "text": "well on right so so so this idea about",
        "start": 2069.56,
        "duration": 7.039
    },
    {
        "text": "fine tuning like if you could maybe shed",
        "start": 2073.919,
        "duration": 5.041
    },
    {
        "text": "some more light like how what exactly do",
        "start": 2076.599,
        "duration": 4.401
    },
    {
        "text": "you have in mind like how would you fine",
        "start": 2078.96,
        "duration": 3.119
    },
    {
        "text": "tune",
        "start": 2081.0,
        "duration": 3.2
    },
    {
        "text": "because at least the way I understand",
        "start": 2082.079,
        "duration": 4.441
    },
    {
        "text": "about fine tuning and like training a",
        "start": 2084.2,
        "duration": 4.28
    },
    {
        "text": "general model and then fine tuning on",
        "start": 2086.52,
        "duration": 3.159
    },
    {
        "text": "some small",
        "start": 2088.48,
        "duration": 3.359
    },
    {
        "text": "data it doesn't seem like we would have",
        "start": 2089.679,
        "duration": 4.881
    },
    {
        "text": "enough data to do",
        "start": 2091.839,
        "duration": 7.04
    },
    {
        "text": "that so for example",
        "start": 2094.56,
        "duration": 4.319
    },
    {
        "text": "100,000",
        "start": 2099.28,
        "duration": 3.0
    },
    {
        "text": "data General 500 TR model on the",
        "start": 2103.48,
        "duration": 11.4
    },
    {
        "text": "500,000 uh data inst and then uh for",
        "start": 2109.119,
        "duration": 10.361
    },
    {
        "text": "each subgroup you TR and you start with",
        "start": 2114.88,
        "duration": 8.6
    },
    {
        "text": "a general model you still still train it",
        "start": 2119.48,
        "duration": 8.119
    },
    {
        "text": "further but using a much smaller uh",
        "start": 2123.48,
        "duration": 6.44
    },
    {
        "text": "step",
        "start": 2127.599,
        "duration": 8.041
    },
    {
        "text": "size and then you train this to a VI",
        "start": 2129.92,
        "duration": 5.72
    },
    {
        "text": "then okay so you were saying that train",
        "start": 2136.04,
        "duration": 6.4
    },
    {
        "text": "one General model just as the Baseline",
        "start": 2139.52,
        "duration": 5.4
    },
    {
        "text": "that we are using here do and",
        "start": 2142.44,
        "duration": 7.0
    },
    {
        "text": "then you take a given subr and you make",
        "start": 2144.92,
        "duration": 7.199
    },
    {
        "text": "some gradient gradient",
        "start": 2149.44,
        "duration": 6.2
    },
    {
        "text": "steps uh on",
        "start": 2152.119,
        "duration": 3.521
    },
    {
        "text": "that",
        "start": 2155.8,
        "duration": 3.0
    },
    {
        "text": "yeah just make we smaller",
        "start": 2158.92,
        "duration": 5.159
    },
    {
        "text": "and but but still it but how will it",
        "start": 2165.119,
        "duration": 7.161
    },
    {
        "text": "address the um like the speedio feature",
        "start": 2168.2,
        "duration": 6.96
    },
    {
        "text": "problem right so what if I mean even if",
        "start": 2172.28,
        "duration": 5.28
    },
    {
        "text": "all the groups had equal predictive",
        "start": 2175.16,
        "duration": 4.64
    },
    {
        "text": "power and had similar distribution of",
        "start": 2177.56,
        "duration": 4.88
    },
    {
        "text": "superious features uh sure this such",
        "start": 2179.8,
        "duration": 4.44
    },
    {
        "text": "kind of an approach could work but I",
        "start": 2182.44,
        "duration": 4.44
    },
    {
        "text": "don't think it takes into account that",
        "start": 2184.24,
        "duration": 5.56
    },
    {
        "text": "some of those groups could have",
        "start": 2186.88,
        "duration": 5.92
    },
    {
        "text": "higher like you know prevalence of spous",
        "start": 2189.8,
        "duration": 6.319
    },
    {
        "text": "features than others so I'm happy uh in",
        "start": 2192.8,
        "duration": 4.64
    },
    {
        "text": "a TR of time I'm happy to talk",
        "start": 2196.119,
        "duration": 4.561
    },
    {
        "text": "afterwards you know but I think uh let's",
        "start": 2197.44,
        "duration": 4.8
    },
    {
        "text": "let's move ahead so I think there was",
        "start": 2200.68,
        "duration": 3.84
    },
    {
        "text": "one more question yeah I I think just",
        "start": 2202.24,
        "duration": 3.52
    },
    {
        "text": "seeing some",
        "start": 2204.52,
        "duration": 3.599
    },
    {
        "text": "examples would be great and then you",
        "start": 2205.76,
        "duration": 4.44
    },
    {
        "text": "know because it's you know it's a little",
        "start": 2208.119,
        "duration": 4.601
    },
    {
        "text": "high level and abct perfect perfect yeah",
        "start": 2210.2,
        "duration": 5.48
    },
    {
        "text": "I think that that sounds good",
        "start": 2212.72,
        "duration": 4.48
    },
    {
        "text": "thanks",
        "start": 2215.68,
        "duration": 4.8
    },
    {
        "text": "okay so um yeah so like speed features",
        "start": 2217.2,
        "duration": 6.24
    },
    {
        "text": "is one one one story like why this why",
        "start": 2220.48,
        "duration": 5.599
    },
    {
        "text": "this approach works and you know this",
        "start": 2223.44,
        "duration": 4.76
    },
    {
        "text": "also has connections to causal interest",
        "start": 2226.079,
        "duration": 5.0
    },
    {
        "text": "okay and that's uh like assume that you",
        "start": 2228.2,
        "duration": 5.52
    },
    {
        "text": "have some data which coming from uh some",
        "start": 2231.079,
        "duration": 5.52
    },
    {
        "text": "unknown distribution and each group uh",
        "start": 2233.72,
        "duration": 5.96
    },
    {
        "text": "data point belongs to uh some group okay",
        "start": 2236.599,
        "duration": 4.681
    },
    {
        "text": "and the training and testing data are",
        "start": 2239.68,
        "duration": 5.36
    },
    {
        "text": "sample from this unknown distribution um",
        "start": 2241.28,
        "duration": 5.559
    },
    {
        "text": "uh and we assume that there is very",
        "start": 2245.04,
        "duration": 3.96
    },
    {
        "text": "little overlap between the dra Trin and",
        "start": 2246.839,
        "duration": 4.921
    },
    {
        "text": "D test",
        "start": 2249.0,
        "duration": 6.4
    },
    {
        "text": "okay right so if you if you assume that",
        "start": 2251.76,
        "duration": 5.319
    },
    {
        "text": "you know then out of distribution",
        "start": 2255.4,
        "duration": 3.959
    },
    {
        "text": "generalization can be seen as a sample",
        "start": 2257.079,
        "duration": 6.24
    },
    {
        "text": "selection problem right so it's like a",
        "start": 2259.359,
        "duration": 8.641
    },
    {
        "text": "like certain examples are more likely uh",
        "start": 2263.319,
        "duration": 6.641
    },
    {
        "text": "to be included into training data versus",
        "start": 2268.0,
        "duration": 3.72
    },
    {
        "text": "testing data so it's like a selection",
        "start": 2269.96,
        "duration": 6.159
    },
    {
        "text": "bias issue okay um and you know because",
        "start": 2271.72,
        "duration": 7.52
    },
    {
        "text": "what you would have wanted to do was um",
        "start": 2276.119,
        "duration": 5.601
    },
    {
        "text": "uh like the X train and white uh X train",
        "start": 2279.24,
        "duration": 4.56
    },
    {
        "text": "and X test were sampled uniformly at",
        "start": 2281.72,
        "duration": 4.32
    },
    {
        "text": "random from this underlying distribution",
        "start": 2283.8,
        "duration": 5.64
    },
    {
        "text": "but uh assume they are not right that",
        "start": 2286.04,
        "duration": 6.16
    },
    {
        "text": "that there is some uh like uh feature",
        "start": 2289.44,
        "duration": 5.12
    },
    {
        "text": "maybe some demographic or writing style",
        "start": 2292.2,
        "duration": 5.08
    },
    {
        "text": "based on which uh a data point is more",
        "start": 2294.56,
        "duration": 4.279
    },
    {
        "text": "likely to be in the training data than",
        "start": 2297.28,
        "duration": 4.36
    },
    {
        "text": "in the testing data",
        "start": 2298.839,
        "duration": 7.121
    },
    {
        "text": "okay and uh so if you uh like and and so",
        "start": 2301.64,
        "duration": 5.84
    },
    {
        "text": "what are some of the common approaches",
        "start": 2305.96,
        "duration": 3.08
    },
    {
        "text": "to deal with such kind of a selection",
        "start": 2307.48,
        "duration": 4.4
    },
    {
        "text": "bias issue uh so as we know like for",
        "start": 2309.04,
        "duration": 5.319
    },
    {
        "text": "observational uh data you know there are",
        "start": 2311.88,
        "duration": 4.52
    },
    {
        "text": "approaches such as propensity score",
        "start": 2314.359,
        "duration": 7.121
    },
    {
        "text": "matching uh or um um like ipw or like",
        "start": 2316.4,
        "duration": 7.52
    },
    {
        "text": "you know its uh cousins you know that",
        "start": 2321.48,
        "duration": 4.44
    },
    {
        "text": "maybe you could have W robust version of",
        "start": 2323.92,
        "duration": 4.24
    },
    {
        "text": "ipw uh you could use such kind of",
        "start": 2325.92,
        "duration": 4.919
    },
    {
        "text": "approaches uh to address these",
        "start": 2328.16,
        "duration": 5.439
    },
    {
        "text": "issues so like turns out with some",
        "start": 2330.839,
        "duration": 5.721
    },
    {
        "text": "algebra you could see our approach is",
        "start": 2333.599,
        "duration": 5.76
    },
    {
        "text": "just inverse propensity weighting but",
        "start": 2336.56,
        "duration": 4.559
    },
    {
        "text": "where the propensity weights are the",
        "start": 2339.359,
        "duration": 2.76
    },
    {
        "text": "group",
        "start": 2341.119,
        "duration": 3.121
    },
    {
        "text": "errors right so the groups that have",
        "start": 2342.119,
        "duration": 4.281
    },
    {
        "text": "higher errors we are waiting them higher",
        "start": 2344.24,
        "duration": 3.599
    },
    {
        "text": "we are giving them higher propensity",
        "start": 2346.4,
        "duration": 3.28
    },
    {
        "text": "weights compared to the groups that have",
        "start": 2347.839,
        "duration": 4.28
    },
    {
        "text": "low errors",
        "start": 2349.68,
        "duration": 6.6
    },
    {
        "text": "okay and this ipw connection also shows",
        "start": 2352.119,
        "duration": 7.081
    },
    {
        "text": "that we don't have to uh like constrain",
        "start": 2356.28,
        "duration": 5.28
    },
    {
        "text": "ourselves to just the group errors that",
        "start": 2359.2,
        "duration": 4.28
    },
    {
        "text": "we could move to other properties like",
        "start": 2361.56,
        "duration": 5.519
    },
    {
        "text": "we could have maybe have uh like like a",
        "start": 2363.48,
        "duration": 5.72
    },
    {
        "text": "broader array of features on which we",
        "start": 2367.079,
        "duration": 4.601
    },
    {
        "text": "could rank ropes so for example we could",
        "start": 2369.2,
        "duration": 4.44
    },
    {
        "text": "rank based on group size maybe the",
        "start": 2371.68,
        "duration": 3.88
    },
    {
        "text": "groups that are really really big are",
        "start": 2373.64,
        "duration": 4.36
    },
    {
        "text": "somehow uh contain lots of serious",
        "start": 2375.56,
        "duration": 4.84
    },
    {
        "text": "features uh and you know need to be",
        "start": 2378.0,
        "duration": 4.52
    },
    {
        "text": "dealt with separately or how similar are",
        "start": 2380.4,
        "duration": 3.8
    },
    {
        "text": "the groups to other features or the",
        "start": 2382.52,
        "duration": 5.04
    },
    {
        "text": "entropy of the labels and so on",
        "start": 2384.2,
        "duration": 7.2
    },
    {
        "text": "right and um uh so now let me show you",
        "start": 2387.56,
        "duration": 5.72
    },
    {
        "text": "some of the some of the results and then",
        "start": 2391.4,
        "duration": 3.88
    },
    {
        "text": "then I'll so this is like part of some",
        "start": 2393.28,
        "duration": 3.92
    },
    {
        "text": "of the on ongoing work work where where",
        "start": 2395.28,
        "duration": 4.4
    },
    {
        "text": "we are using multiple features uh as",
        "start": 2397.2,
        "duration": 5.08
    },
    {
        "text": "opposed to just a group error uh to rank",
        "start": 2399.68,
        "duration": 4.8
    },
    {
        "text": "the groups and like you know uh uh like",
        "start": 2402.28,
        "duration": 4.52
    },
    {
        "text": "do it in our like discounted rank",
        "start": 2404.48,
        "duration": 7.56
    },
    {
        "text": "upating uh setup okay so um so like the",
        "start": 2406.8,
        "duration": 8.2
    },
    {
        "text": "data that we have uh like there are",
        "start": 2412.04,
        "duration": 4.76
    },
    {
        "text": "three common data sets that people use",
        "start": 2415.0,
        "duration": 3.48
    },
    {
        "text": "so one is the Amazon data set you know",
        "start": 2416.8,
        "duration": 3.72
    },
    {
        "text": "where there Amazon reviews and you want",
        "start": 2418.48,
        "duration": 4.359
    },
    {
        "text": "to rate the reviews on a scale of you",
        "start": 2420.52,
        "duration": 5.4
    },
    {
        "text": "know one to five uh IMDb you know people",
        "start": 2422.839,
        "duration": 6.041
    },
    {
        "text": "rate movies uh and there is y right",
        "start": 2425.92,
        "duration": 5.679
    },
    {
        "text": "again people rate restaurants there and",
        "start": 2428.88,
        "duration": 4.28
    },
    {
        "text": "uh there are number of groups in the",
        "start": 2431.599,
        "duration": 3.641
    },
    {
        "text": "training data and the testing data",
        "start": 2433.16,
        "duration": 5.159
    },
    {
        "text": "what's the average group",
        "start": 2435.24,
        "duration": 6.8
    },
    {
        "text": "size right so they're about uh in in in",
        "start": 2438.319,
        "duration": 6.081
    },
    {
        "text": "Amazon a given person has about 75",
        "start": 2442.04,
        "duration": 6.36
    },
    {
        "text": "reviews right and uh in in a group for",
        "start": 2444.4,
        "duration": 6.64
    },
    {
        "text": "IMDb like an average person had 25",
        "start": 2448.4,
        "duration": 6.32
    },
    {
        "text": "reviews okay uh for y it had about 100",
        "start": 2451.04,
        "duration": 5.559
    },
    {
        "text": "so as I said like a group here is a a",
        "start": 2454.72,
        "duration": 4.72
    },
    {
        "text": "person but it doesn't have to be like",
        "start": 2456.599,
        "duration": 4.72
    },
    {
        "text": "you know it could be group could be like",
        "start": 2459.44,
        "duration": 3.8
    },
    {
        "text": "a demographic feature like you know you",
        "start": 2461.319,
        "duration": 4.04
    },
    {
        "text": "could construct a group based on some",
        "start": 2463.24,
        "duration": 3.92
    },
    {
        "text": "demographic attributes why we",
        "start": 2465.359,
        "duration": 3.76
    },
    {
        "text": "constructed a group based on a person",
        "start": 2467.16,
        "duration": 4.159
    },
    {
        "text": "because these are some of the data sets",
        "start": 2469.119,
        "duration": 4.24
    },
    {
        "text": "that people use in this literature so we",
        "start": 2471.319,
        "duration": 4.641
    },
    {
        "text": "wanted to stick to that and not uh you",
        "start": 2473.359,
        "duration": 5.561
    },
    {
        "text": "know change the goal posts uh uh to show",
        "start": 2475.96,
        "duration": 5.2
    },
    {
        "text": "the efficacy of our approach okay what",
        "start": 2478.92,
        "duration": 5.6
    },
    {
        "text": "is out of distribution here mean so the",
        "start": 2481.16,
        "duration": 4.959
    },
    {
        "text": "out of distribution here is on the on",
        "start": 2484.52,
        "duration": 4.839
    },
    {
        "text": "the test data uh like the reviews are",
        "start": 2486.119,
        "duration": 4.72
    },
    {
        "text": "from a different",
        "start": 2489.359,
        "duration": 3.641
    },
    {
        "text": "person potentially a different movie",
        "start": 2490.839,
        "duration": 3.681
    },
    {
        "text": "that they have rated that they haven't",
        "start": 2493.0,
        "duration": 2.88
    },
    {
        "text": "then and that person wasn't in the",
        "start": 2494.52,
        "duration": 3.4
    },
    {
        "text": "training no it was not yeah so let's say",
        "start": 2495.88,
        "duration": 3.68
    },
    {
        "text": "I was in the training data and you know",
        "start": 2497.92,
        "duration": 4.679
    },
    {
        "text": "you were in the test data and so the",
        "start": 2499.56,
        "duration": 4.6
    },
    {
        "text": "idea is that there will be some serious",
        "start": 2502.599,
        "duration": 3.121
    },
    {
        "text": "features you know maybe my writing style",
        "start": 2504.16,
        "duration": 3.4
    },
    {
        "text": "is significantly different from other",
        "start": 2505.72,
        "duration": 4.56
    },
    {
        "text": "people and that will not generalize well",
        "start": 2507.56,
        "duration": 6.0
    },
    {
        "text": "yeah so uh here are some like so if you",
        "start": 2510.28,
        "duration": 4.88
    },
    {
        "text": "were to run a baseline model which is",
        "start": 2513.56,
        "duration": 4.16
    },
    {
        "text": "simple empirical RIS minimization you",
        "start": 2515.16,
        "duration": 4.6
    },
    {
        "text": "know take any state of the art model how",
        "start": 2517.72,
        "duration": 5.16
    },
    {
        "text": "would it do on these data sets right so",
        "start": 2519.76,
        "duration": 7.04
    },
    {
        "text": "this is the average accuracy okay so uh",
        "start": 2522.88,
        "duration": 5.76
    },
    {
        "text": "so you can see the average accuracy is",
        "start": 2526.8,
        "duration": 3.84
    },
    {
        "text": "like you know in the 60s and 70s it's",
        "start": 2528.64,
        "duration": 5.92
    },
    {
        "text": "does reasonably well this is the uh 10th",
        "start": 2530.64,
        "duration": 6.56
    },
    {
        "text": "percentile group accuracy so basically",
        "start": 2534.56,
        "duration": 4.759
    },
    {
        "text": "if you were to rank groups in terms of",
        "start": 2537.2,
        "duration": 4.96
    },
    {
        "text": "their errors like what's the accuracy of",
        "start": 2539.319,
        "duration": 5.24
    },
    {
        "text": "the 10th the the the group at the 10th",
        "start": 2542.16,
        "duration": 4.88
    },
    {
        "text": "percentile and the red one one is the",
        "start": 2544.559,
        "duration": 4.921
    },
    {
        "text": "accuracy of the worst performing",
        "start": 2547.04,
        "duration": 9.279
    },
    {
        "text": "Dr okay so now you could see um uh that",
        "start": 2549.48,
        "duration": 9.359
    },
    {
        "text": "the the like moving from training to",
        "start": 2556.319,
        "duration": 4.881
    },
    {
        "text": "test this is this is slight drop off on",
        "start": 2558.839,
        "duration": 5.681
    },
    {
        "text": "the average accuracy right but what's",
        "start": 2561.2,
        "duration": 5.52
    },
    {
        "text": "what this average accuracy is masking",
        "start": 2564.52,
        "duration": 4.48
    },
    {
        "text": "inside it is like a big discrepancy in",
        "start": 2566.72,
        "duration": 3.76
    },
    {
        "text": "the worst group",
        "start": 2569.0,
        "duration": 3.72
    },
    {
        "text": "accuracy right so note that the worst",
        "start": 2570.48,
        "duration": 4.48
    },
    {
        "text": "group here it's not the same as the",
        "start": 2572.72,
        "duration": 4.52
    },
    {
        "text": "worst group here because I'm in the",
        "start": 2574.96,
        "duration": 4.08
    },
    {
        "text": "training data but I'm not in the test",
        "start": 2577.24,
        "duration": 3.879
    },
    {
        "text": "data so it's just some other person we",
        "start": 2579.04,
        "duration": 4.4
    },
    {
        "text": "don't know who that is uh but like",
        "start": 2581.119,
        "duration": 5.081
    },
    {
        "text": "whatever that whoever that person is the",
        "start": 2583.44,
        "duration": 4.56
    },
    {
        "text": "accuracy was",
        "start": 2586.2,
        "duration": 4.72
    },
    {
        "text": "12% okay and and and again you could see",
        "start": 2588.0,
        "duration": 7.079
    },
    {
        "text": "a big drop off from 26 to 15 and 41",
        "start": 2590.92,
        "duration": 7.56
    },
    {
        "text": "to8 so the goal of our approach and like",
        "start": 2595.079,
        "duration": 5.561
    },
    {
        "text": "any other approach in this is to improve",
        "start": 2598.48,
        "duration": 2.92
    },
    {
        "text": "these",
        "start": 2600.64,
        "duration": 3.6
    },
    {
        "text": "numbers without hurting the average",
        "start": 2601.4,
        "duration": 6.24
    },
    {
        "text": "accuracy much yes oh yeah I got a",
        "start": 2604.24,
        "duration": 6.72
    },
    {
        "text": "question so how we get this aage gr",
        "start": 2607.64,
        "duration": 6.28
    },
    {
        "text": "accuracy so is it weighted based on the",
        "start": 2610.96,
        "duration": 6.48
    },
    {
        "text": "gr uh grp size or no so this is no there",
        "start": 2613.92,
        "duration": 6.32
    },
    {
        "text": "is no waiting this is like simple uh",
        "start": 2617.44,
        "duration": 4.84
    },
    {
        "text": "like you train any model that is",
        "start": 2620.24,
        "duration": 5.44
    },
    {
        "text": "agnostic to group structure okay and",
        "start": 2622.28,
        "duration": 5.48
    },
    {
        "text": "then you compute the accuracy and this",
        "start": 2625.68,
        "duration": 4.52
    },
    {
        "text": "is just the average for each group yeah",
        "start": 2627.76,
        "duration": 4.04
    },
    {
        "text": "if that was your question oh yeah just",
        "start": 2630.2,
        "duration": 4.76
    },
    {
        "text": "so each group has a we one Bic right so",
        "start": 2631.8,
        "duration": 4.759
    },
    {
        "text": "that again each yes each group has a",
        "start": 2634.96,
        "duration": 3.24
    },
    {
        "text": "weight of one so it's like what's the",
        "start": 2636.559,
        "duration": 4.56
    },
    {
        "text": "average of each group you know so so",
        "start": 2638.2,
        "duration": 4.52
    },
    {
        "text": "that's why so so the reason for that is",
        "start": 2641.119,
        "duration": 3.521
    },
    {
        "text": "the bigger groups should not have yeah",
        "start": 2642.72,
        "duration": 4.639
    },
    {
        "text": "they should not drive this right yeah",
        "start": 2644.64,
        "duration": 5.56
    },
    {
        "text": "but this is like any offthe shelf method",
        "start": 2647.359,
        "duration": 5.0
    },
    {
        "text": "that you that you run like how would it",
        "start": 2650.2,
        "duration": 4.119
    },
    {
        "text": "perform right it's totally agnostic to",
        "start": 2652.359,
        "duration": 3.401
    },
    {
        "text": "group structure it doesn't do anything",
        "start": 2654.319,
        "duration": 4.561
    },
    {
        "text": "with it okay sorry one more question",
        "start": 2655.76,
        "duration": 5.0
    },
    {
        "text": "yeah how skewed are the groups do you",
        "start": 2658.88,
        "duration": 4.88
    },
    {
        "text": "have power users and some longtail very",
        "start": 2660.76,
        "duration": 5.44
    },
    {
        "text": "few users so in this particular data set",
        "start": 2663.76,
        "duration": 4.76
    },
    {
        "text": "like you know they in uh like the data",
        "start": 2666.2,
        "duration": 3.919
    },
    {
        "text": "set is created in such a way that all",
        "start": 2668.52,
        "duration": 4.44
    },
    {
        "text": "the users have 75 groups sorry all the",
        "start": 2670.119,
        "duration": 5.361
    },
    {
        "text": "users have at least 75 reviews at least",
        "start": 2672.96,
        "duration": 5.599
    },
    {
        "text": "at least uh some people have more like",
        "start": 2675.48,
        "duration": 5.52
    },
    {
        "text": "you know some people have two 300 but",
        "start": 2678.559,
        "duration": 5.161
    },
    {
        "text": "like there is not a strong uh like power",
        "start": 2681.0,
        "duration": 5.52
    },
    {
        "text": "law Behavior here right but yeah there",
        "start": 2683.72,
        "duration": 4.839
    },
    {
        "text": "are also not people with two reviews so",
        "start": 2686.52,
        "duration": 3.68
    },
    {
        "text": "that's again that's how the data set was",
        "start": 2688.559,
        "duration": 4.0
    },
    {
        "text": "created there are again like as part of",
        "start": 2690.2,
        "duration": 3.84
    },
    {
        "text": "this ongoing research we're trying to",
        "start": 2692.559,
        "duration": 3.081
    },
    {
        "text": "come up with new data sets ourselves",
        "start": 2694.04,
        "duration": 3.44
    },
    {
        "text": "because we see that there are some",
        "start": 2695.64,
        "duration": 4.28
    },
    {
        "text": "limitations in the setup uh that is",
        "start": 2697.48,
        "duration": 4.2
    },
    {
        "text": "there like it might not be fully",
        "start": 2699.92,
        "duration": 3.28
    },
    {
        "text": "represented",
        "start": 2701.68,
        "duration": 4.08
    },
    {
        "text": "yes might be a stupid question but you",
        "start": 2703.2,
        "duration": 4.28
    },
    {
        "text": "in the number of groups you have two",
        "start": 2705.76,
        "duration": 3.599
    },
    {
        "text": "entries what are the difference so it's",
        "start": 2707.48,
        "duration": 3.56
    },
    {
        "text": "training and testing training and",
        "start": 2709.359,
        "duration": 4.521
    },
    {
        "text": "testing yes so there are 1252 people in",
        "start": 2711.04,
        "duration": 6.079
    },
    {
        "text": "training 1334 in testing and so on",
        "start": 2713.88,
        "duration": 5.199
    },
    {
        "text": "yeah thank",
        "start": 2717.119,
        "duration": 6.081
    },
    {
        "text": "you okay so now uh like let's see like",
        "start": 2719.079,
        "duration": 5.641
    },
    {
        "text": "now we've seen the Baseline you know",
        "start": 2723.2,
        "duration": 3.2
    },
    {
        "text": "these were the like the like the",
        "start": 2724.72,
        "duration": 5.119
    },
    {
        "text": "baselines right so now let's see uh how",
        "start": 2726.4,
        "duration": 4.959
    },
    {
        "text": "some of these other approaches performed",
        "start": 2729.839,
        "duration": 3.641
    },
    {
        "text": "so this was the approach that I talked",
        "start": 2731.359,
        "duration": 4.561
    },
    {
        "text": "about like the Minimax approach right",
        "start": 2733.48,
        "duration": 6.24
    },
    {
        "text": "that that just does a convex uh uh like",
        "start": 2735.92,
        "duration": 6.0
    },
    {
        "text": "surrogate of the Minimax objective and",
        "start": 2739.72,
        "duration": 4.879
    },
    {
        "text": "tries to minimize that right so it turns",
        "start": 2741.92,
        "duration": 5.399
    },
    {
        "text": "out that you know that on some data sets",
        "start": 2744.599,
        "duration": 4.841
    },
    {
        "text": "it performs really badly but but in some",
        "start": 2747.319,
        "duration": 3.721
    },
    {
        "text": "of them it does reasonably well like you",
        "start": 2749.44,
        "duration": 3.56
    },
    {
        "text": "know where the worst group in training",
        "start": 2751.04,
        "duration": 3.68
    },
    {
        "text": "might be similar to the worst group in",
        "start": 2753.0,
        "duration": 4.119
    },
    {
        "text": "testing okay and this was another",
        "start": 2754.72,
        "duration": 5.96
    },
    {
        "text": "approach just trained twice uh like",
        "start": 2757.119,
        "duration": 5.681
    },
    {
        "text": "again you know which uh like this is",
        "start": 2760.68,
        "duration": 4.399
    },
    {
        "text": "also reting based approach but like they",
        "start": 2762.8,
        "duration": 3.88
    },
    {
        "text": "just do very similar to what boosting",
        "start": 2765.079,
        "duration": 3.801
    },
    {
        "text": "does you know so that's why I made the",
        "start": 2766.68,
        "duration": 4.6
    },
    {
        "text": "connection to boosting and then there",
        "start": 2768.88,
        "duration": 5.4
    },
    {
        "text": "could be uh other approach that we could",
        "start": 2771.28,
        "duration": 5.24
    },
    {
        "text": "maybe just do this boosting style idea",
        "start": 2774.28,
        "duration": 4.48
    },
    {
        "text": "that I said like as we are doing Epoch",
        "start": 2776.52,
        "duration": 4.68
    },
    {
        "text": "wise upating but let's just upweight the",
        "start": 2778.76,
        "duration": 5.319
    },
    {
        "text": "worst performing growth okay so this is",
        "start": 2781.2,
        "duration": 5.0
    },
    {
        "text": "different than this because this has",
        "start": 2784.079,
        "duration": 4.081
    },
    {
        "text": "this is a more principal convex learning",
        "start": 2786.2,
        "duration": 3.2
    },
    {
        "text": "objective that they're trying to",
        "start": 2788.16,
        "duration": 3.6
    },
    {
        "text": "optimize whereas this is more Epoch wise",
        "start": 2789.4,
        "duration": 4.959
    },
    {
        "text": "learning and in each Epoch you upweight",
        "start": 2791.76,
        "duration": 4.319
    },
    {
        "text": "the worst performing group we wanted to",
        "start": 2794.359,
        "duration": 5.121
    },
    {
        "text": "see how this would perform and does",
        "start": 2796.079,
        "duration": 5.04
    },
    {
        "text": "reasonably well and as you can see like",
        "start": 2799.48,
        "duration": 3.68
    },
    {
        "text": "this simple approach like you know it's",
        "start": 2801.119,
        "duration": 3.72
    },
    {
        "text": "competitive or like better than some of",
        "start": 2803.16,
        "duration": 3.32
    },
    {
        "text": "the more complex approaches that people",
        "start": 2804.839,
        "duration": 4.561
    },
    {
        "text": "have proposed and uh this is our this is",
        "start": 2806.48,
        "duration": 5.92
    },
    {
        "text": "our approach so as you can see like you",
        "start": 2809.4,
        "duration": 5.56
    },
    {
        "text": "know the worst group accuracies are",
        "start": 2812.4,
        "duration": 5.439
    },
    {
        "text": "significantly significantly improved",
        "start": 2814.96,
        "duration": 7.48
    },
    {
        "text": "than any of the uh uh Baseline methods",
        "start": 2817.839,
        "duration": 6.601
    },
    {
        "text": "the 10th percentile is also slightly",
        "start": 2822.44,
        "duration": 4.0
    },
    {
        "text": "improved but sure it's not a big",
        "start": 2824.44,
        "duration": 3.919
    },
    {
        "text": "difference uh in compared to those",
        "start": 2826.44,
        "duration": 4.879
    },
    {
        "text": "approaches and the average accuracy is",
        "start": 2828.359,
        "duration": 6.321
    },
    {
        "text": "slightly worse than what the what the",
        "start": 2831.319,
        "duration": 5.441
    },
    {
        "text": "simple empirical risk minimization was",
        "start": 2834.68,
        "duration": 4.72
    },
    {
        "text": "doing right so which shows like you know",
        "start": 2836.76,
        "duration": 4.16
    },
    {
        "text": "and people have already observed that",
        "start": 2839.4,
        "duration": 3.439
    },
    {
        "text": "there is this tradeoff like even with",
        "start": 2840.92,
        "duration": 4.08
    },
    {
        "text": "this so much literature on fairness and",
        "start": 2842.839,
        "duration": 3.681
    },
    {
        "text": "you're trying to enforce fairness on",
        "start": 2845.0,
        "duration": 3.599
    },
    {
        "text": "different groups that you hurt the",
        "start": 2846.52,
        "duration": 4.039
    },
    {
        "text": "average person or the average accuracy a",
        "start": 2848.599,
        "duration": 4.441
    },
    {
        "text": "little bit in order uh to ensure",
        "start": 2850.559,
        "duration": 4.161
    },
    {
        "text": "fairness or in other words that there's",
        "start": 2853.04,
        "duration": 4.319
    },
    {
        "text": "a cost like a slight cost of fairness",
        "start": 2854.72,
        "duration": 4.599
    },
    {
        "text": "right but that's what we see here like",
        "start": 2857.359,
        "duration": 4.121
    },
    {
        "text": "you know there's like a slight drop off",
        "start": 2859.319,
        "duration": 4.441
    },
    {
        "text": "in accuracy on in DB it's kind of",
        "start": 2861.48,
        "duration": 4.48
    },
    {
        "text": "similar but again these are like some",
        "start": 2863.76,
        "duration": 5.0
    },
    {
        "text": "idos synes of these data sets also and",
        "start": 2865.96,
        "duration": 4.84
    },
    {
        "text": "we definitely need more data sets and",
        "start": 2868.76,
        "duration": 4.64
    },
    {
        "text": "more evaluations uh like to understand",
        "start": 2870.8,
        "duration": 6.6
    },
    {
        "text": "these things okay again like it's a",
        "start": 2873.4,
        "duration": 5.84
    },
    {
        "text": "Apples to Apples comparison all the",
        "start": 2877.4,
        "duration": 4.24
    },
    {
        "text": "approaches had access to the bird fine",
        "start": 2879.24,
        "duration": 5.04
    },
    {
        "text": "tune for the word because it's the input",
        "start": 2881.64,
        "duration": 5.08
    },
    {
        "text": "text and how do we encode the uh input",
        "start": 2884.28,
        "duration": 4.039
    },
    {
        "text": "text into some representation so",
        "start": 2886.72,
        "duration": 4.24
    },
    {
        "text": "everybody use the word fine tune there a",
        "start": 2888.319,
        "duration": 4.601
    },
    {
        "text": "perfect and all the hyper parameters",
        "start": 2890.96,
        "duration": 4.08
    },
    {
        "text": "were tuned on some held out data there",
        "start": 2892.92,
        "duration": 3.639
    },
    {
        "text": "was like a perfect Apples to Apples",
        "start": 2895.04,
        "duration": 3.88
    },
    {
        "text": "comparison like in every way between",
        "start": 2896.559,
        "duration": 4.8
    },
    {
        "text": "these different",
        "start": 2898.92,
        "duration": 2.439
    },
    {
        "text": "approaches okay so uh so",
        "start": 2902.96,
        "duration": 6.24
    },
    {
        "text": "uh so in conclusion um you know like",
        "start": 2906.16,
        "duration": 5.88
    },
    {
        "text": "robust ml is important for ML safety and",
        "start": 2909.2,
        "duration": 5.2
    },
    {
        "text": "and in Equitable ML and we proposed a",
        "start": 2912.04,
        "duration": 5.76
    },
    {
        "text": "simple approach uh Rank and Reade and it",
        "start": 2914.4,
        "duration": 5.76
    },
    {
        "text": "uses you know distributional uh and it",
        "start": 2917.8,
        "duration": 5.0
    },
    {
        "text": "and it uses discounted rank up waiting",
        "start": 2920.16,
        "duration": 4.36
    },
    {
        "text": "uh for it for like addressing group",
        "start": 2922.8,
        "duration": 5.4
    },
    {
        "text": "distribution ships okay and some of the",
        "start": 2924.52,
        "duration": 5.48
    },
    {
        "text": "key strengths of our approach are like",
        "start": 2928.2,
        "duration": 4.48
    },
    {
        "text": "you know there is uh like it shows",
        "start": 2930.0,
        "duration": 4.4
    },
    {
        "text": "strong empirical performance and a",
        "start": 2932.68,
        "duration": 3.36
    },
    {
        "text": "priori it does not require require a",
        "start": 2934.4,
        "duration": 3.76
    },
    {
        "text": "knowledge of serious features or the",
        "start": 2936.04,
        "duration": 6.16
    },
    {
        "text": "associated dag right so uh now there's a",
        "start": 2938.16,
        "duration": 6.32
    },
    {
        "text": "separate set of approaches not for this",
        "start": 2942.2,
        "duration": 4.28
    },
    {
        "text": "distributional robust problem but in",
        "start": 2944.48,
        "duration": 4.48
    },
    {
        "text": "general in dist uh in like uh robust",
        "start": 2946.48,
        "duration": 4.92
    },
    {
        "text": "machine learning where people use causal",
        "start": 2948.96,
        "duration": 4.76
    },
    {
        "text": "infes techniques but they assume that",
        "start": 2951.4,
        "duration": 3.76
    },
    {
        "text": "they know what the superious features",
        "start": 2953.72,
        "duration": 4.2
    },
    {
        "text": "are they know what the dag is now which",
        "start": 2955.16,
        "duration": 4.56
    },
    {
        "text": "could be good in some context but it",
        "start": 2957.92,
        "duration": 3.24
    },
    {
        "text": "could be limiting right like you know in",
        "start": 2959.72,
        "duration": 3.68
    },
    {
        "text": "this case we don't know is like writing",
        "start": 2961.16,
        "duration": 4.159
    },
    {
        "text": "style the only serious feature or there",
        "start": 2963.4,
        "duration": 4.12
    },
    {
        "text": "could be others we don't know what the",
        "start": 2965.319,
        "duration": 4.081
    },
    {
        "text": "dag structure is right like so our",
        "start": 2967.52,
        "duration": 3.599
    },
    {
        "text": "approach is agnostic to that it just",
        "start": 2969.4,
        "duration": 4.04
    },
    {
        "text": "takes several worst performing groups",
        "start": 2971.119,
        "duration": 5.121
    },
    {
        "text": "and up weits them in a simple strategy",
        "start": 2973.44,
        "duration": 5.28
    },
    {
        "text": "yeah and and it turns out like it has",
        "start": 2976.24,
        "duration": 4.04
    },
    {
        "text": "connections to inverse propensity",
        "start": 2978.72,
        "duration": 4.04
    },
    {
        "text": "waiting and our approach is exactly",
        "start": 2980.28,
        "duration": 4.64
    },
    {
        "text": "inverse propensity waiting with uh with",
        "start": 2982.76,
        "duration": 3.76
    },
    {
        "text": "the propensity weights are given by the",
        "start": 2984.92,
        "duration": 3.76
    },
    {
        "text": "group errors",
        "start": 2986.52,
        "duration": 4.24
    },
    {
        "text": "okay",
        "start": 2988.68,
        "duration": 7.6
    },
    {
        "text": "uh so so like you know some ongoing work",
        "start": 2990.76,
        "duration": 8.4
    },
    {
        "text": "that we are doing is like uh rather than",
        "start": 2996.28,
        "duration": 4.88
    },
    {
        "text": "just using the group error use bunch of",
        "start": 2999.16,
        "duration": 3.88
    },
    {
        "text": "other group attributes to rank those",
        "start": 3001.16,
        "duration": 4.12
    },
    {
        "text": "things okay so then this would be more",
        "start": 3003.04,
        "duration": 4.72
    },
    {
        "text": "generalization that that that we would",
        "start": 3005.28,
        "duration": 5.0
    },
    {
        "text": "have a more like broader range of",
        "start": 3007.76,
        "duration": 4.599
    },
    {
        "text": "propensity weights rather than just",
        "start": 3010.28,
        "duration": 4.48
    },
    {
        "text": "based on the group errors okay so we're",
        "start": 3012.359,
        "duration": 4.2
    },
    {
        "text": "looking at things like you know group",
        "start": 3014.76,
        "duration": 4.24
    },
    {
        "text": "size you know entropy of labels you know",
        "start": 3016.559,
        "duration": 4.321
    },
    {
        "text": "how random is like you know because",
        "start": 3019.0,
        "duration": 3.24
    },
    {
        "text": "there are some people who would write",
        "start": 3020.88,
        "duration": 3.239
    },
    {
        "text": "reviews and they would just randomly hit",
        "start": 3022.24,
        "duration": 4.119
    },
    {
        "text": "a three or a four or a five right or",
        "start": 3024.119,
        "duration": 5.48
    },
    {
        "text": "there are some people who would write uh",
        "start": 3026.359,
        "duration": 5.72
    },
    {
        "text": "like a oneline review uh the movie was",
        "start": 3029.599,
        "duration": 4.361
    },
    {
        "text": "really good and give it a two star",
        "start": 3032.079,
        "duration": 3.401
    },
    {
        "text": "because there's like a personto person",
        "start": 3033.96,
        "duration": 3.879
    },
    {
        "text": "variation right and and somebody would",
        "start": 3035.48,
        "duration": 4.319
    },
    {
        "text": "write a very scathing review and like",
        "start": 3037.839,
        "duration": 4.24
    },
    {
        "text": "still give it a four stars right so so",
        "start": 3039.799,
        "duration": 5.04
    },
    {
        "text": "there's a personto person idiocracies in",
        "start": 3042.079,
        "duration": 5.881
    },
    {
        "text": "the way they review things um and so",
        "start": 3044.839,
        "duration": 5.72
    },
    {
        "text": "like entropy of labels you know or like",
        "start": 3047.96,
        "duration": 5.359
    },
    {
        "text": "you know like or the current group",
        "start": 3050.559,
        "duration": 5.161
    },
    {
        "text": "gradients could be like other featur to",
        "start": 3053.319,
        "duration": 5.8
    },
    {
        "text": "look at that and we have like a simple",
        "start": 3055.72,
        "duration": 5.879
    },
    {
        "text": "upating based objective a natural Next",
        "start": 3059.119,
        "duration": 4.281
    },
    {
        "text": "Step could be to think about a convex",
        "start": 3061.599,
        "duration": 5.52
    },
    {
        "text": "objective function uh like like you know",
        "start": 3063.4,
        "duration": 5.52
    },
    {
        "text": "that is based on the ranking loss for",
        "start": 3067.119,
        "duration": 4.281
    },
    {
        "text": "this problem okay you know hopefully we",
        "start": 3068.92,
        "duration": 4.24
    },
    {
        "text": "will get better convergence of results",
        "start": 3071.4,
        "duration": 3.719
    },
    {
        "text": "in that way rather than doing this Epoch",
        "start": 3073.16,
        "duration": 5.959
    },
    {
        "text": "wise uh Epoch wise updating you know um",
        "start": 3075.119,
        "duration": 5.96
    },
    {
        "text": "and and also like we assume that the",
        "start": 3079.119,
        "duration": 3.401
    },
    {
        "text": "group structure is given to us",
        "start": 3081.079,
        "duration": 3.681
    },
    {
        "text": "exogenously but it might not be you know",
        "start": 3082.52,
        "duration": 4.279
    },
    {
        "text": "might you might have to infer groups by",
        "start": 3084.76,
        "duration": 4.839
    },
    {
        "text": "some kind of clustering or like you know",
        "start": 3086.799,
        "duration": 4.481
    },
    {
        "text": "by some other means like you know which",
        "start": 3089.599,
        "duration": 5.041
    },
    {
        "text": "could be endogenous so uh how how to how",
        "start": 3091.28,
        "duration": 5.0
    },
    {
        "text": "would such approach work like you know",
        "start": 3094.64,
        "duration": 4.24
    },
    {
        "text": "the group structure is not uh like you",
        "start": 3096.28,
        "duration": 4.72
    },
    {
        "text": "know given given to us like provided to",
        "start": 3098.88,
        "duration": 5.199
    },
    {
        "text": "us okay so this is a joint work with",
        "start": 3101.0,
        "duration": 6.319
    },
    {
        "text": "like you know professor shabum and uh",
        "start": 3104.079,
        "duration": 6.561
    },
    {
        "text": "like Yuan Leu and bhan Zang our PhD",
        "start": 3107.319,
        "duration": 6.0
    },
    {
        "text": "second year PhD students in our program",
        "start": 3110.64,
        "duration": 5.919
    },
    {
        "text": "and um this paper is uh currently in",
        "start": 3113.319,
        "duration": 5.161
    },
    {
        "text": "review and you know there's some ongoing",
        "start": 3116.559,
        "duration": 4.76
    },
    {
        "text": "work as I said uh on like generalizing",
        "start": 3118.48,
        "duration": 4.92
    },
    {
        "text": "it to other criteria for",
        "start": 3121.319,
        "duration": 4.721
    },
    {
        "text": "ranching that's it uh and thank you so",
        "start": 3123.4,
        "duration": 7.0
    },
    {
        "text": "much and I'll uh stop for",
        "start": 3126.04,
        "duration": 4.36
    },
    {
        "text": "questions yes um you don't have to slide",
        "start": 3133.64,
        "duration": 6.479
    },
    {
        "text": "18 for a minute oh",
        "start": 3136.64,
        "duration": 3.479
    },
    {
        "text": "my I just had a question like reting",
        "start": 3140.64,
        "duration": 5.199
    },
    {
        "text": "there's kind of like a whole",
        "start": 3144.359,
        "duration": 3.881
    },
    {
        "text": "for option okay in the Baseline",
        "start": 3145.839,
        "duration": 4.081
    },
    {
        "text": "everything's considered equally and then",
        "start": 3148.24,
        "duration": 5.24
    },
    {
        "text": "of course the common case dominates it",
        "start": 3149.92,
        "duration": 5.56
    },
    {
        "text": "other groups and then like on the other",
        "start": 3153.48,
        "duration": 3.72
    },
    {
        "text": "side there's the St waiting where you",
        "start": 3155.48,
        "duration": 4.319
    },
    {
        "text": "only wor performance and then here's is",
        "start": 3157.2,
        "duration": 4.919
    },
    {
        "text": "kind of somewhere in the middle um where",
        "start": 3159.799,
        "duration": 4.161
    },
    {
        "text": "you look at the average ERA within a",
        "start": 3162.119,
        "duration": 4.841
    },
    {
        "text": "group and you do some log",
        "start": 3163.96,
        "duration": 5.8
    },
    {
        "text": "B I'm curious did you explore like",
        "start": 3166.96,
        "duration": 4.72
    },
    {
        "text": "instead of like a log function based on",
        "start": 3169.76,
        "duration": 4.64
    },
    {
        "text": "the ranking just actually use like",
        "start": 3171.68,
        "duration": 5.879
    },
    {
        "text": "multiplying that average grou accuracy",
        "start": 3174.4,
        "duration": 6.08
    },
    {
        "text": "instead did you try that that's that's a",
        "start": 3177.559,
        "duration": 5.76
    },
    {
        "text": "great question so so the way so the",
        "start": 3180.48,
        "duration": 5.119
    },
    {
        "text": "reason we use ranking instead of actual",
        "start": 3183.319,
        "duration": 5.121
    },
    {
        "text": "numbers is because of calibration issues",
        "start": 3185.599,
        "duration": 5.081
    },
    {
        "text": "right so like actual group errors could",
        "start": 3188.44,
        "duration": 4.56
    },
    {
        "text": "be very very close to each other right",
        "start": 3190.68,
        "duration": 3.8
    },
    {
        "text": "like you know some group errors could be",
        "start": 3193.0,
        "duration": 3.64
    },
    {
        "text": "let's say on some scale number they",
        "start": 3194.48,
        "duration": 6.44
    },
    {
        "text": "could be five versus 4.5 versus three so",
        "start": 3196.64,
        "duration": 6.52
    },
    {
        "text": "in terms of the waiting they would be",
        "start": 3200.92,
        "duration": 5.36
    },
    {
        "text": "very very similar right so why like",
        "start": 3203.16,
        "duration": 5.48
    },
    {
        "text": "ranking uh like ensures better",
        "start": 3206.28,
        "duration": 5.0
    },
    {
        "text": "separation between the different ranks I",
        "start": 3208.64,
        "duration": 4.679
    },
    {
        "text": "guess what I'm trying to say is like if",
        "start": 3211.28,
        "duration": 4.079
    },
    {
        "text": "the loss functions are so close to each",
        "start": 3213.319,
        "duration": 5.561
    },
    {
        "text": "other yes then like if the ranks",
        "start": 3215.359,
        "duration": 7.081
    },
    {
        "text": "differ um then like basically just a",
        "start": 3218.88,
        "duration": 6.36
    },
    {
        "text": "small perturbation could shift the ranks",
        "start": 3222.44,
        "duration": 4.8
    },
    {
        "text": "and maybe those two classes should be",
        "start": 3225.24,
        "duration": 4.68
    },
    {
        "text": "weighted relatively",
        "start": 3227.24,
        "duration": 5.4
    },
    {
        "text": "equally kind of what the performance is",
        "start": 3229.92,
        "duration": 3.679
    },
    {
        "text": "looking",
        "start": 3232.64,
        "duration": 4.4
    },
    {
        "text": "like true I mean like we we we did try",
        "start": 3233.599,
        "duration": 5.321
    },
    {
        "text": "like non-ranking based approaches in",
        "start": 3237.04,
        "duration": 4.44
    },
    {
        "text": "fact that's how we were initially trying",
        "start": 3238.92,
        "duration": 5.36
    },
    {
        "text": "to do this it's just that like ranking",
        "start": 3241.48,
        "duration": 6.28
    },
    {
        "text": "is just more robust to like you know",
        "start": 3244.28,
        "duration": 5.92
    },
    {
        "text": "calibration miscalibration issues right",
        "start": 3247.76,
        "duration": 5.16
    },
    {
        "text": "that's why we stuck to uh we stuck to",
        "start": 3250.2,
        "duration": 5.48
    },
    {
        "text": "ranking right so so yeah your your point",
        "start": 3252.92,
        "duration": 5.04
    },
    {
        "text": "is well taken that even if the group",
        "start": 3255.68,
        "duration": 4.6
    },
    {
        "text": "errors are similar group erors are",
        "start": 3257.96,
        "duration": 5.72
    },
    {
        "text": "similar but but ranking still uh like",
        "start": 3260.28,
        "duration": 6.0
    },
    {
        "text": "puts a relative prefence in terms of the",
        "start": 3263.68,
        "duration": 4.919
    },
    {
        "text": "group weights right so the group weights",
        "start": 3266.28,
        "duration": 4.36
    },
    {
        "text": "would should should still be clearly",
        "start": 3268.599,
        "duration": 4.321
    },
    {
        "text": "separated right otherwise like what we",
        "start": 3270.64,
        "duration": 4.0
    },
    {
        "text": "were finding was that everything was",
        "start": 3272.92,
        "duration": 4.12
    },
    {
        "text": "kind of moving together like you know if",
        "start": 3274.64,
        "duration": 4.32
    },
    {
        "text": "the group one of the group pars was five",
        "start": 3277.04,
        "duration": 4.24
    },
    {
        "text": "and there was 4.7 and know",
        "start": 3278.96,
        "duration": 5.8
    },
    {
        "text": "4.3 in the bigger scheme of things like",
        "start": 3281.28,
        "duration": 5.36
    },
    {
        "text": "this was very similar to the Baseline",
        "start": 3284.76,
        "duration": 3.24
    },
    {
        "text": "right we are essentially operating",
        "start": 3286.64,
        "duration": 3.84
    },
    {
        "text": "everything the same uh so it was trying",
        "start": 3288.0,
        "duration": 5.24
    },
    {
        "text": "to like be more Stark right like in",
        "start": 3290.48,
        "duration": 4.44
    },
    {
        "text": "terms of the way we are doing aerating",
        "start": 3293.24,
        "duration": 4.839
    },
    {
        "text": "but yeah that's a good question yeah",
        "start": 3294.92,
        "duration": 5.72
    },
    {
        "text": "this is more question about the data set",
        "start": 3298.079,
        "duration": 5.081
    },
    {
        "text": "okay um I know that for a bunch of",
        "start": 3300.64,
        "duration": 4.4
    },
    {
        "text": "reviews there's sometimes concerns about",
        "start": 3303.16,
        "duration": 4.639
    },
    {
        "text": "Bots or people say that again so",
        "start": 3305.04,
        "duration": 4.72
    },
    {
        "text": "situations where you have Bots or people",
        "start": 3307.799,
        "duration": 4.921
    },
    {
        "text": "V on paying other ones toie bomb",
        "start": 3309.76,
        "duration": 5.2
    },
    {
        "text": "or",
        "start": 3312.72,
        "duration": 3.92
    },
    {
        "text": "various",
        "start": 3314.96,
        "duration": 5.56
    },
    {
        "text": "bombie what so as in a bunch of people",
        "start": 3316.64,
        "duration": 5.479
    },
    {
        "text": "for whatever reason you have your",
        "start": 3320.52,
        "duration": 4.64
    },
    {
        "text": "payment or events decide to um",
        "start": 3322.119,
        "duration": 4.761
    },
    {
        "text": "collaborate or trying to reduce the",
        "start": 3325.16,
        "duration": 3.439
    },
    {
        "text": "actual score of the contct oh I see oh",
        "start": 3326.88,
        "duration": 3.199
    },
    {
        "text": "so so you are saying okay how do we",
        "start": 3328.599,
        "duration": 4.361
    },
    {
        "text": "address BS uh or like you know some kind",
        "start": 3330.079,
        "duration": 6.04
    },
    {
        "text": "of strategic yes so so yeah so that's a",
        "start": 3332.96,
        "duration": 6.2
    },
    {
        "text": "great uh so that's a big concern right",
        "start": 3336.119,
        "duration": 4.24
    },
    {
        "text": "like know like you know strategic",
        "start": 3339.16,
        "duration": 3.08
    },
    {
        "text": "reviews like you know people do like",
        "start": 3340.359,
        "duration": 5.561
    },
    {
        "text": "it's done all the time so what what so",
        "start": 3342.24,
        "duration": 5.68
    },
    {
        "text": "you know these data sets at least two of",
        "start": 3345.92,
        "duration": 4.6
    },
    {
        "text": "them came from this paper from Stanford",
        "start": 3347.92,
        "duration": 5.72
    },
    {
        "text": "uh like on this reverse machine learning",
        "start": 3350.52,
        "duration": 5.12
    },
    {
        "text": "Benchmark and what they did like you",
        "start": 3353.64,
        "duration": 3.64
    },
    {
        "text": "know they they describe all the details",
        "start": 3355.64,
        "duration": 2.959
    },
    {
        "text": "and this these were some of the things",
        "start": 3357.28,
        "duration": 3.12
    },
    {
        "text": "that we were worried about that what if",
        "start": 3358.599,
        "duration": 3.48
    },
    {
        "text": "there is there are strategic reviewing",
        "start": 3360.4,
        "duration": 3.48
    },
    {
        "text": "like you know that you just give one",
        "start": 3362.079,
        "duration": 4.601
    },
    {
        "text": "star to the reviews of a given",
        "start": 3363.88,
        "duration": 4.36
    },
    {
        "text": "restaurant or a different a different",
        "start": 3366.68,
        "duration": 5.359
    },
    {
        "text": "product so they build some classifier to",
        "start": 3368.24,
        "duration": 6.28
    },
    {
        "text": "to detect some kind of fake reviews or",
        "start": 3372.039,
        "duration": 4.161
    },
    {
        "text": "you know like reviews that might have",
        "start": 3374.52,
        "duration": 3.4
    },
    {
        "text": "been strategic in some way and and and",
        "start": 3376.2,
        "duration": 4.68
    },
    {
        "text": "remove those right and and like also",
        "start": 3377.92,
        "duration": 5.36
    },
    {
        "text": "this idea that each person like you know",
        "start": 3380.88,
        "duration": 4.84
    },
    {
        "text": "was only kept to 75 you know so they",
        "start": 3383.28,
        "duration": 4.96
    },
    {
        "text": "have good justification for it in terms",
        "start": 3385.72,
        "duration": 5.92
    },
    {
        "text": "of like ensuring that the model runs",
        "start": 3388.24,
        "duration": 5.72
    },
    {
        "text": "that and the data set is representative",
        "start": 3391.64,
        "duration": 5.76
    },
    {
        "text": "but still it's not too trivial right so",
        "start": 3393.96,
        "duration": 5.119
    },
    {
        "text": "so yeah so so some of those issues were",
        "start": 3397.4,
        "duration": 3.84
    },
    {
        "text": "definitely addressed but I think there",
        "start": 3399.079,
        "duration": 4.441
    },
    {
        "text": "could be still some of these more issues",
        "start": 3401.24,
        "duration": 4.4
    },
    {
        "text": "because they still built a classifier to",
        "start": 3403.52,
        "duration": 5.0
    },
    {
        "text": "weave those things",
        "start": 3405.64,
        "duration": 2.88
    },
    {
        "text": "up",
        "start": 3409.76,
        "duration": 6.319
    },
    {
        "text": "yes some GRS are more close for other",
        "start": 3411.64,
        "duration": 8.56
    },
    {
        "text": "say that again so here some groups are",
        "start": 3416.079,
        "duration": 9.76
    },
    {
        "text": "inic to other for example right RWS",
        "start": 3420.2,
        "duration": 6.919
    },
    {
        "text": "Chinese and",
        "start": 3425.839,
        "duration": 5.681
    },
    {
        "text": "singaporeans have the same mistake yes",
        "start": 3427.119,
        "duration": 7.401
    },
    {
        "text": "so",
        "start": 3431.52,
        "duration": 3.0
    },
    {
        "text": "uh more put some way for groups that are",
        "start": 3435.16,
        "duration": 8.28
    },
    {
        "text": "more similar to have a lower weight for",
        "start": 3440.4,
        "duration": 6.24
    },
    {
        "text": "groups that have uh they are similar to",
        "start": 3443.44,
        "duration": 4.599
    },
    {
        "text": "other",
        "start": 3446.64,
        "duration": 4.719
    },
    {
        "text": "fols yeah so that's a that's a good",
        "start": 3448.039,
        "duration": 7.641
    },
    {
        "text": "question and uh did I have it uh I think",
        "start": 3451.359,
        "duration": 6.68
    },
    {
        "text": "I had it somewhere but one of the things",
        "start": 3455.68,
        "duration": 4.52
    },
    {
        "text": "that we are looking at is that maybe the",
        "start": 3458.039,
        "duration": 3.841
    },
    {
        "text": "waiting should also take into account",
        "start": 3460.2,
        "duration": 3.639
    },
    {
        "text": "similarity of",
        "start": 3461.88,
        "duration": 4.52
    },
    {
        "text": "Grows Right so other than so like",
        "start": 3463.839,
        "duration": 4.801
    },
    {
        "text": "currently we're just looking at looking",
        "start": 3466.4,
        "duration": 5.56
    },
    {
        "text": "at errors in an IID way we're looking at",
        "start": 3468.64,
        "duration": 5.6
    },
    {
        "text": "independently for each group what's the",
        "start": 3471.96,
        "duration": 5.399
    },
    {
        "text": "error and upweight based on that but",
        "start": 3474.24,
        "duration": 4.799
    },
    {
        "text": "that maybe somehow consider the",
        "start": 3477.359,
        "duration": 3.48
    },
    {
        "text": "similarity or the network structure of",
        "start": 3479.039,
        "duration": 4.201
    },
    {
        "text": "the groups for for these issues that",
        "start": 3480.839,
        "duration": 4.841
    },
    {
        "text": "there could be correlation uh in the",
        "start": 3483.24,
        "duration": 5.96
    },
    {
        "text": "review patterns of some groups right you",
        "start": 3485.68,
        "duration": 6.72
    },
    {
        "text": "know like even if each person uh each",
        "start": 3489.2,
        "duration": 5.28
    },
    {
        "text": "group is an individual person people",
        "start": 3492.4,
        "duration": 4.399
    },
    {
        "text": "from same country could write singar",
        "start": 3494.48,
        "duration": 4.319
    },
    {
        "text": "types of reviews so like you know have",
        "start": 3496.799,
        "duration": 4.361
    },
    {
        "text": "uh like a separate criteria for",
        "start": 3498.799,
        "duration": 4.601
    },
    {
        "text": "reranking like separate feature on which",
        "start": 3501.16,
        "duration": 5.56
    },
    {
        "text": "we rank based on that",
        "start": 3503.4,
        "duration": 3.32
    },
    {
        "text": "I think we are right about at the hour",
        "start": 3507.839,
        "duration": 3.841
    },
    {
        "text": "so you can probably wrap up I do as want",
        "start": 3509.839,
        "duration": 4.76
    },
    {
        "text": "pass along uh there was a a comment of",
        "start": 3511.68,
        "duration": 5.359
    },
    {
        "text": "appreciation in the chat for Thought",
        "start": 3514.599,
        "duration": 4.921
    },
    {
        "text": "thanking you for Thought talk saying",
        "start": 3517.039,
        "duration": 5.04
    },
    {
        "text": "that they look forward",
        "start": 3519.52,
        "duration": 6.48
    },
    {
        "text": "to thank you so much",
        "start": 3522.079,
        "duration": 3.921
    },
    {
        "text": "and",
        "start": 3529.839,
        "duration": 3.0
    }
]