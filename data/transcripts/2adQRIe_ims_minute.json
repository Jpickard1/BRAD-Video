[
    {
        "start": 0.0,
        "text": "um so I well I snuck in my normal should be on case anyone online does not usually attend this seminar series so it is a venue to discuss new tools technologies and methodologies that are recently developed in development or just of interest and use by researchers so today we have Craig work who's going to give us an introduction to work out well thank you Marcy thank you for having me thank you everyone for coming my name is my sassette is Craig beaver I am a second year in the bioinformatics program here and so when Marcy asks our lab to give a talk trying to decide you know what should we present and so a lot of what I use is sort of more MATLAB or Excel but then I've used this program called Weka a couple times and I thought well I hadn't heard of it before and I didn't know sort of how ubiquitous it was and so I decided why not just give an introduction on why cuz it seems like a pretty cool software so just out of curiosity how many of you have heard of "
    },
    {
        "start": 60.21,
        "text": "this before oh wow okay a couple of years so this is gonna be sort of an introduction so nothing exciting sorry so what is Weka well Weka is short for the Waikato environment for knowledge analysis it's a Lovato University or University of Waikato is in New Zealand it's an open source software released under the gnu general public license and it really at its core it's a collection of machine learning algorithms and there's a lot of ways that you can then take those algorithms and apply them to your data or run scripts and so that's what i'm we're talking about today Weka is also a flightless bird that's pictured here that is endemic New Zealand but that is not what this talk is about so I'm sorry so the idea this talk I think I'm going to give a bit of background and sort of what machine learning is and then we'll sort of talk about what Weka is and how it makes use of that so machine learning "
    },
    {
        "start": 121.86,
        "text": "is a branch of artificial intelligence and the main idea behind it is that given some data some set of data you want to sort of look for extract and as a name suggest sort of learned patterns inherent in this data that you can then use to sort of apply to other sets of data there are a couple different types of machine learning the two types I'll talk about today are supervised and unsupervised and then within each of those there's a bunch of different types of algorithms so there's things like Bayesian networks decision trees I'll talk about support vector machines and what those are but there are other types of machine learning that I won't go into it's a huge field but really like I said sort of what it boils down to is you want to generalize from experience so given some set of data some experience the algorithms try to learn about that and then apply what it learns to new instances of similar data "
    },
    {
        "start": 182.43,
        "text": "so one of the types of machine learning is called supervised learning and in this your data set when it is given to you is labeled so you've got each entry has some sort of label associated with it whether it's a class or an instance and what then happens is you take this data and you split it into two sections there's training data and test data and so the training data what it does is it looks at this and it takes it as input and it also looks at the the label associated with each entry as the desired output for the algorithm so it looking at this training data it sort of infers some function that it can then apply to the data that will generate the desired output once it's got this function that it's things like ok this is a pretty good function then it runs it on the test data so it you give it the input and it computes the output using that inferred function and it then checks that against the label that was supplied so that way you know you can get sort of a sense of accuracy "
    },
    {
        "start": 244.62,
        "text": "specificity things like that and one of the ways it does this is it's called cost Crossfield validation so it'll take this data set and it'll take you know nine-tenths of it as training data and another the last cent of it as test data you know run it and try to come up with some function and then we'll do that again and again and again with different chunks of the data used as training data and different chunks uses data once it's done with all of that it's sort of sort of averages your the functions that it came up with and uses that as it's sort of best estimate for just a general supervised learning algorithm then what you can do is you can give it a new unlabeled data and it will run the function and based on the output it says you know this is what I think the label should be and based on its performance in the test data you can have some sense of accuracy unsupervised learning is kind of I mean it's still machine learning but in this case the data aren't labeled um so "
    },
    {
        "start": 306.76,
        "text": "you're looking for some sort of hidden structure or something you don't quite know what it is generally it's more for clustering in this case there's really sort of no right or wrong because there are no labels with which to sort of base your ideas so one example is if you have a bunch of data on tumors and you've got size and growth rate for these tumors you know that all cancerous and you're just sort of maybe trying to classify a cluster these different types of tumors so when you plot the data based on size and rate of growth you can see there's sort of four clusters there's one here here here and here and so there are small tumors with a slow rate of growth small tumors with a high rate of growth medium tumors with the medium rate of growth and large tumors that grow slowly and so those are your sort of four classes that that some unsupervised learning algorithm might generate then what you can do is you can say well I have this tumor sample and these are you know say it's 800 the size of the tumor is 800 and it grows at 4% so then you "
    },
    {
        "start": 369.97,
        "text": "know it would be somewhere around here in which case you could say well maybe this is a class 4 and it's related to these other types of tumors that's sort of the general idea behind unsupervised learning like I said there's no labels so you can't say these are you know class 1 2 3 4 and am I right or wrong it's just sort of more of a looking for hidden things or trying to find things that aren't necessarily readily apparent so one example of supervised learning that I'll talk about our demo later is support vector machines um this is like I said a sort of an example of supervised learning and your input data has to be set up so that there are two classes there are sort of extensions of this algorithm that can use more classes but generally you work with two you kind of can't tell but some of these dots are blue and some of them are red most of the ones down here blue and most the ones up here in red and so what it does is this algorithm tries to make a model and what it does is it treats all your data at points in space whether "
    },
    {
        "start": 430.93,
        "text": "it's 2d space suit space some sort of high dimensional space and once it plots this data it tries to sort of draw a line through them such that the margin between the line and any of the data points is the largest and any data on one side is in class one and did and the other side is on the next class so in this example I guess that most of these are blue and most of these are red so what it's done now is it's drawn this line and it says anything on underneath the line is blue and anything above the line is red there are a couple of red dots below the line and a couple of blue dots above the line but that's to be expected it's not going to necessarily be perfect and so once you've got this model done then what you can do is you can give it a new date and be like you know here's this point and it's it's somewhere around here and so then you can say well more than likely it's going to be a blue point and if there's a point of view you can say well it's probably your red point so that's sort of the idea behind support vector machines so now we get back to what what can do I "
    },
    {
        "start": 491.2,
        "text": "could do well it can do a lot the first thing you can generally do with Weka is data pre-processing so you've got your data in some format and you want to be able to run some machine learning algorithms on it so how do you go about doing that well you can use Weka to sort of import your data and get it into a format that you want then to be able to apply to these algorithms once that's done it's sort of you know the world is your oyster you can do different types of data classification generic multi instance there's you can do text text data mining or text classification there's been recently some additions of cost sensitive data or cost sensitive algorithm said you can use it does various clusterings association so looking for sort of again relations between your data so for example if you had a bunch of recipes maybe one of the associations it would find as if there's eggs in a recipe there's likely also going to be milk in that recipe for "
    },
    {
        "start": 552.19,
        "text": "example you know it'll try to find associations within your data it does regressions another nice thing it does is attribute selection which means that if you take all your data and if you've got a lot of input values and you don't know necessarily which ones are useful and which ones are just kind of you know something that can be thrown out without much consequence you want to use attribute selection so for example if you've got you know two thousand genes and you want to say like well what are the 10 most important genes in the study that I'm running it can do that too there's a couple different ways they can do that I can just do some native stuff meta classifiers they can just do a straight filter it's also they've recently added some time series analysis to this I haven't worked with that really too much so I can't speak to how good it is but one of the really nice things about Weka is that it can also do data visualization so once you've "
    },
    {
        "start": 612.52,
        "text": "pre-processed your data and got it into some form you can visualize it then and I will I can demo this later but it also lets you once you've run your machine learning algorithms it will let you sort of plot the results and you can see sort of where your data points lie and how they've been classified another nice thing about Weka is that as an extremely extensible it's written in Java and it's open source so you can get at the source code whenever you'd like and you can then obviously if you have some method that you've developed or that your lab is developed and you want to sort of get it out to a wider audience you can implement it in Java through Weka and post it and just be like here you can download this and install it Weka now in the newest version has a project manager sort of things so it lets you download extensions that other people have posted it comes with a large group of "
    },
    {
        "start": 674.61,
        "text": "out-of-the-box algorithms but if you want to add more to it you're more than welcome to so how do you use Weka well so it's like I said it's Java based which means it's platform independent so you can use it on Windows Macintosh UNIX systems whatever you want as long as it runs Java you can run Weka the default file format in Weka is this AR FF which is an attribute relation file format and I'll go into some more examples of that later as a default file format that's what it likes that's how it reads in the data you can also give it CSVs and that's fine there are a couple other files you can use you can connect it to a database I'll show you how to work with a CSV the only disadvantage to that as you can't miss it sort of reads it in as best it can whereas with a our FF file you can actually tell it what is what there is a "
    },
    {
        "start": 735.43,
        "text": "command-line interface that has the full functionality of Weka but there's also a GUI which is pretty nice and there are four aspects to that GUI there's the Explorer which is what I'll demo later and that's kind of really the the meaty bones of Weka as far as sort of explored exploring your data and then there's an experimenter this knowledge flow thing in a simple command-line interface that are all sort of built into this GUI so what is this a rff file format well I said it's attribute relation file format and it's weka's default file format there are two sections within this file there's a header section which is where you sort of put all of your information in a data section anything with a percentage sign in front of it is a comment so you can document these things and put in comments in your header section you've got the name of a relation so sort of what the data sets about and "
    },
    {
        "start": 797.32,
        "text": "then in that you then sort of you list all the attributes of that relation and so that is kind of your templating your data almost and so you can have the names of you have the name of an attribute and then it's type and you just sort of have a list of those and then that's a template for your data which is then used in this data section so in the data section then each row is an is a data entry and it's all it's just comma separated values there's one entry per row I mean so you've got your head or your data and then just all of what follows so this is one of the example files that they had on their website so the first percentages are just comments so Linda McMahon asked where can I find link for past recorded talks that's NCI bi dot org "
    },
    {
        "start": 859.51,
        "text": "so I think that answers your question so so right so this this file format percentages are comments and so that's just kind of this is an iris plant database this is just the example they had up on their website on the wacker website created by these people so there's your sources and so if we look at this and we can see okay so the relation it's an iris relation because it's an iris plant database and each relation then has a set of attributes so in this case there's supple length supple with petal length petal width and then class and the way it works is so here's an attribute this is its name and this is its type so these first four are all numeric which just means that it's a number there are other types besides numeric these are nominal types there's also integer types which are just treated as numeric same with reals it's another type but it's treated as a numeric there are string types so if you want to do text mining or text "
    },
    {
        "start": 920.75,
        "text": "classification you can do that with Weka there's date formats that's a little bit more complicated there's also a relational attribute that's sort of being added and slowly it's kind of a new feature I haven't really used it down much so I can't speak too much about what it is but yeah so you can like you can tell say like this attribute is related to this other attribute of this classical agents otherwise it's not it's still sort of in development that's kind of one of the yeah yeah no it is something that they're working on and I'm sure that people will want to take advantage of it but and like I said I haven't really used it that much so I don't know too much about how it can be used but it is an option so this last attribute called class then is a nominal attribute and what that is is it's a set of sort of classes for what each entry is going to be and so in this "
    },
    {
        "start": 982.28,
        "text": "case you've got three different classes all comma separated iris setosa versicolor and virginica it might be butchering those so I don't know but so that's your sort of set and every data entry in the data section is going to be one of these three things if it's not your data file is not properly formatted and sort of won't work so this is the header section then and then in the data section now we can see that these are all just comma separated so this first one has a sepal length 5.1 a supper width of 3.5 a petal length of 1.4 and a petal width of 0.2 and so and it has a class of virus atone so these are all the same class but that's fine and so this is what an AR f file looks like which you then feed into market you can also have something called an ex rff file which is an xml-based extension of their a file they tend to be larger I would show an example but they tend to "
    },
    {
        "start": 1042.4,
        "text": "be a lot larger as far as sort of the opening header part goes because of that people would tend to gzip them and sort of the people behind what could realize this and so now you can load and save gzip files automatically it works the same for AF but I think it began because the XRF files were bigger you get a extra things with this XR FF file first you can do class attribute specification so if there's some attribute you want to specify for an entire class you can do that with this XML based extension you can also do if you want to have weights for your attributes or your instances you can do that in here and so there's better syntax for that but you can put in you know this attribute has a weight of 0.9 first this attribute which only has a void of 0.1 that you can do with the XR FF files same thing with instances if you have multiple instances and you want some to be weighted more than others you could do that with this XR FF file "
    },
    {
        "start": 1105.49,
        "text": "so going back to now Weka and those four buttons the Explorer I'm gonna demo after this talk and so that's kind of like I said the meaning bones of this but there are three other things that you can use in Weka the first of which is this experimenter and what this does is it sort of lets you compare and contrast different algorithms you open the window and you can load in your data sets and you can load a bunch of different algorithms that you want to run on that data and this can be the same algorithm you can iterate over parameter settings or you can iterate over one parameter or multiple parameters whatever you want you can do multiple different algorithms you can do a combination of them um it's basically sort of like you're planning how you want your data to be analyzed either significance testing built in and this is this is sort of a fire-and-forget way of doing it so you load in your data you load in your algorithms with all your variables and "
    },
    {
        "start": 1167.54,
        "text": "you just sort of press go and you can walk away depending on what you've loaded maybe go get coffee and come back and it's done or maybe you go home and come back the next day and it's halfway done you can sort of work with that as you'd like so that it's it's a pretty nice feature sort of related to that is this knowledge flow idea I don't know how many of you have used nine before but it's kind of the same idea it's a workflow generator and it's a GUI for that so you can drop in nodes like here's a data loader node and then here's a data processing node and you connect them and you tell them how to connect and all that sort of stuff and so if you've got a really long or complicated process with a lot of branching and different analyzing steps you can create one workflow and save it and then you can load it again later you can send it to a collaborator and have them loaded and it's really quite nice like I said it's useful for long sort of more complicated intricate projects where there's a lot of steps or branching and "
    },
    {
        "start": 1227.73,
        "text": "that's just straight up a workflow the thing that's tied to the sort of core functionality of Weka and then there's also a simple command-line interface it has all the functionality that you would get from a terminal so I don't know why you would necessarily use it unless you were scared of terminals but it's I mean it's it's pretty just like here's a terminal so yeah right so now you do and so now you can download a GUI to use command line interface if you want but I don't know necessarily all right so why should you use Weka well it's pretty straightforward and easy to learn I think I haven't been using it that long and I kind of can find my way around as as best as I think I can there is a huge range of different algorithms both supervised and unsupervised just all types of learning algorithms like I said before if you want to write another one go right ahead you can send it to wack and they'll post "
    },
    {
        "start": 1289.08,
        "text": "it it has a lot of potential uses like Brian said you can maybe use it for cancer research you can use it for flower database you can probably use it for birds you can use it for tons of genomic data the stuff that I'll demo later is actually gene expression data and so there's just pretty much yeah right so anything that you want to use machine learning with Weka can do that it's got a great GUI and it has a little memory manager then with a garbage collector so if there's a memory leak you can get rid of that I mean it has great documentation even built into the GUI you can you know if there's some algorithm and you're like what does this do you can click a button and it tells you what it does it gives you sort of the syntax for using it a lot of people do use it too so if you sort of come across a bug you can send it to them it's still being developed if you if you have a question that's not a bug "
    },
    {
        "start": 1349.34,
        "text": "and you just want to know how to do something you can ask someone they might know you can google it if it's not there you can post something online and someone is likely to answer it and this is developed in New Zealand even so it's just it is interesting you know and they're like I said they're still developing it there's a couple different versions the one I'll demo is sort of the newest one which has an extra feature that's pretty nice so and so with that I think unless - yeah no I I don't use that necessarily because I'm not there yet but it is something that I've done a bit of stuff with nine before and I think "
    },
    {
        "start": 1413.02,
        "text": "you can really sort of visualize where you [Music] there's a lot of pressure right now coming from the federal government and I age and so on and you know it was pressure frankly that came from industry about the reproducibility of our work you know that you probably aware that there were some studies at Amgen J&J and other places where they took X number of nature's cell and science papers fifty to a hundred took them into good GLP labs and try to reproduce the work and you know really good you know less than 20 percent success rate on reproducibility of you know basic to clinical translational "
    },
    {
        "start": 1475.11,
        "text": "science work a lot with a lot of informatics and so what the government and that's devastating I mean if you can't reproduce a paper you know especially a tier one journal paper what are we doing and so the government is now coming back and saying well you have to be more explicit in your methods section about your modeling and your statistics and all that stuff and that's where Wacka could really help because i could lay out alternative models ahead of time and evaluate that and you know that might become a standard in its I want to say it's possible right and like you said if you have this workflow you can just sort of take a screenshot of that and be like here's our method so yeah exactly yeah I mean it makes it really easy and especially if you're collaborating with people it's really like you can save and load workflow so you can save a workflow sent it off to your collaborator and exactly so so that ya know I mean it's it's a really sort of diverse program okay so "
    },
    {
        "start": 1544.07,
        "text": "is there an upper limit to the size of the database that you can put in but you mentioned you're gonna you're gonna demo gene expression that was the example yeah yeah so so yeah the gene expression data I have is a it's there's 62 tissue samples and there's 2,000 genes and then a class so it's not necessarily like terabytes of data according to their website Weka can yeah no it is according to the website where can't handle big data but I don't know what their definition of big data is and so [Music] what is big [Music] you have a discussion about that this is an important topic you know just from the point of view of those many of you are trainees you know and it's it's out there and this part a big bout fake data is true and it's connected obviously to analytics that "
    },
    {
        "start": 1605.929,
        "text": "there's probably 10 times more jobs in this area right now out there than there are people that can do them in that you know the other thing is that at least around here you know it's a unit like this and folks like you that are recognized and frankly it's expected of this unit to be the hood of the place where big data and analytics are done so it's just it's just frankly an opportunity and you know there are some things that just are hype and then die away but the thing that will keep the big data thing going over time is the the obvious growth of the of the data sets over time in all domains of work yeah and so one other thing to think about here and this is a term that I think we all have to be word knowing about in bioinformatics and that is data science so if people heard of data science well ok so look that's good "
    },
    {
        "start": 1666.74,
        "text": "because you know let me put it this way our provost and the folks downtown have you know and largely because there are data science Institute's being established including here at the University of Michigan several were funded by a recent good of Gibbs from the competitive on a competitive basis by Gordon and Betty Moore Foundation in the sloan foundation one at Berkeley one at NYU in one at University of Washington in Seattle data science Institute's we're setting up one here so what is it so if you think of bioinformatics as you know kind of this you know mix between the quantitative so you'd have mathematics and statistics and you know the quantitative aspects and then you think of the computer science and algorithmic aspects including you know the science of data bases and so on and then you think of the thing that makes us bioinformatics "
    },
    {
        "start": 1727.7,
        "text": "this quantitation slash computation merging with biology and biomedicine it's bioinformatics so the informatics part is the quantitative statistical / algorithmic component computational component with data and information and the application biology or bioinformatics data science is instead of the biological application just put your attic so the top parts the same but the bottom part is different you could have for example a transportation Institute version of data science what would that mean well we've got all these Google cars going around the street there's a big database through the cars analytics to figure out how it works and so you know they're a data science Institute would take you know those fundamental and you know this is Weka thing would be right in the middle that we fundamental you know enablers that bridge the "
    },
    {
        "start": 1788.679,
        "text": "mathematic statistic in algorithmic right yeah no I mean this yeah this is all machinery application what you have is a generalization of the concept of informatics which is now being called data science because they're gonna ask in ultimately and I will make this prediction right now you know that there will be in this room you know you know several of you five of you ten of you will leave data science effort before it's all over maybe even in the next five to ten years it's gonna happen so something to think of a food for thought thank you so yeah right so big data into that into depending on your data size some of these algorithms will take longer which "
    },
    {
        "start": 1849.23,
        "text": "is why you maybe want to filter your data first depending on what you want to run so I mean you can tell how long it's taking to run and if you want to read about if you want to read about the algorithm you can so I was using one algorithm here and you just sort of google it and you can find the paper that was published on the algorithm you can read about and how long it takes and stuff like that so there's data available certainly if not straight through Weka then it's not far away you can't do it with data it's done with information and really you know we're in an informatics department you know it's "
    },
    {
        "start": 1910.07,
        "text": "like the genome how do you how do you get the genome to be useful you annotate the thing in some way shape well that's what we're talking and so this pre-processing scrubbing all this kind of stuff has to be done in a standardized way to turn the data into information we ready annotation right yeah no absolutely so there's one more new term I'll ask you about I was just reading about it last night this is a hot one okay data wrangling anybody ever heard of it good well I'm glad you've heard of it because that's what that we've been doing for the last long you know and not it's bad when you're sitting in the laboratory and you know you find out oh what have we been doing or narita RFA from nih and it's like we're data wrangling so Alex what is it so basically by these term it's often denoted the whole process from getting "
    },
    {
        "start": 1971.72,
        "text": "data to the stage where you start to process data all the pre-processing exploratory analysis cleaning up reformatting in the way you want to have it all these steps are included in data wrangling finding is that data wrangling is a precursor to data mining and so what we've been running into in the laboratory which alex is living with this you know when you have a process like you're gonna see in Wacka you know data's Ronnie it is over here in boom boom boom you go like this and then all of a sudden you know you want to go from say you know ultimately in our case we take a picture we render the object of interest you know it's a nuclei to start with or a chromosome territory you render that then you get into a case where you want to measure something inside it he may be even as simple as "
    },
    {
        "start": 2034.08,
        "text": "the volume and then you know that's done with another algorithm in your chain of the pipeline and then there's a reformatting stuff in Alex over you can tell you then you know oh are we going to turn that in a nifty pile up that I know what a nifty pile is but I hear these guys are actually what you guys have been doing in the laboratory is called data wrangling it's getting the data into the appropriate format as you go downstream to ensure that the process of moving from data to information and the information is appropriately put together so that it could be analyzed in some kind of uniform way and so if you have a lot of streams that are coming in to aggregate you know the term is called wrangling that's a brand-new one check it out yeah that was the earlier term okay so right so so when you open Weka this is what you see the command-line interface like I "
    },
    {
        "start": 2095.22,
        "text": "said is really just a command-line interface so so one of the cool things with Weka like I said is you can there's a memory usage bar so it tells you how much memory you're using right now we're not using any and you can garbage collect in case there's a memory leak so that's kind of nice when you first since when you first install Weka you you like I said you get a whole bunch of sort of built-in functions but if you want to add more you can and so this is new to Weka this isn't the newest version and it's the manager and so these are all things that people have released and things that you can then use if you want to so IAM imputation all the sort of stuff so one of the things that I talked about was the SVM modeling and that doesn't quite come standard there is a little mark for it but if you try to run it it says you know there's an error we can't find and so what you need to do if you "
    },
    {
        "start": 2155.91,
        "text": "come down here and find lib SVM somewhere I just look for installed so you find this lib SVM it's a classification thing you just select it click install it takes care of dependencies for you everything like that and installs it I had a previous version of Weka and I tried to to get this I downloaded this and try to put it where I thought it should go and it worked except then it gave me a different error so if you download this it worked fine you can install uninstall and so and like I said there's a ton of stuff and if you want to write something I would guess that you could probably get them to put it up here so that's kind of nice that's with the new 3.7 version so now if we want to look at some data so let's if we look at this is the gene expression data that we're going to analyze so there are 62 tissue samples and it's all just gene expression data so there are two thousand genes and at the end of all of "
    },
    {
        "start": 2217.29,
        "text": "this this is a CSV file at the end of all of this is genes one to two thousand there's a class negative one means it's cancerous and one means it's just normal tissue and so if we come into Weka and we want to look in the Explorer so this is the window that you get and you start off by opening a file so if we go into desktop it's not an AR FF file so we have to load a CSV file and we're just looking at our data and so here it is all 2,000 genes and you can see how each one is sort of it bins each one and if we come down and look at our class since it's the CSV file it just reads everything in since they're all numb it reads everything in as numeric data types but we know that this last one should be nominal right negative one is sort of cancerous and one is not going to so the first filter we can apply to this will turn this this particular "
    },
    {
        "start": 2277.62,
        "text": "entry into a nominal data set so we come into filters it's a supervised unsupervised attribute it's unsupervised attribute and it is numeric to nominal so now the default is it just it applies it to everything but we don't want everything to be nominal we just want the last one to be nominal so we can get rid of that if you want to know what it's doing you can click more and it opens up some information about it including where it is as far as the Java path goes what it does how do the different options for it and this is available for pretty much everything capabilities just tells you sort of more about it the attributes minimum number of instances you need to run and stuff like that so we would just want to apply this to the last this last function and so we'll click apply so what it does is it goes through then and now if we select this "
    },
    {
        "start": 2337.63,
        "text": "it has it knows that it's classified the tissue as cancers first not and so its Bend as negative one and one and then if we look at all of our other data it has now colored it so you can see excuse me how many entries in this particular bin our cancer is first non cancerous and then you can they won't plot all 2,000 of them I think it plots a hundred at a time but so you can look at all of your data and you can see immediately if something's jumping out at you is like wow there's just blue on one side and just right on the other that must be something that would be a good indicator of whether it's cancerous or not and so this is what our data looks like um it's all just been these are all 2,000 genes is up to gene all good so that's that's sort of the pre-processing step we know we've read in our CSV file and we've classified it so now what do we want to do or we've sort of pre process so now we're gonna do well let's try classifying it so like I said there are a ton of different classifiers there's Bayes there's "
    },
    {
        "start": 2398.59,
        "text": "functions this is our live SVM so let's run that one tells it where is to go cross-validation let's do 10 sure there are plenty of more options which we won't sort of screw around with but you just click start and it starts running and well while this bird is turning that means the algorithm is running and you can see down here what it's doing so right now it's building a model 4 fold 4 5 6 and so it's running and it's telling you what it's doing there's a log file you can open that just sort of lists everything it's doing so now it's done and it's classified everything as a so it didn't do that good of a job but you get out sort of what it's some statistics related to the algorithm itself so it correctly identified 40 of them and incorrectly identified 22 of them and then you get some statistics true positive false positive rates precision and then just sort of your general confusion matrix so that's how "
    },
    {
        "start": 2458.98,
        "text": "you run a live SVM if you want to do as far as so so you can you can run with you can increase your cross-validation another thing you could try to do is you can do select attributes which is what I talked about earlier we've got right now these two thousand genes but maybe some of them are useless or maybe some of them are counterproductive and so we can choose an attribute evaluator and then if we run this what it'll do and it sort of takes a while because there's two thousand but what it'll do is it'll list like these are the attributes that are sort of the most significant and so then if you want to apply that filter to your data you can pull out just the attributes you want and so then it'll run faster and it's sort of cleaner data so it's sort of data wrangling right your pre-processing and getting out just "
    },
    {
        "start": 2520.06,
        "text": "the in this case just the genes that are sort of ranked highest in terms of relevance to what your desired output is so that's one way to go about it you can also like I said you could increase your cost fold validation there are tons of options I don't know what half of them are for this particular one you could try running a different method there are obviously a lot of options and so if we were to run say a random forest 10-fold cross-validation again sure it's done and it did a much better job so it correctly classified 35 it well it correctly classified what 43 and incorrectly identified 19 so it did better and it again it tells you it classified a lot of them as cancerous and not too many of them is not cancerous and here's all of your statistics associated with that if you want to go back at any time you can look "
    },
    {
        "start": 2581.66,
        "text": "at it like it saves the output so at any time you can go back and check and see sort of what has been done and again this has more options associated with it clustering is pretty much the same idea there's different clusters you can use start and it'll do its thing and it's done so it's got its clusters but that we already knew Association is again you know if you've got milk and all your recipes then you know eggs are coming next so selecting attributes like I said this takes a while but we can narrow down that mm gene file to something with 15 genes and run that and it'll be faster and then for visualization then it's kind of hard to see that's not what I want with this so now it lets you plot on your X and your Y axis any of the 2,000 genes or the class so in this case you're plotting class first gene 1 and so all "
    },
    {
        "start": 2643.28,
        "text": "of the red dots are up top and all the blue dots are bottom because you're just plotting either negative 1 or 1 and so that you know doesn't mean too much but you can come through and look at all of your data and just sort of see how sort of gene 5 is related to gene 1661 and so here's you did if you want to zoom in that you can you can select a rectangle to zoom in or a polygon or whatever and say like I want to zoom in on this area here then you click Submit and then now it's zoomed in on that area um so this really gives you a chance to sort of visualize what the data is that you have in our works and if you want to reset you can come back here to something else right so um I think once you've finished with that I don't actually know how that works I know you can save data and there's a log file associated with this with decision trees I know you can get the decision tree out of it so you "
    },
    {
        "start": 2704.9,
        "text": "can know how it's working with this though you can get the instances that have been classified as one or the other but really past that I don't know how much you'd want out of the algorithm because a lot of it is sort of black box stuff and it's all it is yeah it's all open source you can look at the code for the algorithm if you want and see what it's doing but at least with this ya know I mean so I mean where it's it's all sort of hidden away and stuff like that but like I said it's open source and this is a Windows machine so I just downloaded the install file but would be pretty computationally intensive I mean is there does this run "
    },
    {
        "start": 2768.53,
        "text": "on somebody's cloud and come back and then could you run a local version I mean how does that so this is all local right now you're running it right I'm running it right on my laptop yeah and so and it's - and fine um you can use the experimenter to sort of this is the one where you load in your datasets and then you load all the algorithms you want to run and you could go I'm sure you could farm this off to a cluster if you had one available to you or otherwise you can just that's why they commit you have for example and so and you can use this from other programs as well it's all it's like I said it's just Java so if you've got Python it's kind of hit or miss sometimes you can have it if you use jython like some sort of java implementation in python you can have it call this stuff but again it's kind of like python in particular it's sort of like sometimes it works sometimes it doesn't but if you've got code that you can run java with you can run Wacka in that code and then if you want to farm that out somewhere you can "
    },
    {
        "start": 2829.869,
        "text": "this is like I said it's just running on my laptop and unless you have huge amounts of data you have huge amounts of algorithms you want to run like if you want to test a thousand different entries for one parameter yeah you can farm it out but yeah because I know why Brian is asking this thing because we are using it yeah we are using the instruments that are support exactly cloud computing and remote access so I was asking if there are configuration for these two it's a poor sexually client-server model that you start your job on a cluster let's say and as you said you go home and you have your tea and you want to just log into the salmon on a web interface and to see the progress current progress on your job so I don't know I haven't ever had to use a client-server version of this I don't know that one exists you could remote "
    },
    {
        "start": 2892.22,
        "text": "back into your machine and check and see how it's doing but yeah I'm not I can't answer that with confidence so yeah yeah because sometimes it's like we're working in a big group and there are a lot of collaborators and it's it's good to have a possibility to share your progress to other people of course you want what you want you don't want to give them SSH access to your machine right right and so for something like that I would say sort of the workflow the knowledge flow thing is useful because you can sort of generate this workflow like this is how we process our data and you can save it and send it to your collaborators and then they can load it up just fine and as long as they have the same data that you have you can use it that way and if they have their own cluster they can do that as well okay so and also I know that the guys who authors of this software they started a online class on this wacker a month ago something like that okay did you look at that not "
    },
    {
        "start": 2953.03,
        "text": "really I watched some stuff on YouTube and like run around in the documentation there's there's a lot like I said there's a lot of stuff out there yeah a lot of people will just run little tutorials on YouTube on just intros or like sort of more advanced stuff it's you know there's not you know millions and millions and millions of hours of this but there is enough to certainly get your feet wet and get started and start playing around with it so sort of yeah so the stuff we have is like our project right now is trying to classify sort of efficacy of diets and so given a bunch of sort of clinical data can you determine and like given clinical data and given success or failure in the end of whether or not "
    },
    {
        "start": 3013.54,
        "text": "they lost weight can you determine just by this is with yeah with Chuck and so given that can you determine whether or not you're going to be successful just by your initial doctor visit so that's how we've used this "
    }
]