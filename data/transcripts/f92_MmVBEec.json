[
    {
        "text": "good afternoon my name is Kevin Nigerian",
        "start": 0.06,
        "duration": 7.38
    },
    {
        "text": "with department of computation and",
        "start": 4.85,
        "duration": 5.47
    },
    {
        "text": "medicine and by informatics department",
        "start": 7.44,
        "duration": 5.52
    },
    {
        "text": "of emergency medicine department of",
        "start": 10.32,
        "duration": 3.72
    },
    {
        "text": "electrical engineering and computer",
        "start": 12.96,
        "duration": 3.87
    },
    {
        "text": "science at the University of Michigan",
        "start": 14.04,
        "duration": 9.06
    },
    {
        "text": "I'm working with two centers Michigan",
        "start": 16.83,
        "duration": 9.0
    },
    {
        "text": "Institute for data science at University",
        "start": 23.1,
        "duration": 5.759
    },
    {
        "text": "of Michigan also Center for Integrative",
        "start": 25.83,
        "duration": 8.7
    },
    {
        "text": "research in critical care the title of",
        "start": 28.859,
        "duration": 9.331
    },
    {
        "text": "the discussion today would be on future",
        "start": 34.53,
        "duration": 5.67
    },
    {
        "text": "of artificial intelligence in medicine",
        "start": 38.19,
        "duration": 4.56
    },
    {
        "text": "and healthcare focusing on fears and",
        "start": 40.2,
        "duration": 3.589
    },
    {
        "text": "hopes",
        "start": 42.75,
        "duration": 3.45
    },
    {
        "text": "speaking of years this is the first time",
        "start": 43.789,
        "duration": 6.641
    },
    {
        "text": "I'm doing a webinar like that so I hope",
        "start": 46.2,
        "duration": 6.3
    },
    {
        "text": "I check all the technical things hoping",
        "start": 50.43,
        "duration": 5.16
    },
    {
        "text": "that everything works fine but please",
        "start": 52.5,
        "duration": 6.21
    },
    {
        "text": "through the chat let me know if you have",
        "start": 55.59,
        "duration": 7.949
    },
    {
        "text": "any concerns or if anything is not",
        "start": 58.71,
        "duration": 11.12
    },
    {
        "text": "working so we're going to start by",
        "start": 63.539,
        "duration": 9.87
    },
    {
        "text": "acknowledging the sponsors of the",
        "start": 69.83,
        "duration": 6.49
    },
    {
        "text": "research that I will be presenting and I",
        "start": 73.409,
        "duration": 5.941
    },
    {
        "text": "thank our sponsors for funding the",
        "start": 76.32,
        "duration": 5.729
    },
    {
        "text": "research that presented here I'm gonna",
        "start": 79.35,
        "duration": 6.93
    },
    {
        "text": "start by introducing the people in my",
        "start": 82.049,
        "duration": 6.0
    },
    {
        "text": "lab or the actual people who are doing",
        "start": 86.28,
        "duration": 3.6
    },
    {
        "text": "this research and I'm presenting their",
        "start": 88.049,
        "duration": 5.28
    },
    {
        "text": "works basically our lab has a number of",
        "start": 89.88,
        "duration": 7.669
    },
    {
        "text": "faculty associated with them and we have",
        "start": 93.329,
        "duration": 8.15
    },
    {
        "text": "people from the technical side of this",
        "start": 97.549,
        "duration": 7.57
    },
    {
        "text": "mathematicians engineers and also",
        "start": 101.479,
        "duration": 5.68
    },
    {
        "text": "clinicians from different backgrounds",
        "start": 105.119,
        "duration": 4.171
    },
    {
        "text": "who are essentially leading these",
        "start": 107.159,
        "duration": 7.341
    },
    {
        "text": "projects our lab has research manager",
        "start": 109.29,
        "duration": 9.78
    },
    {
        "text": "and dr. Jonathan Creek and we also have",
        "start": 114.5,
        "duration": 7.299
    },
    {
        "text": "research faculty dr. sue Schmidt who's",
        "start": 119.07,
        "duration": 5.07
    },
    {
        "text": "leading the efforts we have a number of",
        "start": 121.799,
        "duration": 6.751
    },
    {
        "text": "postdoctoral fellows and these are the",
        "start": 124.14,
        "duration": 6.209
    },
    {
        "text": "graduate students the people who",
        "start": 128.55,
        "duration": 4.15
    },
    {
        "text": "actually conduct the research in the",
        "start": 130.349,
        "duration": 6.431
    },
    {
        "text": "laughs PhD students some of them are PhD",
        "start": 132.7,
        "duration": 6.21
    },
    {
        "text": "students some of them MD PhD students",
        "start": 136.78,
        "duration": 5.58
    },
    {
        "text": "and we also have a number of very",
        "start": 138.91,
        "duration": 5.82
    },
    {
        "text": "talented smart undergraduate students",
        "start": 142.36,
        "duration": 5.22
    },
    {
        "text": "who are contributing to the research in",
        "start": 144.73,
        "duration": 7.49
    },
    {
        "text": "the lab so I'm gonna start by talking of",
        "start": 147.58,
        "duration": 11.01
    },
    {
        "text": "the fears in using AI in medicine many",
        "start": 152.22,
        "duration": 9.43
    },
    {
        "text": "so I'm gonna outline some of the issues",
        "start": 158.59,
        "duration": 5.16
    },
    {
        "text": "and we get back to them and discuss them",
        "start": 161.65,
        "duration": 5.49
    },
    {
        "text": "later on in a different format first",
        "start": 163.75,
        "duration": 6.209
    },
    {
        "text": "issue is that if you look at solutions",
        "start": 167.14,
        "duration": 4.73
    },
    {
        "text": "designed for medicine based on",
        "start": 169.959,
        "duration": 3.84
    },
    {
        "text": "artificial intelligence and machine",
        "start": 171.87,
        "duration": 4.75
    },
    {
        "text": "learning you realize that majority of",
        "start": 173.799,
        "duration": 4.44
    },
    {
        "text": "what they have developed in in",
        "start": 176.62,
        "duration": 4.679
    },
    {
        "text": "literature stays as publications they",
        "start": 178.239,
        "duration": 6.661
    },
    {
        "text": "don't go beyond publications they you",
        "start": 181.299,
        "duration": 6.181
    },
    {
        "text": "know people cite them people you know",
        "start": 184.9,
        "duration": 4.47
    },
    {
        "text": "discussed them but in reality they don't",
        "start": 187.48,
        "duration": 4.71
    },
    {
        "text": "turn into a commercial product a real",
        "start": 189.37,
        "duration": 6.33
    },
    {
        "text": "product that can help improve the",
        "start": 192.19,
        "duration": 6.389
    },
    {
        "text": "quality of care provided to the patients",
        "start": 195.7,
        "duration": 6.84
    },
    {
        "text": "and all the ones that envision as a",
        "start": 198.579,
        "duration": 6.63
    },
    {
        "text": "product and designed to help with",
        "start": 202.54,
        "duration": 5.97
    },
    {
        "text": "medicine they fail to pass regular",
        "start": 205.209,
        "duration": 5.641
    },
    {
        "text": "clinical trials and never make it to the",
        "start": 208.51,
        "duration": 6.569
    },
    {
        "text": "market and the are the ones that make it",
        "start": 210.85,
        "duration": 7.77
    },
    {
        "text": "to the market or they're getting towards",
        "start": 215.079,
        "duration": 5.851
    },
    {
        "text": "becoming a commercial product some of",
        "start": 218.62,
        "duration": 4.29
    },
    {
        "text": "them they're not if they approve they",
        "start": 220.93,
        "duration": 5.1
    },
    {
        "text": "face to be you know if they approve and",
        "start": 222.91,
        "duration": 6.09
    },
    {
        "text": "all the ones that pass if they approve",
        "start": 226.03,
        "duration": 6.39
    },
    {
        "text": "all the few products that are truly",
        "start": 229.0,
        "duration": 4.98
    },
    {
        "text": "using machine learning and artificial",
        "start": 232.42,
        "duration": 5.34
    },
    {
        "text": "intelligence they get the FDA but",
        "start": 233.98,
        "duration": 6.06
    },
    {
        "text": "they're not widely used by the community",
        "start": 237.76,
        "duration": 4.68
    },
    {
        "text": "so the impact of this product is very",
        "start": 240.04,
        "duration": 4.229
    },
    {
        "text": "limited and that's like in an",
        "start": 242.44,
        "duration": 4.879
    },
    {
        "text": "observation that you see in many",
        "start": 244.269,
        "duration": 5.22
    },
    {
        "text": "publications in many you know",
        "start": 247.319,
        "duration": 3.941
    },
    {
        "text": "discussions that people are having they",
        "start": 249.489,
        "duration": 5.241
    },
    {
        "text": "fail many panels disdain that are up and",
        "start": 251.26,
        "duration": 8.37
    },
    {
        "text": "all of these issues are somehow fueled",
        "start": 254.73,
        "duration": 8.35
    },
    {
        "text": "by a type of hype over artificial",
        "start": 259.63,
        "duration": 5.64
    },
    {
        "text": "intelligence and in particular when",
        "start": 263.08,
        "duration": 3.38
    },
    {
        "text": "applied to medicine",
        "start": 265.27,
        "duration": 4.22
    },
    {
        "text": "and perhaps unreasonable expectations",
        "start": 266.46,
        "duration": 7.109
    },
    {
        "text": "that you know people have in terms of",
        "start": 269.49,
        "duration": 7.44
    },
    {
        "text": "what AI can do in medicine and there is",
        "start": 273.569,
        "duration": 5.521
    },
    {
        "text": "a fear that if we continue having these",
        "start": 276.93,
        "duration": 5.18
    },
    {
        "text": "expectations and not addressing the",
        "start": 279.09,
        "duration": 6.18
    },
    {
        "text": "existing issues one by one we may head",
        "start": 282.11,
        "duration": 6.61
    },
    {
        "text": "into another AI winter and this time",
        "start": 285.27,
        "duration": 6.6
    },
    {
        "text": "mostly in medicine and biology because",
        "start": 288.72,
        "duration": 5.49
    },
    {
        "text": "all those expectations may not you know",
        "start": 291.87,
        "duration": 4.68
    },
    {
        "text": "fulfill and people feel that may perhaps",
        "start": 294.21,
        "duration": 6.66
    },
    {
        "text": "like the problem is with AI so what I'm",
        "start": 296.55,
        "duration": 7.32
    },
    {
        "text": "gonna talk about is I'm gonna show you a",
        "start": 300.87,
        "duration": 5.639
    },
    {
        "text": "challenge treat the major challenges and",
        "start": 303.87,
        "duration": 4.979
    },
    {
        "text": "opportunities that exist when we talk",
        "start": 306.509,
        "duration": 4.771
    },
    {
        "text": "about using AI and machine learning in",
        "start": 308.849,
        "duration": 5.311
    },
    {
        "text": "in healthcare and I addressed some of",
        "start": 311.28,
        "duration": 5.81
    },
    {
        "text": "those challenges in more detail later on",
        "start": 314.16,
        "duration": 6.33
    },
    {
        "text": "so as you see the challenge tree has",
        "start": 317.09,
        "duration": 6.759
    },
    {
        "text": "three types of issues involved in the",
        "start": 320.49,
        "duration": 5.64
    },
    {
        "text": "three types of challenges technical",
        "start": 323.849,
        "duration": 4.141
    },
    {
        "text": "challenges health and clinical",
        "start": 326.13,
        "duration": 4.08
    },
    {
        "text": "challenges and cultural and policy",
        "start": 327.99,
        "duration": 7.82
    },
    {
        "text": "related challenges this one",
        "start": 330.21,
        "duration": 5.6
    },
    {
        "text": "socio-economic and cultural challenges",
        "start": 336.44,
        "duration": 4.24
    },
    {
        "text": "I'm not going to focus too much on those",
        "start": 338.849,
        "duration": 3.63
    },
    {
        "text": "but you can guess that there is a whole",
        "start": 340.68,
        "duration": 4.769
    },
    {
        "text": "lot of you know concerns about how the",
        "start": 342.479,
        "duration": 6.361
    },
    {
        "text": "regulatory and incentive methods and the",
        "start": 345.449,
        "duration": 6.03
    },
    {
        "text": "policies that are put in place can",
        "start": 348.84,
        "duration": 6.629
    },
    {
        "text": "affect the user of AI so what happens if",
        "start": 351.479,
        "duration": 7.921
    },
    {
        "text": "you know AI recommends for certain",
        "start": 355.469,
        "duration": 7.141
    },
    {
        "text": "things in medicine and that course of",
        "start": 359.4,
        "duration": 5.4
    },
    {
        "text": "action that medication that treatment",
        "start": 362.61,
        "duration": 5.25
    },
    {
        "text": "results in a negative outcome for the",
        "start": 364.8,
        "duration": 6.209
    },
    {
        "text": "patient according to the legal system is",
        "start": 367.86,
        "duration": 5.929
    },
    {
        "text": "not clear who exactly gets you know",
        "start": 371.009,
        "duration": 5.641
    },
    {
        "text": "stood for that or who's responsible for",
        "start": 373.789,
        "duration": 5.5
    },
    {
        "text": "that who's the liable entity in it is",
        "start": 376.65,
        "duration": 5.94
    },
    {
        "text": "the clinician that used that is the",
        "start": 379.289,
        "duration": 6.18
    },
    {
        "text": "company that created the the product is",
        "start": 382.59,
        "duration": 5.1
    },
    {
        "text": "the hospital system that acquired the",
        "start": 385.469,
        "duration": 5.73
    },
    {
        "text": "product there's a spectrum of legal and",
        "start": 387.69,
        "duration": 6.24
    },
    {
        "text": "you know policy related issues that are",
        "start": 391.199,
        "duration": 5.611
    },
    {
        "text": "not vague here and I see that you know",
        "start": 393.93,
        "duration": 6.18
    },
    {
        "text": "in at least a couple of cases in the",
        "start": 396.81,
        "duration": 7.08
    },
    {
        "text": "and since the policy on these aspects",
        "start": 400.11,
        "duration": 6.27
    },
    {
        "text": "were not clear that cause total you know",
        "start": 403.89,
        "duration": 5.76
    },
    {
        "text": "an issue for for commercialization",
        "start": 406.38,
        "duration": 5.43
    },
    {
        "text": "through commercialization of the usage",
        "start": 409.65,
        "duration": 5.1
    },
    {
        "text": "of these products what I'm going to",
        "start": 411.81,
        "duration": 5.97
    },
    {
        "text": "focus mainly in here is the technical",
        "start": 414.75,
        "duration": 6.24
    },
    {
        "text": "challenges some of them are data related",
        "start": 417.78,
        "duration": 5.16
    },
    {
        "text": "some of the algorithmic related",
        "start": 420.99,
        "duration": 4.23
    },
    {
        "text": "challenges which I will talk about them",
        "start": 422.94,
        "duration": 6.44
    },
    {
        "text": "next but I also refer to some of the",
        "start": 425.22,
        "duration": 6.99
    },
    {
        "text": "clinical issues and technical issues in",
        "start": 429.38,
        "duration": 5.62
    },
    {
        "text": "terms of the health such as epistemic",
        "start": 432.21,
        "duration": 5.73
    },
    {
        "text": "issues in terms of who defines these",
        "start": 435.0,
        "duration": 5.91
    },
    {
        "text": "these diseases what is the exact",
        "start": 437.94,
        "duration": 4.71
    },
    {
        "text": "definition of the diseases that we're",
        "start": 440.91,
        "duration": 4.59
    },
    {
        "text": "trying to address with AI for instance",
        "start": 442.65,
        "duration": 5.58
    },
    {
        "text": "what is the exact definition of sepsis",
        "start": 445.5,
        "duration": 4.4
    },
    {
        "text": "so if you want to create a",
        "start": 448.23,
        "duration": 4.14
    },
    {
        "text": "computer-aided support system to address",
        "start": 449.9,
        "duration": 5.29
    },
    {
        "text": "sepsis first you have to have a very",
        "start": 452.37,
        "duration": 5.09
    },
    {
        "text": "clear definition of what steps I see and",
        "start": 455.19,
        "duration": 6.42
    },
    {
        "text": "lack of clear clinical definitions can",
        "start": 457.46,
        "duration": 6.61
    },
    {
        "text": "cause issues for the AI then they are is",
        "start": 461.61,
        "duration": 5.66
    },
    {
        "text": "not essentially responsible for that so",
        "start": 464.07,
        "duration": 8.01
    },
    {
        "text": "let's focus on data related challenges",
        "start": 467.27,
        "duration": 10.03
    },
    {
        "text": "in terms of AI in medicine first thing",
        "start": 472.08,
        "duration": 8.09
    },
    {
        "text": "is you have to consider the fact that",
        "start": 477.3,
        "duration": 6.12
    },
    {
        "text": "there is a lot of variability and there",
        "start": 480.17,
        "duration": 5.29
    },
    {
        "text": "is there are a lot of different",
        "start": 483.42,
        "duration": 4.44
    },
    {
        "text": "structures to the data used in in",
        "start": 485.46,
        "duration": 5.1
    },
    {
        "text": "clinical decision support and medicine",
        "start": 487.86,
        "duration": 5.49
    },
    {
        "text": "for instance you have all kinds of",
        "start": 490.56,
        "duration": 5.22
    },
    {
        "text": "images that have specific structure",
        "start": 493.35,
        "duration": 4.23
    },
    {
        "text": "videos that have structure and enough",
        "start": 495.78,
        "duration": 3.87
    },
    {
        "text": "data and electronic health records each",
        "start": 497.58,
        "duration": 4.77
    },
    {
        "text": "one of them having different different",
        "start": 499.65,
        "duration": 5.67
    },
    {
        "text": "sort of format and not just that in",
        "start": 502.35,
        "duration": 5.7
    },
    {
        "text": "medicine the input data that you use the",
        "start": 505.32,
        "duration": 4.95
    },
    {
        "text": "attributes that you use as the input",
        "start": 508.05,
        "duration": 4.71
    },
    {
        "text": "often extremely noisy like you have a",
        "start": 510.27,
        "duration": 5.15
    },
    {
        "text": "lot of missing data you have a lot of",
        "start": 512.76,
        "duration": 5.73
    },
    {
        "text": "noisy attributes that their measurements",
        "start": 515.42,
        "duration": 6.16
    },
    {
        "text": "is not quite certain more importantly",
        "start": 518.49,
        "duration": 5.97
    },
    {
        "text": "the labels that they use they using in",
        "start": 521.58,
        "duration": 6.51
    },
    {
        "text": "medicine are also not very certain as an",
        "start": 524.46,
        "duration": 6.21
    },
    {
        "text": "example the issue of sepsis that I",
        "start": 528.09,
        "duration": 4.85
    },
    {
        "text": "discussed before if you're designing",
        "start": 530.67,
        "duration": 3.36
    },
    {
        "text": "classification",
        "start": 532.94,
        "duration": 3.82
    },
    {
        "text": "technique to predict occurrence of",
        "start": 534.03,
        "duration": 5.79
    },
    {
        "text": "sepsis or even detect the presence of",
        "start": 536.76,
        "duration": 5.66
    },
    {
        "text": "sepsis first you need to know exactly",
        "start": 539.82,
        "duration": 6.96
    },
    {
        "text": "what sepsis is and there is clear lack",
        "start": 542.42,
        "duration": 8.38
    },
    {
        "text": "of you know clarity and and exact",
        "start": 546.78,
        "duration": 6.54
    },
    {
        "text": "definition of things like sepsis a RDS",
        "start": 550.8,
        "duration": 5.01
    },
    {
        "text": "and other things the other thing is the",
        "start": 553.32,
        "duration": 5.48
    },
    {
        "text": "issue of completeness of the data a",
        "start": 555.81,
        "duration": 5.73
    },
    {
        "text": "patient may go to different healthcare",
        "start": 558.8,
        "duration": 4.9
    },
    {
        "text": "systems for the same disease like first",
        "start": 561.54,
        "duration": 5.79
    },
    {
        "text": "they go to the urgent care close to",
        "start": 563.7,
        "duration": 5.46
    },
    {
        "text": "their house they get some tests done and",
        "start": 567.33,
        "duration": 3.69
    },
    {
        "text": "then they go to a hospital then they go",
        "start": 569.16,
        "duration": 4.26
    },
    {
        "text": "to another hospital for the same disease",
        "start": 571.02,
        "duration": 4.56
    },
    {
        "text": "for the same condition for the same",
        "start": 573.42,
        "duration": 4.26
    },
    {
        "text": "issue they may go to different places",
        "start": 575.58,
        "duration": 5.16
    },
    {
        "text": "and none of these databases are truly",
        "start": 577.68,
        "duration": 4.89
    },
    {
        "text": "connected with each other and even",
        "start": 580.74,
        "duration": 4.02
    },
    {
        "text": "within an Hospital within one healthcare",
        "start": 582.57,
        "duration": 5.4
    },
    {
        "text": "system some of the data that we need may",
        "start": 584.76,
        "duration": 5.21
    },
    {
        "text": "be told in a completely different",
        "start": 587.97,
        "duration": 4.92
    },
    {
        "text": "database for example it's on the images",
        "start": 589.97,
        "duration": 7.38
    },
    {
        "text": "are in the packs and clinical data is on",
        "start": 592.89,
        "duration": 7.92
    },
    {
        "text": "electronic health record systems like in",
        "start": 597.35,
        "duration": 7.36
    },
    {
        "text": "a Cerner or epic and there are a bunch",
        "start": 600.81,
        "duration": 6.12
    },
    {
        "text": "of data that are you know sort of",
        "start": 604.71,
        "duration": 5.76
    },
    {
        "text": "collected locally within the you know",
        "start": 606.93,
        "duration": 6.75
    },
    {
        "text": "the the unique that is that is running",
        "start": 610.47,
        "duration": 6.47
    },
    {
        "text": "the test and they never shared or",
        "start": 613.68,
        "duration": 5.31
    },
    {
        "text": "essentially distributed through these",
        "start": 616.94,
        "duration": 4.75
    },
    {
        "text": "any of these databases so completeness",
        "start": 618.99,
        "duration": 4.91
    },
    {
        "text": "of the data is another issue",
        "start": 621.69,
        "duration": 5.25
    },
    {
        "text": "another thing is data security and",
        "start": 623.9,
        "duration": 6.07
    },
    {
        "text": "privacy and data sharing because of all",
        "start": 626.94,
        "duration": 5.22
    },
    {
        "text": "the concerns that different healthcare",
        "start": 629.97,
        "duration": 4.619
    },
    {
        "text": "systems has a bad part about the privacy",
        "start": 632.16,
        "duration": 6.99
    },
    {
        "text": "of the data having personnel has",
        "start": 634.589,
        "duration": 8.311
    },
    {
        "text": "information pH I data in there often",
        "start": 639.15,
        "duration": 8.07
    },
    {
        "text": "they cannot pair data with others and",
        "start": 642.9,
        "duration": 7.83
    },
    {
        "text": "they have to anonymize the data and some",
        "start": 647.22,
        "duration": 6.78
    },
    {
        "text": "of these anonymization will somehow",
        "start": 650.73,
        "duration": 5.7
    },
    {
        "text": "remove the information that might be",
        "start": 654.0,
        "duration": 4.44
    },
    {
        "text": "helpful for clinical decision support",
        "start": 656.43,
        "duration": 4.59
    },
    {
        "text": "system or on the other hand may they may",
        "start": 658.44,
        "duration": 5.25
    },
    {
        "text": "not remove some of the you know some of",
        "start": 661.02,
        "duration": 4.68
    },
    {
        "text": "the data that they are not considered as",
        "start": 663.69,
        "duration": 4.11
    },
    {
        "text": "PHR but combination of",
        "start": 665.7,
        "duration": 5.999
    },
    {
        "text": "these can essentially be a risk for",
        "start": 667.8,
        "duration": 7.399
    },
    {
        "text": "privacy and security of the of the data",
        "start": 671.699,
        "duration": 6.151
    },
    {
        "text": "but there are concerns about that and",
        "start": 675.199,
        "duration": 5.531
    },
    {
        "text": "because of these concerns over data",
        "start": 677.85,
        "duration": 7.589
    },
    {
        "text": "sharing we we have the issue of not",
        "start": 680.73,
        "duration": 7.649
    },
    {
        "text": "having enough large data bases large and",
        "start": 685.439,
        "duration": 6.84
    },
    {
        "text": "comprehensive data bases so in any other",
        "start": 688.379,
        "duration": 5.221
    },
    {
        "text": "things in machine learning and",
        "start": 692.279,
        "duration": 3.691
    },
    {
        "text": "artificial intelligence the quality of",
        "start": 693.6,
        "duration": 4.56
    },
    {
        "text": "the model that you develop to the most",
        "start": 695.97,
        "duration": 4.349
    },
    {
        "text": "part depends on the comprehensiveness",
        "start": 698.16,
        "duration": 3.989
    },
    {
        "text": "and the size of the data base that",
        "start": 700.319,
        "duration": 4.11
    },
    {
        "text": "you're using and these issues that I",
        "start": 702.149,
        "duration": 4.98
    },
    {
        "text": "mentioned which prevent creating the",
        "start": 704.429,
        "duration": 4.741
    },
    {
        "text": "data bases that you can actually use to",
        "start": 707.129,
        "duration": 6.36
    },
    {
        "text": "create a reliable mother then",
        "start": 709.17,
        "duration": 6.599
    },
    {
        "text": "algorithmic side most of our thought",
        "start": 713.489,
        "duration": 3.96
    },
    {
        "text": "would be focusing on the algorithmic",
        "start": 715.769,
        "duration": 4.44
    },
    {
        "text": "challenges algorithmic challenges the",
        "start": 717.449,
        "duration": 5.49
    },
    {
        "text": "first point that I can mention here is",
        "start": 720.209,
        "duration": 6.93
    },
    {
        "text": "the need to customize machine learning",
        "start": 722.939,
        "duration": 7.11
    },
    {
        "text": "algorithm to match any specific",
        "start": 727.139,
        "duration": 6.69
    },
    {
        "text": "application that we are processing one",
        "start": 730.049,
        "duration": 6.27
    },
    {
        "text": "observation that anybody can make is",
        "start": 733.829,
        "duration": 5.94
    },
    {
        "text": "that recently and more specifically in",
        "start": 736.319,
        "duration": 8.041
    },
    {
        "text": "medicine people have been using one size",
        "start": 739.769,
        "duration": 6.961
    },
    {
        "text": "fits all kind of approach in machine",
        "start": 744.36,
        "duration": 4.199
    },
    {
        "text": "learning for example they have this deep",
        "start": 746.73,
        "duration": 5.419
    },
    {
        "text": "learning method that regardless of what",
        "start": 748.559,
        "duration": 6.181
    },
    {
        "text": "exact problem they're addressing they",
        "start": 752.149,
        "duration": 4.63
    },
    {
        "text": "put the data in this machine and they",
        "start": 754.74,
        "duration": 4.409
    },
    {
        "text": "shake it and they expect to have a model",
        "start": 756.779,
        "duration": 4.8
    },
    {
        "text": "that would be suitable for that specific",
        "start": 759.149,
        "duration": 6.271
    },
    {
        "text": "application which essentially is not",
        "start": 761.579,
        "duration": 7.651
    },
    {
        "text": "very realistic expectation in reality",
        "start": 765.42,
        "duration": 7.529
    },
    {
        "text": "every every application every domain",
        "start": 769.23,
        "duration": 6.689
    },
    {
        "text": "requires particular type of mother that",
        "start": 772.949,
        "duration": 6.541
    },
    {
        "text": "matches the reality of that that problem",
        "start": 775.919,
        "duration": 7.59
    },
    {
        "text": "that application and the tendency to use",
        "start": 779.49,
        "duration": 6.089
    },
    {
        "text": "the same machine learning for everything",
        "start": 783.509,
        "duration": 5.16
    },
    {
        "text": "has created you know some results that",
        "start": 785.579,
        "duration": 5.91
    },
    {
        "text": "are not reproducible and some models",
        "start": 788.669,
        "duration": 5.491
    },
    {
        "text": "that are not robust enough so it's",
        "start": 791.489,
        "duration": 5.19
    },
    {
        "text": "highly desirable to look at the",
        "start": 794.16,
        "duration": 5.82
    },
    {
        "text": "realities of medical applications and",
        "start": 796.679,
        "duration": 4.661
    },
    {
        "text": "see if we can Jenny",
        "start": 799.98,
        "duration": 3.73
    },
    {
        "text": "algorithms that match those a specific",
        "start": 801.34,
        "duration": 6.75
    },
    {
        "text": "application second problem is that in",
        "start": 803.71,
        "duration": 6.12
    },
    {
        "text": "medicine law as I mentioned a few",
        "start": 808.09,
        "duration": 4.8
    },
    {
        "text": "minutes ago majority of the databases",
        "start": 809.83,
        "duration": 6.51
    },
    {
        "text": "are extremely sparse in other words like",
        "start": 812.89,
        "duration": 5.85
    },
    {
        "text": "you know you do have a bunch of",
        "start": 816.34,
        "duration": 5.28
    },
    {
        "text": "variables for which you don't have a lot",
        "start": 818.74,
        "duration": 6.81
    },
    {
        "text": "of instances you have some examples but",
        "start": 821.62,
        "duration": 6.42
    },
    {
        "text": "in if you look at the data as a",
        "start": 825.55,
        "duration": 6.99
    },
    {
        "text": "comprehensive like you know entity there",
        "start": 828.04,
        "duration": 6.57
    },
    {
        "text": "are so many missing data points in it",
        "start": 832.54,
        "duration": 5.1
    },
    {
        "text": "and that causes an issue for training",
        "start": 834.61,
        "duration": 4.77
    },
    {
        "text": "neural network or any other machine",
        "start": 837.64,
        "duration": 3.72
    },
    {
        "text": "learning algorithm in particular neural",
        "start": 839.38,
        "duration": 5.85
    },
    {
        "text": "networks and in order to address that we",
        "start": 841.36,
        "duration": 7.11
    },
    {
        "text": "feel that there should be approaches in",
        "start": 845.23,
        "duration": 5.549
    },
    {
        "text": "machine learning that allow the domain",
        "start": 848.47,
        "duration": 5.58
    },
    {
        "text": "knowledge what else mean is known about",
        "start": 850.779,
        "duration": 6.031
    },
    {
        "text": "the application to help address this a",
        "start": 854.05,
        "duration": 5.76
    },
    {
        "text": "sparsity I'm gonna leave it vague at",
        "start": 856.81,
        "duration": 5.07
    },
    {
        "text": "that level and I get back to it when I",
        "start": 859.81,
        "duration": 4.35
    },
    {
        "text": "talk about you know some potential",
        "start": 861.88,
        "duration": 6.42
    },
    {
        "text": "approaches to that and another factor is",
        "start": 864.16,
        "duration": 7.14
    },
    {
        "text": "if you look at what people publish in",
        "start": 868.3,
        "duration": 7.039
    },
    {
        "text": "the field first thing that come",
        "start": 871.3,
        "duration": 6.36
    },
    {
        "text": "especially like you know statisticians",
        "start": 875.339,
        "duration": 5.471
    },
    {
        "text": "and people with more mathematical",
        "start": 877.66,
        "duration": 5.7
    },
    {
        "text": "approach to the problems they they see",
        "start": 880.81,
        "duration": 5.34
    },
    {
        "text": "is the fact that some of these models",
        "start": 883.36,
        "duration": 5.45
    },
    {
        "text": "are not properly validated and assessed",
        "start": 886.15,
        "duration": 6.36
    },
    {
        "text": "they use a certain small amount of data",
        "start": 888.81,
        "duration": 8.2
    },
    {
        "text": "to pain a very large model and then the",
        "start": 892.51,
        "duration": 7.53
    },
    {
        "text": "assessment is is not comprehensive",
        "start": 897.01,
        "duration": 5.76
    },
    {
        "text": "enough to actually show that the model",
        "start": 900.04,
        "duration": 5.34
    },
    {
        "text": "is not doing overfitting many of these",
        "start": 902.77,
        "duration": 5.97
    },
    {
        "text": "methods are not are not reproducible in",
        "start": 905.38,
        "duration": 5.25
    },
    {
        "text": "a sense that they created with the data",
        "start": 908.74,
        "duration": 3.9
    },
    {
        "text": "that is either too small it has the",
        "start": 910.63,
        "duration": 3.84
    },
    {
        "text": "flavor of one particular healthcare",
        "start": 912.64,
        "duration": 4.53
    },
    {
        "text": "system and then tested in larger",
        "start": 914.47,
        "duration": 5.67
    },
    {
        "text": "databases on other databases on other",
        "start": 917.17,
        "duration": 5.609
    },
    {
        "text": "healthcare system data they completely",
        "start": 920.14,
        "duration": 5.85
    },
    {
        "text": "fail and this is because full validation",
        "start": 922.779,
        "duration": 5.131
    },
    {
        "text": "methods that are used for majority of",
        "start": 925.99,
        "duration": 5.06
    },
    {
        "text": "these machine learning algorithm and",
        "start": 927.91,
        "duration": 5.81
    },
    {
        "text": "last item is",
        "start": 931.05,
        "duration": 5.219
    },
    {
        "text": "is the challenge that is becoming more",
        "start": 933.72,
        "duration": 6.809
    },
    {
        "text": "and more evident in in medical field and",
        "start": 936.269,
        "duration": 9.0
    },
    {
        "text": "that's lack of you know ability in terms",
        "start": 940.529,
        "duration": 6.271
    },
    {
        "text": "of like these machine learning",
        "start": 945.269,
        "duration": 4.201
    },
    {
        "text": "algorithms to address the structure and",
        "start": 946.8,
        "duration": 5.55
    },
    {
        "text": "the temporal relation of the data it's",
        "start": 949.47,
        "duration": 6.27
    },
    {
        "text": "in order to see how important structure",
        "start": 952.35,
        "duration": 5.79
    },
    {
        "text": "is imagine that if I show you a",
        "start": 955.74,
        "duration": 4.92
    },
    {
        "text": "structure two dimensional structured",
        "start": 958.14,
        "duration": 5.4
    },
    {
        "text": "data we call it an image if I show you",
        "start": 960.66,
        "duration": 5.85
    },
    {
        "text": "an image and I ask you what you see in",
        "start": 963.54,
        "duration": 4.65
    },
    {
        "text": "that image let's say there's a like you",
        "start": 966.51,
        "duration": 3.6
    },
    {
        "text": "know image of a person you will",
        "start": 968.19,
        "duration": 4.38
    },
    {
        "text": "immediately just by looking at the two",
        "start": 970.11,
        "duration": 6.419
    },
    {
        "text": "dimensional entity you know that this is",
        "start": 972.57,
        "duration": 6.269
    },
    {
        "text": "a person a person that you know perhaps",
        "start": 976.529,
        "duration": 5.281
    },
    {
        "text": "but if I get the same data I get the",
        "start": 978.839,
        "duration": 5.701
    },
    {
        "text": "same image and I flatten the data and",
        "start": 981.81,
        "duration": 4.86
    },
    {
        "text": "make a big vector out of that like I'm",
        "start": 984.54,
        "duration": 4.289
    },
    {
        "text": "concatenate all the rows one after",
        "start": 986.67,
        "duration": 4.74
    },
    {
        "text": "another ending up with a large peg that",
        "start": 988.829,
        "duration": 5.401
    },
    {
        "text": "I haven't changed the pixel values I",
        "start": 991.41,
        "duration": 4.59
    },
    {
        "text": "haven't changed the information in any",
        "start": 994.23,
        "duration": 5.25
    },
    {
        "text": "of like individual pixels but by making",
        "start": 996.0,
        "duration": 5.61
    },
    {
        "text": "a very very long vector as opposed to",
        "start": 999.48,
        "duration": 4.08
    },
    {
        "text": "the structure two-dimensional structure",
        "start": 1001.61,
        "duration": 5.01
    },
    {
        "text": "if I show you this long vector and I ask",
        "start": 1003.56,
        "duration": 5.76
    },
    {
        "text": "you what is it that I'm showing in this",
        "start": 1006.62,
        "duration": 4.68
    },
    {
        "text": "image you cannot say that and it's",
        "start": 1009.32,
        "duration": 4.38
    },
    {
        "text": "because because of the fact that the",
        "start": 1011.3,
        "duration": 5.76
    },
    {
        "text": "most important information in that image",
        "start": 1013.7,
        "duration": 6.12
    },
    {
        "text": "was the 2d structure and by flattening",
        "start": 1017.06,
        "duration": 5.13
    },
    {
        "text": "the data you're actually destroying the",
        "start": 1019.82,
        "duration": 5.609
    },
    {
        "text": "main information in the data and if you",
        "start": 1022.19,
        "duration": 5.66
    },
    {
        "text": "look at majority of these algorithms",
        "start": 1025.429,
        "duration": 5.191
    },
    {
        "text": "these algorithms are actually doing",
        "start": 1027.85,
        "duration": 4.9
    },
    {
        "text": "nothing but that they get the",
        "start": 1030.62,
        "duration": 4.86
    },
    {
        "text": "information flatten the information then",
        "start": 1032.75,
        "duration": 5.189
    },
    {
        "text": "we'll try to figure out what was the",
        "start": 1035.48,
        "duration": 4.979
    },
    {
        "text": "object that they process and that's an",
        "start": 1037.939,
        "duration": 5.64
    },
    {
        "text": "issue that was recognized by the",
        "start": 1040.459,
        "duration": 5.761
    },
    {
        "text": "community and and now there are metals",
        "start": 1043.579,
        "duration": 5.191
    },
    {
        "text": "like deep learning is trying to in some",
        "start": 1046.22,
        "duration": 4.02
    },
    {
        "text": "way address that there are other",
        "start": 1048.77,
        "duration": 4.59
    },
    {
        "text": "techniques that are doing the same the",
        "start": 1050.24,
        "duration": 7.05
    },
    {
        "text": "same task so I talked about all these",
        "start": 1053.36,
        "duration": 7.68
    },
    {
        "text": "issues and fears and challenges I think",
        "start": 1057.29,
        "duration": 6.629
    },
    {
        "text": "it's now it's a good time to talk about",
        "start": 1061.04,
        "duration": 4.769
    },
    {
        "text": "some of the hopes some of the good thing",
        "start": 1063.919,
        "duration": 4.89
    },
    {
        "text": "happening one thing is that FDA and",
        "start": 1065.809,
        "duration": 6.891
    },
    {
        "text": "other regulatory authorities I think the",
        "start": 1068.809,
        "duration": 6.09
    },
    {
        "text": "improving the guidelines they're",
        "start": 1072.7,
        "duration": 5.229
    },
    {
        "text": "becoming more of a dove what an AI based",
        "start": 1074.899,
        "duration": 5.551
    },
    {
        "text": "product is and and they're trying to",
        "start": 1077.929,
        "duration": 4.651
    },
    {
        "text": "come up with better way of testing and",
        "start": 1080.45,
        "duration": 4.949
    },
    {
        "text": "validating these things they're some of",
        "start": 1082.58,
        "duration": 4.26
    },
    {
        "text": "the regulations that they have they're",
        "start": 1085.399,
        "duration": 3.6
    },
    {
        "text": "still very old and outdated but I think",
        "start": 1086.84,
        "duration": 4.35
    },
    {
        "text": "there is a trend to better understand",
        "start": 1088.999,
        "duration": 4.53
    },
    {
        "text": "where AI is stands machine learning and",
        "start": 1091.19,
        "duration": 6.17
    },
    {
        "text": "artificial intelligence stand on how to",
        "start": 1093.529,
        "duration": 7.59
    },
    {
        "text": "test them in a clinical setting the",
        "start": 1097.36,
        "duration": 6.1
    },
    {
        "text": "other thing there are so many consurtio",
        "start": 1101.119,
        "duration": 5.371
    },
    {
        "text": "that are dealing with creating larger",
        "start": 1103.46,
        "duration": 5.49
    },
    {
        "text": "databases even though they're not as",
        "start": 1106.49,
        "duration": 4.559
    },
    {
        "text": "comprehensive as you want them to be but",
        "start": 1108.95,
        "duration": 5.13
    },
    {
        "text": "there's still so many you know there are",
        "start": 1111.049,
        "duration": 6.57
    },
    {
        "text": "so many efforts national and",
        "start": 1114.08,
        "duration": 5.75
    },
    {
        "text": "international efforts that are trying to",
        "start": 1117.619,
        "duration": 5.04
    },
    {
        "text": "create larger databases that are more",
        "start": 1119.83,
        "duration": 5.64
    },
    {
        "text": "useful for AI and and machine learning",
        "start": 1122.659,
        "duration": 6.11
    },
    {
        "text": "the other thing is I would say that some",
        "start": 1125.47,
        "duration": 7.12
    },
    {
        "text": "components on parts of the medical",
        "start": 1128.769,
        "duration": 7.39
    },
    {
        "text": "community they are becoming more",
        "start": 1132.59,
        "duration": 5.459
    },
    {
        "text": "reasonable with their expectations from",
        "start": 1136.159,
        "duration": 5.041
    },
    {
        "text": "AI they're not expecting magic from AI",
        "start": 1138.049,
        "duration": 5.73
    },
    {
        "text": "they don't expect a box that can always",
        "start": 1141.2,
        "duration": 5.939
    },
    {
        "text": "tell them what they want to hear and all",
        "start": 1143.779,
        "duration": 5.64
    },
    {
        "text": "the bulletins are also improving and",
        "start": 1147.139,
        "duration": 4.681
    },
    {
        "text": "addressing some of these challenges so",
        "start": 1149.419,
        "duration": 5.041
    },
    {
        "text": "from now what I'm gonna do I'm gonna",
        "start": 1151.82,
        "duration": 5.52
    },
    {
        "text": "focus on on how to address some of these",
        "start": 1154.46,
        "duration": 6.839
    },
    {
        "text": "challenges I would love to just focus on",
        "start": 1157.34,
        "duration": 7.559
    },
    {
        "text": "the overall methods of addressing these",
        "start": 1161.299,
        "duration": 5.76
    },
    {
        "text": "challenges and don't talk about our own",
        "start": 1164.899,
        "duration": 5.671
    },
    {
        "text": "research but in reality I know the",
        "start": 1167.059,
        "duration": 6.21
    },
    {
        "text": "solutions that I'm using better than",
        "start": 1170.57,
        "duration": 5.91
    },
    {
        "text": "others what I'm trying to do is talk",
        "start": 1173.269,
        "duration": 5.61
    },
    {
        "text": "about these challenges and give you an",
        "start": 1176.48,
        "duration": 4.71
    },
    {
        "text": "example of a solution that we have",
        "start": 1178.879,
        "duration": 5.43
    },
    {
        "text": "develop in our lab so the first",
        "start": 1181.19,
        "duration": 6.739
    },
    {
        "text": "challenge is systemic integration of",
        "start": 1184.309,
        "duration": 6.651
    },
    {
        "text": "auxiliary information that we have",
        "start": 1187.929,
        "duration": 8.2
    },
    {
        "text": "around around the subject remember I I",
        "start": 1190.96,
        "duration": 7.54
    },
    {
        "text": "mentioned that",
        "start": 1196.129,
        "duration": 4.951
    },
    {
        "text": "when the data is very sparse in order to",
        "start": 1198.5,
        "duration": 5.76
    },
    {
        "text": "have better machine learning or better",
        "start": 1201.08,
        "duration": 6.12
    },
    {
        "text": "modeling of the problem you have to use",
        "start": 1204.26,
        "duration": 7.59
    },
    {
        "text": "what else is available in the domain you",
        "start": 1207.2,
        "duration": 6.21
    },
    {
        "text": "have to use the domain knowledge you",
        "start": 1211.85,
        "duration": 3.51
    },
    {
        "text": "have to look at other data that can",
        "start": 1213.41,
        "duration": 4.77
    },
    {
        "text": "somehow affect your ability to address",
        "start": 1215.36,
        "duration": 6.17
    },
    {
        "text": "this and to model this a sparse data",
        "start": 1218.18,
        "duration": 6.09
    },
    {
        "text": "this particular example that I'm going",
        "start": 1221.53,
        "duration": 5.23
    },
    {
        "text": "to talk about is an algebraic approach",
        "start": 1224.27,
        "duration": 4.92
    },
    {
        "text": "to drug repositioning and there are",
        "start": 1226.76,
        "duration": 5.25
    },
    {
        "text": "repurposing that we have you know",
        "start": 1229.19,
        "duration": 6.63
    },
    {
        "text": "started working on and it seems to be",
        "start": 1232.01,
        "duration": 5.97
    },
    {
        "text": "doing exactly what what we wanted to do",
        "start": 1235.82,
        "duration": 4.76
    },
    {
        "text": "in terms of integration of auxilary",
        "start": 1237.98,
        "duration": 6.9
    },
    {
        "text": "information so just a quick couple of",
        "start": 1240.58,
        "duration": 9.04
    },
    {
        "text": "definitions drug repositioning is user",
        "start": 1244.88,
        "duration": 7.68
    },
    {
        "text": "job and already used drug for one",
        "start": 1249.62,
        "duration": 5.27
    },
    {
        "text": "purpose for another purpose for example",
        "start": 1252.56,
        "duration": 5.76
    },
    {
        "text": "a press card that I mentioned in here",
        "start": 1254.89,
        "duration": 5.71
    },
    {
        "text": "was originally developed for prostate",
        "start": 1258.32,
        "duration": 5.36
    },
    {
        "text": "cancer and now people are using that for",
        "start": 1260.6,
        "duration": 6.48
    },
    {
        "text": "some sort of male pattern baldness as",
        "start": 1263.68,
        "duration": 6.01
    },
    {
        "text": "well so the drug was used for some",
        "start": 1267.08,
        "duration": 4.68
    },
    {
        "text": "purpose now you're seeing that if you",
        "start": 1269.69,
        "duration": 3.87
    },
    {
        "text": "can use it for another purpose as well",
        "start": 1271.76,
        "duration": 4.86
    },
    {
        "text": "and drug repositioning is the case that",
        "start": 1273.56,
        "duration": 5.97
    },
    {
        "text": "there is a a drug that has failed for",
        "start": 1276.62,
        "duration": 4.5
    },
    {
        "text": "certain application and now you're",
        "start": 1279.53,
        "duration": 3.54
    },
    {
        "text": "asking yourself can be used for another",
        "start": 1281.12,
        "duration": 4.59
    },
    {
        "text": "purpose for another application so this",
        "start": 1283.07,
        "duration": 10.79
    },
    {
        "text": "is a huge total effort and direction in",
        "start": 1285.71,
        "duration": 10.38
    },
    {
        "text": "pharmaceutical research and we're trying",
        "start": 1293.86,
        "duration": 4.6
    },
    {
        "text": "to somehow use algebraic method to help",
        "start": 1296.09,
        "duration": 5.79
    },
    {
        "text": "with that so if you look at what why we",
        "start": 1298.46,
        "duration": 5.61
    },
    {
        "text": "need like algebraic and computational",
        "start": 1301.88,
        "duration": 4.17
    },
    {
        "text": "method towards that you have to think",
        "start": 1304.07,
        "duration": 5.58
    },
    {
        "text": "about that the fact that typically they",
        "start": 1306.05,
        "duration": 6.81
    },
    {
        "text": "have a few thousand if not a few tens of",
        "start": 1309.65,
        "duration": 6.54
    },
    {
        "text": "thousands of small molecules that they",
        "start": 1312.86,
        "duration": 8.55
    },
    {
        "text": "use for the drugs and they have a few",
        "start": 1316.19,
        "duration": 7.88
    },
    {
        "text": "thousand if not tens of thousands of",
        "start": 1321.41,
        "duration": 5.51
    },
    {
        "text": "potential targets that could be you know",
        "start": 1324.07,
        "duration": 6.16
    },
    {
        "text": "proteins could be genes could be other",
        "start": 1326.92,
        "duration": 5.71
    },
    {
        "text": "factors but we have",
        "start": 1330.23,
        "duration": 4.14
    },
    {
        "text": "a lot of you know if you think of a",
        "start": 1332.63,
        "duration": 4.67
    },
    {
        "text": "matrix of drug versus targets we have",
        "start": 1334.37,
        "duration": 6.33
    },
    {
        "text": "high dimensional matrix but this matrix",
        "start": 1337.3,
        "duration": 7.24
    },
    {
        "text": "is highly highly sparse in a sense that",
        "start": 1340.7,
        "duration": 7.46
    },
    {
        "text": "one drug was tested against one or a few",
        "start": 1344.54,
        "duration": 6.03
    },
    {
        "text": "targets and you don't know anything",
        "start": 1348.16,
        "duration": 4.99
    },
    {
        "text": "about the interaction between the this",
        "start": 1350.57,
        "duration": 6.84
    },
    {
        "text": "drug and other potential targets so you",
        "start": 1353.15,
        "duration": 7.38
    },
    {
        "text": "are dealing with sparseness of sometimes",
        "start": 1357.41,
        "duration": 8.96
    },
    {
        "text": "around 99.997% so there are very few",
        "start": 1360.53,
        "duration": 8.58
    },
    {
        "text": "known numbers in there whether it's zero",
        "start": 1366.37,
        "duration": 5.47
    },
    {
        "text": "saying that there is no interaction or",
        "start": 1369.11,
        "duration": 4.26
    },
    {
        "text": "there is one there saying is an",
        "start": 1371.84,
        "duration": 4.14
    },
    {
        "text": "interaction and the rest of the numbers",
        "start": 1373.37,
        "duration": 7.44
    },
    {
        "text": "in the rest of 99.997% it just unknown",
        "start": 1375.98,
        "duration": 7.83
    },
    {
        "text": "so you don't know so if you think of",
        "start": 1380.81,
        "duration": 5.22
    },
    {
        "text": "this problem in terms of mathematical",
        "start": 1383.81,
        "duration": 4.92
    },
    {
        "text": "formulation it's nothing but matrix",
        "start": 1386.03,
        "duration": 4.74
    },
    {
        "text": "completion in a sense that you have a",
        "start": 1388.73,
        "duration": 4.77
    },
    {
        "text": "matrix of drug versus targets but we",
        "start": 1390.77,
        "duration": 4.77
    },
    {
        "text": "have very few numbers in there you want",
        "start": 1393.5,
        "duration": 5.46
    },
    {
        "text": "to somehow use what you know to complete",
        "start": 1395.54,
        "duration": 6.57
    },
    {
        "text": "this matrix and estimate the interaction",
        "start": 1398.96,
        "duration": 5.78
    },
    {
        "text": "potential potential interaction between",
        "start": 1402.11,
        "duration": 7.32
    },
    {
        "text": "drugs and and other other proteins so",
        "start": 1404.74,
        "duration": 7.12
    },
    {
        "text": "various techniques have been designed to",
        "start": 1409.43,
        "duration": 4.76
    },
    {
        "text": "address that some of them are based on",
        "start": 1411.86,
        "duration": 4.62
    },
    {
        "text": "similarity based methods some of them",
        "start": 1414.19,
        "duration": 6.13
    },
    {
        "text": "you know they're based on other",
        "start": 1416.48,
        "duration": 5.67
    },
    {
        "text": "techniques in machine learning such as",
        "start": 1420.32,
        "duration": 4.14
    },
    {
        "text": "deep learning and some of them are using",
        "start": 1422.15,
        "duration": 4.77
    },
    {
        "text": "algebraic methods like matrix",
        "start": 1424.46,
        "duration": 5.7
    },
    {
        "text": "factorization what we want to do we want",
        "start": 1426.92,
        "duration": 6.66
    },
    {
        "text": "to go back to our policy and our",
        "start": 1430.16,
        "duration": 5.37
    },
    {
        "text": "understanding that there is a whole lot",
        "start": 1433.58,
        "duration": 4.32
    },
    {
        "text": "of you know side informations around",
        "start": 1435.53,
        "duration": 5.61
    },
    {
        "text": "this matrix that can help us complete",
        "start": 1437.9,
        "duration": 6.06
    },
    {
        "text": "these more intelligently and have a more",
        "start": 1441.14,
        "duration": 5.07
    },
    {
        "text": "reliable model first approach is",
        "start": 1443.96,
        "duration": 4.92
    },
    {
        "text": "something we call it coupled matrix",
        "start": 1446.21,
        "duration": 6.15
    },
    {
        "text": "matrix completion so this is the matrix",
        "start": 1448.88,
        "duration": 6.51
    },
    {
        "text": "that we want to complete this is the",
        "start": 1452.36,
        "duration": 6.72
    },
    {
        "text": "drug versus target but in reality we",
        "start": 1455.39,
        "duration": 5.94
    },
    {
        "text": "know a whole lot about the interaction",
        "start": 1459.08,
        "duration": 4.41
    },
    {
        "text": "between the drugs for example we look at",
        "start": 1461.33,
        "duration": 3.96
    },
    {
        "text": "the 3d structure of these",
        "start": 1463.49,
        "duration": 3.99
    },
    {
        "text": "and we can say how similar the structure",
        "start": 1465.29,
        "duration": 4.44
    },
    {
        "text": "of these molecules are to each other",
        "start": 1467.48,
        "duration": 5.07
    },
    {
        "text": "so that's some information there is",
        "start": 1469.73,
        "duration": 4.38
    },
    {
        "text": "another information that deals with",
        "start": 1472.55,
        "duration": 3.78
    },
    {
        "text": "targets the relationship between the",
        "start": 1474.11,
        "duration": 4.55
    },
    {
        "text": "targets we have protein-protein",
        "start": 1476.33,
        "duration": 5.28
    },
    {
        "text": "interaction matrices that you know very",
        "start": 1478.66,
        "duration": 6.28
    },
    {
        "text": "quantitatively tell us how these",
        "start": 1481.61,
        "duration": 5.52
    },
    {
        "text": "proteins interact with each other so",
        "start": 1484.94,
        "duration": 4.74
    },
    {
        "text": "this is information auxilary information",
        "start": 1487.13,
        "duration": 4.73
    },
    {
        "text": "that is highly valuable this is also",
        "start": 1489.68,
        "duration": 5.04
    },
    {
        "text": "exhibiting formation is highly value but",
        "start": 1491.86,
        "duration": 4.87
    },
    {
        "text": "the question is can we use these",
        "start": 1494.72,
        "duration": 4.71
    },
    {
        "text": "additional matrices and make sex and miy",
        "start": 1496.73,
        "duration": 5.04
    },
    {
        "text": "in order to help complete",
        "start": 1499.43,
        "duration": 5.55
    },
    {
        "text": "mxy so that's one thing that we started",
        "start": 1501.77,
        "duration": 4.68
    },
    {
        "text": "working on there are others who are",
        "start": 1504.98,
        "duration": 6.57
    },
    {
        "text": "doing that but with the help of dr. harm",
        "start": 1506.45,
        "duration": 9.8
    },
    {
        "text": "dicks and was a well known algebraic",
        "start": 1511.55,
        "duration": 8.1
    },
    {
        "text": "theoretical algebraic mathematician we",
        "start": 1516.25,
        "duration": 6.0
    },
    {
        "text": "came up with an approach that",
        "start": 1519.65,
        "duration": 5.21
    },
    {
        "text": "systematically uses the information in",
        "start": 1522.25,
        "duration": 5.74
    },
    {
        "text": "these two auxilary matrices to better",
        "start": 1524.86,
        "duration": 9.22
    },
    {
        "text": "complete this drug target interaction",
        "start": 1527.99,
        "duration": 8.28
    },
    {
        "text": "matrix but not just that",
        "start": 1534.08,
        "duration": 4.68
    },
    {
        "text": "keep in mind that if you want to look at",
        "start": 1536.27,
        "duration": 4.23
    },
    {
        "text": "the interaction between the drugs",
        "start": 1538.76,
        "duration": 4.62
    },
    {
        "text": "between these small molecules there is",
        "start": 1540.5,
        "duration": 5.46
    },
    {
        "text": "no just one way of looking at for",
        "start": 1543.38,
        "duration": 4.05
    },
    {
        "text": "example you can look at the interaction",
        "start": 1545.96,
        "duration": 3.66
    },
    {
        "text": "of these molecules in different pH",
        "start": 1547.43,
        "duration": 4.41
    },
    {
        "text": "environment you can look at this from",
        "start": 1549.62,
        "duration": 4.98
    },
    {
        "text": "there are different different simulators",
        "start": 1551.84,
        "duration": 4.86
    },
    {
        "text": "different models to show the 3d",
        "start": 1554.6,
        "duration": 4.38
    },
    {
        "text": "structure singularities there are all",
        "start": 1556.7,
        "duration": 4.83
    },
    {
        "text": "kinds of other ways of looking at",
        "start": 1558.98,
        "duration": 5.73
    },
    {
        "text": "similarity of drugs to drug so there is",
        "start": 1561.53,
        "duration": 6.26
    },
    {
        "text": "in reality that we have multiple",
        "start": 1564.71,
        "duration": 5.64
    },
    {
        "text": "matrixes like that same thing with",
        "start": 1567.79,
        "duration": 3.97
    },
    {
        "text": "targets you can look at the interaction",
        "start": 1570.35,
        "duration": 3.93
    },
    {
        "text": "between the targets in many different",
        "start": 1571.76,
        "duration": 5.45
    },
    {
        "text": "ways and as a result we are dealing with",
        "start": 1574.28,
        "duration": 5.7
    },
    {
        "text": "another problem and more comprehensive",
        "start": 1577.21,
        "duration": 5.64
    },
    {
        "text": "problem called coupled tensor matrix",
        "start": 1579.98,
        "duration": 5.58
    },
    {
        "text": "competition in in other words you want",
        "start": 1582.85,
        "duration": 4.72
    },
    {
        "text": "to again you want to complete this",
        "start": 1585.56,
        "duration": 5.55
    },
    {
        "text": "matrix that's your target matrix but you",
        "start": 1587.57,
        "duration": 6.48
    },
    {
        "text": "have two tensors a stack of matrices",
        "start": 1591.11,
        "duration": 6.12
    },
    {
        "text": "that identify drug drug interaction",
        "start": 1594.05,
        "duration": 6.66
    },
    {
        "text": "a stack of matrices that identify target",
        "start": 1597.23,
        "duration": 5.76
    },
    {
        "text": "target interactions so you have a tensor",
        "start": 1600.71,
        "duration": 3.27
    },
    {
        "text": "of the target",
        "start": 1602.99,
        "duration": 3.84
    },
    {
        "text": "tensor of the of the drugs and you want",
        "start": 1603.98,
        "duration": 5.27
    },
    {
        "text": "to use these non value this.value",
        "start": 1606.83,
        "duration": 5.4
    },
    {
        "text": "structured data within these two tensors",
        "start": 1609.25,
        "duration": 7.36
    },
    {
        "text": "to complete this unknown matrix that is",
        "start": 1612.23,
        "duration": 7.65
    },
    {
        "text": "very sparse so I'm not going to go over",
        "start": 1616.61,
        "duration": 5.49
    },
    {
        "text": "the details of the algorithm but this",
        "start": 1619.88,
        "duration": 4.56
    },
    {
        "text": "algorithm systematically considers what",
        "start": 1622.1,
        "duration": 4.61
    },
    {
        "text": "is known as the interaction between them",
        "start": 1624.44,
        "duration": 5.43
    },
    {
        "text": "the matrices of the drug drug",
        "start": 1626.71,
        "duration": 4.78
    },
    {
        "text": "interaction and target target",
        "start": 1629.87,
        "duration": 3.21
    },
    {
        "text": "interaction and the same thing with the",
        "start": 1631.49,
        "duration": 5.15
    },
    {
        "text": "tensor to have a better estimation of",
        "start": 1633.08,
        "duration": 6.839
    },
    {
        "text": "drug target interaction so the question",
        "start": 1636.64,
        "duration": 5.56
    },
    {
        "text": "is let's we developed such a model how",
        "start": 1639.919,
        "duration": 5.161
    },
    {
        "text": "we tested how we validated in order to",
        "start": 1642.2,
        "duration": 7.17
    },
    {
        "text": "validate it in we repeat this a process",
        "start": 1645.08,
        "duration": 6.63
    },
    {
        "text": "that I will describe 100 times or like a",
        "start": 1649.37,
        "duration": 4.89
    },
    {
        "text": "thousand times doesn't matter what we do",
        "start": 1651.71,
        "duration": 7.339
    },
    {
        "text": "each time we go and remove 10% of the",
        "start": 1654.26,
        "duration": 7.82
    },
    {
        "text": "data that we know that are there right",
        "start": 1659.049,
        "duration": 6.281
    },
    {
        "text": "known information we pretend that we",
        "start": 1662.08,
        "duration": 5.44
    },
    {
        "text": "don't know that and we use the rest of",
        "start": 1665.33,
        "duration": 4.74
    },
    {
        "text": "the 90% remaining to estimate the ones",
        "start": 1667.52,
        "duration": 5.039
    },
    {
        "text": "that we have removed and we keep doing",
        "start": 1670.07,
        "duration": 5.79
    },
    {
        "text": "that for 100 times so each time randomly",
        "start": 1672.559,
        "duration": 6.211
    },
    {
        "text": "remove 10% and our ability to predict",
        "start": 1675.86,
        "duration": 4.34
    },
    {
        "text": "what we have already removed",
        "start": 1678.77,
        "duration": 3.99
    },
    {
        "text": "intentionally tells us with it algorithm",
        "start": 1680.2,
        "duration": 6.82
    },
    {
        "text": "can guess what what might be the values",
        "start": 1682.76,
        "duration": 7.02
    },
    {
        "text": "other values in the matrix and complete",
        "start": 1687.02,
        "duration": 5.67
    },
    {
        "text": "the matrix for us so without going into",
        "start": 1689.78,
        "duration": 5.16
    },
    {
        "text": "the details I'm going to show you one",
        "start": 1692.69,
        "duration": 4.77
    },
    {
        "text": "these set of results that we have we",
        "start": 1694.94,
        "duration": 7.5
    },
    {
        "text": "have done multiple databases of drug",
        "start": 1697.46,
        "duration": 8.459
    },
    {
        "text": "interactions these are all the",
        "start": 1702.44,
        "duration": 5.25
    },
    {
        "text": "techniques that you know majority of the",
        "start": 1705.919,
        "duration": 3.421
    },
    {
        "text": "techniques people are using in the field",
        "start": 1707.69,
        "duration": 6.38
    },
    {
        "text": "and this is coupled matrix matrix",
        "start": 1709.34,
        "duration": 8.07
    },
    {
        "text": "completion method which you see that in",
        "start": 1714.07,
        "duration": 5.229
    },
    {
        "text": "terms of a you see in terms of the",
        "start": 1717.41,
        "duration": 4.139
    },
    {
        "text": "computational time in terms of accuracy",
        "start": 1719.299,
        "duration": 3.51
    },
    {
        "text": "and in terms of the standard deviation",
        "start": 1721.549,
        "duration": 5.071
    },
    {
        "text": "over all of these factors is superior to",
        "start": 1722.809,
        "duration": 8.071
    },
    {
        "text": "all that but when you get to copper 10",
        "start": 1726.62,
        "duration": 6.56
    },
    {
        "text": "matrix completion then we have",
        "start": 1730.88,
        "duration": 4.65
    },
    {
        "text": "substantially better results compared to",
        "start": 1733.18,
        "duration": 5.86
    },
    {
        "text": "all of these techniques and and all",
        "start": 1735.53,
        "duration": 5.49
    },
    {
        "text": "across all the measures like you know if",
        "start": 1739.04,
        "duration": 4.08
    },
    {
        "text": "you look at F F 1 is score is",
        "start": 1741.02,
        "duration": 3.84
    },
    {
        "text": "significantly higher than the rest of",
        "start": 1743.12,
        "duration": 5.19
    },
    {
        "text": "them so we have tested that on multiple",
        "start": 1744.86,
        "duration": 6.75
    },
    {
        "text": "databases like there are drug Bank is",
        "start": 1748.31,
        "duration": 5.97
    },
    {
        "text": "you know one of the large publicly",
        "start": 1751.61,
        "duration": 5.75
    },
    {
        "text": "available databases we have used other",
        "start": 1754.28,
        "duration": 6.27
    },
    {
        "text": "databases and all like you know it use",
        "start": 1757.36,
        "duration": 6.16
    },
    {
        "text": "something around 15 to 20 percent",
        "start": 1760.55,
        "duration": 5.13
    },
    {
        "text": "improvement in a you see just by using",
        "start": 1763.52,
        "duration": 4.64
    },
    {
        "text": "auxiliary information in a systematic",
        "start": 1765.68,
        "duration": 6.15
    },
    {
        "text": "structured way so that's one of the",
        "start": 1768.16,
        "duration": 5.71
    },
    {
        "text": "challenges the next challenge that I'm",
        "start": 1771.83,
        "duration": 4.52
    },
    {
        "text": "talking about it would be creating",
        "start": 1773.87,
        "duration": 3.78
    },
    {
        "text": "generalized",
        "start": 1776.35,
        "duration": 4.54
    },
    {
        "text": "yet robust models that can be trained by",
        "start": 1777.65,
        "duration": 7.53
    },
    {
        "text": "small databases keep in mind that we",
        "start": 1780.89,
        "duration": 6.75
    },
    {
        "text": "have you know techniques that can be",
        "start": 1785.18,
        "duration": 5.22
    },
    {
        "text": "they you know robust but you need",
        "start": 1787.64,
        "duration": 5.75
    },
    {
        "text": "substantial amount of data to train them",
        "start": 1790.4,
        "duration": 6.12
    },
    {
        "text": "can we have models that can be traded",
        "start": 1793.39,
        "duration": 6.58
    },
    {
        "text": "pain with small data sets but will be",
        "start": 1796.52,
        "duration": 5.13
    },
    {
        "text": "robust and and repeatable and",
        "start": 1799.97,
        "duration": 4.53
    },
    {
        "text": "generalizable or that I'm going to talk",
        "start": 1801.65,
        "duration": 6.78
    },
    {
        "text": "about one example that we have develop",
        "start": 1804.5,
        "duration": 5.58
    },
    {
        "text": "in our lab and algorithm that we",
        "start": 1808.43,
        "duration": 3.75
    },
    {
        "text": "developed for detection of in-vehicle",
        "start": 1810.08,
        "duration": 7.83
    },
    {
        "text": "cardiac events funded by Toyota and we",
        "start": 1812.18,
        "duration": 8.94
    },
    {
        "text": "want to for that we want to essentially",
        "start": 1817.91,
        "duration": 6.78
    },
    {
        "text": "detect some severe types of arrhythmia",
        "start": 1821.12,
        "duration": 6.56
    },
    {
        "text": "like severe atrial fibrillation afib",
        "start": 1824.69,
        "duration": 5.75
    },
    {
        "text": "super ventricular tachycardia or SVT",
        "start": 1827.68,
        "duration": 5.64
    },
    {
        "text": "ventricular arrhythmia OVA and",
        "start": 1830.44,
        "duration": 6.58
    },
    {
        "text": "bradycardia bc so what we want to do and",
        "start": 1833.32,
        "duration": 6.16
    },
    {
        "text": "we look at other types of like very you",
        "start": 1837.02,
        "duration": 5.25
    },
    {
        "text": "know or less less common types of",
        "start": 1839.48,
        "duration": 5.22
    },
    {
        "text": "editing as well majority of the",
        "start": 1842.27,
        "duration": 3.96
    },
    {
        "text": "techniques that are out there they have",
        "start": 1844.7,
        "duration": 3.35
    },
    {
        "text": "you know they look at the",
        "start": 1846.23,
        "duration": 5.73
    },
    {
        "text": "electrocardiogram and they try to first",
        "start": 1848.05,
        "duration": 6.85
    },
    {
        "text": "we take where the major peaks and major",
        "start": 1851.96,
        "duration": 5.1
    },
    {
        "text": "features of the signal for example they",
        "start": 1854.9,
        "duration": 5.94
    },
    {
        "text": "do our detection pqrst detection and",
        "start": 1857.06,
        "duration": 6.359
    },
    {
        "text": "based on the timing between these",
        "start": 1860.84,
        "duration": 5.009
    },
    {
        "text": "and the duration of some segments such",
        "start": 1863.419,
        "duration": 5.79
    },
    {
        "text": "as st-segment they come up with wait",
        "start": 1865.849,
        "duration": 7.38
    },
    {
        "text": "with some algorithm one major issue with",
        "start": 1869.209,
        "duration": 6.54
    },
    {
        "text": "these algorithms the fact that in some",
        "start": 1873.229,
        "duration": 4.68
    },
    {
        "text": "of these like a hit me that I listed in",
        "start": 1875.749,
        "duration": 4.86
    },
    {
        "text": "here like a fib and others in some of",
        "start": 1877.909,
        "duration": 5.07
    },
    {
        "text": "these I'll it means you don't have some",
        "start": 1880.609,
        "duration": 4.8
    },
    {
        "text": "of these things like you it's very rare",
        "start": 1882.979,
        "duration": 6.51
    },
    {
        "text": "that you can ever see you and you wave",
        "start": 1885.409,
        "duration": 6.69
    },
    {
        "text": "and and sometimes most of the time you",
        "start": 1889.489,
        "duration": 4.89
    },
    {
        "text": "don't see T and P is also missing in",
        "start": 1892.099,
        "duration": 5.55
    },
    {
        "text": "some of them so even the existence of",
        "start": 1894.379,
        "duration": 5.52
    },
    {
        "text": "some of these waves is questionable it",
        "start": 1897.649,
        "duration": 4.38
    },
    {
        "text": "alone like you know you can't on these",
        "start": 1899.899,
        "duration": 8.82
    },
    {
        "text": "as features in order to assess the the",
        "start": 1902.029,
        "duration": 9.81
    },
    {
        "text": "arrhythmia for instance if you if you",
        "start": 1908.719,
        "duration": 6.12
    },
    {
        "text": "rely too much on ST segmentation for",
        "start": 1911.839,
        "duration": 5.49
    },
    {
        "text": "your decision-making and as T cannot be",
        "start": 1914.839,
        "duration": 4.351
    },
    {
        "text": "computed because T is not very visible",
        "start": 1917.329,
        "duration": 3.871
    },
    {
        "text": "this mixed with noise then you have a",
        "start": 1919.19,
        "duration": 4.139
    },
    {
        "text": "lot of inaccuracies just because of that",
        "start": 1921.2,
        "duration": 5.069
    },
    {
        "text": "assumption so these are if you look at",
        "start": 1923.329,
        "duration": 5.31
    },
    {
        "text": "two groups of algorithms used for this",
        "start": 1926.269,
        "duration": 4.681
    },
    {
        "text": "the first group of algorithm that I'm",
        "start": 1928.639,
        "duration": 4.32
    },
    {
        "text": "going to talk about here are the",
        "start": 1930.95,
        "duration": 4.529
    },
    {
        "text": "algorithms that are combination of",
        "start": 1932.959,
        "duration": 6.06
    },
    {
        "text": "conventional signal processing and image",
        "start": 1935.479,
        "duration": 5.64
    },
    {
        "text": "processing techniques these techniques",
        "start": 1939.019,
        "duration": 4.56
    },
    {
        "text": "essentially prior to pre-process the",
        "start": 1941.119,
        "duration": 5.4
    },
    {
        "text": "data do the peak detection as I said",
        "start": 1943.579,
        "duration": 7.08
    },
    {
        "text": "find where our pqrst are do some feature",
        "start": 1946.519,
        "duration": 6.84
    },
    {
        "text": "extraction with you know methodology",
        "start": 1950.659,
        "duration": 5.94
    },
    {
        "text": "such as wavelet or HIV techniques and do",
        "start": 1953.359,
        "duration": 5.52
    },
    {
        "text": "feature reduction with pca I say other",
        "start": 1956.599,
        "duration": 4.74
    },
    {
        "text": "methods and then feed this feature to",
        "start": 1958.879,
        "duration": 4.41
    },
    {
        "text": "some algorithm random for a support",
        "start": 1961.339,
        "duration": 3.9
    },
    {
        "text": "vector machine artificial neural network",
        "start": 1963.289,
        "duration": 3.45
    },
    {
        "text": "to come up with the prediction even",
        "start": 1965.239,
        "duration": 4.951
    },
    {
        "text": "Markov models on the features that's the",
        "start": 1966.739,
        "duration": 5.461
    },
    {
        "text": "more conventional approach to this",
        "start": 1970.19,
        "duration": 5.609
    },
    {
        "text": "problem but another group of methods are",
        "start": 1972.2,
        "duration": 5.759
    },
    {
        "text": "using deep learning which is very",
        "start": 1975.799,
        "duration": 4.021
    },
    {
        "text": "different from those they just feed the",
        "start": 1977.959,
        "duration": 4.68
    },
    {
        "text": "ECG directly to the model to the deep",
        "start": 1979.82,
        "duration": 6.029
    },
    {
        "text": "learning technique and then you get the",
        "start": 1982.639,
        "duration": 5.07
    },
    {
        "text": "prediction there are good things are bad",
        "start": 1985.849,
        "duration": 3.99
    },
    {
        "text": "things about both of them like I said",
        "start": 1987.709,
        "duration": 4.17
    },
    {
        "text": "the issue with this approach is that you",
        "start": 1989.839,
        "duration": 3.72
    },
    {
        "text": "know everything the conventional",
        "start": 1991.879,
        "duration": 3.84
    },
    {
        "text": "approach depends on your ability to get",
        "start": 1993.559,
        "duration": 3.511
    },
    {
        "text": "these features and name",
        "start": 1995.719,
        "duration": 3.451
    },
    {
        "text": "make sure that this is actually our it's",
        "start": 1997.07,
        "duration": 5.25
    },
    {
        "text": "not a different peak and the issue with",
        "start": 1999.17,
        "duration": 5.22
    },
    {
        "text": "deep learning is that you know deep",
        "start": 2002.32,
        "duration": 5.37
    },
    {
        "text": "learning is works fine relatively fine",
        "start": 2004.39,
        "duration": 6.0
    },
    {
        "text": "if you have an enormous amount of data",
        "start": 2007.69,
        "duration": 5.94
    },
    {
        "text": "for some of these like SVT if you if you",
        "start": 2010.39,
        "duration": 5.79
    },
    {
        "text": "put all the report that is assuming that",
        "start": 2013.63,
        "duration": 5.16
    },
    {
        "text": "the quality of the annotation is very",
        "start": 2016.18,
        "duration": 6.09
    },
    {
        "text": "high there would be there is no big",
        "start": 2018.79,
        "duration": 6.54
    },
    {
        "text": "database on SVT it would be very",
        "start": 2022.27,
        "duration": 5.22
    },
    {
        "text": "difficult to create enough cases so that",
        "start": 2025.33,
        "duration": 3.75
    },
    {
        "text": "like a deep learning algorithm can",
        "start": 2027.49,
        "duration": 6.21
    },
    {
        "text": "reliably and robustly predict SVT I'm",
        "start": 2029.08,
        "duration": 7.05
    },
    {
        "text": "going to show that through some results",
        "start": 2033.7,
        "duration": 4.95
    },
    {
        "text": "first I'm going to quickly introduce our",
        "start": 2036.13,
        "duration": 6.24
    },
    {
        "text": "algorithm algorithm is very simple it's",
        "start": 2038.65,
        "duration": 7.53
    },
    {
        "text": "a probabilistic sort of version of a",
        "start": 2042.37,
        "duration": 6.33
    },
    {
        "text": "finite automata system that's one way of",
        "start": 2046.18,
        "duration": 4.65
    },
    {
        "text": "looking at it another way of looking at",
        "start": 2048.7,
        "duration": 5.729
    },
    {
        "text": "it is is some automated version of a",
        "start": 2050.83,
        "duration": 6.42
    },
    {
        "text": "Markov model what it does starts with",
        "start": 2054.429,
        "duration": 7.231
    },
    {
        "text": "soft symbolization let's assume we're",
        "start": 2057.25,
        "duration": 5.97
    },
    {
        "text": "not doing software doing hard",
        "start": 2061.66,
        "duration": 3.81
    },
    {
        "text": "symbolization this is what we do we put",
        "start": 2063.22,
        "duration": 4.68
    },
    {
        "text": "some levers a B and C we don't care",
        "start": 2065.47,
        "duration": 5.67
    },
    {
        "text": "about the waves like R or whatever we",
        "start": 2067.9,
        "duration": 7.29
    },
    {
        "text": "just like divide the the range of the",
        "start": 2071.14,
        "duration": 7.17
    },
    {
        "text": "values in normalized ECG as a B and C",
        "start": 2075.19,
        "duration": 5.85
    },
    {
        "text": "and we change the sequence of numeric",
        "start": 2078.31,
        "duration": 6.119
    },
    {
        "text": "data in sequence of alphabetic data for",
        "start": 2081.04,
        "duration": 5.58
    },
    {
        "text": "example if you look at all these region",
        "start": 2084.429,
        "duration": 5.071
    },
    {
        "text": "is B so you have D BBB then you go to",
        "start": 2086.62,
        "duration": 5.309
    },
    {
        "text": "see you get a bunch of C's then you go",
        "start": 2089.5,
        "duration": 4.95
    },
    {
        "text": "back to be you give them one B and then",
        "start": 2091.929,
        "duration": 5.101
    },
    {
        "text": "you go to a get a couple of a's you go",
        "start": 2094.45,
        "duration": 5.13
    },
    {
        "text": "back to C and B and again a bunch of",
        "start": 2097.03,
        "duration": 5.85
    },
    {
        "text": "seeds so instead of relying on on the",
        "start": 2099.58,
        "duration": 7.25
    },
    {
        "text": "exact numeric value you create a long",
        "start": 2102.88,
        "duration": 8.76
    },
    {
        "text": "string of variables like I said this is",
        "start": 2106.83,
        "duration": 9.1
    },
    {
        "text": "the hard version of symbolization we're",
        "start": 2111.64,
        "duration": 6.06
    },
    {
        "text": "doing a soft symbolization in other",
        "start": 2115.93,
        "duration": 4.92
    },
    {
        "text": "words we create probability of each",
        "start": 2117.7,
        "duration": 5.7
    },
    {
        "text": "thing being a or b or c so instead of",
        "start": 2120.85,
        "duration": 5.01
    },
    {
        "text": "like saying is definitely it's a B we",
        "start": 2123.4,
        "duration": 4.71
    },
    {
        "text": "don't want to rely too much you have",
        "start": 2125.86,
        "duration": 4.28
    },
    {
        "text": "like sensitivity over what is the",
        "start": 2128.11,
        "duration": 4.07
    },
    {
        "text": "like value of threshold here and exact",
        "start": 2130.14,
        "duration": 4.47
    },
    {
        "text": "value the threshold between B and C in",
        "start": 2132.18,
        "duration": 4.58
    },
    {
        "text": "order to reduce those sensitivities",
        "start": 2134.61,
        "duration": 5.46
    },
    {
        "text": "instead of actually you know art code",
        "start": 2136.76,
        "duration": 6.19
    },
    {
        "text": "that as a or B or C we trade the",
        "start": 2140.07,
        "duration": 5.31
    },
    {
        "text": "probability of being a.m. B and C and we",
        "start": 2142.95,
        "duration": 8.79
    },
    {
        "text": "use that to create a tree and we look at",
        "start": 2145.38,
        "duration": 9.3
    },
    {
        "text": "the words the sequence of symbols that",
        "start": 2151.74,
        "duration": 6.45
    },
    {
        "text": "are more likely to happen and and we",
        "start": 2154.68,
        "duration": 5.88
    },
    {
        "text": "spread this tree as long as we have a",
        "start": 2158.19,
        "duration": 4.92
    },
    {
        "text": "certain amount of you know minimum value",
        "start": 2160.56,
        "duration": 5.31
    },
    {
        "text": "of frequency of these words once we have",
        "start": 2163.11,
        "duration": 5.13
    },
    {
        "text": "these words and their probabilities then",
        "start": 2165.87,
        "duration": 5.64
    },
    {
        "text": "we create a transition probability",
        "start": 2168.24,
        "duration": 4.47
    },
    {
        "text": "transition",
        "start": 2171.51,
        "duration": 4.83
    },
    {
        "text": "among these states going from like a to",
        "start": 2172.71,
        "duration": 9.21
    },
    {
        "text": "a B from a B to to a BA or something",
        "start": 2176.34,
        "duration": 8.19
    },
    {
        "text": "like that we create a finite automata",
        "start": 2181.92,
        "duration": 5.88
    },
    {
        "text": "but probabilistic finite automata based",
        "start": 2184.53,
        "duration": 5.76
    },
    {
        "text": "on these values and this becomes the",
        "start": 2187.8,
        "duration": 4.65
    },
    {
        "text": "mother in this mother we don't care what",
        "start": 2190.29,
        "duration": 4.62
    },
    {
        "text": "is all we don't care what is T we don't",
        "start": 2192.45,
        "duration": 4.47
    },
    {
        "text": "care whether T is even there or not we",
        "start": 2194.91,
        "duration": 4.08
    },
    {
        "text": "just you know look at the range of the",
        "start": 2196.92,
        "duration": 4.29
    },
    {
        "text": "values that we dealing with when it",
        "start": 2198.99,
        "duration": 7.11
    },
    {
        "text": "comes to prediction we use a window of",
        "start": 2201.21,
        "duration": 6.96
    },
    {
        "text": "time look at the start with the first",
        "start": 2206.1,
        "duration": 6.27
    },
    {
        "text": "row we look at observation window for",
        "start": 2208.17,
        "duration": 6.57
    },
    {
        "text": "the signal so for example we monitor the",
        "start": 2212.37,
        "duration": 4.68
    },
    {
        "text": "signal for half a minute for five",
        "start": 2214.74,
        "duration": 5.49
    },
    {
        "text": "minutes whatever and then based on the",
        "start": 2217.05,
        "duration": 5.22
    },
    {
        "text": "value that we observe here we make a",
        "start": 2220.23,
        "duration": 3.9
    },
    {
        "text": "prediction of the event that is",
        "start": 2222.27,
        "duration": 3.24
    },
    {
        "text": "happening in the future",
        "start": 2224.13,
        "duration": 4.05
    },
    {
        "text": "we put a prediction gap between them so",
        "start": 2225.51,
        "duration": 5.13
    },
    {
        "text": "for example we we look at the values",
        "start": 2228.18,
        "duration": 4.38
    },
    {
        "text": "that we recorded for the last two",
        "start": 2230.64,
        "duration": 4.05
    },
    {
        "text": "minutes and make a prediction for four",
        "start": 2232.56,
        "duration": 4.11
    },
    {
        "text": "and a half minutes in in the future",
        "start": 2234.69,
        "duration": 5.55
    },
    {
        "text": "right and we change with the values of",
        "start": 2236.67,
        "duration": 6.72
    },
    {
        "text": "signal window the window of observation",
        "start": 2240.24,
        "duration": 6.03
    },
    {
        "text": "and prediction gap sometimes we get we",
        "start": 2243.39,
        "duration": 6.42
    },
    {
        "text": "get the sync signal window the same but",
        "start": 2246.27,
        "duration": 6.33
    },
    {
        "text": "we increase the prediction gap we want",
        "start": 2249.81,
        "duration": 4.56
    },
    {
        "text": "to make a prediction for well ahead of",
        "start": 2252.6,
        "duration": 4.38
    },
    {
        "text": "time and sometimes we keep the",
        "start": 2254.37,
        "duration": 4.59
    },
    {
        "text": "prediction cavities as it is but we",
        "start": 2256.98,
        "duration": 4.71
    },
    {
        "text": "monitor the signal for longer time and",
        "start": 2258.96,
        "duration": 4.47
    },
    {
        "text": "we want to see all these models",
        "start": 2261.69,
        "duration": 5.879
    },
    {
        "text": "other related to each other so next I'm",
        "start": 2263.43,
        "duration": 6.27
    },
    {
        "text": "gonna show you the comparison of our",
        "start": 2267.569,
        "duration": 4.611
    },
    {
        "text": "results in making these predictions",
        "start": 2269.7,
        "duration": 5.1
    },
    {
        "text": "compared to some conventional methods so",
        "start": 2272.18,
        "duration": 5.23
    },
    {
        "text": "let me show you what we have here the",
        "start": 2274.8,
        "duration": 6.12
    },
    {
        "text": "blue line is our algorithm the red line",
        "start": 2277.41,
        "duration": 5.79
    },
    {
        "text": "is deep learning the green one is a",
        "start": 2280.92,
        "duration": 4.86
    },
    {
        "text": "combination of HRV features and support",
        "start": 2283.2,
        "duration": 5.82
    },
    {
        "text": "vector machine and the yellow one is dwt",
        "start": 2285.78,
        "duration": 5.49
    },
    {
        "text": "and an support vector machine so we",
        "start": 2289.02,
        "duration": 3.87
    },
    {
        "text": "looking at two of the conventional",
        "start": 2291.27,
        "duration": 3.599
    },
    {
        "text": "methods one deep learning and our method",
        "start": 2292.89,
        "duration": 5.13
    },
    {
        "text": "and the halo that you see around each",
        "start": 2294.869,
        "duration": 6.72
    },
    {
        "text": "line is talking about you know standard",
        "start": 2298.02,
        "duration": 5.16
    },
    {
        "text": "deviation over that so the whole",
        "start": 2301.589,
        "duration": 4.561
    },
    {
        "text": "vertical lines are AUC and area under",
        "start": 2303.18,
        "duration": 6.0
    },
    {
        "text": "the curve horizontal line is how many",
        "start": 2306.15,
        "duration": 5.04
    },
    {
        "text": "minutes ahead of time we make the",
        "start": 2309.18,
        "duration": 4.53
    },
    {
        "text": "prediction after minutes before before",
        "start": 2311.19,
        "duration": 4.5
    },
    {
        "text": "the event one minute before the event",
        "start": 2313.71,
        "duration": 4.02
    },
    {
        "text": "all the way to four and a half minute so",
        "start": 2315.69,
        "duration": 4.23
    },
    {
        "text": "each one of these is like you know for",
        "start": 2317.73,
        "duration": 4.32
    },
    {
        "text": "half a minute observation one minute",
        "start": 2319.92,
        "duration": 4.04
    },
    {
        "text": "observation and two minute observation",
        "start": 2322.05,
        "duration": 5.37
    },
    {
        "text": "but observation for events that are",
        "start": 2323.96,
        "duration": 5.53
    },
    {
        "text": "happening in like in a minute in the two",
        "start": 2327.42,
        "duration": 3.449
    },
    {
        "text": "minutes and three minutes or four",
        "start": 2329.49,
        "duration": 4.379
    },
    {
        "text": "minutes as you can see here our method",
        "start": 2330.869,
        "duration": 5.161
    },
    {
        "text": "is essentially better than any of the",
        "start": 2333.869,
        "duration": 4.171
    },
    {
        "text": "other methods the blue one is our method",
        "start": 2336.03,
        "duration": 5.76
    },
    {
        "text": "deep learning for a thief is very close",
        "start": 2338.04,
        "duration": 6.329
    },
    {
        "text": "to others but look at the halo the red",
        "start": 2341.79,
        "duration": 5.97
    },
    {
        "text": "halo the red halo is so significantly",
        "start": 2344.369,
        "duration": 6.841
    },
    {
        "text": "larger than the blue halo which you",
        "start": 2347.76,
        "duration": 5.52
    },
    {
        "text": "hardly see that which means that",
        "start": 2351.21,
        "duration": 5.49
    },
    {
        "text": "standard deviation of the results that",
        "start": 2353.28,
        "duration": 5.97
    },
    {
        "text": "you get from deep learning are much",
        "start": 2356.7,
        "duration": 4.23
    },
    {
        "text": "bigger than the standard deviation that",
        "start": 2359.25,
        "duration": 3.93
    },
    {
        "text": "he gets from our method staying that our",
        "start": 2360.93,
        "duration": 4.679
    },
    {
        "text": "method even we have a lot a lot of data",
        "start": 2363.18,
        "duration": 4.02
    },
    {
        "text": "and you train your reliable deep",
        "start": 2365.609,
        "duration": 4.98
    },
    {
        "text": "learning our method is more robust and",
        "start": 2367.2,
        "duration": 5.22
    },
    {
        "text": "the ups and downs are far less",
        "start": 2370.589,
        "duration": 3.571
    },
    {
        "text": "regardless of whether you're doing the",
        "start": 2372.42,
        "duration": 4.919
    },
    {
        "text": "prediction is in half a minute or longer",
        "start": 2374.16,
        "duration": 6.0
    },
    {
        "text": "than that another observation is that no",
        "start": 2377.339,
        "duration": 5.911
    },
    {
        "text": "matter how long the prediction is how",
        "start": 2380.16,
        "duration": 6.209
    },
    {
        "text": "much how big the prediction gap is there",
        "start": 2383.25,
        "duration": 5.96
    },
    {
        "text": "is still around 0.8 AUC which is",
        "start": 2386.369,
        "duration": 5.311
    },
    {
        "text": "significant you can predict what is",
        "start": 2389.21,
        "duration": 7.37
    },
    {
        "text": "about to happen with 0.8 AUC",
        "start": 2391.68,
        "duration": 7.03
    },
    {
        "text": "but now if you look at SVT",
        "start": 2396.58,
        "duration": 4.44
    },
    {
        "text": "supraventricular tachycardia you will",
        "start": 2398.71,
        "duration": 4.47
    },
    {
        "text": "see that you know now deep learning is",
        "start": 2401.02,
        "duration": 5.43
    },
    {
        "text": "far less accurate and ours in all three",
        "start": 2403.18,
        "duration": 6.08
    },
    {
        "text": "cases you see deep learning is is",
        "start": 2406.45,
        "duration": 5.13
    },
    {
        "text": "significantly lower than our mentor the",
        "start": 2409.26,
        "duration": 4.6
    },
    {
        "text": "blue one red one is deep learning blue",
        "start": 2411.58,
        "duration": 4.77
    },
    {
        "text": "one is hours and look at the halo around",
        "start": 2413.86,
        "duration": 4.59
    },
    {
        "text": "deep learning and other methods that are",
        "start": 2416.35,
        "duration": 5.43
    },
    {
        "text": "significant they're not as robust so",
        "start": 2418.45,
        "duration": 5.31
    },
    {
        "text": "this is what we wanted to do we wanted",
        "start": 2421.78,
        "duration": 4.23
    },
    {
        "text": "to do an algorithm that is when you have",
        "start": 2423.76,
        "duration": 4.17
    },
    {
        "text": "a lot of data it's very robust but if",
        "start": 2426.01,
        "duration": 4.38
    },
    {
        "text": "you have few data like SVT that doesn't",
        "start": 2427.93,
        "duration": 5.37
    },
    {
        "text": "have a lot of data you can still have a",
        "start": 2430.39,
        "duration": 5.85
    },
    {
        "text": "reliable model and it's robust and",
        "start": 2433.3,
        "duration": 8.19
    },
    {
        "text": "repeatable so another challenge that we",
        "start": 2436.24,
        "duration": 7.55
    },
    {
        "text": "wanted to talk about is was",
        "start": 2441.49,
        "duration": 4.59
    },
    {
        "text": "incorporating the uncertainty of the",
        "start": 2443.79,
        "duration": 5.08
    },
    {
        "text": "labels and utilizing the timing of the",
        "start": 2446.08,
        "duration": 5.61
    },
    {
        "text": "data for that I'm going to talk about an",
        "start": 2448.87,
        "duration": 5.42
    },
    {
        "text": "approach that we are using for",
        "start": 2451.69,
        "duration": 5.64
    },
    {
        "text": "prediction of acute respiratory distress",
        "start": 2454.29,
        "duration": 6.85
    },
    {
        "text": "syndrome a RDS when you look at a RDS",
        "start": 2457.33,
        "duration": 5.94
    },
    {
        "text": "there are two major challenges in in",
        "start": 2461.14,
        "duration": 4.65
    },
    {
        "text": "making detection of a RDS which is like",
        "start": 2463.27,
        "duration": 4.86
    },
    {
        "text": "a very you know major respiratory issue",
        "start": 2465.79,
        "duration": 6.99
    },
    {
        "text": "for all ages one is that nobody really",
        "start": 2468.13,
        "duration": 7.19
    },
    {
        "text": "knows what a RDS is if you get",
        "start": 2472.78,
        "duration": 6.06
    },
    {
        "text": "clinicians to label any ideas and when a",
        "start": 2475.32,
        "duration": 4.75
    },
    {
        "text": "RDS happened",
        "start": 2478.84,
        "duration": 3.3
    },
    {
        "text": "you get significantly different results",
        "start": 2480.07,
        "duration": 4.56
    },
    {
        "text": "so no matter how you create these labels",
        "start": 2482.14,
        "duration": 6.03
    },
    {
        "text": "these drivers are uncertain secondly is",
        "start": 2484.63,
        "duration": 6.63
    },
    {
        "text": "the timeline of how the decision is made",
        "start": 2488.17,
        "duration": 5.79
    },
    {
        "text": "the majority of the time the clinicians",
        "start": 2491.26,
        "duration": 5.37
    },
    {
        "text": "are looking at the patient physiological",
        "start": 2493.96,
        "duration": 5.22
    },
    {
        "text": "and you know EHR data they look at you",
        "start": 2496.63,
        "duration": 7.91
    },
    {
        "text": "know some physiological things such as",
        "start": 2499.18,
        "duration": 8.37
    },
    {
        "text": "vital signs and some EHR data such as",
        "start": 2504.54,
        "duration": 5.5
    },
    {
        "text": "lab results and they have to make a",
        "start": 2507.55,
        "duration": 4.68
    },
    {
        "text": "decision with it this is a RTS or not",
        "start": 2510.04,
        "duration": 8.7
    },
    {
        "text": "but in reality maybe perhaps two days or",
        "start": 2512.23,
        "duration": 8.88
    },
    {
        "text": "whatever days after that they will order",
        "start": 2518.74,
        "duration": 6.27
    },
    {
        "text": "chest x-ray and Chex x-ray is the most",
        "start": 2521.11,
        "duration": 5.73
    },
    {
        "text": "informative data that they can have",
        "start": 2525.01,
        "duration": 4.53
    },
    {
        "text": "having chest x-ray it would be much",
        "start": 2526.84,
        "duration": 3.39
    },
    {
        "text": "easier",
        "start": 2529.54,
        "duration": 2.49
    },
    {
        "text": "to say whether they're dealing with a",
        "start": 2530.23,
        "duration": 5.82
    },
    {
        "text": "RTS or not but in reality at the time",
        "start": 2532.03,
        "duration": 6.39
    },
    {
        "text": "that the patient is is admitted to the",
        "start": 2536.05,
        "duration": 3.18
    },
    {
        "text": "hospital",
        "start": 2538.42,
        "duration": 4.199
    },
    {
        "text": "nobody even or their chest x-ray they",
        "start": 2539.23,
        "duration": 5.609
    },
    {
        "text": "may not even think of the ideas to order",
        "start": 2542.619,
        "duration": 4.861
    },
    {
        "text": "a chest x-ray so chest x-ray you cannot",
        "start": 2544.839,
        "duration": 5.01
    },
    {
        "text": "assume it's available at the time that",
        "start": 2547.48,
        "duration": 4.68
    },
    {
        "text": "they want to make a decision so if you",
        "start": 2549.849,
        "duration": 5.851
    },
    {
        "text": "give this problem to two regular machine",
        "start": 2552.16,
        "duration": 5.31
    },
    {
        "text": "learning regular machine learning would",
        "start": 2555.7,
        "duration": 3.659
    },
    {
        "text": "always want to get you know",
        "start": 2557.47,
        "duration": 5.01
    },
    {
        "text": "physiological clinical data as an X the",
        "start": 2559.359,
        "duration": 5.49
    },
    {
        "text": "input X and a RTS",
        "start": 2562.48,
        "duration": 5.369
    },
    {
        "text": "no ideas as Y and machine learning",
        "start": 2564.849,
        "duration": 5.01
    },
    {
        "text": "regular machine learning wants to",
        "start": 2567.849,
        "duration": 5.721
    },
    {
        "text": "develop a function f that map's X to Y",
        "start": 2569.859,
        "duration": 7.74
    },
    {
        "text": "input to output and as you see chest XA",
        "start": 2573.57,
        "duration": 6.269
    },
    {
        "text": "is nowhere in the picture in other words",
        "start": 2577.599,
        "duration": 5.281
    },
    {
        "text": "since you don't have chest x-ray when",
        "start": 2579.839,
        "duration": 4.99
    },
    {
        "text": "you're making this decision yesterday",
        "start": 2582.88,
        "duration": 5.01
    },
    {
        "text": "chest x-ray has absolutely no impact on",
        "start": 2584.829,
        "duration": 5.611
    },
    {
        "text": "how f was generated because you need to",
        "start": 2587.89,
        "duration": 6.33
    },
    {
        "text": "have like you know the input and the",
        "start": 2590.44,
        "duration": 5.55
    },
    {
        "text": "output and you cannot assume you have",
        "start": 2594.22,
        "duration": 4.56
    },
    {
        "text": "chest x-ray the question we're asking is",
        "start": 2595.99,
        "duration": 6.42
    },
    {
        "text": "can we use a new way of machine learning",
        "start": 2598.78,
        "duration": 7.44
    },
    {
        "text": "we call it learning not we call it",
        "start": 2602.41,
        "duration": 5.58
    },
    {
        "text": "others call it learning with privileged",
        "start": 2606.22,
        "duration": 5.16
    },
    {
        "text": "information that still tries to do the",
        "start": 2607.99,
        "duration": 4.71
    },
    {
        "text": "same thing you wants to look at the",
        "start": 2611.38,
        "duration": 5.01
    },
    {
        "text": "physiology X and map it using a function",
        "start": 2612.7,
        "duration": 6.869
    },
    {
        "text": "f p2 Y which is a RTS or not but",
        "start": 2616.39,
        "duration": 5.34
    },
    {
        "text": "remember pay attention to the fact that",
        "start": 2619.569,
        "duration": 5.311
    },
    {
        "text": "in painting data in retrospectively",
        "start": 2621.73,
        "duration": 5.879
    },
    {
        "text": "collected data we have access to x-rays",
        "start": 2624.88,
        "duration": 4.739
    },
    {
        "text": "right these are the cases that happened",
        "start": 2627.609,
        "duration": 4.801
    },
    {
        "text": "last year or something he we have like",
        "start": 2629.619,
        "duration": 4.291
    },
    {
        "text": "you know three days after the first",
        "start": 2632.41,
        "duration": 3.419
    },
    {
        "text": "assessment they didn't x-ray so we have",
        "start": 2633.91,
        "duration": 6.0
    },
    {
        "text": "an x-ray can we somehow train FP in such",
        "start": 2635.829,
        "duration": 7.53
    },
    {
        "text": "a way that the impact of those x-rays in",
        "start": 2639.91,
        "duration": 5.4
    },
    {
        "text": "the training data is affecting the",
        "start": 2643.359,
        "duration": 4.74
    },
    {
        "text": "choice of FP pay attention to the fact",
        "start": 2645.31,
        "duration": 5.85
    },
    {
        "text": "that if we can do that FP can be used",
        "start": 2648.099,
        "duration": 6.27
    },
    {
        "text": "operationally in real-time usage just",
        "start": 2651.16,
        "duration": 5.49
    },
    {
        "text": "like F in a sense that their input their",
        "start": 2654.369,
        "duration": 4.891
    },
    {
        "text": "real input to the system is still X but",
        "start": 2656.65,
        "duration": 4.86
    },
    {
        "text": "it's predicting Y for you but the",
        "start": 2659.26,
        "duration": 4.319
    },
    {
        "text": "difference between F",
        "start": 2661.51,
        "duration": 4.499
    },
    {
        "text": "and FP is shown in this diagram that",
        "start": 2663.579,
        "duration": 4.561
    },
    {
        "text": "shows the family of functions he like",
        "start": 2666.009,
        "duration": 4.59
    },
    {
        "text": "the family functions with big F and yet",
        "start": 2668.14,
        "duration": 4.949
    },
    {
        "text": "if you use regular machine learning",
        "start": 2670.599,
        "duration": 4.23
    },
    {
        "text": "regular machine learning is trained",
        "start": 2673.089,
        "duration": 3.51
    },
    {
        "text": "without the knowledge of x-ray and it",
        "start": 2674.829,
        "duration": 4.53
    },
    {
        "text": "gives you f but if you use privileged",
        "start": 2676.599,
        "duration": 6.601
    },
    {
        "text": "learning it gives you the knowledge of X",
        "start": 2679.359,
        "duration": 4.801
    },
    {
        "text": "esta will",
        "start": 2683.2,
        "duration": 3.48
    },
    {
        "text": "pushes the choice from F to F P which is",
        "start": 2684.16,
        "duration": 5.549
    },
    {
        "text": "you know the difference between a naive",
        "start": 2686.68,
        "duration": 5.939
    },
    {
        "text": "predictor and a more informed predictor",
        "start": 2689.709,
        "duration": 5.79
    },
    {
        "text": "that is F P so now putting everything",
        "start": 2692.619,
        "duration": 6.541
    },
    {
        "text": "together we design an algorithm that is",
        "start": 2695.499,
        "duration": 6.81
    },
    {
        "text": "essentially considers the availability",
        "start": 2699.16,
        "duration": 5.819
    },
    {
        "text": "of privileged information not only just",
        "start": 2702.309,
        "duration": 4.321
    },
    {
        "text": "the input and output of privileged",
        "start": 2704.979,
        "duration": 3.48
    },
    {
        "text": "information and the level of uncertainty",
        "start": 2706.63,
        "duration": 5.25
    },
    {
        "text": "over the data over the latest I'm not",
        "start": 2708.459,
        "duration": 6.0
    },
    {
        "text": "going to go over the algorithm but this",
        "start": 2711.88,
        "duration": 5.189
    },
    {
        "text": "is the revision of SVM support vector",
        "start": 2714.459,
        "duration": 6.211
    },
    {
        "text": "machines under the learning method that",
        "start": 2717.069,
        "duration": 6.45
    },
    {
        "text": "we call it learning using label",
        "start": 2720.67,
        "duration": 4.859
    },
    {
        "text": "uncertainty and partially available",
        "start": 2723.519,
        "duration": 5.73
    },
    {
        "text": "privileged information pal Lulu puppy we",
        "start": 2725.529,
        "duration": 6.06
    },
    {
        "text": "decided to put like a funny name for it",
        "start": 2729.249,
        "duration": 3.87
    },
    {
        "text": "maybe that would attract you know some",
        "start": 2731.589,
        "duration": 5.25
    },
    {
        "text": "more researchers to that so with Lulu",
        "start": 2733.119,
        "duration": 6.75
    },
    {
        "text": "puppy if you look at how Lulu puppy",
        "start": 2736.839,
        "duration": 5.041
    },
    {
        "text": "compares the results of Lulu potty",
        "start": 2739.869,
        "duration": 4.321
    },
    {
        "text": "compared to conventional techniques as",
        "start": 2741.88,
        "duration": 5.189
    },
    {
        "text": "well as you know that shallow neural",
        "start": 2744.19,
        "duration": 4.95
    },
    {
        "text": "networks and Ellis TM as as deep",
        "start": 2747.069,
        "duration": 4.591
    },
    {
        "text": "learning approach you will see that in",
        "start": 2749.14,
        "duration": 5.219
    },
    {
        "text": "terms of the level of AUC and the",
        "start": 2751.66,
        "duration": 6.149
    },
    {
        "text": "closeness the between training and",
        "start": 2754.359,
        "duration": 5.7
    },
    {
        "text": "testing a you see we are beating",
        "start": 2757.809,
        "duration": 4.4
    },
    {
        "text": "essentially every other technique so",
        "start": 2760.059,
        "duration": 5.19
    },
    {
        "text": "sometimes you can have like 9 percent",
        "start": 2762.209,
        "duration": 6.28
    },
    {
        "text": "difference between training and testing",
        "start": 2765.249,
        "duration": 6.631
    },
    {
        "text": "between like you know in lsdm cases but",
        "start": 2768.489,
        "duration": 5.55
    },
    {
        "text": "the training that the difference between",
        "start": 2771.88,
        "duration": 3.949
    },
    {
        "text": "training and testing a you sees are",
        "start": 2774.039,
        "duration": 4.111
    },
    {
        "text": "really insignificant in this case we are",
        "start": 2775.829,
        "duration": 7.03
    },
    {
        "text": "actually getting a slightly higher AUC",
        "start": 2778.15,
        "duration": 7.469
    },
    {
        "text": "for for our method which is what we",
        "start": 2782.859,
        "duration": 4.59
    },
    {
        "text": "wanted to do we wanted to have a robust",
        "start": 2785.619,
        "duration": 4.14
    },
    {
        "text": "technique that uses all the information",
        "start": 2787.449,
        "duration": 5.1
    },
    {
        "text": "in there and considers the temporal you",
        "start": 2789.759,
        "duration": 5.371
    },
    {
        "text": "know relationship between the data last",
        "start": 2792.549,
        "duration": 4.721
    },
    {
        "text": "one that I'm going to quickly",
        "start": 2795.13,
        "duration": 5.65
    },
    {
        "text": "talk about is addressing the issue that",
        "start": 2797.27,
        "duration": 6.12
    },
    {
        "text": "I said like you know how to somehow keep",
        "start": 2800.78,
        "duration": 5.01
    },
    {
        "text": "the structure of the data using tensor",
        "start": 2803.39,
        "duration": 6.09
    },
    {
        "text": "methods and for that we are going to",
        "start": 2805.79,
        "duration": 5.94
    },
    {
        "text": "talk about an example that is funded by",
        "start": 2809.48,
        "duration": 6.2
    },
    {
        "text": "Department of Defense and that's",
        "start": 2811.73,
        "duration": 7.5
    },
    {
        "text": "development of algorithms and monitoring",
        "start": 2815.68,
        "duration": 6.64
    },
    {
        "text": "systems to essentially predict",
        "start": 2819.23,
        "duration": 6.53
    },
    {
        "text": "postcardiac the events in patients",
        "start": 2822.32,
        "duration": 6.81
    },
    {
        "text": "recovering from major cardiac surgeries",
        "start": 2825.76,
        "duration": 6.79
    },
    {
        "text": "so the question is first question is how",
        "start": 2829.13,
        "duration": 5.94
    },
    {
        "text": "to define these major cardiac events we",
        "start": 2832.55,
        "duration": 5.79
    },
    {
        "text": "spent a year and a half almost putting a",
        "start": 2835.07,
        "duration": 5.58
    },
    {
        "text": "panel of different clinicians from",
        "start": 2838.34,
        "duration": 4.62
    },
    {
        "text": "different backgrounds to come up with a",
        "start": 2840.65,
        "duration": 4.47
    },
    {
        "text": "definition of what is an event and we",
        "start": 2842.96,
        "duration": 4.35
    },
    {
        "text": "came up with the event we quantified",
        "start": 2845.12,
        "duration": 4.23
    },
    {
        "text": "each one of them that took a significant",
        "start": 2847.31,
        "duration": 3.81
    },
    {
        "text": "amount of time to come up with but it's",
        "start": 2849.35,
        "duration": 4.44
    },
    {
        "text": "all worth it then we design an algorithm",
        "start": 2851.12,
        "duration": 5.36
    },
    {
        "text": "that looks at physiological signals",
        "start": 2853.79,
        "duration": 5.94
    },
    {
        "text": "electrocardiogram arterial blood",
        "start": 2856.48,
        "duration": 7.72
    },
    {
        "text": "pressure and spo2 and using some",
        "start": 2859.73,
        "duration": 6.23
    },
    {
        "text": "estimation method called",
        "start": 2864.2,
        "duration": 4.11
    },
    {
        "text": "total string will create multiple",
        "start": 2865.96,
        "duration": 4.84
    },
    {
        "text": "resolution estimation of the metal and",
        "start": 2868.31,
        "duration": 4.65
    },
    {
        "text": "for each of these estimations we'll",
        "start": 2870.8,
        "duration": 4.47
    },
    {
        "text": "calculate a bunch of features then we",
        "start": 2872.96,
        "duration": 5.61
    },
    {
        "text": "use tensor methods to compress this",
        "start": 2875.27,
        "duration": 6.12
    },
    {
        "text": "information on by night with EHR data",
        "start": 2878.57,
        "duration": 5.19
    },
    {
        "text": "and use machine learning for prediction",
        "start": 2881.39,
        "duration": 5.1
    },
    {
        "text": "in order to better explain what happens",
        "start": 2883.76,
        "duration": 4.74
    },
    {
        "text": "with tensor ization how we create these",
        "start": 2886.49,
        "duration": 4.56
    },
    {
        "text": "tensors we get this signal we divide",
        "start": 2888.5,
        "duration": 5.4
    },
    {
        "text": "that signal into some windows for each",
        "start": 2891.05,
        "duration": 5.64
    },
    {
        "text": "of the windows based on multiple",
        "start": 2893.9,
        "duration": 5.37
    },
    {
        "text": "resolution that we put on on on for",
        "start": 2896.69,
        "duration": 4.95
    },
    {
        "text": "testing we create approximation and",
        "start": 2899.27,
        "duration": 5.13
    },
    {
        "text": "different levels and we create like a",
        "start": 2901.64,
        "duration": 4.74
    },
    {
        "text": "set of features and it could be multiple",
        "start": 2904.4,
        "duration": 3.63
    },
    {
        "text": "sets of features like this set of fish",
        "start": 2906.38,
        "duration": 3.36
    },
    {
        "text": "it could give a bed and we do another",
        "start": 2908.03,
        "duration": 3.86
    },
    {
        "text": "thing with a different type of you know",
        "start": 2909.74,
        "duration": 6.51
    },
    {
        "text": "method like Fourier in reality in in",
        "start": 2911.89,
        "duration": 6.43
    },
    {
        "text": "terms of algorithmic representation of",
        "start": 2916.25,
        "duration": 3.45
    },
    {
        "text": "what is happening in schematic",
        "start": 2918.32,
        "duration": 3.12
    },
    {
        "text": "representation of what is happening is",
        "start": 2919.7,
        "duration": 4.83
    },
    {
        "text": "that we create multiple sets of features",
        "start": 2921.44,
        "duration": 5.13
    },
    {
        "text": "and these sets of features some of them",
        "start": 2924.53,
        "duration": 4.35
    },
    {
        "text": "are very very long you have many",
        "start": 2926.57,
        "duration": 3.54
    },
    {
        "text": "features in",
        "start": 2928.88,
        "duration": 4.14
    },
    {
        "text": "in these tensors what we do we use",
        "start": 2930.11,
        "duration": 4.92
    },
    {
        "text": "higher order singular value",
        "start": 2933.02,
        "duration": 4.68
    },
    {
        "text": "decomposition to reduce them in terms of",
        "start": 2935.03,
        "duration": 7.23
    },
    {
        "text": "those long dimension put them in in all",
        "start": 2937.7,
        "duration": 7.7
    },
    {
        "text": "of these tensors in the same or similar",
        "start": 2942.26,
        "duration": 6.63
    },
    {
        "text": "size then we put them on top of each",
        "start": 2945.4,
        "duration": 5.77
    },
    {
        "text": "other to form the fourth order tensor",
        "start": 2948.89,
        "duration": 4.92
    },
    {
        "text": "for each patient I cannot show fourth",
        "start": 2951.17,
        "duration": 5.55
    },
    {
        "text": "order tensor so I decided to use a cube",
        "start": 2953.81,
        "duration": 5.07
    },
    {
        "text": "but in your in your mind please add",
        "start": 2956.72,
        "duration": 4.23
    },
    {
        "text": "another dimension to that to make it a",
        "start": 2958.88,
        "duration": 4.95
    },
    {
        "text": "four dimensional cube so that becomes",
        "start": 2960.95,
        "duration": 4.86
    },
    {
        "text": "one patient and we have so many other",
        "start": 2963.83,
        "duration": 3.93
    },
    {
        "text": "patient each one of them is represented",
        "start": 2965.81,
        "duration": 4.53
    },
    {
        "text": "as a four dimensional cube then we do",
        "start": 2967.76,
        "duration": 4.56
    },
    {
        "text": "tensor decomposition we put all of that",
        "start": 2970.34,
        "duration": 4.32
    },
    {
        "text": "reduce that and get the features and",
        "start": 2972.32,
        "duration": 3.75
    },
    {
        "text": "then we feed that to machine learning",
        "start": 2974.66,
        "duration": 4.56
    },
    {
        "text": "algorithm with this algorithm we want to",
        "start": 2976.07,
        "duration": 5.07
    },
    {
        "text": "make a prediction whether the event is",
        "start": 2979.22,
        "duration": 5.88
    },
    {
        "text": "happening in half an hour in one hour in",
        "start": 2981.14,
        "duration": 6.27
    },
    {
        "text": "two hours in four hours in eight hours",
        "start": 2985.1,
        "duration": 6.0
    },
    {
        "text": "and 12 hours ahead of time so we wanted",
        "start": 2987.41,
        "duration": 5.7
    },
    {
        "text": "to have a technique multiple models that",
        "start": 2991.1,
        "duration": 4.41
    },
    {
        "text": "each one of them will tell you about the",
        "start": 2993.11,
        "duration": 6.03
    },
    {
        "text": "short term and long term event outcome",
        "start": 2995.51,
        "duration": 6.06
    },
    {
        "text": "of whether there is an event or not and",
        "start": 2999.14,
        "duration": 5.73
    },
    {
        "text": "I can quickly show you your results that",
        "start": 3001.57,
        "duration": 6.03
    },
    {
        "text": "you know our technique that is using",
        "start": 3004.87,
        "duration": 4.17
    },
    {
        "text": "some machine learning algorithm",
        "start": 3007.6,
        "duration": 5.52
    },
    {
        "text": "developing in arla those that in half an",
        "start": 3009.04,
        "duration": 4.38
    },
    {
        "text": "hour",
        "start": 3013.12,
        "duration": 3.12
    },
    {
        "text": "prediction one other head prediction all",
        "start": 3013.42,
        "duration": 5.28
    },
    {
        "text": "the way to 12 hour prediction we are in",
        "start": 3016.24,
        "duration": 6.84
    },
    {
        "text": "the range of 0.8 AUC which means that",
        "start": 3018.7,
        "duration": 7.29
    },
    {
        "text": "you can predict the results twelve hours",
        "start": 3023.08,
        "duration": 5.97
    },
    {
        "text": "ahead of time predict if some event is",
        "start": 3025.99,
        "duration": 5.1
    },
    {
        "text": "about to happen twelve hours ahead of",
        "start": 3029.05,
        "duration": 5.19
    },
    {
        "text": "time with very high AUC and if you look",
        "start": 3031.09,
        "duration": 5.45
    },
    {
        "text": "at f1 values they're also very high",
        "start": 3034.24,
        "duration": 6.0
    },
    {
        "text": "which means the power of adding all the",
        "start": 3036.54,
        "duration": 5.95
    },
    {
        "text": "data in the structure and keeping the",
        "start": 3040.24,
        "duration": 3.87
    },
    {
        "text": "structure while you're reducing the",
        "start": 3042.49,
        "duration": 4.86
    },
    {
        "text": "dimensionality is extremely important so",
        "start": 3044.11,
        "duration": 6.24
    },
    {
        "text": "those are the items that I wanted to",
        "start": 3047.35,
        "duration": 6.45
    },
    {
        "text": "cover in in my presentation so I guess",
        "start": 3050.35,
        "duration": 6.45
    },
    {
        "text": "that we have some time for questions and",
        "start": 3053.8,
        "duration": 6.42
    },
    {
        "text": "and if you want to use the chat button I",
        "start": 3056.8,
        "duration": 5.4
    },
    {
        "text": "guess if you if you are",
        "start": 3060.22,
        "duration": 5.67
    },
    {
        "text": "your question or comment in the chat box",
        "start": 3062.2,
        "duration": 5.46
    },
    {
        "text": "we should I should be able to read it",
        "start": 3065.89,
        "duration": 8.31
    },
    {
        "text": "I'm guessing to wait a few minutes to",
        "start": 3067.66,
        "duration": 10.49
    },
    {
        "text": "see if there are questions coming",
        "start": 3074.2,
        "duration": 3.95
    },
    {
        "text": "I'm not sure if if the system is is",
        "start": 3095.29,
        "duration": 7.23
    },
    {
        "text": "allowing for for people to post their",
        "start": 3099.69,
        "duration": 13.21
    },
    {
        "text": "their questions we are the chat so oh I",
        "start": 3102.52,
        "duration": 12.57
    },
    {
        "text": "started seeing some some things that",
        "start": 3112.9,
        "duration": 4.05
    },
    {
        "text": "people are posting let me see if I can",
        "start": 3115.09,
        "duration": 5.78
    },
    {
        "text": "if I can see that",
        "start": 3116.95,
        "duration": 3.92
    },
    {
        "text": "maybe not top it's in that case I'd be",
        "start": 3130.57,
        "duration": 10.77
    },
    {
        "text": "happy to answer any questions if you",
        "start": 3139.3,
        "duration": 4.26
    },
    {
        "text": "email your question to me and I will try",
        "start": 3141.34,
        "duration": 6.03
    },
    {
        "text": "to answer them via email so thank you",
        "start": 3143.56,
        "duration": 9.33
    },
    {
        "text": "for your time and I look forward to",
        "start": 3147.37,
        "duration": 7.56
    },
    {
        "text": "interacting with you about potential",
        "start": 3152.89,
        "duration": 6.23
    },
    {
        "text": "questions have a nice day",
        "start": 3154.93,
        "duration": 4.19
    }
]