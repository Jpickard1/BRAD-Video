welcome everyone what get started it's my pleasure to introduce today's speaker dr. Tina Hernandez person whose heart sorry dr. Helen that person came from Stanford she is currently associate professor in medicine as well as other affiliations those are medical informatics biomedical data sciences and surgery her background contains the following landmarks she received a bachelor's degree in biology psychology in UC Irvine followed by and asked her to be in public housing epidemiology that from their medical school then teach the education in computational biology in University Dr then back to the States for many years in Stanford initially with baby Barton yes right right and then since 2011 she saw a faculty in Stanford of assistant professor then rose through the ranks now she's associate professor her research is our health record informatics in the past we've learned of her work related to mining data in yay for prostate cancer and for a number of other conditions and tried to improve the quality of care so today we'll let her talk about her research she's been founded with multiple streams from NIH both past and ongoing ones we like to about those the past and future ones her title is leverage in biomedical big data to transform healthcare delivery welcome thank you so thank you so much for having me here today it's really a pleasure to be able to present this research to you and I've had a wonderful day just meeting some of the faculty some of the other people around campus and learning about some of the really innovative research that you guys are doing so it's a pleasure to come here and and talk to you about my some of the work that we're doing and so so my work is really gonna focus on using electronic medical records and I think that we can all agree that in the era of electronic biomedical data it's going to be possible to efficiently and accurately examine processes and outcomes of care and with the goal to improve both the quality and outcomes of healthcare and so I'm here to say that you know really EHRs are not the future of healthcare each ours our healthcare right I mean we have just we've been having just so much hospitals and and data coming from each ours that that's where we are today in healthcare and if any of you have been following some of the literature for electronic medical records you know that there are a lot of challenges in using these data first electronic medical records were not built for research purposes they were built for billing purposes so data are not structured according to patients or episodes of care second utilization a bedside is not practical there's been a lot of research recently talking about clinician burnout frustration with using electronic medical records they're saying they spend more time trying to get information into the medical record and out of the medical record then they have time to spend with their patients another challenge is that documentation is variable there's a saying garbage in garbage out and and that's what we see in electronic medical records nobody's monitoring the type and quality of information that's being put into these medical records therefore when we look at what's inside the electronic medical record we have to deal with things like missing data incorrect data or outdated data and for outdated data this is becoming a real problem when we start looking at that so if you think about one of the main pieces of an electronic medical record we look at is the problem list so a patient comes in they have a problem and they get documented with that problem usually associated with an icd-9 code well nobody's going back that problem is resolved to take that issue off of their problem list we were looking at our healthcare records and we had you know a thousands of patients who had pneumonia for over ten years you know and and so what had happened was the patients came in diagnosed with pneumonia they got on the antibiotic they completed their antibiotic but nobody went back to the healthcare record to mark that this was resolved and so you have to be creative when you're looking at this data finally interoperability and exchange are limited there's disconnects between the the technical algorithmic and incentive motivations to really share these data however we're not going back to paper records right so so that's what I'm saying electronic healthcare records are here today and you know looking at some of the work from your former colleague julia adler Milstein this was something she published just a couple months ago we showed her she shows that over 90 percent of hospitals in the US have some form of an electronic medical record so we need to think about these problems and we need to identify solutions on how we can deal with these and so a little bit of background about myself so I first began my training in the gene expression era and I along with Jim Lee were some of the first people working in the gene expression world and I think there are striking similarities between the challenges we faced in the early gene expression era but are similar to the new barriers that limit the utilization of EHRs for scientific research and clinical care so what were some of these earlier challenges let's think about these and think about how they are similar to our electronic health care data well the first problem we had with gene expression data is was data storage and organization when we first started creating I'm and I'm not going to date myself but you will get a sense for how old I am but when we were first cloning those first spotter to raid the data was stored in text files they were stored in a directory we had lots of problems on how to identify information within these text files how to store them so first thing we did was we develop a database right so we took this information from the from the text files and we mapped it to an Oracle database second problem was we didn't know how to extract the knowledge and information that was on these arrays so we had these es T's this was before the sequencing of the human genome so we had to think of how do we take this clone that's spotted on our array and map it to a specific gene a location you know how do we deal with that so we developed software and tools to actually take that information and get it back to the clinician and researcher so this was one of the tools we built a long time ago now and it was the source which was the Stanford online resource for clones and es teeth and it's actually still being used today so I was I was kind of surprised to see it was still up and going but so similar problems with electronic medical records we have all this data going in we don't know how to get it out it's stored in different formats various ways and so these are challenges that we're facing finally the next challenge we had was thinking about novel statistical methods to deal with the data again when we first started using microarrays we had to think about how these data are going to be clustered how we're going to do unsupervised learning for them so it all opened up a lot of opportunities with by a statistical bio stats department to think about what are new ways that you can think about analyzing these data processing these data so my work over the past decade has really been focusing on how we overcome these barriers with electronic medical records my work is focused on taking really an interdisciplinary approach to leveraging the granular data that's stored in these in ended records and we we tackle this by four specific items so first we look at gathering and organizing information from multiple source multiple data sources so we're pulling information from our electronic medical records but we're also linking these data to outside resources to get a more granular capture of the data or applying novel data mining tools to identify and extract information from the medical records this leads to new statistical challenges that we're trying to address and think about and also I think one of the the important aspects is you need to think really hard about the data challenges and how we overcome them and then that also leverages what questions you can ask of EMR data there's a lot of frustration when we work with clinicians and who come in and they say you know I want to look at longitudinal diabetes patients who've been on this particular drug well longitudinal data is difficult in EHR certainly at a tertiary care system such as Stanford and Michigan where people come in they get their healthcare services and then they leave so we have spotty sparse information so you need to think about the questions you're asking to these to the electronic medical records so let's talk a little bit about EHR organization and storage you know what does an episode look like in an electronic medical record so at Stanford we use epic and I believe you're using epic here also so as I mentioned EHRs are not developed for research in our epic clarity system we have over 15,000 tables that stores the data data are stored for a particular for one particular variable it can be stored in multiple locations and the same information to be stored in various types of data for example we're interested I have a cohort that looks at prostate cancer we're looking at PSA levels so that can be stored as a lab value it can be stored in the in the text so the clinician might just write it in the text it can be stored as a PDF file that's coming in from an outside consultant so these data are stored in multiple places and in multiple types second there's no standard way to represent data variables or outcomes of interest it's really clinician based division based a particular department might have a way of recording some information that might be completely different another department and and and and so there's no standardized way to to store that so we've put a lot of effort in defining clinical cohorts of interest so how do we do that we first identify a topic so for example in my work we've been working a lot with prostate cancer so we've worked closely with the clinicians to define we do a manual chart review to define our variables of clinical interest we want to know what what these variables are how they're stored where they're stored and so we do manual chart review on you know about 50 or 100 records before we even begin the project to identify where this information is we use all available data for a cohort so say for example if I'm interested in identifying a cohort of prostate cancer patients I'm gonna use diagnosis codes procedure codes there is free text there might be lab values we pull all information to get a comprehensive cohort and then we develop electronic phenotypes that and it's so learning you familiar with vkb org it's been used to store genotype phenotype information it was mainly developed for jiwa studies but it's to identify electronic cohorts and so we have developed these electronic phenotypes for our patients of interest and so what does that mean what do these look like and I'm not sure if you can see this but it was just hided to give you an idea of the types of information that are stored in these phenotypes so you generally have a flow diagram so how would you think about identifying that cohort of interest you then have a list of like ICD known and icd-9 and clinical ICD 9 and 10 codes and clinical terms that you would also use to define the cohort and then you have an NLP piece to think about how you would extract this information and by depositing it in ckb org what we do is release it we release it once a publication is released and that allows other people to utilize your phenotype to identify populations in their own cohorts you can get accuracy scores across Institute's that can help you define that cohort and it just helps disseminate this this piece of important piece of cohort identification so if I so when we build these EHR cohorts you know as I said it requires a multidisciplinary team we have clinical people we have informatics we have technology we have people from HSR helping us think about the question we use all available data we use all data available as I mentioned and we also linked to in addition to just grabbing the information in the EHRs we link the EHR information to genetics to clinical trials that are going on within our Institute clinicians often have their personal databases so we match those up and pull those into our cohorts and also patient surveys and a lot of the patient surveys get at quality of life some other types of information and so we we pull all those together into our cohort and then we link to outside datasets so for example for pass prostate cancer cohort we link to the California Cancer Registry and we do that for several reasons one it allows us to identify patients who were diagnosed at Stanford but sought treatment outside of our Institute it allows us to follow up on longitudinal data so they capture information on metastatic disease survival etc that we might not necessarily have in our electronic healthcare records and and then it also contains detailed curated information on pathology histology etc still we capture we link to the database and we pull all this information into our cohort we have other datasets we're also looking at post-operative pain for those we link to different substance abuse information so the Cure's database is a registry of all controlled substance substances in the state of California and then we also look at since status so some of our questions are related to access to care or patient outcomes so we have the patient's tip code in our electronic medical records so we we look at the geographical information systems to get information on where you know what's going on in their local zip code so what's the what is the crime rate what is you know how many grocery stores you can get information on how many grocery stores are in a walking distance you can start looking at distance to their their care centers so what is the burden on the patient coming back and forth to the clinic so you can start asking some really interesting sort of health services health policy questions by leveraging by capturing all these data so what we do is we take information from across all the data fields to build these cohorts so that we can really drill down and look at an individual and try and help help provide evidence that can improve the care they receive and so I told you about we've developed a cohort for prostate cancer so in our prostate cancer cohort we've identified several subpopulations our primary population is prostate cancer patients seeking initial treatment at our University we have the full episode of care for these patients so we see previous risk factors we see processes of care we get sub sequential diagnosis survival and metastatic status and and then that allows us to start developing prediction models some classic classifiers to look at some of these different outcomes using all available we have data we have available we have a secondary cohort which are patients diagnosed with prostate cancer seeking treatment for something else and we also have a screening cohort so I had a lot of interest in health services research so we look at guideline recommendations and things like that so we've pulled in our entire male population 35 and over to look at screening pattern differences to see who's being screened for prostate cancer who's not being screened so you can see by developing these you just have so many questions that you can start asking of this cohort from all different directions we have you know how services questions clinical questions epidemiology questions and so it really develops this really nice resource so the second piece when we're thinking about building this cohort is we need to start thinking about standardized formats for tool development so it's great when I'm building at Stanford I've built this cohort it's it's you know if we're doing a great job with this but what if I want to implement this at Michigan how do we start thinking about that and so there's two initiatives that we have been really working closely with and following the first is the observational medical outcomes partnership which is called Olaf and it's actually there they're actually no longer existing as a community but what they've developed is a common common data model to evaluate data standards comparative effectiveness research personalized risk prediction and data characterization using this common data model I'll walk you through how we develop this but what it is it's a standardized way to identify things within the electronic healthcare records so patient has to be named you know patient underscore and zero or something like that and then in addition to OMA there is the Odyssey workgroup and Odyssey has leveraged the OMA common data model to build several software tools so they're developing algorithms that can be shared across systems to look at data characterization prediction models and data quality so so how does that work so the first step to doing this is you have to convert your electronic medical records to the OMAP OMA format and so what you do is they have developed an extract transform load load program that allows you to efficiently map your information to the common data format it's something that really needs to be done in combination with the clinicians who really understands the variables they have software developed to implement and then they also have testing so it's it's a reiterative thing so you you map your data you do test you might have to go back and change some of the mappings so what is the Odyssey and Oh map can't give you so so right now for the common data for common data model from OMA they have over 50 databases that have mapped to this model what's interesting is the VA has now announced that they are going to map their er EHR data to the comp this common data model the the data translation so it conserves the source values all the data can be maintained but what it really allows you to do is develop algorithms develop prediction models using your own EHR and share these models with other institutes and they can implement them within 24 hours because you're using the same data structure using the same formats so it can be very powerful when you think about sharing data sharing algorithms so resources needed in order to do this as I said it's really a multidisciplinary adventure you need to have feedback from the clinicians from the ite and from the programmer who can actually run the programs and so what we've been doing with some of these formats they have one of the features they've developed is called Aphrodite and what Aphrodite does is it take the clinical note and it pulls out there we go so it takes a clinical note and it pulls out for example all icd-9 codes all structured data all lab features and it's developing prediction models so it will give you a vector of occurrences for all of these different aspects in your electronic medical record and it will start helping you develop some prediction models giving you all the information you need to test recall sensitivity accuracy these models don't yet include the free TechSoup don't wait don't yet include the free text but it's something that they're working on and so there's been a lot of effort in developing these common data tools for this so the next problem when we're thinking about using electronic healthcare records is extracting that data that information that's embedded within the record so one thing to note is that about 80 percent of EHRs are stored as unstructured free text but that is really the granularity that's really the important information that want to get out so we've developed a few pipelines to extract this information from the electronic whole from the from the medical record and what we do is we take the free text we have an NLP engine so a natural language pipeline pipe engine that does first some text pre-processing so if the text is in a note that is for history we assume it's going to be past past history there's a lot of pre-processing you can do to help you know make the the pipeline run more efficiently we then do term recognition so we give it a either a list of terms that we want to recognize in the text or we do index the entire record based on ontology Xand and key terms of interest and then we extract the knowledge and so we can either take the knowledge that's extracted and store it back in our database or we put it in a matrix of terms that for example in this matrix we have patients our rows are clinical term oops clinical terms are columns and then you can look across episodes of care so regarding the the NLP I think it doesn't really matter if there's there's so many off-the-shelf tools right now to use NLP and then we've tried a variety of different tools to to extract this information I don't think it's we have found it's not important the type of tool you use it's just important that you're able to use a tool to extract this information so this first pipeline here we index all terms within the note using medical oncology ontology sorry and then we extract the terms of interest that were that we want to look at put it in a matrix and then and then we can evaluate it the second one we'd use gate which is a stand-alone software to extract natural to extract text from EHR both of them are equivalent both of them are giving us fairly similar results as far as accuracy and recall and so I don't want to say I mean I would love to talk to you more about some of the you know more in detail about the algorithms but it's been our experience that there's we haven't seen a big difference in using these to extract the information from the medical records it's just important that you use something to extract these and so what do we do with this information and and so one of the reasons why we want to extract the text as I said is because 80% of the information is stored in this unstructured text so I just wanted to give you a view of some of the research we're doing on this so in our prostate cancer there are outcomes that are known as patient-centered outcomes which are outcomes that are not measured by lab values or structured data they can only be reported by the patients and so we're really interested they're very important following prostatectomy a prostatectomy so it can be urinary incontinence or erectile dysfunction so when a patient goes to receive treatment they have to decide you know which treatment is better for me do I want a treatment that has higher rates of urinary incontinence or do I want a treatment that has higher rates of erectile dysfunction it's a very personal question and we don't have a lot of evidence to guide these treatment decisions so we sought to look in our in the medical records to see one is this information recorded and here you see that we looked in 5,000 patients and we saw that of the 5000 patients only four patients had urinary incontinence recorded as an icd-9 code but we had about 1,500 patients who had it recorded in the text we were able to extract so this information is in the the medical record next question is you know how good are the clinicians at documenting this information so these are some results looking at the components between the information we found in our unstructured text and those reported by the patient in a patient survey and so you can see the blue line is the the rates extracted from of the unstructured text using our NLP algorithm and the green line is the information from a patient survey a mailed out survey so you can see we're highly highly concordant in these outcomes so it's being documented and it's being documented accurately now this might be a special case as I said this is a very important outcome following prostate cancer and so that's why we wanted to look at it in this setting but I think that you can apply these algorithms to any other domain thinking about some of these other patient-centered outcomes that are not recorded as structured data we can then take this information further and look at it across treatments to help guide clinical decisions so here we're looking at the different rates between erectile dysfunction and urinary incontinence over time following prostatectomy and you can see that you know at 3 months the rates are fairly similar but when you go out to 12 and 18 months you have this oh sorry this is only for prostatectomy you have higher rates of a wreckless function than you have urinary incontinence when we look at this after irradiation we see flipped results so really developing evidence that the clinician can talk to the patient about trying to guide those treatment decisions I think this really opens up the door or patient-centered outcomes research and leveraging it bringing it into sort of the Big Data environment moving away from mailed out patient surveys and being able to look at these outcomes at a population level so I want to talk a little bit also about what we're generating these data we're using these algorithms to identify text I want to talk about some of the important statistical challenges that we have with this data and I mentioned some of these briefly the first challenge we have is missing this and incomplete data data are sparse unhealthy people are more likely to return to the clinic than the healthy people so when you think about getting your patient sample in the EMR s you have to think about this inherent bias and and how are you going to deal with this data are noisy we have inconsistent information we have inflammation mismatch we have inaccurate information and so we need to think about how we deal with this this is very similar to the challenges we dealt with in gene expression data you know 20 years ago and so you also need to think about when we're developing these NLP algorithms you know we're giving you an accuracy score so I'm saying I'm about 89% act sure that this patient has urinary incontinence or not so then when I start developing algorithms seeing thinking about associations with urinary incontinence what's predictive of urinary incontinence I need to start thinking about how do I take those accuracy scores into account when I'm starting to look at regression models and things like that and the standard errors so I think there's a lot of interesting challenges that we need to think about and right now there right now it's it's it's an open field you know people aren't really thinking about these data and and the challenges with the data right now we also need to think about data capture and measurement they're not consistent when you one of the projects we're looking at is pain measurement during the inpatient period and so a lot of the packaged algorithms expect that you're taking measurements at specific time points or at regular time points but when you look at this information in the EHR there's no consistency you know you're taking the measurement when the patient is is requesting his PCA you're taking the measurement when the patient's complaining or when the nurse is doing rounds so you need to start thinking about you know this inconsistency in how we're capturing the data and and the time intervals involved and also the data is hierarchical one of the strongest predictors of receiving a typical meta and opioid medication after surgery is the division who you went to have the division who you saw in your hospital so it's practice culture it's it's the training culture and it's so data are nested so we need to think about that when we start looking at these data the patient belongs to the clinician who belongs to the to the division within the hospital so all challenges that we need to think about and people are you know people are thinking about this but III think there's a lot of opportunities to really dig deeper into these methodological issues and I just said that so so we've been thinking about this and in what's nice is our biostatisticians are so excited about some of the data that we have because for them it's offering opportunities for them to carve out this new field in you know thinking about the biostatistics of measuring and using electronic healthcare records we've developed a couple new methods for dealing with these data the first is a nom parametric method with robust linear regression and Comedians cluster package to look at disease trajectories so for that again we're taking into account that these measurements when we're looking at trajectories these measurements are not taken at at regular intervals there there's a randomness to that we have a lot of outliers in this data we're also looking at methods for FM estimating the causal effects in the presence of differential missing data across sites so again I said you know healthy healthy patients less data so so we're looking at differences in imputation method methods do you do you impute this data before you cluster the the patients to you how are the different time intervals and how does that affect your standard error and your bias we're also looking at testing portability of prediction models across sites so as I said it's really important for the the algorithms that were developed that we can look use these algorithms and other sites so we're thinking about how do you measure the accuracy there's a Gini index that can compare models but there are other novel ways that you can think about comparing the the transportability of some of these algorithms across sites sorry this is some of the clusters when a that we've been developing for pain score trajectories so what you see in the first part of the slide is what we've done is we've looked at pain trajectories across the impatient stay for all patients receiving four types of surgery we then use all of the data points for their pain scores so some patients had ten pain scores other patients had 150 within a three-day period so then we cluster the trajectories and here we're looking at principal principal component analysis and then these were the actual the the the pain trajectories themselves and what we found is the patients who had these trajectories that working that that went up before they were discharged had a higher rates of post-operative complications and higher rates of 30-day readmissions so this is something you can think about you can start taking this into account when you see a patient in the clinic and their pain scores are gradually increasing it might be a way to think about you know this patient might need additional monitoring this patient might need additional resources and we're able to do this before they're discharged so there's still action that can be taken so I think that what we're developing by using these electronic medical records is we're trying to learn from all the data points available you know where we've been developing a lot of projects using our pipeline and it's really enabled a lot of opportunities for research across communities in our institution so if you think about our patient cohort it's providing opportunities for all types of studies we Junior faculty coming to us trying to get preliminary data for for ongoing projects we have junior faculty or trying to carve out some information want to know more about their patients we have it the infrastructure set up so that students so medical students PhD students residents fellows can come with a very specific type question and do a research project within a period of three to nine months so it's important because they don't have to spend the first three to nine months of their fellowship trying to gather the data we already have that set up for them it also offers a lot of teaching opportunities I think we're training training the next generation and we need to think about these important statistical opportunities important software development opportunities and new ways to think about and extract this data and some of the research that we've been doing with these cohorts I've had listed up here from a health services research point of view we've been looking at guideline guideline recommendations so as I mentioned or looking at for example the u.s. task force recommendation to stop all PSA screening in 2012 and so with that information we can look at one how did clinicians react to that to that guideline change we saw most of them to still kept doing PSA tests but then we also want to look at you know could these guidelines affect staging of diagnosis and could they affect treatment outcomes we're also looking at guidelines from the Center for Disease Control regarding opioid discharge medications or opioid impatient medications so we can look at our cohorts to see are these guidelines being followed for our surgical patients they're discharged a lot of them do not are not following the guidelines for opioid prescriptions however what we care and do is we can see where they're not being followed and why they're not being followed and mostly what happens is that they're a specific population of patients that we can identify the guidelines don't aren't appropriate for this type of population so for example in particular with the opioid there's patients who are Weston taking SSRIs which is a serotonin inhibitor and so those patients don't do well on opioids because SSRIs block the SIP cytochrome p450 2d6 so therefore the opioid is not metabolized so we can use these data to one look at these guidelines to identify are there specific populations that might need different types of medications different types of treatment and really it's a step towards that precision medicine and identifying the right treatment for the right patient based on evidence that we have as I mentioned we're also doing research in the patient-centered outcomes I showed you our our information for prostate cancer and urinary incontinence and we're also getting into the personalized care and prediction models another thing we're doing with our opioid information is we're looking at can we identify the right amount of opioids that should be going home with each patient so right now the guidelines are you know anybody getting Neri surgery surgery goes home with 30 pills of narco for example and so maybe not 30 pills isn't right for every patient you know that's the average patient but how do we start identifying which patients are going to need more or less opioids some patients don't even use their opioids so we can start generating this evidence to really guide those treatment decisions we also have been doing some work taking these cohorts to investigate generalizability of clinical trials here I'm showing we did a clinical trial at our Institute looking at the effect of perioperative gabapentin on post-operative pain and opioid cessation so first they did a very expensive randomized control trial it included 422 patients and their results were that the gabapentin which is an alternative to opioid had no significant decrease in pain however it reduced the amount of opioids that they were given so you know this was a four year trial very expensive so we said I wonder what this looks like in our EMR data so because we've had our cohort developed in a matter of I think three or four weeks we were able to replicate the study results from the clinical trial using a population of 4,000 patients I believe we have over 4,000 patients and we showed the same results so one using gabapentin did not change their pain their pain outcome however we saw 37 reduction in the amount of opioids they needed during the inpatient stay so this is a good example of how we can use this data to to look at different to start thinking about research in a different way to start you know what is the generalizability of these trials at a much less expensive and much more diverse population for thinking about the methodological opportunities we have of these cohorts we have BMI students who are working in my group right now developing predictive models working on open open source software tools so some people in our group are contributing to the Odyssey common data models that I spoke about earlier we have patient students working on unsupervised machine learning algorithms missing data imputation we're looking at disease progression models so how can we start measuring disease progression using the amount of data we have we have biostatistical students we have postdoctoral fellows getting much bigger projects and we also have clinical informatics people who come in they take a year off their residency to come in and learn about informatics so a lot of opportunities for teaching and and and methodological projects so where are the opportunities not everyone is going to go out and build their own EHR systems so I wanted to talk kind of about some of the opportunities I see and and where some of this work is going so has anybody heard of the cures Act The Cure's Act which went out I believe it was two years ago so the Cure Zach donated 4.8 billion dollars to advance research it's support it provides whole but invest in research and it streamlines streamlines like FDA guideline and regulatory information each of the projects here in under the Cure's act have some type of computational order or informatics component for example you have 1.8 billion dollars going to cancer research you have 1.6 billion going to brain diseases you have 1 billion going to opioid abuse and so these are all things you should start thinking about as an implementation when we're starting to think about these data how can we start leveraging you know some of the tools and the opportunities that are out there to address these questions using our EMRs and some novel statistical methods when you think about what's being funded right now from nih some of the the most funded projects are on opioids machine learning obesity precision medicine adverse drug events and patient safety so all of these all of these topics have some type of component that can be leveraged through bioinformatics through through EMRs and these are things are getting funded so you should for opportunities I think there's a lot of opportunities I can see our EHR cohort addressing every one of these questions in some form or another the Institute of Medicine has also put out an initiative to look at social determinants of health using electronic medical records so they have suggested that somehow we need to start capturing this information in the electronic medical record and they even give you how this information should be captured and and the frequency that it should be captured these are opportunities these are opportunities to think about how can we capture this information how can we incorporate this into the EMR and more importantly how can we start incorporating this into our analyses when we're thinking about clinical research when we're thinking about clinical analytics these are all opportunities if you think about the hot topics in 2017 so if you look at the news media the hot topics if things that have been reported most in 2017 smartphones wearables real-world evidence remote care but look at the middle one prediction precision medicine pharmacogenomics participating medicine so capturing information from the individual these are all these are all areas that everyone's talking about and we're getting funding from these from the from NIH so there's really a lot of opportunities to think about how your research can leverage some of these things that are being funded that can leverage how this information is being extracted to answer these questions and finally NLP interfaces burnout which I spoke about earlier and new MD competencies you know the the clinician now has to think about not only how to treat the patient but how to document that patient how to get the information in the EHR and how to synthesize that information when they go to treat the patient so I am just going to wrap up here so I think that you know when you think about the big data movement there's been rapid development in computer and laboratory technologies data storage eing and processing or no longer limitations we get voluntary data contributions we have information coming in from wearables from patients or sending in information we have this outside data we can leverage public health data environmental data incorporating omics data right integrating into the healthcare record genomics proteomics all of this information to start thinking about disease and we also have global collaborations where we're sharing information trying to share information not only across sites but across Institute's and across countries so then the question comes you know how do we treat population health while dealing with the precision medicine right it's a challenging question where we're trying to look at population health information while treating that individual patient and so I think there's a lot of opportunities and I think that data can really the the the EMRs can really generate data that can help to count drive some of these decisions and so with that I think there are opportunities as I said in tool development in dissemination a lot of the tools we develop our open source software it's really interesting to see when you do develop these tools and you put them into open source software how other people utilize them how they refine them how they package them how they promote them you can your tools that you develop can be used in all different ways that you didn't think of but it really gets to the dissemination of the information and so I think that our group has really worked hard on overcoming the hurdles using electronic medical records I've really leveraged my past experience using gene expression data where I think there are a lot of similarities as I mentioned I believe we can really accelerate data-driven evidence looking across multiple collections of big datasets developing novel models for describing and managing data and real time monitoring which is something we're really challenged to do if getting that real-time monitoring and then bringing that information to the point of care I think it's important that we remember our experiences from from other areas you know electronic medical records are not the only ones dealing with a lot of these issues and so it's important that we think about that and we need to think about disseminating is hearing this information in novel ways of course I have a very very multidisciplinary team I have worked with a lot of clinician methodologists staff and students and it really is a multidisciplinary approach I alone cannot think of these problems or the solutions to these problems by themselves and it's been really exciting working with a dynamic group who can think about these questions in different ways and so with that I will stop I will put my disclosures up this work is funded by NCI hrq and ask Seneca and I would be happy to take any questions you might have questions in the beginning of the talk you had mentioned there's a big issue with the physician HR interface and you know as this becomes a bigger part of healthcare I was curious to hear your thoughts on how you think that will change and second more more technically as I'm just curious what kinds of programming environments your group uses so first question is dealing with physician burnout right and so so that that is a big challenge and a lot of people are approaching it in different ways some some groups are developing smart forms to capture the information there's a lot of things going on with doc talk so the narrative text can automatically be trance translated and described transcribed into the EHRs but there aren't any good solutions right now so if you look at some of the rates there's been some publications looking at the rate of physician burnout and it's just escalating and it's interesting because this this great increased corresponds as soon as the Institute installs the electronic medical records so physician burnout is a big challenge right now and and again it's hard because these records are only useful if you get good quality data put in but somehow you know we need to make that easier and facilitate that from from the physician side and sorry your second question was what kind of programs are we using so most of our programs are developed in Python and then for the NLP we're using context we've used nuggets sometimes we have developed the gate the gate software system which is used for NLP but we're moving more towards just the Python code that incorporates context and nigut now let me ask you a follow-up question on the ontology - to clean up the language yeah to make the word more more disciplined there is a database in Stanford but what about a nationwide effort to standardize all right so so far on college so what we do when we're developing our phenotypes we identify these clinical terms and then we map our clinical terms - like sno-med and other oncology's to grab all the synonyms and and right answer yeah and so then what we do is in our algorithms we don't code every synonym for for the different ontologies we just link to the different sources and bio portal to incorporate all the ontologies and then we we share these terms and the mappings to the ontology through the ckvr repository I just wonder when this is open source and transparent that's all good but to what degree we wish for a national authority to have staged knocking of the dictionary right and and and that's that's challenging I mean because there are no standards for how to do this and so I think that there needs to be and the right there needs to be some national efforts on how we do this now I talked a little bit about the Oh mop and these common data models and and Odyssey and and so that's not a national effort right it's a consortium but it is gaining interest and and now having the VA map to that system that will be a very interesting interesting thing to see how that takes off as questioners continuation of the question about burnout and the data entry is dirty work and difficulty in finding advice how do you see would be one some mechanism that effort why so what so we've we've been looking at that question a lot for burnout and so some of the burnout comes from like documentation of quality metrics and quality reporting clinicians have to write okay I documented this I documented that so some of the algorithms we're developing extracts as information automatically just based on the free text so for example one of the one of the quality metrics that that urologists have to record for prostate cancer is the direct digital rectal exam and so there's checkboxes the clinician has to do so what we're able to do was we're able to find that they've documented this in the electronic health care record so we're pulling this out in generating automatic reports and sending them to the hospital so that the clinician it just reduces some of the burden of the clinician so there are innovative ways to think about how to grab that information out and and reduce the burden on the physicians so any other questions okay that's so I'm not a field of Epidemiology for many many many years has been thinking about you know observational data with many of the same right messy issues and they worry a lot about bias and confounding and so what what's fundamentally more promising about EHR that epidemiology hasn't been able to I don't think anything other than the volume of data we have and and the missingness of data so in in the healthcare records you just they're just being randomly recorded and so how is it different from epidemiology it's same questions it's like it was the same questions in gene expression but I think that because of the volume and the size of the data we need to think about new ways to think about some of these questions and for example when we think about accuracy scores and things like that you're out in epidemiology sometimes we have very hard outcomes they're easy ones to look at like death or or mortality there's no inaccuracy when I'm saying this person died or not but when we start looking at some of these machine learning outcomes there or sorry um some of the algum outcomes we generate from NLP we have to start taking about thinking about accuracy scores how to put that into the algorithm but you're right they are the same questions that we keep revisiting over and over so maybe it's not the new algorithms it's the new systems or saw where to deal with the data formats and the data types we have great talk Tina when you do some of your analyses do you ever look at the instead of that patient level at the provider level like if certain providers are copying and pasting from note to note and you've got one doctor who spends you know 15 minutes documenting everything in the world versus another doctor who spends 2 seconds yeah like do you account for that and you know you can and there's a lot of technique so you can look at like keystrokes they've used to input the text so you can tell if it was copy pasted we haven't done that I've there's been some reports that have done that what we found works even better is we go back to the clinician and we show them okay here's the data you know here we were able to pull this pull this out of the documentation and we found that as soon as they realize that we're using their documentation they become much more conscious of what they're putting in there we've had so many close you say oh I didn't know anybody look at that other than me I'm like now we do and keep out you know EPR I don't know what that means no one else does either so so really sharing that information has been really useful to to make clinicians aware that we can use this and I think that the more proficient we become and utilizing this information and generating you know research using this information the more that they will be aware that this is important and useful thank you I have a question which is that this is not my field yeah and I'd look at some of the data in the area of of all assignments they have a program right now using ammo packs can tell me whether that could be a biomarker okay yet we know from data a lot of people have shown that get beta-amyloid the PI's I really antioxidants so I'm confused because antioxidants to me is a curing aging that's it yet they are looking at the same thing whether they are the cause of the outside the party is that big data telling us telling us that's right I think you're asking about some contradicting evidence about applying but on you know it's with any observational data we we don't we're just looking at what the data it's really hard to have a causal inference using this data I think it can really guide us we can see you can look at it and say you know I have a patient who has you know diagnosis XYZ and has lab results ABC how are they treated before you know what a previous treatments have been done for this patients that were successful but we're it's very hard to look at causal relationships I think with this data it can generate evidence it can help guide us think about what are the right treatment options but I think that it needs to be used cautiously and just you know viewed as as evidence-based information so that's why I was very surprised that some of the data yeah bad data going in and of course that that data will come out but yet they are spending a lot of money today have this kind of program to determine whether amyloid is a biomarker right profiler and and so one of the things we're doing with the EMRs is we're not is we're just looking at what biomarkers are recorded we're looking at where they're recorded we're looking at if they're recorded some of the if you think about for cancer registries they're trying to capture all the biomarkers associated with particular cancers so what we can do with the EMR s is we can identify are these being recorded you know what is the information there and extract that information and you know it as I said it just depends on the information that's put in there it could be contradictory it could be wrong it's incorrect but hopefully because you have the mass information those turn into noise and you can get a strong signal with some of the real important data I think a lot discussion can continue afterwards thank you thank you all right let's thank you [Applause]