hi everyone um it's my pleasure to be here to give the talk about my research uh some of my background I I just joined the Department of rology last year after finishing my medical physics residency still at and I did my PhD here uh in at the apply physics program so that's a little about me uh I will come to start my talk now so the title here is translating workour to practice leveraging machine learning with imaging data in radiation qualy um so some uh background for radiation therapy um on the right side is a linear accelerator that's the main device that we used to treat cancer patient um this device rotates 360 Degrees around the patient the patient will be immobilized on the couch and depending on uh what kind kind of cancer we want to treat and the disease type we will use photons electrons in some institutions there's also protons of carbon ions available for the treatment for um we only have 4on electrons and this machine as shown in the right is a Varian a true beam uh linear accelerator or lck so the rational that we how we can use radiation to treat tumor is uh shown on the left figure um the x axis is a dose and Y AIS is a probability so there are two curves one is a tumor control probability which is the one that's on the left side and the other curve is the normal tissue complication probability so for radiotherapy we want to find the optimum dose that we have the um Good Humor control probability another also limiting the complications as low as possible so that's kind of a like a sweet spot that we want to find and give this dose to the specific patient and this is a radiation therapy process um so the first step um is to uh based on the physician um they will make a this treatment decision so for cancer treatment except for radiotherapy there's also chemotherapy of course surgery um So based on a tumor ball discussion if a patient is referred to to have radiation therapy then we will have the second step to have the patient uh in the CT simulator to get a planning CT ready and that CT for the third step will be uh used to Contour the tumors and the physician will prescribe a dose that's desired for for the tumor and the symmetrists will do the treatment planning based on this planning CT and the next step is um primarily our job as a medical physicist we review these plans and make sure it's correct and accurate and um most optimal and do the QA and if there's anything that's sub optimal we probably want to replan it and then after all these are ready we will do the radiotherapy delivery so the patient will and in uh uh like lying on the couch as I shown and in the linear accelerator and after the treatment there's always U fall up depending on the type of disease and physician sometimes it's three months uh every three months sometimes it's like one year so that we will know how the tumor control and normal tissue complications are um so this comes to like a over viw of my research so so there's this kind of panomics or omics of radiation oncology so uh like our routine treatment there will be different types of data collected such as tissues uh blood bom markers and imaging data of course as I just shown U so all these different types of data can be used to correlate with our outcome if we use genomic data it's called genomics and there's other omics available so uh my my research mainly focuses on using Imaging data and try to corate or predict the outcome so it's kind of under this radiomic subcategory and then um so we analyze the data and try to see how well um this images can be informative to the treatment response um so the goal of this these studies are all focusing on how we can use these images combining with other type of clinical Bell markers and leverage on the S of Arts machine learning to help improve patient outcome so um so we want to predict local tumor control and all distant metastasis and we also want to know um what is the probability of noral tissue complication and of course one important thing is what will be the overall survival be and using this type of uh treatment and um so for machine learning it has been um criticized a lot being to be a blackbox so in my research I also want to understand the factors that contributing to the outcome and to understand what's going on within the model So based on this uh we want to seek ways to have better tumor control and less uh distant metastasis and less side effect and uh finally help to improve uh the patient quality of life um this is an outline of the talk that I want to uh introduce some of my work previously um so first one is um inro hepatic recurrence prediction it can be called it's not metastasis um but it's like we treat the primary tumor for liver cancer patient but um the tumor recurred elsewhere still in the liver so it's called intop apathic recurrence and uh the second project I will introduce is due for a liver cancer is called heptocellular caromal or HCC so I combine different uh modality images and clinical biomarkers to predict the overall survival for this patient and the third project um will steer the um towards the head and neck cancer or H SEC patient so there are lot of local and distant progression even after our radiotherapy treatment so we want to understand and predict How likely a patient will develop this recurrence and try to understand which features are contributing to this and to um modify our treatment strategy so I will start with the first project uh the inic recurrence prediction the motivation of this work is is although we have improved the tumor control prob probability to be above 90% using the new sterotactic body radiation therapy a kind of radiation therapy with low toxicities however Ina recurrence elsewhere then the primary tumor remains prevalent it's like higher than 50% and is a main CA of deaths for post treatment patients so the goal of this work is try to be bu multimodality deep learning models to predict the location of progression elsewhere inally and Bas on this we want to provide some quantitative guidance for the treatment planning so this is a tough project um but um I I will show an example to see the feasibility um so this is an example our patient uh liver images um like the first these are m the first two on the top um like different contrast the same image as we can show uh see that the yellow circles out the primary tumor and um the red circles out where the tumor recurred after 46 days and the third um figure um on the top is a dose distribution we can see that the higher the intensity or the brighter it is the higher dose we give to the primary tumor but because at that time we don't think that the red circle is a is a lesion so we didn't treat it but after like 100 about a little bit more than 100 days when we do the followup we found that this red circle actually is a recurrence um using this MRI images so there the assumption is there are some signals already exist in the image pre-treatment that we can Lage out maybe for the treatment planning we can modify the dose to cover this um red suspicious Mass um early on to uh reduce the probability of the recurrence um there are about2 HCC patients enrolled in this study and all of them have cont enhanc CT images as well as T1 withed Mr images and also the 3D dose distribution and the end point is uh like to predict the location of new tumor outside of the previous planning tumor volume after SP RT B on the Kun note segment Kuno segment mainly used in liver uh surgery based on this whel so it um um so it will like segment the liers into eight parts so we we we will use this concept here to predict which segment the lesions uh end up recurred um there are like 59 Patients Out of the 122 patients that develop this incaic recurrence and if you look at the segment wise so there are 85 segments that have recurred tumor out of the of the N about 900 segments and this is a distribution of like where the tumor recurs we can see that segment seven and eight and maybe 4 a are primarily like the higher probability of having recurrence um to predict it uh so we propose a framework um to first use uh deep learning based or registration method to get the segment for each patient and then using an attention neuron Network to predict whether or not a segment will have a recurrence so as we can see here um the patient CT and the patient Mr will be registered by this five 51 and then um the atlas C which so uh just some background so we don't have the AG segments for all these patients so it will take a very long time and effort for physician or where uh anybody else to make the Contour so for this particular Atlas C we have the the segments Contour so we try to use um to register this Atlas CT to the patient each patient CT and also deform the corresponding eight segments based on this deformation and then for each patient we will have a segments that segment out this lever based on the kote method um this is like so we have the liver and tumor contour and dose distribution and uh this is the Atlas segment um mask for the Kuno and this green means um uh rigid registration and the purple is uh deal registration using deep learning for the uh to obtain the Kuno segments uh we use a method called box Vox voxo more of CNN the basic idea I just explained so there will be a moving input image which is here in our uh study is a moving Atlas CT and a fixed patient CT um which we have like around uh we we have 52 patients and going through this kind of unit structure Network and then so there will be a registration field learned by this network and we can do spal transformation and this moving uh Atlas CT will be uh like uh registered to this fixed patient CT so and then we can calculate the loss between this output and the fixed patient CT and then train the model and this is an example of the after this Atlas is registered to the F uh fix patient C te how these Contours of the atlas can be um applied to the patient and get the patient eight segments so it's it's not um perfect so but it's good enough for our purpose for the prediction uh this is some more of the mathematical part of the loss function so there are two parts one is a similarity loss uh to compare the move um image and a a fixed image and the other is a regularization of smoothing uh loss so that um the similari is using cross correlation this kind of uh metric is very good at um like you if the two images have very different uh intensity or it's very different modity um like CT and Mr and smoothing lws is trying to so U is a deformation field uh each like each box so we have uh three Direction XY Z so we want to make the gradient small that it doesn't have very um um like weird deformation field uh this is kind of the a little more detail of the Box Mo structure with the two channel input and three Channel output for the deformation field for each boxo and um the first step is to try to get the segment or could uh Kuno segment and the second it will be to predict where the tumor will recur in the segment and we use an attention Network as shown here it still has a unit backbone structure um One new uh um technique here is called attention gate that is used used here to give more attention to important parts in the images and then afterward there's the output Channel one will be used with multiplied by the Kuno segments we already get and then um to average scores from this segment um by using Banner cross entropy loss to the prediction and this is um uh affiliate or surrogate task that can help face the final prediction on the top so we have the primary tumor mask we can also get the segmentation loss so that if the network learns where the tumor is it might might help um to get some more information relevant to our uh final task this is some uh of the details about the attention Network so on the uh right side the figure uh shows like for the gating input um and we do convolution with a one one by one by one kernel and then we um combine our conate is with like the UN structure um you like upper or uh more higher resolution image and then go through um this another convolution and then the alpha here is a coefficient that is also learned by the network that that it will help to know which regions is important for our final task uh so this is a result for the unsupervised form of registration uh so for all these 102 patients uh it just used like about 2 minutes to get all the Contours it segments comparing with like manual work it's kind of maybe several days of work um and the average dice coefficients the dice coefficient is just um a metric showing how good the segmentation is it's about point8 so it's it's as I just mentioned it's not perfect but since we are not our main task is not to do segmentation so this is good enough our uh Downstream task for the prediction of recurrence and this is an example of the registration result um so this is uh from left to right is a patient C Atlas C and moved Atlas CT um and the transformation field and the segments that's like for the eight uh kote liver segments and also uh the bottom I show some training process of the total loss and reconstruction loss and the smoothing loss um for the network um the results for the uh prediction of recurrence is is not perfect for now um so the four Images the first one is we if you use only CT and the second one is if we use only Mr image and the third one is if you only use those and the fourth one is with use the combined all of the three um image information so the combined one have slightly better result in terms of predicting which segment we have recurrence but it's it's a little bit far from uh what we can actually use clinically so um I will continue working on this I think another challenge we have is although some patients um the pre-treatment image does show signals of where the recurrences but for some patients there's really nothing that we can see using bare eyes in the pre-treatment image to guide um the prediction I think that's one of the challenges okay um so uh I will talk a little bit more about HCC this is a second project that we have also used multimodality data uh so it's a deep survival interpretable romic model uh to predict the survival um the data we have still is counter enhan it images and there are some other variables like uh there are 37 clinical factors including age gender and like the r function test um and there are 56 radiomic features so these radiomics features are some texture features that are calculated from the images for example um like Zone size nonuniformity so or that there are some formula that helps us to calculate this three or design features which represent how hetrogeneous uh like a region is and there are also some micr ra data uh but unfortunately there's only a subset of patient have it have this information and uh on the left figure shows like brief um uh structure of the uh study uh with 67 patients in this study and we use a variational auto encoders uh combined survival Network for each of these different information input and then combine of you this um um um information and then have a final prediction for the world survival and to uh help evaluate all um overcome some of the uh overfeeding issue we use 10 times five F cross validation and this is just show um the histogram of over survival time for the patient um as we can see it's mostly like the media it will be about 500 Days uh this is a network structure so as I just mention there are three uh type of input one is extracted Imaging features which is the radiomics and the second is clinical variables including uh some uh common age gender and uh lab test and also contrast enhan City images so these three parts and then we fuse the we use the St surviv loss here and then combine the kind of prediction from these three channels to get our final result uh so for the variation of Auto encoder which is used for both romics and uh clinical features there is an encoder and decoder and we try to reconstruct the put by this kind of structure so there are also like two laws one is a reconstruction law and the other is a k Divergence um this is kind of the detail and there's a latent layer that kind of condense all the information uh that we want and then reconstruct it back um so there's one thing is this is a time to event analysis not a classic ific ation work so there are different Mo conventional models for time to event analysis uh Cox model is a very uh standard one uh that uh it's a linear and uh uh proportional haed assumption method the Deep serve is kind of recently people proposed that to our um change the linear combination here for the hazard function to be nonlinear using a network to get the hether function so this is the only change so these are all this deep Ser is also prop proportional Heather the Assumption it's just a nonlinear uh calculation for the haer function and this is a loss function uh which for the both C and deep serve model is a um a partial log likelihood and this is a haard function and the the final loss is loss of variational Auto encoder and also the the survival loss um this is some more details of it so Cox model has this partial likelihood as a loss function and de serve is the same thing as you can see here but it adds some regularization the L2 and also the output to make it not explode after the training and for the image input it's a little bit sorry it's a little bit different from um the um clinical and romics variable so I I just use a 3D convolutional neur Network I've also tried 3D version Auto encoder it doesn't help maybe there are too many parameters so I just simply use a small convolution Network to extract features from images and some final result that we get so um mcro is very predictive however we only have 25 of them so I didn't include it in the neural network model but the simple correlation analysis show that this macro Ras are highly correlated with some of the radiomic features um as you can see like this is a on the left side is a patient City a craft patient City on the right side is kind of a random input so we see like there are definitely some feature textures from these images of liver that are somehow correlated with the genomic information this is very interesting but La data for more like comp Le Lex analysis and um so the table shows uh the survival uh prediction result um so c Index is is values here is kind of how accurate um The Sur time to event analysis is is a common metric we can see Cox model it cannot be used for image data it can only deal with like um one one dimensional features so that's why this is na for image um the neural network generate output form the Cox model and also the combined um like a um diff combining different types of information will also be better than uh just using single modality um so the yeah I will change the topic a little bit more so um the the third project I want to show here it's um I want to emphasize on the explainable soel n Network and we here we also use longitudinal quantitive Imaging B markers from multi type of images like MRI and f um the outcome prediction is due for a local a distant failure for per prognosis had the ne cancer patients um local feure um is a clinical challenge especially for per prognosis had the ne cancer patient and um if we can find Imaging bow markers to predict this local failure we may be able to help identify patients for intensified local Regional therapy and in the form of radiation boosting targeted systemic therapy or surgical intervention um so that's kind of the motivation why we want to do the prediction for this local failure um so yeah the purpose for this work is just to identify these patients with high risk of locure using this multi parametric multi modality Imaging bow markers and my important aspect is to understand how these features interact in these deep learning models so a lot of work our work has very limited patient sample size and uh this one also only have 94 patients but this is from AR randomized pH to physiological adaptive trial and this is some of the basic information T4 and3 is a stage of the cancer we can see this mostly High stage or L stage cancer patient and um for this randomized trial um 41 patients is randomized to ascended arm of uh chemor ration therapy which is um 70 grade dose in 35 fractions and about 40 patients was randomized to an experimental arm so as I just mentioned there will be a boost volume that we will give a bit more dose um so this boost volume is determined by a union of persistent tumorous sub volume with low blood volume and persisting tumor sub volume with low ADC from pre-treatment to two weeks during RT so this low blood volume and the ADC map Are all uh MRI parametric uh images that uh we can calculate based on the acquired MRI and to show some functional or physiological information voxal by voxo for the patient if so what this is saying is that pre-treatment we will take these images and two weeks after the treatment we will still take the same image and see the difference if the low blood volume region and low ADC region um in like persisted um then we will kind of boost this volume using radiation um there's some like um U um patient that's entered observation arm because of their small bu volume size and most patient uh here Al so there are 21 local failure for this patient and the medium followup is about 20 months so it's fairly long and this is um the the information uh that we use to do the prediction um so we have PET CT and Mi scans pre-treatment and uh at fraction 10 or after two weeks and the blood volume map as I just mentioned is um calculated by modified Tops Model on DC MRI or D Dynamic contct enhance MRI and the ADC map is apparent diffusion uh coefficient is calculated from diffusion weighted Mr images and gross tumor volume um is like we we contoured on the post uh treatment T1 weighted images and all these IM are co-registered uh to this uh standard image by rigid registration and there uh this is an example patient from left to right are the post uh contrast T1 weighted image and uh and the red and green couns are primary GTV or gross tumor volume and uh noo tumor volume and the second figure is a blood volume and uh the third is a ADC map and the fourth is a pad image and on the right is a table showing the input features that we get P6 status um is U like commonly agreed to be a very predictive for the outcome um PCC postive has a bit favorable result for this disease and the Boost if we get the Boost or not for the patient and uh there's like the GTV uh GTV and the uh the the low LD uh like low ADC volume and mean ADC and some other like all Imaging in uh features that we extracted from the MRI allad images um this for the the survival part so because this is also time to local progression we still use the same methods as the Deep serve um I will not explain it so one thing different here is uh because we have two time points we use this uh recurrent neur Network and combined with this U um Cox Bas survival uh Network to get the results so the first part is a recurrent network uh to have our two time points input and uh the the second part here is a survival prediction so the output features from the first network will be here you're going through a fully connected layer and get the result this is still the paral loog likelihood as a loss function um for the future attribution and interaction in the Deep learning models um so this we used uh a method called integrated gradient it basically as you can see here is after we trained a network um there will be the output if you have a patient input information and then we can take d uh derivative uh of this uh output function with respect to the input and this integral just is just because um so if we just take it at one point it will have it will not be robust and have a lot of noise and this integral helps to reduce the noise and get the real signals and to see how much um this input feature XI will contribute to the outcome um and this is kind of the uh the how important this feature is is for the prediction and this feature interaction means how two features are correlated or interacted and then to give certain result so but mathematically it's simply to take the second derivative I'll take another derivative of this integrated gradient and do the in integral so it will show like if one feature changed how the importance of the other feature will change um this is the results for the local progression prediction uh we have Benchmark of c and deep serve and also the recurrent uh recurrent network based survival model and we also look at different populations like all the patients are PES in positive and negative subgroups because we know how important the infection of HPV to the outcome uh as we can see that the proposed method I'll perform the pre the benchmarks uh is a lot especially for this p16 uh posive we can get to about 0.86 of the prediction for this is DC index however we we see that for PCC negative patient um even the best model here gives kind of near random result which make I think that all the features we have extracted are mainly more predictive for PC in positive patients uh another reason may be because in this cohor of patient majority I guess um about 70% are PC impulsive so this is another um reason that why this is more uh useful for PCC parp Pati uh on the right side is a captain May plot So based on the our prediction we were able so this is using the medium value of the predicted score we were able to significantly stratify low and high risk patients with a a blue one being a highrisk patient with very short um uh like local progression time and this is a results for the feature uh attribution uh in the Deep learning so this uh left side shows different features and higher it is the higher the more important it is to the prediction and uh the color here um is kind of the for each feature how it's high value or low values and um this is kind of why xais is ATT attribution score so two information we can get one is uh how important this is is and the other is a direction uh for example PCC status is kind of the most important feature and based on this uh different like values here and respect to zero uh we can see p16 positive is fa has fa outcome which means better outcome um this is consistent face kind of a lot of the literature out there and the second um important is a boost so which this direction also shows boost is favorable so if we give boost to the patient they will have a low probability of local failure uh this is also great news um and some other Imaging features are around following so like this is a pet how large the pet metabolic region is so the higher this pet volume is um the higher local failure um probability so this is also um like correct based on our ination uh this this is the result for fature interaction similar to the previous figure on this um left side shows which features interact strongly with other features and u yeah so the um xaxis shows the interaction score some information we can get here is PC status so this is interaction with like yeah PCT and with other features so has the most interaction with other Imaging features um and boost has the largest interaction with p16 here so and also the Direction shows boost is beneficial for PC imp postive patient with this un known then we will think why maybe we it is not reasonable to boost for the P6 negative patient since uh it might be and it might not be helpful and the mu1 similarly mu12 week is kind of a um ADC MRI feature it's more important for PCC negative patients and out of these features most of quite a few of them are ADC based features which shows like MRI probably have some um useful information for the prediction of local failure um for this project uh we have a predictive model for local failure using all this multimodality multi parametri multi-time points Imaging B markers and uh we learned how to assess feature attribution and interaction identify the top ranked features and uh review some of the strong interactions of the HPV infection status with imaging B marker however of course this needs to be validated uh in a larger patient coher um with that I think um I I finished introducing some of my work uh I I do want to acknowledge some of the foundings for this work um I would open to any questions sorry I know it's kind of a lot of information the well as a reminder if you have any questions when you're online you can put them in the Q&A box and if anyone in the room has a question feel free to speak up and ask there are no questions but I'll give it another minute or so in case anyone online is typing if anyone in the room thinks of anything please keep that um really great talk thank you so much um I was curious on many of these cases are often data limited so I'm curious if you tried any sort of dat augumentation strategies and you know what your prospects are for increased accuracy with more data um so I didn't hear very clearly so or the the the last question is uh if I have more data how the accuracy will change right how about the first one data augmentation oh okay yeah um yeah so I've tried augmentation especially for so not for this um third project because this is mostly um sorry this is mostly like feature input so it's very low Dimension but of course for the images um I did try different kinds of augmentation like so commonly use like um uh like uh you you you you you CFT the image randomly and you do some transformation so this kind of method I've used one thing I haven't used is um so there's like a some generative method um like Gans or recently the diffusion model they probably can just simulate some more patients data but I I I I don't know how effective this will be so yeah I think data augmentation is definitely needed uh it's especially for our small data set but it I've tried sometimes it doesn't work and of course I think um with a larger data set um it I I believe it will help the Visa accuracy a lot and the generalizability um another method that I have tried is to do transfer learning so there are a lot of pre-trained models available online some challenges for that is those are mostly um natural images like it's very different from the medical images uh so that's kind of a a little bit hard to transfer thank you for the question any other questions not see any in the room or online so let's thank our speaker one more time thank you so much yeah it's pleasure to be here if you have any question reach out to me through email thank you thanks everyone