[
    {
        "start": 0.17,
        "text": "Aaron our series thank mo suicide did you have it there's a sign-in sheet please fortunately mana it helps with the pizza I'll bring it to the back good luck um hello we do have people that are viewing remotely ask questions if you can speak up a little bit there are microphones in the room but some of the people working or sitting on the periphery arcing up great so just to remind everyone so that I'll introduce today's speaker we have done god he's a grad student and statistics over at Alltech thank you Thank You Marsha for the invitation today I'll be talking about a little bit of piece piece of "
    },
    {
        "start": 60.96,
        "text": "software that I wrote about six months ago on gene do you know my dissociation studies and I assume that most of the audience is from Department repetition of pathology so if people are more familiar with the topic then people in stats but in general I'd like to just remind everybody what this is that the genome-wide Association study is so basically what people are doing and this is from my understanding that before scanning the people's genomes they collect a large number of samples and they scan their genetic locations working for variations in genetic composition and they look they're looking for associations with the the phenotype that the the disease outcomes or the some kind of phenotypic traits and then they the prefer modular margin or Association task to try to locate the set of genetic locations that are relevant for the disease or for the condition that you're interested in they're in a way are trying to look for "
    },
    {
        "start": 121.86,
        "text": "a set of small locations that small set of locations among a large number of candidate locations and try to narrow down the search but if you look in the you know my association study the Wikipedia page I think people used to know there's this trade-off between something called allele frequency and the effect size in terms of how many people have you heard of this tray of yes one okay - right so so what this means is basically saying that allele frequency on the x-axis is saying how rare a genetic variant is in the population so if it's rare it's most so if you have a genetic composition which is 99% of one kind and one percent of the other kind then you have a pretty rare but you could go even further down you could have a rare mutation that makes up a unit smaller fraction of the "
    },
    {
        "start": 182.79,
        "text": "population so that's on the x-axis now the y-axis is the odds ratio is basically saying if you have the disease so that the ratio of the the odds ratio of you having the disease when you have one genetic composition versus the other so the larger this number is so the larger this number is the more likely your con you are going to have the condition if you have the the variant that caused the condition so basically this is a matter of the effect size measured in terms of observation so people have found in the pocket this is from a 2012 review paper is that there's a some kind of a trade-off between the area frequency and the effect size but in the sense that if you have really rare variants with very small effects imagine that some mutation that's very rare in the population at the same time it causes the the probability of you "
    },
    {
        "start": 243.27,
        "text": "contracting the disease or you have developing the symptom to go up by not so much then it's really hard to find in these kind of studies so you found virtually nothing in these regions but if you have very common mutations with large larger effects it's usually easier to find in these kind of screening studies so this there this kind of diagram that that Oh drew but I want to draw attention to one thing if you look at the y-axis right this goes from one to infinity okay and what kill do you have and y-axis going from one to infinity can anybody give me gas pollution plane yes but do you have infinity it marked somewhere in the Cartesian plane and you usually go one two three four you never reach infinity right so so there's this "
    },
    {
        "start": 305.86,
        "text": "one giveaway that this is not really a result that's quantitative this is a plot that the the authors drew to draw attention to the to the qualitative that does there's a trade-off between these two quantities so I've got the email D the author here I said which first of all it's not that the regular cut is a plan with the regular grid right then it's not the rock part either right otherwise she would have said two and then four and eight right at a regular interval so this is not a lot on Roxio either but email the author I said what scale did you use I said oh we were just trying to illustrate the the conceptual point so this is not qualitative quantitative results so what I did in a way is to quantify this trade-off in this in this little app here so it's exactly the same thing so each dot here "
    },
    {
        "start": 366.34,
        "text": "each point here is going to tell you a genetic location that they found to be associated with the condition and the location of this point is going to tell you the estimated area frequency and the estimated odds ratio so this is an estimated location of that particular genetic location in this diagram and now this up here this is it quantifies everything in the sense that if you look at this part of the diagram it's almost similar to what we saw before except now this is a quantitative result it says each start here still marks one genetic location that is associated with the condition that you're interested in and then the the act and y locations are estimated allele frequencies and the estimated odds ratios reported in India's literature and this particular point when it's pointed this out to you is found so in a particular study of "
    },
    {
        "start": 432.4,
        "text": "estimated odds ratio this much and estimated of allele frequency this much with these p-values and the name of the paper etc now what is the the shade of grey what is the dark color and the bright color so the dot parlor says that under okay under regular conditions that if you perform the study again you are very not likely to discover this under this particular sample sizes and the white region on the right regions you will have exactly power one you have perfect power to rediscover this association again if you were to try to reproduce this so this is an app that basically that quantifies this trade off so in a way if you have red mutations with very low defect size then it's difficult to discover and if it's common "
    },
    {
        "start": 493.759,
        "text": "and it's half as large effect size then it's easy to discover it now I'm going to talk about what this is in details but this is an overview of this app so this full interactive allows geneticists to explore what has been reported in the literature and also it allows you to do a power analysis so if you want to design a study for example if you want to design a study to you want to determine how many samples how many people you have to recruit in order to discover a certain effect size then you can go through the power calculations in putting the necessary quantities which I'll talk about in about five minutes then this will give you an approximate number of samples that you will have to correct so how many how many people you have to reach out to to collect their the genetic information in order to reach the conclusion that you want so this is just an overview of the "
    },
    {
        "start": 554.9,
        "text": "app okay let's just go into the the talk so that was a very quick review effort pretty sure that that we call everything yeah so this is be a bit before agenda of today is to tell you what this app is doing really and talk a little bit about the software how a builded the tourists they build this tool I think that would be a slightly broader interest if you can if you want to build a dashboard like this how can you do it if we have time we'll go into this party more theoretical direction on why is there a bracket right why is there zero one distinction in these kind of Association studies when you try to fight signals in a large number of candidates so the first thing I want to talk about is what this app is really doing so what are we doing here so in genome-wide Association studies "
    },
    {
        "start": 617.84,
        "text": "what typically people do is like I said they collect the genetic variants of each locations over not large number of people with probably half of them having the disease I have them don't have the disease and then at each genetic location what people do is classify everybody into four categories so based on whether they have the condition or they don't have the condition they fall into one of two categories that there are either cases or controls like cases standing for it the fact that they have the condition and controls if they don't now based on their genetic composition at that particular genetic location you can also classify them into two categories whether they have one particular variant of genotype or the other genotype right the base on this 2x2 combination you can classify everybody in your study for example if you have a million people which is a really large study thing to classify there's a million people into four cells so it can count how many people have this condition with genetic "
    },
    {
        "start": 678.72,
        "text": "variant one and so on I do three characters so the four numbers should add up to a million and what when people do geneticists do I think is that they try to find if the genetic composition has any association with the other marginal which is the outcome of the phenotype so they do kind of Association tasks between the two marginals in a way if you imagine that if these two are related this table is going to tilt towards one diagonal versus the other now if they're completely independent the the number of counts in this in a particular cell is just going to be the total number of subjects times the two marginals at that particular combination right so if you have nothing related is going to be roughly independently distributed the columns and the rows now rules are doing "
    },
    {
        "start": 742.59,
        "text": "in the app so typically that again the same question if you have these kind of studies you want to find out how many people you have to recruit in order to reach the conclusion that you desire now these are the counts of the actual outcome the actual outcome of there are of the experiment underlying this if you assume a multinomial table we assume random sampling from the population then there are about the nominal distributions underneath this table right so for each combination there's a probability associated with each of the four outcomes so these four numbers should add up to one now if you want to test for associations that if there if if they're independent that this mule I want is going to be the marginal parent one times the marginal case for example so that's the probability part of it before that there was randomness in the "
    },
    {
        "start": 804.699,
        "text": "sampling now now you have the probability table but the first question is what kind of tax should you perform on these kind of tables and I've seen many many kinds of tests that are floating around in the literature and people do different things indeed don't count some common tasks for a finding of sociation between the two marginals is a chi-square test like with the racial caste right and do the t-test if you just compare the proportions of keeping having the disease across the different genetic composition groups well sure Steve psychologists do Russians etc so that you can just for other factors now different tests in principle they deliver different power but if you have a different procedure to discover things that you have different power of discovering things now the question is it doesn't matter does your choice of a statistic matter in this case and where do these what has to all "
    },
    {
        "start": 866.019,
        "text": "these existing power calculators assume they're floating around in the internet the turns out is not that poor that you have some colleagues in the the bow stats Department for example they publish a calculator that assume that that tells you that they calculate the power for this this procedure about they don't tell you which one and and it's quite frustrating in fact to find out which what they they they calculate this for unless they're very explicit about this of course then that question is does your choice matter if you use a power calculator that that is specific for example to logistic regression can you use this result if you are doing student t-test for example a Welch's t-test in principle you can't write that but it turns out that the choice doesn't really matter when they have really large sample sizes there's just asymptotic prove myself as emphatically so that means when you have really "
    },
    {
        "start": 926.74,
        "text": "samples in your genetic Association studies the answer is no so that's very comforting right whatever you find out the internet because unfold bye-bye done by Osiris group in the box that's from and that calculator still works even if your test statistic doesn't exactly match what he's calculating for but I don't think this has been sad enough in the literature because I haven't seen it so this is very comforting in a way so that no matter what kind of test or these kind of like a relationship test and the logistic regression effusions housework acid juice re-watch this tacit circle all these tests have the same acid that's entropic power curve so in human language it doesn't really matter the calculation still applies now the second question is perhaps more I don't know more relevant for actionable in a way for geneticists so imagine if you if you're writing a front you're saying that I have to correct this number of people in order to discover certain associations how do "
    },
    {
        "start": 988.12,
        "text": "you reach that number you go through a calculation right you go through a power calculator like what they provide for example Gonzalez here and when they asked for in this town of calculators is these three things the genotypes relative risks there are risk value frequency in the general population the disease prevalence in the general population so that's what they asked for though but in my experience very few people know precisely what they mean so just to recap a little bit of what I mean and okay so so now in these kind of disease models so-called disease models it's slightly different from the true by true tabulated table that we saw earlier so in these kind of disease models you have three columns instead of two so just now we just counted the total number of counts of certain genetic variants in two counts where they're "
    },
    {
        "start": 1048.84,
        "text": "usually so there could be more but typically there are only two that constitute most of the population but in these times of disease model you have three columns and each of the columns are tells you how many copies of a genetic variant there are in one person because you have a pair in in every single person right so you have zero copies you could have zero or one or two copies of the disease inducing so-called quote unquote genetic larry'd in every one person so now you could tabulate these and in a two by three table instead of a two by two table so that's what the disease model is now here's what they assume in their disease models so you have conditional families of you contracting or developing a certain condition given that you have zero copies so that's the first one here so that's I 1 0 divided by the sum of Pi 1 0 / 2 0 divided by the probability of "
    },
    {
        "start": 1109.33,
        "text": "you developing the condition if you have one copies divided by the probability of you developing that the condition is have 2 copies so that's a the ratio of 3 numbers and the disease mother's little day falls in one of four categories so if your product look at it then these the ratio of these three numbers is also multiple created in a sense that the ratio of the if you have two copies is dr r times like more likely that if you have developing the condition is well gr times more likely than if you have one copy and in turn your times more likely if you have zero copies and so on and i want to explain how the other one said but you see that's that's a very particular parametric assumption about the disease models relating to their - they are called copy numbers oh yes so the additive model says that the the probability is progressing like with "
    },
    {
        "start": 1171.91,
        "text": "with it with a constant difference instead of a constant ratio right right and you can stop me at any time you have questions thank you so this - that is the same as G R minus 1 right so that's the probability let's say if this is zero point one and this is zero point 2 then this is zero point three if you're a month okay model it is 0.1 0.2 0.4 less dominant basic says if it's 0.1 0.2 and 0.2 so there if it's dominant in the sense that as long as you have one copy you have increased bubbly and stays the same a recessive means that only if you have two copies then you have increased probability of contracting or developing the condition now the second quantity if they ask for is the prevalence of the disease in the population now this is important they don't tell you it's the number for the population right and that in my "
    },
    {
        "start": 1233.24,
        "text": "experience when I ask people were kind of what number is this really prevalence of the disease is it disease in the in the sample that your problems of the disease in the sample you correct which is typical 50 percent right if you design a study you want 50 percent conditions 50 percent controls but this number is really asking for the number in the population yes so the question is in order to compute this er what's the question sir and your power calculator also need you to know mechanism right that's a very good point sir so he's saying that DF in order to perform this calculation you have to know the the the mechanism of the disease in a sense that you have to know if yes which one which "
    },
    {
        "start": 1295.1,
        "text": "one of the four bottles it is and you also have to have an estimate of the gr associated with that particular model you're absolutely right so in order to do that you have to know both if you want to go through their calculation and I'll tell you in a minute you don't have to do that so that's that's the beautiful part and I'm arguing against in fact these can't these type of calculations because it never will be able to precisely pin down which one of the four models it is and you'll never have an accurate report they are estimate in the literature if I people don't report this report something else to the center number they require is this prevalence in the in the population or I could talk about and the third number is the risk area frequency in the population the P basically how many if you mix everything together how many of them are are the annuals that are risk associated this now in order to perceive the the calculation you also "
    },
    {
        "start": 1355.22,
        "text": "have to assume howie weinberg equilibrium which dictates that these probability tables behave something like according to incompatible incompatible with these number P here now the probability tables you I 1 0 to PI 2 to the 2 by 3 table are determined jointly by these three numbers so that you can proceed with the calculation so that's how existing calculator have-have proceeds now that's not okay so when you have these three numbers you have this have this this there's two by three table but that's for the population that's not for the the samples that you correct imagine if you have very few cases in the population that the sum of these three numbers would be very small right close to let's say 1 percent or 0.5 percent in population that's how "
    },
    {
        "start": 1415.67,
        "text": "many people can publish and develop the condition but in your study you actually over example the cases typically if you have rare diseases let's say you typically do a study with 50% control at 50% cases when you have to adjust for that fact as well so in the sample in the study you have to adjust for the fact that you over sample the cases so you kind of in addition to this pi11 pi12 if i want to you adjust for the fact that the phi which is the fraction of places in the study is rather than the travelens that is actually in the population so these this line is scaled up at this tangent line is going down if you over sample the cases now okay finally if you have this 2x3 table for this study you can calculate the area of counts the origin or two by two tables okay according to all these numbers now the exact parameterization "
    },
    {
        "start": 1477.18,
        "text": "doesn't really matter it's to compute nobody remembers I don't but that's how stuff do you go through the disease model you adjust for the sampling over sampling under sampling in the study and then you have the underlying probability table for the queue by two table counts that you actually observe that's how an alternative is specified in in the typical power calculator hey that's what we saw earlier so each number corresponds to the other the other table now the question is can we skip the disease mother seems like the long winding process you have to assume that certain kind of biology it have to assert some you have to have the estimates for that biological model and the answer is yes in fact this table if you think about it when the parametrize quite simply has only fair numbers you don't have to go through that and in fact this is parametrized by two our quantities at the first is what people say the the risk allele frequency in the "
    },
    {
        "start": 1539.01,
        "text": "control group app which is really when you look at the controls the ratio of I to 1 over the sum of hi to 1 and PI 2 - and why are we using this is because this number is widely reported in the genetic literature so that's what it is and and the other quantity is this the odds ratio of the value Barrett's this quantity is really the cross product the ratio of the cross products in this cube a truth table so I won 1 times 5 to 2 divided by 5 to 1 divided by I want to so basically matters how fast diagonal this table is reference how associated this to marginal time but anyway we went through the disease matter the our original frequency is population in the parlance etc so that we can derive a two-by-two table which is fully parametrized which is "
    },
    {
        "start": 1600.36,
        "text": "fully parametrized by these two qualities so why you will have to go through this the answer is no we don't have to right to go through this to go through this part in order to get to the power of your analysis and I'm even arguing that we should and for good reasons at first these two quantities are widely available in the literature if you recall the app that we just saw the numbers here the the x-axis is precisely this risk allele frequency in the control group that people estimate from to study a report in the GOS catalogs and the y-axis is precisely this odds ratio the the inertia of the cross product in that tube a truth table that people actually start report in the catalogs so these two numbers are widely available as opposed to the disease models well the last time you see a disease model and the parameters be reported for me it's never so so maybe "
    },
    {
        "start": 1666.72,
        "text": "for power calculations this is the right way to go and doctors robustness against human errors because people don't typically know and it goes through this calculations what precisely fabulous mean right doesn't mean the in population in a study right people can make mistakes and then there's the third point that this type of temperature because directly through this two finally is it's robust against modern specification this goes back to the question just now you have to know the disease you have to know the biology in an inner way what if your the ratio of the two of the three probabilities is not one two and four what if it's one three and four it's not multiplicative it's not additive it's not dominant it's not recessive right if the biology dictates that's it one two three to four then it doesn't fall in any of the four typical models that you have so the calculation if you go through the disease models won't allow you to do this "
    },
    {
        "start": 1728.11,
        "text": "but it still allows you to do food directly the the app and our calculation if you get to the power so and then there's a compatibility issue of parameters in disease models not all numbers are compatible so you can have impossible that you can have three numbers that are not compatible with each other I won't go into details on that but it could be biologically impossible if you have any arbitrary three number combinations in disease models on the contrary if you go through this critical frequency in truth and odds ratio any valid numbers any any number between 0 1 here and 0 infinity here will be a valid pair well there you have another way of reduced chance of human error and finally and I think this is the really the most important point is that allows you to perform systematic reviews and unified power analysis across all studies because it's independent of all the first that the "
    },
    {
        "start": 1788.559,
        "text": "first two slides I talked about how the test statistic doesn't really matter as emphatically and now I'll talk about how the disease model can be bypassed right to a number that's universal to all the all the all the numbers to all the models so that's what I was really doing and if this weren't better interest to me because there's just clearly some kind of now the great work and a little bit of rethinking of what people have been doing in the in the past now I'm going to talk about again the software so so now that we understand what the x axis and the y axis is also what each point again like I said is that as Association discovered in 130 go study now the orange point here is algae associations discovered in one particular study in 2017 and all the points are the different discovery Association for the disease breast cancer so this particular study has 76 "
    },
    {
        "start": 1855.34,
        "text": "thousand cases and sixty-three thousand controls so if you have this temple size the power calculator predicts that you have higher course to run in the white regions and power flows to zero in the dark regions and when you overlay all the discoveries in that particular study it turns out that all the discoveries live precisely in the region where you have power to discover things this is an indication that this power calculator is really precise in the sense that you it predicts exactly where these then business not right fitting this this this this look of phase transition of dark and light is not doing is not trying to fit to the discoveries of this particular study this is really predicting what you should be discovering and this precisely predict "
    },
    {
        "start": 1916.1,
        "text": "what this study has discovered now if you have smaller sample sizes for example if they have another set okay so some some studies don't report their number of controls so that you got into trouble trying to calculate the power curves there but yet this the software is a smart enough to detect that but if you have a study with let's say smaller sample sizes then you would predict a smaller region of discovery and this is precisely again where people make discoveries they don't discover anything that beyond whether the sample or provide able to provide right so you can also upload your own data that is as long as it's compatible with the the NH DB I energy re vig Watts catalog data format so you can upload your data and "
    },
    {
        "start": 1977.059,
        "text": "then you would do exactly the same thing here so I have loaded just now a pre-loaded data set crash cancer you also have fact only three data sets have pre-loaded these data sets can be downloaded directly from the the but you can also choose one of the three pre-loaded data sets to go explore these things that's a very specific interest I understand I want to talk about next how I build this app I think that that will be of value more general interest and if you want to do something like this how can you make make this a shop I didn't know anything about front-end web development about a year ago so I did this about in last February to March dr. Anna had zero idea from that development how to do interactive visualization that's for sure the others must have more experience with these kind of "
    },
    {
        "start": 2038.05,
        "text": "things but this tool is build with our shiny so Johnny is a package in our that allows you to build interactive dashboards to visualize data to - so basically a layer abroad are there runs in a browser that allows you to interact with the explore data now the basic structure of shiny is that you have three files they have your UI layer so the user interface that specifies how you want to look at the data what kind of panels you want to see in the browser for example I can specify there's a desert disappearo here that requests the inputs of model specification and the the output should go on the right for example and then there's the server in the center file which is like your usual are a Python script that tells you how to process the data so once you take the data from the the UI layer you posit to the server doing usually this is not "
    },
    {
        "start": 2099.7,
        "text": "really too far from from regular squid or or Python scripts now you have your gravel bar which you can stash up your user-defined functions and any package loading operations and there's no - I think the biggest advantage in terms of doing these kind of interactive South is you have parking between the the exploration and the calculations under underneath another advantage they have dynamic UI so if you have if you want to do different things for example if you want to design your study then depending on the input you can have different outputs in in your in your in your user interface so this is something I think really nice and once you it takes a "
    },
    {
        "start": 2159.789,
        "text": "little bit of time to build this but it saves you much I don't know much time further down the pipeline if you want to explore the data so that's kind of the cool thing about these this this shiny app and then you have there's an input and output like I showed you just now you can dynamically plug in your data set doesn't have to be pre-loaded earth it doesn't have to be hard-coded in and that all these are achieved with something called reactive programming so usually you have your what object is object oriented programming procedural imperative programming but this is something related to the the reactive nature of front-end program it's not reactive programming so to observe that once I clicked something here the object output here will be different so how "
    },
    {
        "start": 2221.41,
        "text": "does it know to to change the output to to to visualize different things basically what this is doing is underneath in the server out of it in the in the in the script it's observing what the front hand is doing but once something changes in the front hand it will try to update whatever is the backend and then throw that back to the through the user interface so you can kind of do that pretty easily very easy in fact in in shiny apps this is all package now it it helps if you know a little web development especially reactive programming but you don't really have to you can build this pretty quickly in the mouth or in a week even the plenty of the examples floating out there and outside shiny I would also like to advertise some other tools that I think work very well in this project the first is properly I'm not substituting within "
    },
    {
        "start": 2282.69,
        "text": "but I have to advertising through it so look at this about your all these photo are in fact done with properly the property is a company as well but they'll provide some pretty fantastic interactive visualizations so you don't have to do all these program is specifying that let's say if I hover my mouse here is going to show me some information about this particular data point so this is all taken care of by properly in addition this brought the also a place very well for interactive display so just now we saw that when I click on it particular data point the server is able to know that I equipped on a particular point update the information displayed here and the plot as well and that's because this Authority allows you to capture whatever event is happening inside the plot inside the figure so you can pass that back to the server now this this the seventh they're a little add-on I want "
    },
    {
        "start": 2344.25,
        "text": "to introduce is this intro that Jay asked I'm only listing the names I think each of these deserves a little bit of discussion on there all but I'm only introducing the names of these tools so so this virtual draya's is a little introductory applet developed in JavaScript so if you want to build app and allow users to quickly explore what the app is capable of doing you you plug this introductory us into your app and just type in wherever you want to display at particular modules of this app and then when you launch this little intro Deus is going to dry the users who the interface or whatever you want to guide them over and tell them what the the aplex capable of doing and then it's a very nice guided tour that that the otherwise a "
    },
    {
        "start": 2410.519,
        "text": "user will be overwhelmed with the interface of your app so if you want to guide them through a little bit easier this is something I find very useful now the final little add-on I want to tell you about this load spinner the run you live in the web page for example when it's loading you see a little spinner turn it around yeah so it actually makes a difference if you didn't notice the I think the server is responsive or not you don't see this but if let's say the internet connection is throw ah there we are okay so if the internet connection is slow and the picture hangs you don't know what happens this is something that tells you it's still going on it this is a very small point but when you take this away and I can give you a demo I'll fly on how this would work if you don't have the spinner this will frustrate you right so that's "
    },
    {
        "start": 2476.369,
        "text": "everything I want to talk about this for this app and how I built this you can they're equivalent tools in Python as well there's flask framework for building web applications for video visualization but this but I think it takes I'm biased of course by the takes of slimy it's slightly more difficult and it takes slightly longer for me at least to build these kind of apps and frogs in frost Python and I think it's so far I I find shiny that the best tool to build these kind of so any questions so far Chris event you're in data Turkey was that and sorry can you repeat the question um how do you basically populate your tool with let's say new jeeva studies I see so this is this is so the question "
    },
    {
        "start": 2538.959,
        "text": "is how do I populate the the app with the actual data from GUI studies so all these data are pulled in so I'm going to talk about how everything is done from the beginning so the data is downloaded from this Evi gos Kerala battle okay so I don't have an interface yet but directly requesting data from the Geoff's database but you can manually download this and it doesn't take that long actually it's just one click if you go if you if you want if you want the drink you can choose upload my data here and then we'll give you the link to the header information on the abig was catalog here so this will tell you the header information needed the headers needed in that particular data file for example the date added to that to some "
    },
    {
        "start": 2600.16,
        "text": "of them are essential to uploading the data to the app some of them are not and if you don't have the essential columns in that in your data set this app will automatically detect that and tell you which one of the columns you need ok so if you miss any cups of mist or any of the column names who give your word copy but the the easiest thing to do here is to download data directly in their data format we go to gos catalog Biagio catalog and go to dollar you search for example breast carcinoma carcinoma and you go here and you download that's it this this download from the website is precisely in their own format they don't have to do any format but if you want to upload your own data you have to go through the formatting but doing with downloading from their catalog is takes quite a bit time so it "
    },
    {
        "start": 2662.19,
        "text": "can be quite slow like you can see here so that's why I didn't integrate this into the app itself otherwise it just hangs there for five minutes and not very productive I'd rather it yes they have to have a tool for that you should use their tool for this yes so that's for exploring the odd whatever is available in the in the literature but you can also design your study according to whatever you need so if you have a fixed number of cases for example if you're on a study a study the study of the particular condition they have certain number of revisions people with that condition you want to know how many controls you have to recruit in population again go through this seven tap which tells you how many controls you need for example in this case is six thousand but there's a third cap that "
    },
    {
        "start": 2725.04,
        "text": "does the disease model conversion so this question that was asked this that if you have having to have precise information about the biology of this particular disease if you want to get at the the two canonical what I call canonical parameters the risk allele frequencies and the odds ratios you can go through the third calculator which converts the disease models into the canonical parameters and he can copy directly cut that say I had multiple I have an additive model with disease prevalence 0.1 risk i with frequency in the population point three and relative risk one point five and this gives me zero point two nine risk allele frequency in control group and there are racial about 1.5 as well you could copy directly by putting your go to this calculator so this this number number here at zero point do nine and zero point one five is called me directly from that up to do yeah that's another "
    },
    {
        "start": 2786.9,
        "text": "thing that can do with this what genotype are you referring to out of it model you said you know type relative risk oh one or two of those so so if good question so the question is what genotype am i referring to in this model it does this in this box right so I'm assuming an additive model so by the way all these information in the slide is available as manuals in this in this app as well so if you have additive model genotype relative risk like I specified is 1.5 here so the probability is 1 to 1.5 to about to so yeah that's another good point you can make is that the the grr numbers really mean different things in different models right so the depending on what model is "
    },
    {
        "start": 2852.049,
        "text": "the third column and even the second column can be different even if you have the same grr number so that is really model dependent so the advantage of doing not going through this is that you don't have to know precisely and another point you can make here is that different disease models can in fact give you exactly the same risk allele frequency and all stration so it's not a one-to-one correspondence multiple disease models can map to the same canonical parameter for example yeah I have an example here in fact down here so down here this is critical for instance since so many people have asked questions about this is that if you hug that's they're not feeling Marron that gives you these two canonical parameters you can have an additive model with slightly different disease model parameters that may be exactly the same parameter you see if these are example of four different disease models that give you exactly the same canonical "
    },
    {
        "start": 2913.22,
        "text": "parameters so this is not uniquely identify from data in a way oh and I think a very good reason why people don't report it these models in the literature because it's not uniquely identified if you only have the two by two tops that's if that's a list that they later than the question is about the uncertainty in the point estimate right so I can tell you right away that that nobody reports it so the two layers of purpose but the numbers reported in G related rates out if you think that this "
    },
    {
        "start": 2977.3,
        "text": "number is so precise it's exactly predicted by the theory here of whatever power calculated here is not the case the problem with these estimates is that the discovery and and the add the fact PI's estimates are down with the same set of data so so what I mean by that is that traditionally okay back in the day we have type 1 and phase 1 and phase 2 studies right at first one for discovery and fails true for confirmatory and you use the data in Phase two to estimate the parameters in your model so that you don't get this selective Direction bias now things are getting messy where people say that we should poor phase one and Phase two together to increase power so so you get IIST estimates of all these parameters that people report in fact all these reports 99% I cannot say a hundred because I have seen every one of the failures reported there but not "
    },
    {
        "start": 3037.64,
        "text": "all all the papers I have seen they report the numbers by using the data together so I'm saying that I discovered these in fact with the set with this out of data and also estimated the parameters with the same set of data then that creates a selection bias right if they have a large number of hypotheses to screen though all these numbers are biased actually upward biased do you think about it and then there are no uncertainty estimates there usually is uncertainty estimates of Sochi with the odds ratios I haven't plotted them but to begin with these numbers are not right because you have selection bias but if you have unbiased estimates with uncertainty estimates you can certainly problem let's say so this wouldn't be a point this would be a dagger right with uncertainty estimates around them but "
    },
    {
        "start": 3098.619,
        "text": "but if you have large samples in a way this and and if they are the odds ratios and the error because there are any and the in the middle region so the if the risk I would think is they are in the middle region that if your estimates are not too far off the dagger the horizontal part of the dagger will be small but because this is kind of in a lot scale when you go into the the tail part when you go into the region where you're closer to 0 or what this dagger will be dragged quite long for quite a bit longer so you have quite a bit uncertainty when you have really rare conditions really rare genetic variants so I haven't done that so but but the the reason why I haven't done that is because it's not very not really possible with what's reported in the US catalogue and it would very much advocate for this we go back to the first one that goes to study and that without biased estimates I think there's too much of an emphasis on discovery and "
    },
    {
        "start": 3160.269,
        "text": "not estimation in a my opinion estimation is sometimes more important question than reporting that this set of genetic locations are rather than this would thank you for question we have about 10 minutes I'm going to the third part which is that the tension so we saw that there's a pretty sharp transition between where you have power where you doped and there is a mathematical reason behind this sharp base transition why suddenly you get our one from power zero when you just increased the sample size by 200 there's a mathematical reason behind that as well yes but that's about it any question yes yes yes whichever way "
    },
    {
        "start": 3225.74,
        "text": "you calculate did you use yes so in the very beginning I kind of talked about the question that when you perform different tests you have different power and these files are asymptotically the the power of all these tests are asymptotic equivalent now what I visualized is the comp limit of all the power limits - so there's what - this phase transition this this power calculation let's say if you have this many cases and controls and if you are underlying this carrot frequency and the other is this much then this power calculation acquires to add these Association tests regardless which one you choose this is the company - if you "
    },
    {
        "start": 3286.4,
        "text": "don't - for example Gonzales calculator give you pretty much the same answer authorize maybe from 1% that's it but so you're safe using his as well using any other attempt laters but it's not quite clear you see this is the biggest advantage I would say is to explicitly spell out which numbers you have to input into these kind of calculators and the test part doesn't really matter it's the so the question is which one of the tests did I implement the calculations for it's all of them at the same time because the the power limits is Compton - all these tests I listed here so it doesn't really matter what kind of test you use with exception okay when you have when you have other controls for example when you do read this is only this only applies to marginal screenings this is this is applicable when you don't have other "
    },
    {
        "start": 3347.92,
        "text": "controls for example if you want to do logistic regression but you have other variables in there then this doesn't strictly apply but but in the literature what I found is that this applies pretty well so even if you have other controls it doesn't increase your power by very much by an order of magnitude doesn't do all these studies one way or the other use some kind of control then it doesn't go off the power Fox emissions by orders of magnitudes so that's that's the point I'll make so this is applicable to pretty much all Association studies whichever you used yes I mean or bottom line is the ecwid power curve thank you good question okay I'll spend two more minutes on explaining what it everything is so the dotted line here is the active pyro curve the way this means is that at this "
    },
    {
        "start": 3408.97,
        "text": "sample size added all the allele frequency and odds ratio combination on the same drive will give you the same power so if you move around this line you would have the same power of discovery now there's a red line here this has rare variants on the typically people define rare variant is that they take us they take a percentage right if you have a genetic variant that is present in less than 0.5% of the population you call that a rare variant so that's the typical the definition of Reverend in the genetics literature but I find that definition of the problematic because what are you using rare variants for so you typically what people do is that if "
    },
    {
        "start": 3470.39,
        "text": "you have a rare variant you know that your usual Association test the Association test doesn't apply right because it has distorted power you don't you don't have proper type 1 error control so that's the concern there so if that's your goal the definition of relevance should really be something different you shouldn't be a percentage of the population that has a suitable the genetic variant you should be the number of genetic Baron thousand the population such that you can properly control the type 1 error you see if that's the goal we should tell you for that so this is the number that calculates how any genetic how many how many genetic variants need to be present in your study in order to properly control type 1 error so so that's different definition of rare guard and are very much in failure of this definition of mine I'm biased of course but if you think about it if your goal to use is to use well the definition of we're going to tell you when to use the test to properly control the type 1 error then "
    },
    {
        "start": 3531.259,
        "text": "this is the way to go but then of course I'm not done artistic eye I implemented another version as well so if you want to have if you want to be traditionally if you want to say that if you want to say that I still want to define this as a fraction of the total population in the study you can start do that so there's an option to specify the rare variant as a fraction of the total subjects in the study and if you do that as typically done at 0.5% and this curve shifts right accordingly all right so this case is 61 but you see this doesn't there's not compatible with the power calculations here this miss miss don't resolve so I called danger zone is really around here not as compared to as compared to when you specify as a fraction of the total population and and "
    },
    {
        "start": 3593.09,
        "text": "the grouping one last if chemistry so this definition is adaptive to the sample size in a way that if you have let's say this many cases in this many controls you see that the curve shifts accordingly March the danger is all accordingly as opposed to the usual definition it's it's there it's not a fight compatible in a way with the power calculations maybe the other way is more obvious so you have more controls than you have faces then you see this this is really far if you define it as a fraction but if you define it as okay in this case if we define this as the number of counts you need to control type one error it doesn't even appear it's not a problem for you if you have if we have "
    },
    {
        "start": 3655.67,
        "text": "this many cases in this many controls it's just a different constant I think we're variant is a different concept in power calculations all these in here so I have a user guide predator with animated gifs or gifts that tells you what each of these apps do I think I also have a pretty detailed document on what this rare variant business is I'm also struggling oh yes so here you have a full supplement here you can read out there mathematics and "
    },
    {
        "start": 3719.16,
        "text": "all the the definitions of rare variants in this document [Applause] "
    }
]