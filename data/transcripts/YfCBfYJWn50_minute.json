[
    {
        "start": 0.0,
        "text": "we'll break for the summer I have already begun scheduling a few people for the fall so if anyone is interested in presenting let me know I can get you on the schedule um so today we have Radha Malhotra and she is associate professor in computer science and engineering [Music] basically what they do "
    },
    {
        "start": 65.159,
        "text": "I've been expanding beyond language it has been said that language is only half of the communication channel in addition to that we have course facial expressions we have the pitch of the voice what I'm going to talk about today is where that I'm done in this space multi-processing and specifically are multi modal sentiment analysis and I'll try to clarify these terms and if there is anything that's unclear please feel to be free and to give credit this is joint work with two postdoctoral fellows Veronica Perez roses and Mohammed abuela onion and then also collaborated in mechanical engineering hi pores and guessing that you don't know a whole lot about my group so I figure I'll give you my one slide on that I currently have "
    },
    {
        "start": 127.729,
        "text": "750 students three postdoctoral fellows and also a number of undergraduate and masters working on various projects just to highlight three of the groups of projects that we're currently working on we have work focusing on understanding the meaning of text for instance how we can figure the meaning of words if you think of plant as an industrial plant or plant as I have a lot of plants in my backyard those are two different meanings and we figured the meaning of words naturally but for computer it turns out to be a very difficult problem it's very relevant for machine translation obviously when you translates English into French you want to translate the correct meaning it turns out it's also relevant for educational applications search engines and so we have a project that looks at "
    },
    {
        "start": 187.739,
        "text": "figuring the meaning of words and how that can be used that some that we are doing right now how it can be used to assist English as a Second Language Learners by showing signal names and translations in context we also have work on looking at the similarity of two pieces of text which again found applications in education for instance for automatic short our grading very relevant for the MOOC classes that we see more and more often today if you have a question we have an answered an instructor answer or textbook are still considered to be correct and then you have a thousand plus answers coming from the students how can you grade those automatically and so we've been exploring methods that look at the semantics of these answers and try to determine which parts are correct which are incorrect and tried based on that not only to give a grade but also to provide some kind of feedback to the students another set of projects that we have "
    },
    {
        "start": 250.16,
        "text": "have to do with cultural analysis I'm really excited about how we can use language and as I show today also other modalities for learning about human behavior and also beyond that learning about differences between human behaviors when we look at large groups for instance there are some differences between say Americans Indians or Chinese or Romanians and how can we use language as a window into human nature and we've been working on cross cultural analysis to try to detect human values also worldview for instance how would a certain culture see the concept of Education or women versus another culture and also how we can make inferences about for instance the location of a certain text and respectively the writer and another set of projects which I'll say more about throughout the talk today is multi model "
    },
    {
        "start": 312.53,
        "text": "processing where again with the focus on human behavior in addition to language we also look at vision physiological sensing also on speech so with that let me move to the topic of today's my mother sentiment analysis and I want to start with a little bit of terminology just to make sure we are on the same page subjectivity and sentiment analysis is considered to be the task of identifying private states and here is an example if I said I love Ann Arbor that refers to my own feelings about another there might be other people who seemingly neutral about that or dislike Ann Arbor now this is our like saying Ann Arbor is a city in Michigan there is nothing personal about that it's just a fact I will assume everyone would agree on that and so the difference that we "
    },
    {
        "start": 372.87,
        "text": "are making is between subjective statements like the I love Ann Arbor statement versus objective statements or facts as an arbor is a city initiative so that's the first layer where we identify opinions or subjectivity the second layer once we identify an opinion figuring out whether is a positive or negative opinion the I love Ann Arbor versus I hate in are very kind of statements so that would be often before as sentiment analysis now sentiment analysis has been finding a lot of applications lately for the past five years or so not only in academia is a very nice application to work on and it has a lot of deep research questions when it comes to identifying these private states except only but also in industry someone referred to sentiment analysis as the next hot wave in Silicon Valley and it turns out there are literally hundreds of companies that are "
    },
    {
        "start": 433.05,
        "text": "trying to do just that and the reason for it is because it has a number of applications for instance think only about product reviews companies are interested in that as a way to replace traditional surveys rather than doing a focus group bringing a number of people to ask them how much they like the new Colgate toothpaste they could instead run a program on social media and figure that out automatically whether people like it or dislike it what do they like about it what do they sleep dislike about that song so it's a great tool for doing these marketing intelligence and understanding more the audience of certain products the same goes for the other side which are the consumers himself pretty sure when you buy a really expensive product you do your own research online I mean you probably don't do it if you buy a bag of chips but if you buy a camera then you likely go online and try to see what other people have said about different models that you are considering and so forth at "
    },
    {
        "start": 494.43,
        "text": "- doing some kind of automatic sentiment analysis is very useful where you would put in a product say and you'll get back a number of opinions also rated for whether they are positive or negative on how strongly positive or how strongly negative they are there is also interest in terms of ad placement obviously you wouldn't want to place an ad for same Toyota or somebody blog who just said that they hate Toyota so you would want to have a sense of the opinion of people when you place clocks and the same goes for search engines there has been a case what's three years ago which is actually covered by media quite a lot with somebody who managed to get in the top search on Google by having a terrible product and his approach because he figure how patrons work which is the algorithm behind Google that would look at the number of "
    },
    {
        "start": 557.19,
        "text": "links that the page gets in order to run that page higher he figured he could get a lot of links to his company just from people who hated his company and since search engines back then were not looking at the opinion of the pages that would point to another page he managed to get in the top they've done by getting a lot of such negative leads I feel very ventually they only started to look into changing that so sentiment analysis is also very relevant in the context of information sheet revolve and there are a number of other other applications like I said there is a lot of impressed not only in academia if you go to computational linguistics conferences is one of the most attended such sessions it exceeds a lot of submissions but also in in industry and research box now if you look at the work that has been done today most of it was on text and that's not surprising there "
    },
    {
        "start": 618.87,
        "text": "is a lot of text out there of course and language has this nice property of already being relatively granular it's not like in speech or an image where you have to identify the units you really have words in most languages with boundaries between them so we already have a good starting point to do language analogies and in text there are methods that are based on Mexicans we have dictionaries where words are labeled with whether they are positive or negative and those have been successfully used for building automatic systems for sentiment analysis and they are also the data-driven methods and those would rely on data that textual data that has been annotated for being positive or negative and then you can train machine learning now is it there is more and more multimodal content online if you look for instance that at blogs there seems to be a trend for people to post videos rather than "
    },
    {
        "start": 678.93,
        "text": "written text those will be referred to as vlogs with a V and there is more and more of those so instead of having just a written entry you would have a whole video about that person's opinion or thoughts for the day and we also have a large number of other sources thinking about the news that you watch this morning were you last night thinking about just regular interaction if you just had a conference call over Skype that's also a multi-modal nature so there is a lot of multimodal content around us and also when it comes to opinions which is what I'm focusing on in today's talk there is a growing number of opinions expressed in video format and there are sides that rather than trying to collect text opinions as for instance Amazon will do they really focus on collecting video opinions here "
    },
    {
        "start": 739.529,
        "text": "are some examples of that I use these on blogs you will see here the X for TV these are some snapshot from there there's the website that I mention which has a very large number of video opinions on products movies and events and so on there are the blogs there is just a regular communication say on an iPhone you can do FaceTime that's also an instance of a multi-modal stream on YouTube for instance apparently there are 10,000 new YouTube videos uploaded every day which is a lot of content something that's very relevant to us or the video lectures the MOOCs would have a lot of lectures this very seminar I learned it has a very large archive of videos and again there is a lot of content that can be analyzed and maybe processing it easy ways so let me give you an example of multimodal sentiment "
    },
    {
        "start": 839.89,
        "text": "so this is an example of somebody's opinion on on the cost office as you guess is in England by the accent and what interests us is the fact that for one thing you do have the language which is quite suggestive suggested saying I hate the post-office drives me insane but then beside that there is also a lot of change in the energy of the boys howl which again is quite expressive and this guy in particular I mean I chose this example on purpose is also using a lot of gesture and that may be useful as well and of course facial expressions and so on so our idea in this project is that in addition to what we can get through the linguistic channel maybe we could use some other some other features to enhance the accuracy of algorithms that could detect opinions and polarity "
    },
    {
        "start": 901.99,
        "text": "the reason we think and I think other people working on multimodal content would agree that multiple modalities help as opposed to using a single modalities a language alone there are many times with language when language is ambiguous and so if you couple language with other other channels of information you can help in addressing that ambiguity there is also this today sparsity problem which we almost always face and so in addition to having clues that come from language we could use additional clues and that would help it with that issue and then there is also this idea of rounding there are different interpretations and that come from language that is grounded to its surrounding context and this is an instance of that now there are also disadvantages in using multimodal content noisy environment your fancy "
    },
    {
        "start": 962.579,
        "text": "background that also includes music or other noise the quality of the video also matters for today's state-of-the-art video processing video image processing it doesn't work very well if you have blurry images for instance you could also have a clusion and we actually run a lot into that when we did a study on identifying opinions on products when for instance somebody would talk about the book they just got and they will get the book and just put it in front of their face and then you lose a lot of the information that will otherwise come from their facial expression and of course movement we naturally move and that also is a difficulty when it comes to video processing so let me run you through three different studies progressively that we've done on this on this project and then if time permits I can also show you a couple of other projects that we are working on also in this multi modal space why should I aim to finish by one "
    },
    {
        "start": 1023.389,
        "text": "or before one is good one is that people usually interrupt with questions as we go okay yeah I welcome that all right so they very first study was truly a palace audit where we look for opinionated videos on YouTube we use some keywords such as the ones I'm trying here for best perfume opinion review cosmetics review and based on that we identify 47 videos which were then manually truncated so we remove the ads at the beginning and we only kept the opinion piece as opposed to keeping the whole thing that would also tell you I don't know how much the private course and stuff like and within manual transcription and we also did manual labeling of sentiment in this initial study we labeled four positive negative and neutral we had three annotators the overall agreement was seventy eight point seven "
    },
    {
        "start": 1084.669,
        "text": "and at the end we came up with thirty forty twenty two neutral and twelve negative videos you use the possible numerical value for positives they present what tools we use that they want and skill for more positive future that no it's just a very three-way classification here then we extracted features from the three modalities one is language and here we looked at polarized words posted on negative words as label in a large dictionary and pqa is a dictionary that includes a long list of words together with their priority label we also use valence shifters words like not no you say not good obviously it has a negative implication and we look then at acoustic "
    },
    {
        "start": 1145.97,
        "text": "features specifically we have pause duration we look at how many pauses we had in a sample and then normalize that and we also look at the pitch so we'll try to get the voice intonation and then also for for that feature as well without related a average over entire 30 seconds and then we had some features that came from the video specifically we'll look at smile duration so we took the video and we look at how many frames we're identified a smile and we look at two thresholds one is 50% or 75% so depending on that we'll label this video as including smile or not so these are all general literature's one feature per video many more ultimately this is all automatic so the annotation of sentiment was done manual and that because that is our gold "
    },
    {
        "start": 1207.82,
        "text": "standard but all these features are extracted automatically and then the other feature that comes from the visual stream is look away duration we measure how much of the time the speaker would look away from the camera using a 10 degree angle so if the site is outside the 10 degree I will say it's a look away so what models do you use for like smile detection right now we are using cert which is a program out of University of California San Diego between before and this particular initial study it was a car which is a tool from Japan that's owned by one of our collaborators on this we didn't really have access to it so eventually we ended up switching to cert and I'll show some results later that we did with the cert tool that's given that one it used to be publicly "
    },
    {
        "start": 1269.23,
        "text": "available for research purposes I understand that right now for the past year they restricted that as well but it can be purchased and it's fairly good in terms of processing facial expressions are just a few question about your linguistic features there's a first do positive sentences based on so do you extract the features based on sentences or here is based on video but I'll talk in the third study we did based on address because previously you also mentioned that you use some balance so I'm interesting like we may extract that information you care about the presence of the like negation or you can you read carry about like how many times so we care at this point at how many times words with a polarity are used inside the entire video and then the polarity of a word is measured based on the "
    },
    {
        "start": 1329.59,
        "text": "information we have from our dictionary coupled with this valence shifter where we look for a balanced shifter in the immediate vicinity of the world so if there is a valence shooter within two words then we'll consider that as a shifted polarity so say the dictionary says good is a positive word and then we see a battleship the right before then we'll mark that as a negative word so here is just some statistical analysis on these features to see what what matters it seems that word polarity it is a great way to differentiate sentiment smile also seems to be helping not so much to look away pausing seems to be able to distinguish between neutral versus sentiment possible negative but not necessarily between positive negative themself and here is some information on the pitch "
    },
    {
        "start": 1390.69,
        "text": "again the same trend where you can distinguish between neutral versus sentiment but not between precision and negative and what we did we put all these features in a classifier and again the classification is that at video level and here is what we got in this initial study where we look at the performer that we got on using text only visual clues only speech only and then all three together now the one thing to keep in mind is this is a relatively small data set we know to give you high hopes for the subsequent studies we still limited ourself with twenty hundred videos but this was done as a three way classification on forty seven videos so for each class we had a relatively small number of of instances but this initial study was encourage us "
    },
    {
        "start": 1454.299,
        "text": "to pursue this misser direction because we notice that indeed looking at all three modalities would help in comparison with one modality at the time yes where this performance for audio is lower than text you know like text it all also my including this old here the way that people are working this first would consider they speech people are actually ignoring text they mostly consider things like peach intensity so it's really acoustic feature we may be more proper to say speech signal to mess on the text I know you like this more interview son like what the way we understand it it would be and I would agree with you the way it's done in the research communities and it has no features when you say speech features is mostly referring to acoustic features known as silly to individual words "
    },
    {
        "start": 1514.95,
        "text": "so acoustic features would not subsume text features and it's the same understanding here and I'm thank you for for the question as it clarifies an important point so I audio does not subsumed stats it's two different things it's it among all your sound is here how many of them have the caustic we haven't looked at that so we did go manually to them so I cannot really say how many we try to keep only those that were not sarcastic but we haven't really focused on the analysis on that side I think contact it help me found it about 10 percent of social media that's opinionated will be sarcastic I wouldn't necessarily expect that here like I said because we manually verify them but I can't really say that we did this checkout circle okay so based on these what we figure is that it makes sense to try to separate between neutral "
    },
    {
        "start": 1577.53,
        "text": "versus sentiment and look only at sentiment by itself so rather than doing the three classification we could do it to a classification where we assume we already know there is an opinion and we look at whether that opinion is positive or negative we also try to get a somehow larger data set and the other thing that we wanted to do is to see if we could apply this study on another language and to be honest the choice of language and the choice of another language was also motivated by the student who did most of the work on these who's originally from Mexico and so she felt comfortable with Spanish and she was also interested and motivated to work on Spanish so the same the same main idea where we want to combine language with facial expressions and with a mystic features and this time what we have again from YouTube we "
    },
    {
        "start": 1637.95,
        "text": "selected 105 videos this time in Spanish so we use key phrases in Spanish that would help us identify videos that might contain an opinion and as before we targeted them to 30-second clips removing the introductory part and also keeping only the opinion piece so you incorporate slang into your dictionary I noticed on the previous slide it said this camera is a bomb and not only that different slang is associated with different ages so we have the dictionary is fairly large it's a good point we don't necessarily do the age distinction the dictionary what have for instance bomb as a possibly positive is my generation bomb is amazing well see so there are the other issues that there is ambiguity and and that's it depends on the context it could have a negative or a positive interpretation and that's "
    },
    {
        "start": 1699.8,
        "text": "necessary problem so the dictionary would in many cases will use them all in some case it will only list one interpretation and it will be up to the classifier to try to make that distinction we are not doing that I have another project I'm not talking about it at all today where we specifically focus on the word senses in relation to sentiment and how the same word can carry a positive or negative interpretation depending on context but we haven't applied it here so this is is fairly simple music features is looking for the presence with some valid shifters so try not to include a not good thing as a positive clue so yeah a lot and I'm glad that you're making all these points there are a lot of interesting and sometimes challenging aspects when it comes to language processing but also to other modality processing site sarcasm you know the background of the speaker "
    },
    {
        "start": 1760.13,
        "text": "word ambiguity and so so forth and that makes it very exciting so in this data what we have is 21 males and 84 females in the range of 15 to 60 years old and they do count for various from various leap spanish-speaking countries so they do not necessarily reflect we had as before manual annotation agreement was 92 percent and in the final dataset we had 47 positive 54 negative and for neutral we did remove the neutral one since we wanted to focus on just the sentiment classification so the baseline for that if you were to say that every single negative would be 51% now we use a polite lexicon for Spanish learn from another data set in Spanish since we did not have as in English a "
    },
    {
        "start": 1820.4,
        "text": "pre-compiled manually checked lexicon of color words we compiled our own from large opinionated data in in Spanish and we use that and then we also use a pause duration and teach the same speech acoustic features as before and we added intensity and two other measures of of the speech and then similar to the previous experiment we looked at smile and look away as features for the visual Channel and here is what we got on on this dataset and the text would do better so we have now started photos 85% interestingly the acoustic features do fell to quite poor on this data I had various interpretations someone suggested that they might have to do with the language itself with Spanish "
    },
    {
        "start": 1881.04,
        "text": "speakers having a rather flat voice when it comes to different either positive or negative statements that they make unlike the English speakers which would fluctuate their voice more I'm not sure if that's the reason why we didn't really managed to use acoustic features well to differentiate between positive and negative the combinations do help and the highest performance we get by a three-way combination where we put together the text acoustic features which would not subsume that as I said before and also the the visual features now one other thing that we we did here was to look at the weight of the feature so we calculated the information gain to try to get some insight into what helps most we didn't do that for the language feature because there are a lot of them so we had a large number of words that were considered as features but we "
    },
    {
        "start": 1941.16,
        "text": "mainly focus on acoustic and visual features it turns out that smile is the feature that has the highest information gain which perhaps is not surprising pauses would also help and then the others in order would be the intensity and pitch of the voice and then gaze at the in the camera so whether you look away or you look straight would be will help you differentiate between having a positive or negative actually control loudness a lot of times when warnings are made that's true that's we actually use of the shaft tool that would try to remove the background noise and that were not about background noise sometimes recordings compress the range we haven't really done anything in that respect so it they want these "
    },
    {
        "start": 2001.88,
        "text": "the steps that we did was to remove background noises as well as we could in a stock feature so we haven't really looked at that the Spanish speakers was that all of Mexican origin no no so there are so many confusions there are two I've understood Spanish in Mexico is a bit different Spain this so this rule and one big interest of mine is in cultural differences this is not the right data for that for instance but I would be interested in learning how people from different cultures would express for instance opinions and for that we wouldn't need to know the source of that in this data said we don't we don't we truly don't know I mean it's just people speakers but it might weaken signals sorry it might we weaken some of the same okay so let me walk you through the third and last study aware again we did sentiment only but this time we "
    },
    {
        "start": 2064.55,
        "text": "wanted to do it at a smaller spend level relating to the question that was asked before where rather than doing it at video level we do it at Atwells level an utterance is the terminology that people working in speech and I don't necessarily consider myself one of them would use instead of a sentence so is the the one segment between to pause ease that put reflect like on a piece of a piece of of an expression so it's then sentence or or utterance would be equivalent in language or even for speech one thing that we we notice is that some time you would have mixed opinions in a video so you could say something I like this lipstick because of this and that but I hate the price is too high so there is a positive and a negative opinion in the same video and also some time you'd see mixed topics so doing "
    },
    {
        "start": 2125.33,
        "text": "utterance levels and technologies hopefully would address these two issues outside of doing a gross level sentiment analysis that obviously you have a smaller span to work with and so some of the feature that we posted there before may not even be present or maybe to course for our purpose so for that reason we moved to an extended set of features and I only briefly talked about those we had visual features such as smile detection as I said before but also action units there is a number of action units that software like cert which is what we are using can detect for instance inner brow rays or outer brow rays or jaw drop and and so forth and so this will give you a more granular view or facial expressions and then also we use a larger set of features for the acoustic signals and "
    },
    {
        "start": 2187.62,
        "text": "these are some examples of that this all come from open ear which is a tool that would be using to do the analysis of the speech Channel and then for linguistic features we use the same as before features that are drawn from the text itself unicron's own individual words and yeah some examples of the utterances in in the data set this is all based on the Spanish sad that I showed before you see a neutral statement and then also a couple of positive ones for instance it looks beautiful it's positive or something that reflects a negative opinion the problem with those lipsticks that when you apply them they leave a very nasty taste and that's an example of a negative opinion all in all we had 498 attributes and again we manually annotated those two different annotators "
    },
    {
        "start": 2250.17,
        "text": "when agreement of 88,000 and and before we remove the neutral ones so that we focus on sentiment only and here is what we got on on this data at the same trend where language does very well and I'm proud of it because my background and my main work outside is in language but then visual and audio streams do help so the final result that we get by combining everything together would exceed the performance of the best individual modality which is language and the baseline again was somewhere around 50% if you were to go with the major class there are some of the features that have the most distressed brow and smile also some boys acoustic "
    },
    {
        "start": 2313.68,
        "text": "features those are the voice for ability and MFC see features that come from this open ear an emotion of anger this also comes from concerts assert which is the stool for analysis of facial expressions will also try to make some predictions of the emotion on a face and we use those as well and it seems that they do have with the overall classification and there any questions up to now I will move on cross-validation and that to come up with the play but the sensitivity and the classification is there anything so this all these results are leave one out so we take one instance out train on the rest and test on that that's out and repeat that n times where n would be the size of the dataset just wondering the shift from 70 to 74 percent was actually statistically "
    },
    {
        "start": 2375.81,
        "text": "significant we did check individual so we checked there yes between 70 and 74 it is statistically significant I cannot really reproduce those we did do the analysis I cannot tell you for instance between text and text plus visual my recollection is that that was not statistically significant but I'll have to check we did do pairwise statistical since those tests for that seems like you have much higher accuracy the cultural prediction so said have you checking to the case that this must be into any kind of civilization based on your ultimate level predictions you predicted hope you have ferrets say wait this video has a lot of words that is expressing negative opinions "
    },
    {
        "start": 2437.42,
        "text": "probably the hope it is more about we have thought of that but we haven't done and that's a good point we did do something like this in a complete different project where we work on social media and we use the prediction from individual tweets to make prediction about the whole user and that's seem to help on this project we haven't done that but it will make sense of all the questions about I don't know really need to share a little bit more detail about short extra features I remember the very beginning is that we predict with a clarity you have the words when you can see there's occasions you only can see the case when they when they are not next to each other right two birds on put it together right so there's no pausing of dramatic information objects we don't use that "
    },
    {
        "start": 2497.87,
        "text": "and I guess I'll just say it I found so we did do a lot of exploration in different features it turns out that you get the most mileage out of relatively simple things like unique grams accounting for shifting in balance you can do with star based on parsing for instance there is recent work that's based on deep learning that would move along the parse tree is to propagate sentiment and it does improve a little but at the end of the day you don't get as much improvement as you would expect from the effort that you put in so generally that a lot of these relatively simple features and you can try other things of course like parsing and they're generally does help but not a whole lot because why interested something like a lot of deposit based analysis they are very sensitive about the features based on fine this is the occurrence of the engaging words of the "
    },
    {
        "start": 2558.299,
        "text": "count that has the problem saying when you get the sentence that is expressing like double negation to say not all these tools are bad or like are not very good plugins right such active things they have problems I'm interested in like how your system is working on those cases I'm not I mean there isn't anything more than what identifying double negation there has been work and I'd be happy to point you to some publication not on out of my group I'm specifically focusing on negation in sentiment analysis and the role that it plays if you do a good recognition of negation again the game that you get is not as as big as you'd expect from the amount of effort required but it's all interesting directions to explore and it does help a little bit to consider for instance double negation there was the mmm and of course is my own bias I'm "
    },
    {
        "start": 2620.93,
        "text": "really into having the right data and when I say data it's broadly including not only like raw data but also for instance dictionaries what I found in this project and also in other projects is that if you have the right dictionaries it helps you a lot even more than having I don't know recurrent neural networks with this and that and I'm not saying anything about those matters I think they are great but to me the kind of data broadly including lexicons and textual data is revision and all that it's often bringing even more than the algorithms itself themselves and I think that points to features versus the classic items the last one is a face-off combining the three set up right how about we did that "
    },
    {
        "start": 2682.96,
        "text": "as well and you didn't do as well as doing what we've done right here which is really cool calculating all the features in one long feature vector and working with that I think people in working multi modal processing would refer to decision based combination where you combine the decisions of individual classifiers versus feature based combination which is what we've done here the one direction that I'm I'm excited about and we haven't done a whole lot is to exploit somehow the temporalities of this data so if we could somehow do some temporal alignment and extract features based on that I think that would be interesting that could be potentially more different than what we've done now but we are working on that direction another project on deception so let me just briefly tell you about two related projects that one we work on we aren't currently working on this one on affective response on "
    },
    {
        "start": 2743.23,
        "text": "visual narratives it's closely related to what I said before but in this situation we are trying to sense response to an effective stimulus it's not necessarily someone expressing an opinion is really just watching something and we try to determine whether they like it or dislike it and also another difference in this study is that we added some physiological set see we had recordings with a thermal camera that will give me information about the thermal map of the face and there are a lot of visual narratives movies for instance or anything else we watch on TV the irregular communication we have and of course the what we generally understand by natural it could be stories or other kind of narratives streams that will either watch or read and I will to give you an example of one stimulus that we use this is the general overview "
    },
    {
        "start": 2804.55,
        "text": "of of the experiment that we've done so we had a video stimulus which was either positive or negative we used two positive to negative stimuli and then we had the participant that we're watching that and we are tracking the faces of the participants with the video camera and we also tracked with the thermal camera and afterwards we asked for their input on how what they thought about the video that they've just seen and based on this we build a multi-modal prediction model to try to determine whether the person was feeling positive or negative about what did I see and let me give you an example of that I'll give you the one of the positive examples I want by "
    },
    {
        "start": 2890.83,
        "text": "Oh I wish I had my cameras with me you have made some great subjects so this is the kind of reaction that we're trying to monitor in a way and see if we can analyze them automatically so we figured that people actually enjoyed watching this video this is only a fraction of e there is one more minute that goes on along the same lines and so we had 14 subjects which we recorded with thermal and visual camera and like I said I only "
    },
    {
        "start": 2952.03,
        "text": "briefly walk you through these we had linguistic features we had visual features we had heartrate features the visual input there is a cool technology coming out from the Media Lab and we had the collaboration with student there where based on the RGB channel they can actually make inference on what is the heart rate of the participant and then we also had thermal features collected from different areas of the face from the thermal camera input and here is what we got in terms of in terms this is in terms of just separating between a faculty versus non affective States all the subjects that came in were recorded when they were watching this possible negative stimuli but also were recorded in a neutral State you're just looking at the recording session and Tatian and we recorded them for for one minute and it turns out we can actually differentiate quite well between the neutral state versus a an effective state and here is where we ignore the "
    },
    {
        "start": 3015.45,
        "text": "neutral recordings and we only try to differentiate between positive and negative and this works also reasonably well compared to the baseline it's less well than just identifying whether there is an effective state so what we learned from here is that physiological measures are good at identifying the presence of effective state and then facial behaviors and also the verbal description that we had : after the study are better at separating between positive and negative effect yes that might be a little bit of something but I just need to say now do you have any sample that says I've seen this like those kind of neutral and I somehow negative reaction but it's not really related to your contents of you we haven't noticed those but we did "
    },
    {
        "start": 3076.72,
        "text": "notice people we had another video which I think was less amusing of happiness state which some people actually didn't enjoy they'd have necessarily seen that we can say to be a positive stimulus but it turned out to be for some a negative stimulus and so our analysis is based on on those reactions as well and we've done studies and they are all in like a longish paper on whether you consider what we think is false negative versus what the subjects themselves think is positive negative and so on and I agree with you that there could be also that effect of someone having seen that we try to avoid that by not exposing any of the subjects to the video that we had I'm curious in this room how many have seen the coca-cola track one so they they that's what we notice too with them I'll be the subjects we had so here when you use this which is all sorry so here "
    },
    {
        "start": 3140.14,
        "text": "we extract the features from those participant reactions extracting features from the consensus of all the I just so we have individual it's not segmented in any way so is the whole recording but it's individuals and again it's a live one out cross validation I could stop here I could also go on for another five minutes from this after inspection it's up to you which classified e-learning we mostly use SVM's those they're not to work well nowadays we also use random forests on some other problems that so can I get the raise of hands who so once five minutes on deception detection I can also stop I find either way I'll just quickly go to and then so this is an "
    },
    {
        "start": 3204.17,
        "text": "ongoing study it's a party that's in a way surprisingly funded by NSF they did say we don't care about deception but I said return I care about the combination of language with physiology which I think it's quite exciting and could be applied to any other human behavior it happens that we propose to work on deception so difference here is that of course we focus on another human behavior which is deception and also we added a number of biosensors which were connected on the subject fingers or around the body for heart rate sensing and of course there are a number of applications screening for instance where it needs to be high coverage non-invasive very quick and you don't have enough experts for that interestingly enough whenever I talked about this project and I mentioned it we actually have a hard time collecting data because it's hard to get people to lie in the lab and a lot of different "
    },
    {
        "start": 3267.02,
        "text": "people told me that I should look for political speeches so this might be another nice application just to do politician screening they see one rely on ya only gives you one side of the equation though it would yes but so so far what healthy news is the polygraph testing which is primarily based on physiological sensing and what we are trying to build a system that would be mainly non-contact by using other modalities such as language and also facial expressions and non-contact physiological sensing which comes from the thermal camera so here is the setup where we have tracking of facial expressions speech I haven't actually used much each I mean we did use it a lot we never manage to get it to work for deception for some reason and then we have the thermal map of the face and then various signals that come from the biosensors like heart rate respiration rate galvanic skin "
    },
    {
        "start": 3328.88,
        "text": "response and those would also be input in the in the classifier so this is an overview of the equipment that we are using and as you can see some of them are contact non invasive but still contact so they have to be attached to the subject and we use we have three different scenarios two of them would ask people to either tell the truth or lie about a certain topic that we tell them one for instance is abortion we ask them to tell us what is there to opinion on abortion and then we ask them to tell us the opposite of that as if they would believe it's true so for instance if somebody believes that abortion should be allowed in the deceptive statement they should make a statement of how they believed it should not be allowed so they were basically be lying about their belief on that another set up is where we ask them to talk about their best friend and then we ask them to talk about the person they cannot stand as if "
    },
    {
        "start": 3390.65,
        "text": "that person were their best friend and then we also have one where we try to as much as we could to simulate a more realistic scenario there is somehow higher stake where we hit some money in an envelope we ask them to go I think the envelope and some people did find some money some didn't and then we ask them all to negate that they found the money and that was a little bit more more involved so it was more simulating a real setting but as I said before we do have a hard time getting good data although recently we got a handle on some some of these issues by looking for highly mediated real cases people for instance who kill somebody and they negate it for a long while and if it has been a highly mediatized case we do get recordings we don't get the physiological sensing though for that which turns out to be useful I don't think it'd be tricky with this because there's no consequence to lying it's different than somebody's lying I definitely agree with "
    },
    {
        "start": 3454.219,
        "text": "you and that's their hard time that we have a collecting data I mean people will do their best but this here is telling a story it turns out and I'm I mean I'm not really spoiling it because it just comes here so we have linguistic features his logical features and then thermal features that come from the map of the face will also look at visual features and acoustic features we didn't really get them to work I'm not reporting them here we came back to them in another study that we are doing right now and have higher hopes for those but it turns out that language does work reasonably well even though they are these fakes and I use but there is no high stake and people don't truly lie I mean they don't necessarily do their best for for lying well combined with thermal features it does we do get better results so you see here the about 70 percent the addition of physiological "
    },
    {
        "start": 3515.539,
        "text": "sensing does not help much and it might have to do with what has injured so people are not really having a lot of perspiration we are tracking that but they are no worse right so it's it's not it's not truly really helping I think ideally you would want a collaboration wait I don't know Department of Justice or something like that to get to the real cases I'm not sure if I would pick 100 cases but I think that would give you like better data in terms of physiological sensing at least so I'm truly conclude here I think the lessons that we are learning from all these experiments that I mention is that language is a strong signal but it can be effectively supplemented with other modalities such as visual features acoustic features physiological features "
    },
    {
        "start": 3575.65,
        "text": "so far we looked at sentiment analysis of active state and we're currently working on deception and we have done some initial work on detecting discomfort and alertness and we're in the very early stages of starting to think about detection of stress it's similar set up of course different stimuli and different different behavior but I think these combinational modalities it's quite an exciting direction to work on which can help with tracking of human behavior so if you have additional questions something that's interesting that the thermal is quite low together with the linguistic shoot up well the "
    },
    {
        "start": 3639.179,
        "text": "physiological is high on its own and doesn't do nearly as much so it's like some of this information is correlated and so you're not gaining much when you so where we are now trying to build some temporal models when we look at the lineman's and that hopefully will bring some insight into these behaviours I guess the main idea of the of the project and they are being funded by NSF is that there will be benefit from combining these different features and we thought of them as a token al but it turns out that some are less orthogonal than others but we still don't know where is the terminology and there is some difficulty or a lot of difficulties coming with this analysis because language is more discrete so I I just said the word but then if my heart beats it won't go like up and down if I say I "
    },
    {
        "start": 3701.079,
        "text": "don't know love it won't go up and then it goes right back down so there is this factor which makes the alignment pretty hard but we're trying to get there um for collecting data on the debt the deception stuff have you considered looking into like I'm bluffing games or something along those lines like it would be hard for data question because you'd probably have multiple people in the same room which makes it a pain but I think that's a good place to like have a place where people naturally buy in a controlled setting and like you kind of I'm so like a game like like or like having people play poker and like you know the cars that they have but then if they're like if there's table talk saying like oh I have to beat when they actually have nothing like that could be a place to do something there's plenty of other games like that but what we did think of and we collected some data was these Street "
    },
    {
        "start": 3761.78,
        "text": "interviews and apparently there are TV shows around that where people would be asked about different things like have you seen that movie how did you like it and then it turns out they haven't seen it but they would you know we naturally lie about it for various reasons and so we got some data from there but that's a very good suggestion and there is some motivation to that I mean at least you want to win the game yeah well I mean if I was designing this extra I would just make it most free flow aesthetics if you successfully convinced me something that I would just write you a check or the other way say if you fail to convince me that you should make it like you did something you will be punished in a manner like we decrease I don't know if IRB would be happy well I mean like this more like serious all right today it's mostly gonna to the ones that even having like a peace officer said if you fail to come forward some information "
    },
    {
        "start": 3824.38,
        "text": "there will be screaming probably yeah so where we are about to record another batch of data right now and we're rethinking the scenarios or we might consider that there was another group at University of Houston who did some work on this detection they were giving the participants $10 allow the lines that you suggested I don't know how much better their data was but I think it's something to consider to motivate the people to truly lie if you could say that other questions what are the key technical challenges in this area like I would say well deep learning is a big buzz in in my community and as it might it's likely in "
    },
    {
        "start": 3886.56,
        "text": "other communities as well so I think doing work along algorithms like having algorithms that take better advantage of the data you have I think better alignment between the modalities that you have that's another trend that I see and we're trying to to go after that as well where you don't really just get summary features but you do better in terms of alignment between between features one thing that I see and it's how it's mostly in the linguistic community computationally with the community is to do more in terms of analysis and inside so it's what are we learning from what we are doing it's one thing to say okay I can do deception detection I don't know 70% 80% okay and what are you learning from from that what are some behaviors associated with that insight into the data and I see more and more of "
    },
    {
        "start": 3947.4,
        "text": "that which I actually very happy about so if you have a purely statistical paper that just throw some day turned and final result that's less likely to fly then one that also does some work in doing I don't know like feature analysis or data analysis other questions thanks for having me "
    }
]