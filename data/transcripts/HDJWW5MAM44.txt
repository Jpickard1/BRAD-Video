hi everybody thanks for the introduction ly um my name is Kevin I'm from the distri lab uh I'm really excited to present at Tools in Tech um about my tool called Ms booster which is a tool for improved peptide identification in momet based proteomics so as an overview first we'll talk about why you might be interested in uh lcms Ms based proteomics or tandem liquid chromatography math electrometry based proteomics I'll talk about kind of what a typical experiment looks like as well as with data analysis with our um with our computational suite FR pipe would look like and then I'll get into the specifics of my specific tool on this booster in terms of the algorithm one really example use case of it as well as some cool new features such as uh choosing your own models uh diagnostic Q SE plots and then how to use it in the graphical user interface or on the band line and all around out with some future directions so why use lcms any pics um I'm actually kind of curious if anybody here has used phics before or like yeah thank you U or just like worked with the data before I know it's like a lot less of a uh used om technology um but I think it's a really cool uh piece uh I guess technology to work with because it provides a complimentary view to other om Technologies so I know many people are familiar with genomics or trans transomics but there just so many levels of regulation in between those levels and then finally like the prot form that you see uh and so I think by doing all those om together in a really truly like multi omix way you can get a more comprehensive picture of the data that you're looking with uh furthermore it's really cool for detecting and quantifying prot like I mentioned so you have these alternative spliced ISO forms like are those actually expressed in the end uh it's a good way of finding that if you're interested in post transation modifications like phosphorilation uh the you know chemical modification that will actually modify the shape and the function of your proteins uh this is a really good way of doing it and furthermore it's a very high throughput technology uh where you know recently people have been sequencing thousands of proteins in uh in the order of minutes to hours and so it can really give you high throughput if you're looking at these large cohorts of many many thousand samples perhaps and this just a pment search I did for proteum trometry I always like doing this um when I do a talk just to see how state of proteomics is and you know in the year 2022 4600 articles we published using using this technology uh so I think it has a lot of utility and people are kind of valuing it more and more I more accessible so what does a bottom up proteomic workflow look like uh well we call it bottom up because we basically take our proteins and then we digest them down into individual peptide because a little more it's a little easier for us to sequence them that way so first uh like I mentioned you can use an enzyme to digest your proteins uh so for example if you use uh trips and enzyme you end up with peptides that are ending in arginines and lysines uh which help us better identify kind of what peptides you might be identifying rather than looking at all possible subsequences of the uh protein database that you're working with uh another way of doing it is you can also directly extract endogenous peptides so one example I'll talk about is in amop peptidomics you're looking at peptides that are presented naturally um by your cells to the te- cells and so you can extract those as well if you just want to skip that entic digje step then you can do a depletion or imission step such as if you're doing phoso proteomics you can get those phop peptides specifically and then finally this is really important part just you can separate all your peptides with li chromatography columns that's the LC step and lcmsms and the time at which your peptide is eluding out of the column I show here yeah it flows through the peptide or the LC column right here uh and they're separated based on different uh physical properties based of the peptide such as the hydr and when they allude out of the column is called the retention time or RT and then they can be detected in the mometer kind of a cross time or each of these individual kind of groups will be a separate peptide uh after you do that um and you get one of your peptide precursors entering the MPC uh you actually have two different MPC steps hence the msms so in the first mass uh Mass Spectrum scan you can detect the mass of charge ratio of the peptide precursor we just take peptide Mass divide by like the positive charge for example to get that and then that actually is not enough to identify what peptide you have because if you imagine we have uh one peptide sequence and you Shuffle the amino acids around you end up with the same mass of the peptide uh but those are fundamentally two different sequences so you actually had to do a second Mass spe Stu in order to identify which one of those is going to be and so to do that uh we have this fragmentation step um right here so as you can see you take your precursor that you identify in the first massm put into this Collision cell where you uh will basically throw energy at all the peptide bonds and then fragment them into these individual uh amino acid these individual fragments here uh and so you can see that they're being broken at every single amino acid Bond and all the fragments that are to the starting from the left hand side are called V ions and if they're from the right hand side they're called y ions and then you can then shuttle all those fragments into your MSN skin where now each fragment's uh at Mass overcharge ratio and intensity is recorded in an msms Spectrum so now that we have these msms scans right here we have to do I guess like the search again and see what peptide is making that Spectrum uh so the way we do that is by doing a uh database search with a database Search tool such as n Drager which is in our Pipeline and the way that works is you can give it a protein sequence database such as from the human protein sequence database and then you can do this insilico digestion where you'll take your protein sequence and then basically cut it after all those lysin and ardines if you're using like a tripson enzyme uh and then you can try to see which one of those peptides will best fit uh your experimental Spectrum so because you know the precursor MZ that generated this experimental Spectrum you can narrow your list down of all the possible peptides in your uh pep sequence database now to this list of poal candidates and then we have to basically rank them somehow and so we have the sear score idea uh where you can basically see how many Peaks are matching in between uh your experimental spectrum and your theoretical one and uh that score is based on basically how many matches there are where the more matches you have whether to match the more likely the peptide is and then you can do that for all your peptides and then rank them in the list and whatever Happ like the highest score is hypothetically your best pepti Spectrum match um and this is the abbreviation for that is PSM but within I guess this process you're naturally bound to get a lot of false positives uh because there's a lot of noise in the Spectrum you know it's not as pretty for example as we see with this theoretical Spectrum where everything is kind of the same there's no extra stuff in there um and so how do we actually control that know those false positives uh what we do this FDR false Discovery rate control and we estimate that using this idea of deut peptides and so first of all before we talk about decoys we talk about Target peptides which are all those peptides that you get from uh doing your insilico digestion of your protein database um and so you can see up here we have this pep sequence ay t d lb lhr uh and then if you want to get a counterpart of it you basically flip that uh in Reverse or you can Shuffle It For example uh you make sure that the arine or lysine at the end stays the same uh but then everything else kind of gets shuffled around and then this ends up being uh this peptide sequence that you expect to not be actually in your sample because it's not from actual protein uh and so this has been a really cool type technique people have used um decoys uh help us to uh estimate those false positive because they have a lot of similar uh features as false positives in our sample and so when we search against our Pro sequence database we're EI either saying this spectrum originates from a Target or a decoy and then you can learn in a post processing tool such as percolator uh What uh you'll basically visualize all your targets and decoys and then try to learn this hyperplane that'll separate them as much as possible and so in the end you get all these Target psms over here that are most likely true positives or more likely true positives and then you get your decoys clustering on the other side along with a bunch of other Target psms that are more likely false positive because they're more similar to those decoys which are the false ones and then from there uh you have your peptides you can infer your protein just by saying what protein sequences are those peptides from um SK with that any questions so far so now that we have uh our our data like how do we actually do all this data analysis um well I'll talk about prod type specifically which is from our lab it's this comprehensive proteomic data analysis Suite that basically has all the tools you might possibly need and so you can see here there's a lot of tabs at the top uh that are just different steps of the pipeline you can upload all your mzml files here which are just the files from the mometer that give you the Spectra and then you can do your database search with Fragger you can get all these uh cool downam analyses so I'm just going to shout out uh other members of our lab here who contributed to this pipeline so for example if you want to visualize the actual Spectra that you're getting um you can use SC Tye pdv which was made by Kylie in our lab and then uh you from our lab also made P Tye analyst uh which gives you a bunch of cool slots afterwards so if you have a bunch of samples that you expect a cluster based on condition or whatever then you can generate PTA plots you can make heat Maps Etc so those are all super helpful so another question is where does Ms booster fall into all of this so Ms booster was based off this idea of open science and data reuse um I'll show here basically one of the downfalls of database searches is that you're not taking into account kind of the differential intensities of all your fragments so you see here this is the acir Spectrum you see there's a lot of variance and and how these fragments are being expressed but in the theoretical database search you're basically thinking that all the fragments are have the same intensity and that's truly not the case and so what people have done in the last uh couple years is they've been sharing all their uh math electrometry data online for reuse for people to use they can search it again they can do whatever they want with it and I think this has been super helpful because uh this data that they've been posing online we have like millions and millions of Spectra and now we can train these machine and deep learning models to help us predict these properties of peptides and the nice thing is that um for example if you look at these MSM Spectra they're very reproducible across different Labs or instruments I mean there's variation obviously uh but there's enough similarities between many different conditions that you can actually train machine learning models to predict these uh and similarly for RT or retention time um you know the hydrophobicity of the peptide is not going to change drastically based on the LC column and so you can also replicate that through prediction models and so these are kind of like the foundations of what MSS rely on they use these predicted values of a peptide and compare them versus the experimental ones and see say you know a true positive should truly you know had the prediction match the expermental values uh so that's what we look for so the booster algorithm um the paper is online as of July of last year if you're interested uh but the workflow of this booster is first we'll go over kind of what it looks like withus booster so first in frag pipe uh we have uh your M data that you're searching and you can pass it to Ms rager for that database search and mssager will give you all these features uh that you can then get to a tool called percolator which will learn the hyr plane separate between the true and false positives uh and you can do all your Downstream FDR control stuff with philosopher but if you're using Ms booster you want to basically propagate these new deep learning based features uh to C later as well so what it does is it extracts all your peptides that Ms booster gives to you all the possible candidates whether those are true or false or likely or not uh it'll give these peptides um to it will format them for the appropriate deep learning model to be predicted and then you'll get all your MS2 Spectra and retention time predictions there's also this idea of ion predictions or ion Mobility which is another feature that people have been using to separate peptides however we found that that's not super helpful in this Pipeline and so I'll exclude that conversation for now but I do discuss in the paper Al and then once you have your predictions you can basically again compare those versus your experimental ones from your M data calculate these features and then add them to C later for better restoring what does that look like um so the input in Ms booster is these tabular pin files uh I just visualize them in Excel because they're just PSV files essentially and so every single row here is going to be it's a little small but every single row here is going to be different scan along with all the different features that describe it you have at the end the pepti sequence uh as well as the protein that it was originating from uh and then Ms boost are just impending these new features based on deep learning at the end uh so pin files are kind of this a very popular feature format because not only are they human readable they're used by peror and other uh tools like mapod which is an extension of percolator that gives you more deep loading models or models to to use uh so that's what we use uh for processing these pin files and in the future there's also these XML based uh pep xmo files that people often use and I haven't fully supported that yet but that's also when net Works uh if people want to use that for their pipelines so the two um features that MSP calculates mostly uh the first one is this spectral similarity uh and to calculate this it's is pretty simple uh just have two uh vectors of scalar Valu you can compare them with something like coine similarity for example uh the way that works is you'll get your prediction we'll say I'll take the top 20 highest predicted intensity fragments uh from the prediction and then compare that to the experimental Spectrum are those predicted fragments actually in the observed spectrum and if they are do they kind of match the ratios of the intensities that we expect from the predictions um and so by default what we use here to do that similar calculation is called spectro entropy score um and we found that this is super helpful because actually outperforms more traditional metrics such as CL and similarity uh but if you are interested we also do provide doc products and other things as well if you want to mess around with that and like I mentioned before uh because it's fully integrated and this booster is fully integrated into bagpipe uh you can use the other tools that are available so like back pdv you can now compare your experimental Spectrum versus your predicted ones and and see is this truly a good match so on the left hand side here we see we have this one peptide uh with the top part is experimental bottom is predicted and the MS2 similarity between them is 098 uh this on a scale from 0 to one where one is more similar uh so it being 98 means that it's very likely to be true uh we see that a lot of the fragments are matching you get this y1 I is very intense both the prediction and experimental so we'll be more confident that this is a true uh true positive on the other side though uh you see the experimental pred Spectra have a similarity of 0.1 and it's it's very evident here you see in the experimental you get a lot of these B ions matching however it's missing a lot of these y ions which are quite intense in the prediction and so because of that we believe that this is more likely a false positive and so pepti is probably not going to be in our sample uh the second feature we use is based on the retention time and we calculate this potential time difference um and so basically we have to generate this locally weighted regression curve uh whenever we do this uh renal time difference calculation that's because LC columns differ naturally again they can be looting peptides out for just like on a minute scale or for hours uh and there's just a lot of differences between them however the general idea of what peptide should be exiting the colum the beginning versus what are exiting at the end should be pretty similar and so we just have to calibrate between those two different scales uh so to do that we take our top 5,000 psms based on what has the best database search score because we believe that these pepti already have a good database seource score should more likely to be more likely to be a true positive and so we can learn uh this regression curve as you can see here uh the fit is pretty good where every dot is single PSM and the red line is the curve that we've learned uh and the idea is that basically you want a PSM to be close to this curve because that means the difference is is very small but as you venture more and more out into the sides here I mean that just means that experimentally for example you see that like the PSM was here that means it's eluding at the end of the column but it's predicted to elute at the end then that means like it's probably not going to be true uh so this is also a super helpful metric to add to uh the ttin files and this is a QC plot that is always generated by m booster if you're using these RT features uh and so you can examine that yourself as well one caveat of this is that um you know we always have to take deep learning with the grain of salt sometimes you have a PTM for example that uh has never been encountered by your deep learning model before and so predictions aren't going to be optimal in this case here we see that we have a PTM of uh 42 dot which is and terminal acetalation uh which this one model is not able to predict and so uh you see that it's represented by all these black diamonds here and that band uh is now kind of straying away from the main band and foring its own thing and so if we only generated one calibration curve then all these interally assulated peptides would be penalized uh when in fact maybe you want to keep them because maybe they're truly important to you um in this case inter terminal culation isn't really important but the idea is generalizable uh so what we do here is we provide this feature or parameter you can call called RT mass for calibration so you can just put in the mass of your PTM that you're interested in that you see this this ship reg generated for and then it'll a separate calibration curve for so it's not heavily as penalized uh but in the future you know it can be a little tedious to try to find all these Mass ships yourself and if they have to have a separate calibration curve so I'm going to be working on automatically detecting if a mass is associated with uh different retention time and then I'll generate a calibration curve automatically so um I want to give one kind of use case uh for Bo booster which is HLA immunopeptidomics um there's a lot of other use cases but I think this is a really enticing one so HLA peptides are just those peptides that are presented on your cells uh to te- cells uh for kind of like the immune response um and so if the t- cell recognizes that this is like a foreign antigen such as uh from a bacteria um then this imun response will happen so people are like really interested in identifying these peptides in order to design Therapeutics uh so how does Ms booster help with that how do we help find more H peptides so first we looked at this original row right here I basically ran the simulation or this analysis 10 times um and I saw that without amus booster we're getting about 7500 peptides in this dat in this data set but now if you use this retention time feature you get about 17% more identifications if you use the spectral feature you get 20% more and if you use both of them combination those are two kind of orthogonal pieces of information and so Al together they give you about a 31% boost in the data set uh which is kind of astounding if you look at the peptides that are identified in this Ben diagram uh you can see that a large portion of them are shared about 7,000 you get uh this huge chunk of new peptides identified by Ms booster but also the smaller subset of those peptides in the original set that you no longer get when using Ms booster uh so I want to make sure that the pepti that we getting are actually true positives and so one way of doing that uh thankfully in HLA pepid domics uh you know these HLA peptides are presented on these MHC molecules um which each have their own binding specificity uh and we know that in this data set we have this monol MHC that only likes to bind peptides that have this sequence right here where it's binding Lucine and theine at position two and isoline Lucine and veine at position n and so hypothetically we would want all these peptides from Ms booster to be you know following that sequence Motif and when we do SK clustering of it we do see in fact that uh that is the case that allow these new Ms booster identified peptides follow that Motif another way of looking at it is based on predicted binding specificity um and so there's some tools out there called uh net MHC that can help you predict based on this Al this MHC Alo how strongly is going to bind different peptides and so we break up uh again this Bend diagram set into booster only into the shared ones and original only and we see that while the peptides that are identified by Ms booster or those shared between the two sets uh are likely to be high or weak binders uh that percentage decreases a lot in the original set so more than 50% of them are predicted to be non-binders and so uh those are likely to be false positives that we end up kicking out because used Ms booster and so this tool really helps you not only find more true positives but you know decreasing the amount of false PS you have one really cool thing uh is that M actually works better for the hard problems that database search tools do not look well for so I've already mentioned in HLA pics we get this 30% boost uh and the reason for that is because this hugely expanded search space where now uh peptides presented uh in in this data set are are not um digested by tripson so you don't expect Len and aring at the end of all of them they could really be any subsequence that you find in protein and so because of that uh lack of constraint then you get a lot more peptides you have to consider and so database search tools will struggle with that much larger database uh likewise you can see with data independent acquisition or Dia uh this is a method of uh sequencing your proteins um or peptides where you generate a lot of these pic Spectra where there's going to be a lot of peptid fragmenting in the same Ms on the skin so that also presents a difficulty because now decoys have like a better chance of just like sply uh matching r fragments uh so that makes it difficult for them single cell proteomics you about like a 10 15% boost um and then at the very bottom when you're just doing a typical data dependent acquisition with trips in nowh ptms out there you see that you get like less than a 5% boost to with booster and the reason for this is that uh this kind of the bread and butter of database search tools they're already like so good and so well tuned to these sort of searches that the features that are being generated by Ms per instance are already helping identify most of the peptides there and so adding deep learning on top of that isn't really necessary which is kind of a cool thing to think about that sometimes deep learning doesn't really help because you've already done all the feature engineering yourself um any questions um this is a really cool application um I'm curious if there's more um like in or more like controlled experimental data that you could use to Benchmark the quality of your predictions yeah I was like so whether we know like the ground truth of what peptides yeah there's actually a good amount of them uh there um I think people have uh like one example of that would be like a spike in eoli Sample into like a human proteome and so that can help you um basically yeah what say yeah you can then identify what human peptid you're identifying and what col peptides you're identifying and then like Downstream you can see like how much quantification you're getting at each of those because you can do like in unnown quantity and so you can like truly like are your are you identifying the peptides that you know should be in there like the quantity is matching what you expect um so that's one way of doing it there's a lot of examples of that uh there's also this idea of an ENT trapment search where you can just take your human sample but then search it against both uh human and equal database together for example uh and you know that there should be no ecoli proteins in there and so if you do start matching to more ecoli then that is a case for you matching M positives um so I did some of those en Tren searches before and there's nothing Ms booster did not increase the number of false positives in that case uh so we're pretty confident that that is one way that is like Ms booster is like giving us the true positives there that makes sense um yeah so that's kind of like the bulk of what that first paper was about um but I think there's a lot of Co applications for must booster besides that uh so one thing that I'm working on right now and the manuscript is in progress is this idea of model selection so in version 1.1 of our tool we only use this tool called Dian for our spectral and RT predictions um but there's some drawbacks to Diane because it wasn't really meant to be like the prediction tool it's it's used for different application truly and the prediction module was just one part of that and so because of that um you know it's it's not optimized for this sort of thing so for example I mean first of all it's close Source I don't really know what the training data was the architecture of the model it's a little you know confusing there and furthermore Dian itself does not predict these YB one and two ions which suggest that you fragment your peptide at either the left or right side and you just take either one or two amino acids off um Dian is not predicting that and this these fragments are actually super helpful for identifications and so while Diane itself is doing quite well with predictions there's a reason that you might want to look at other models as well and so a lot of groups have been interested in publishing more open source models uh for a lot of different use cases such as chemical tags such as different ptms uh so I want to allow Ms booster to be able to work with all sorts of these models and so uh I'll give first two use cases here like again to prove that Dian isn't always going to be optimal uh so this is again with the H data uh that it's a different data set but same same idea um so we see here that Dian was able to get how many is that uh like 15,000 peptides Maybe uh using its features but then if you swap in a different model such as this prit model right here uh well proit would actually train on a lot more H peptides and they talked about the whole data set that they used they did a bunch of like like hundreds of thousands of synthetic H peptides that they sequenced and trained the model on so because of that better dating that better data set you get about a thousand more peptides from this this model um so that's one use case there's also this Tim stoft instrument right here uh where before I've been talking about thermop Fisher instruments um but this is a different uh instrument fromer and again you see here that Diane is predicting a certain amount but then by using a more optimal model like Alpha pep uh that was trained on Toft data specifically again you see an increase in peptide IDs uh so already the two good use cases for why you want to swap in different models and so if you're using it in the command line uh you can call the different modelss uh and you know future release of frag pipe with or sorry uh with with the current Ms booster model model with Spectra model parameter or RT model parameter and when we incorporate in frag pipe we're envisioning like a drop down menu that can kind of just you know plug and chug whatever model you want to do would you be worried about some of these models having more false positives than others if you're just detecting more I mean you could just enumerate them and end up with lots lots more but that seems like that would not be a good predictor right that's that's true um and so I think in the manuscript I'll try to incorporate some tests to make sure that we're getting like all the true positive and notc F positives like the the use case I showed with like the sequence motifs and then The Binding that been predicted uh that could be that could be nice but I think you know even the Baseline when you're looking at the Spectra itself um those intensities are just matching a lot better you can like visually see that um so I think false positives are always you know an issue in in proteomics and I think we do our best to control for that uh we do it at you know both the pepti level and the protein level um but yeah I mean hopefully the idea is generalizable and by showing like a single example or maybe multiple examples on the paper uh people will have some more utility in that um but I mean that's a good point maybe I need to think of some way to have a QC plot to make sure that false positives aren't increasing for example um and I'll actually have like a slide about that kind of in the future yeah while you are trying to control have you also um to over negative um yeah so I guess with with the idea behind Ms booster is that it'll also try to save or rescue these psms that originally weren't good enough so for example uh if this database search score was pretty poor because um maybe like not all the fragments were there or something then initially maybe you weren't capturing that um but then with Ms booster you see that even with fragments that it is expressing those intesting ratios are quite accurate then maybe you'll say that um and so I I haven't any plots in terms of the number of proteins they identifying but we do get a lot more proteins as well uh so yes it is ruing these these false negatives as well um but that being said you don't want to go on like this uh what it called like a wild abuse Chase sometimes the Spectra itself is just so messy it's hard to actually see that any peptide generated anything in there um and so we don't try to rescue those because I mean those are un unsavable so here you compared each model against each other model is it's possible that if there's a way to aggravate the model result you might end up with a better technique like an emble model um yeah just like by running all the models together and then putting all those features in there yeah that's a good point um that is true I have not looked into that specifically um there is one potential downside uh where if you know because these models are predicting the same thing and so they're often going to be very linearly correlated and we found that when you add all those features um into like the pin file for percolator percolator itself is this linear SPM um and it actually struggles a lot with having these linearly corated features we now it will tell you before um the weights of the importance of each of these features but now if you have all these different features that are telling this very similar things and those weights start to become weird like maybe you'll get one so typically uh you get a positive weight um for this MS2 similarity score but we've seen that at least in the case of adding like Coen similarity and special entropy and like P the correlation together those are all correlated and when you add those all together then you start to get like negative weights for some of them which do to not make sense and you don't actually fundamentally get any like uh statistically significant boost of peptides after that um this might be a little different just because um it's not just like different metrics you're Computing for the same Spectra you actually are using different predicted Spectra to calculate them um so you actually might get a better boost which is something I should definitely look into um but I haven't at this point that's a good idea now that you have these open data model trained um do you see that there's a dependence on the on the actual experimental patform that's the data was generated so if you're testing it on one platform but the data is collected on a different platform that that might be not as good as the same platform yeah definitely um I don't think I included anything here but like for example if you have different instruments how you're doing uh sometimes those Spectra will differ greatly uh and you'll actually be able to see it when you actually look at you know um like a a PSM that has really good database search score but then no longer like those intensities don't match up anymore so it actually looks really poor and so that's why I have a lot of QC plots that are generated to show you um is your model acting suboptimally right um on a more fun model scale how do you like correct for that I mean do you need to train a model that will be optimized for every single like instrument or Pam or something uh that might be something that I have to do um but it's also like a piece of meta information that you can include in models to help you kind of like modu modulate your prediction a little bit but that is a good point like sometimes you get suboptimal things from there's just a lot of parameters to calibrate with these things uh so it's not always going to be good uh but even that being said we've seen that sometimes we' done predictions for uh these TMT tags which change the Spectra a lot and while you see then that the prediction is suboptimal it's still like kind of good enough that you get like a smaller boost in there which again brings up the question of false positives um but yeah you have to optimize things but even if they're suboptimal they provide some benefit uh so the question is how do we support all these different models that I just talked about uh well di is just like the C++ tool that we've incorporated into our frite package um but all these other ones um I don't really want to go through the effort of having to you know generate all the different python environments or environments for all them package all the python tools with it it's a notot of work because these models are being generated all the time and that just more worked for me and so so our collaborators over in Germany have generated this uh coin server and that's super nice because they have this trident inference server uh that gives you access to a lot of Nvidia gpus um and so the idea is that even if you're working at an institution that doesn't have access to gpus if all you have access to is like a laptop for example all you have to do is just send some uh curl HTTP requests over to the server and then you'll get all of your deep learning enable predictions uh which I think is super cool because now GPU power predictions are for everybody hypothetically uh in terms of runtime um I did it first for these retention time models uh on the x-axis here you see number of peptides you're predicting um but I just did a bunch of different data sets so here you get about 600,000 peptides and you can predict all those in like the order of 10 to 100 seconds um so that's you know pretty reasonable um for the MS2 models they take more time because now you're not just predicting a single scalar value you're predicting that intensity for every single fragment uh so it does take longer but still in the order of like hundreds of seconds for the very worst model which is Al de which is uh slower than everything else um but that being said this prediction step only needs to be done once uh and then it saves it into a file like an MGF file for you to you know par through and load again so if you want to with the MS booster parameters after you've done your first search you can just reuse those predictions and ultim um the prediction step is kind of out of my control I'm not the one designing the the models it's up to the people who actually make them and so if you kind of look at these different data sets uh I'm showing here uh these different boxes are colored based on the step in algorithm that is being timed so red is when we generate the input file for the models uh green is the predict prediction step orange is when we calculate the features and blue is for percolator post processing and so you see that the majority of the time here is based on on the prediction itself and on the post processing and Ms booster itself is is quite fast and this is even just from the initial publication and since then I've multi threaded a lot of the steps uh so it goes a lot faster and you can you know it's best that you do on a server uh we have like a lot of memory um and RAM but uh for most analyses if you could just do on a desktop I often just test on my desktop with 14 gigs of RAM it works just fine uh so now the diagnostic plots have been mentioning um um so again you want to make sure that your model is uh predicting the right thing and that your data doesn't look weird and so we provide these two different histograms and so in blue here uh you basically see all your Target psms and in Orange you see your decoy ones and from your target ones you expect to see this B mod distribution of your scores where this is going to be your two similarity and this is RT difference but you expect this Bal distribution because you want your true positives in one distribution and then your false positive in the another and you also want your false positive targets to be matching the deod psms and so in this case we see that uh here we see like this bump is being matched quite well in both targets and decoys same thing in the RT difference uh and so when you're looking at these plots for the MS2 similarity the more on the right you are the higher the similarity you have which is more likely likely to be true positive and for the r difference you want that difference to be small and so you want the on the one left hand side but sometimes things do go wrong and so there's two cases right here that I'm showing we now uh in this file we see that you get a lot of decoys and F positives and you still see the small bump in your true positive targets but it's much smaller uh so this is not necessarily an issue in and of itself it just means that in your data set uh perhaps you have um there not a lot of targets there um if you do a lot of fractionation of your data for example Maybe you just get you know the the final couple peptides auding at the end um another possibility for this is maybe you use the wrong database so maybe you have your your human uh data set and you have like a very different uh species that you're Imaging to by accident because you've forgot to change your database well now you only get like a few of these true positive because you're only maybe getting a few of those homologous sequences um so that's one thing that you learn from your histograms another thing here is like I mentioned before with uh not having the optimal prediction model uh in this case you see that while you do still see this shift toward the right hand side of um your peptides kind of being similar um there's also just not this like huge um concentration around around one and so in this case we're using a model that is not truly optimized for your data set and while it'll still be helpful it's definitely not as good as it could be like I mention mentioned before for Co um this is just a model or a figure that I'll show you on the xaxis the timing and on the right hand side the y- axis you'll see the number of peptides that have been predicted in thousands uh so you just want to see how quickly it's being done you can see it in this figure and then this is an interesting plot right here is this normalized Collision energy calibration plot um which I'm again is currently in uh the manuscript of the progress but the idea is interesting where at this at the step when you're putting energy into the pep and fragmenting them uh you can actually customize how much energy you put into that step uh and if you put in less energy then through those bonds are fragmented which could be helpful for something like a label modification like phosphorilation where those tend to fall very easily and you want to use like less energy in order to keep that phosphorilation on the peptid that can localize it um and then you might also want to use more energy for example if you want better fragmentation and so this Collision energy parameter has a lot of effect on the actual peptides uh predictions and so in order to calibrate that you know these these values differ a lot between instruments so like saying 30% on one instrument isn't the same as on a different instrument and so what we do here is we take the top 1,000 psms again ranked by their database search score uh give it to COA and then predicts it at this whole range of MCE values and then we take uh the highest median similarity across the across the ncees and then choose that as the optimal Collision energy for all predictions in the future so one thing is also that the box andal plots here are just super chunky um so Java doesn't really have a lot of good uh I guess graphing packages unfortunately such as like python or R and so I messed around with this a lot but it doesn't really look that good but you can kind of still get generally get the idea behind it so how do you use uh Ms booster and back pipe well all our code is open source uh minus a few things like Ms rer is uh is a little more close Source but a lot of our tools are very CL very open source and so you can see how we're doing everything you can provide uh your own commits to our repositories and can pull them if they're good uh it's very you know popular tool so Ms booster has been uh is packaged now with frag pipe and frag pipe has has been downloaded 47,000 times across all 21 versions um so we're always coming up with with improvements uh to the tools and yeah I mean we have a very active presence on GitHub always solving different issues people have uh addressing different feature requests so if you do end up using proteomic uh for your data analysis um and want to use frag pipe we can definitely help you out there and answer your questions or uh if you have like any like weird like chemicals that chemical tags that you're synthesizing F proteins um we can also help adapt our our pipeline for them uh that being said you know the brag pipe um gii uh has been very well popular it's been very popularly used however the command line version of MS booster is much less used uh I'm mostly the one who's using it um but there's a couple other people may be but if you're interested in using the command line version which has a lot more parameters for you to mess around with uh I actually just up updated the GitHub documentation today um so I have a lot more details about how you can do that uh and if you have any questions you can just contact me as well like I mentioned Ms booster and frag pipe very easy to use currently um in the current version all you can do is basically click a check box and say I want to run out this booster and then you can say I want to use RT features or Spectra features uh you can turn those on or off there's also this one called these correlated features which I'm not like a particular fan of but kind of addresses the point that we made before about you can have your PIN file now having both spectral entropy and po similarity and all these correlated features uh it's not super helpful but I mean maybe you can you know di around with it and maybe there's a use case for it if you want to use Ms booster VI the command line uh well supported on Windows or Linux and you want to run it it's a Java based tool so you can just do Java jar provide a path to the jar file for booster and then you have this parameter list um and this is where you provide all your parameters uh at the at the very minimum all you need to provide is the location of your Dian executable file for the prediction model you provided the path to your mcml directory that has your mass data and then you can give it the pin p XML directory directory which is where all your PIN files are as well uh but there's other parameters that are also accepted and our document on GitHub and for future directions uh well I I've spent the last year and a half really just um thinking of more and more really cool ideas and I'm presenting at these conferences and not publishing yet because I'm very lazy about writing uh but I have all these things on the docky here I think will be super helpful to people so one idea is that you can use these models that predict non YB fragments because everything I've talked up to this point about is only predicting YB but there's also different fragmentation modes that you might be interested in uh also in the case of H peptides you get a lot of these internal fragments where you get fragmentation both on the left and right hand side so you give these like internal sequences uh but those aren't predicted by Prime models and so I'm going to incorporate some of those uh to help improve rescoring again uh if you want to set up your own local Co server you can do that with a Docker image uh that the qu team provided uh this might be nice if you want more privacy for your data uh if you have lab specific models that you're training you want to post on your own server and you can do that uh and then finally you have transfer learning with alha prep de and transfer learning I know some of you are familiar with but it's this idea of if you want to specialize your model for your own use case so we already have this basine Alpha pepd model which is really powerful uh but if for example you want to train like a fos relation specific model and Alpha pepd is not doing as well as that as well on the data set well now I can just give the model maybe like a few thousand psms that have your data that have your fos relation peptides in it and then it can learn those specific phosphopeptide patterns and then just by using a small subset of your data you can train a very TP model for your specific use case so truly I'm just envisioning Ms booster to be kind of like this playground we can mess around with models and see like what works for you and then help you train new models uh so this is kind of what I'm going to be implementing in the next year or so uh so be on the look out for that and yeah just see all the cool features I'll be adding yeah so here's my contact information if you want to get in touch with me uh we have a lab page along with the frag pipe page that will link you to GitHub uh if you want to use the QR codes you can go to frag pipe we can read my manuscript um and yeah there's some pictures of our lab we don't actually have any current photos that have everybody in there the lab is currently changing a lot like Jenny you're in the lab you're not in these pictures um but yeah we're all really fun people we're all very helpful uh and again we're always excited to work with new collaborators and answer questions um so if you want to reach out to us and talk about your specific use case or anything uh yeah please reach out to us any questions if you're online you have a question you can put it in the Q&A box any questions in the room Yeah you mentioned the DN model to start was closed you just used it as is and then you said you switch to these open models um and then you talked about fine-tuning your specific set but I missed at some point like um how how how specific are these models for the specific application like what what are they trained for and is there a mismatch between what they're trained for and your application what Diana is trained for or just generally I mean like the newer ones that oh yeah um so they try to be uh as diverse as possible and a lot of are publishing their training data sets along with it so they will uh I mean the really cool use case I think is the pra team because they have this wet lab that generates a lot of synthetic peptides like millions of them and those are all available online and those span a wide range of uh normaliz Collision energies they stay on different instruments um they have both tryptic data sets non triptic data sets a lot of ptms that they're looking at specifically like they synthesiz 21 different ptms um and so the idea is that uh there as generalizable as POS um so hopefully they they like know is and know what the Spectra is and they're trying to the pep from the SP exactly yeah okay yeah um so that data set is is really available but there's also this idea that sometimes when you put in like so many different uh like PTM for example model it like starts to like forget about the other PTM patterns right uh so I'm I'm more an advocate for having more specialized models when you have them available um but because there's like so many things train on is possible to cover all of them and so I think for most these cases um and we like not all ptms actually change your Spectra or to find that much I think the generalizable model that they have is actually quite good um and I'll be showing that in the manuscript as well um at least for HLA and nonic they per very well because they have huge data sets for that any other questions thank one more time thank you everyone for coming and