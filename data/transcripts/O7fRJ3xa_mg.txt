all right so um hi everyone I'm Mii I'm Kimi so we are co-chairing the seminar committee this Academic Year and we're happy to U welcome you to the first of the Series this year we have a um very nice lineup of speakers ranging from uh mathematics statistics engineering and computational biology being applied to a wide range of biological systems like cancer and Immunology Etc um so um please uh I want you want to see participation from students you can have lunch with speakers and ask lots of questions during seminar series um so we'll hand it over to Inda Roger P to introduce your first speaker thank you thank you Mii thank you thank you thanks all for coming and it's my great pleasure to introduce uh Professor Mason Porter and Mason is a professor in the Department of Mathematics at UCLA and previously he was professor at Nini and complex systems at Oxford University university of Oxford M has so many papers if you can check it out like almost like 250 now good CL and uh and Mason is from Los Angeles from LA and he he got his undergraduate at Caltech and then PhD at conell and uh I know Mas for a long time now but it's so I'm so happy you are here Mason and thanks for coming yeah thank you so much for inviting me I think we're gonna use this mic um but yeah so so Inda and I met when we met at the 2002 Dynamics days conference in January um when we were both graduate students both working on entirely different things than what we work on now of course um okay so thank you for having me and yeah so so yeah especially if students have questions post talks have questions and you want to um ask stff pleas please do um okay so I'm going to talk about topological data analysis of spatial systems and there'll be some different applications that arise but I I really want to kind of give the perspective of of this and kind of how we're thinking about these problems um and so I'm going to have a lot of a lot of focus will be on the sort of background in case this is something that you might be interested in in learning more about okay so a a a topic from so actually an interesting thing is I I actually gave a version of this talk I mean some slides were different but I actually I had a I gave a one-hour math talk at the world science fiction convention um a month ago I'm serious so I actually modified this talk from the ones for the science fiction audience and and and one of the things that was really cool from that is that there were literal parallel sessions during mine about time travel right that was actually literally true okay anyway so so um I I hope that some of those slides I was giving to that General audience would also apply here and then we'll see how it goes so anyway some mathematical underpinnings so the subject of topology ology gives some of the mathematical underpinnings of of some of these methodologies and if you look at Wikipedia and this was from a month ago when I Was preparing this slide so I can't promise that this heex has changed but this is what Wikipedia had to say and so it's concerned with certain properties and you're allowed to do some stuff to the space that you're in or the object so you can squish it you can twist it you can crumble it you can Bendle it bend it but what you cannot do you can't you can't tear it and you can't glue things together okay so there's certain things that you're allowed to do and certain things that you're not allowed to do and we care about things and and this will come up later in slides that we call invariance what stuff changes in particular what stuff does not change when you're allowed to do certain things okay so that's the type of thing that you're going to end up wanting to compute so a very classical one is donuts and coffee cups the picture on the left there's a video version of this so from um Henry segman and and Keenan crane these are sort of computation geometry sorts of folks you can actually buy this sequence of of of of things um in in various colors if you want to spend certain amounts of money to do it I I I I was curious enough to be tempted and then I got to my senses before actually paying a couple hundred dollars for these but you know um but a coffee cup can be transformed to a donut and and one of the things that that happens is that the number of objects stays the same it's always one object so that's one component and the number number of holes although eventually you have to start defining different types of holes but the number of holes stays the same and that's one so you can count the number of objects and say that there's one object and you can count the number of holes and say there's one hole and both the donut and the coffee cup satisfy this and so this is a deformation that I'm allowed to do and so a topologist you know can't tell the difference in that sense because the things that they're measuring are are giving them the same number for both okay so that's a sort of classical type of thing things can get a lot Messier like if you live at the border of Belgium and the Netherlands and everything that's in yellow um is in Belgium and everything that's in the Netherlands is is is in beige and you know as an exercise you can go there and and turn on your GPS and see what country it's in and your country will be like Belgium Netherlands Belgium Netherlands Belgium Netherlands and and and and so so you have this complicated structure and of course I'm showing you this one because an extreme example but the thing is when you're dealing say with geospatial data like if you're looking at something like say um spread of of covid over certain regions of New York City which is something that we have looked at I've actually took those slides out but there's a paper where we've looked at that you actually have to worry about the boundaries of different regions that are not trivial topologically and we literally have cases of theorems because of areas of New York City in that paper okay but any so so so this is an extreme example but if you're dealing with geospatial data you're not just having a you know bunch of blocks you have to actually deal with some complicated topology sometimes now a particular type of topology or or subfield of topology that shows up a lot in topological data analysis is known as algebraic topology so this is the Wikipedia entry as about a month ago and this is the one that's going to really be talking about invariance and so it gets things from algebra when I was talking about the number of of of of components the number number of pieces this is going to correspond to an algebraic object and have an its Dimension which has that number of pieces and the number of holes is going to correspond to an algebraic object that has that number of pieces and so this is where ideas from algebra are going to get combined now as it's common in applied math we don't need all of algebraic topology or all of like a graduate course in algebraic topology to do it because we're going to take chapter one of one of those books and get a lot of mileage out of it because that's what we often do in Applied Mathematics um and if you ask me about chapter two I'm going to tell you I have no idea how any of that stuff works because you know you learn what you need to learn okay um so again the key idea I said it verbally but you want to describe the properties of an object that stay the same you're allowed to do certain things you can stretch it or Shrink it or bend it but you can't glue and you can't tear and so we seek topological invariance what things can we count that don't change under the deformations that were allowed um and other people could do different things and allow different sets of De so you can have different types of invariant okay so there's number of components number of holes technically number of holes in different dimensions so for instance the hole that's shown here is not the same as a void inside a spherical shell right so I'd actually count those differently this is a one hole that would be a two-hole um so you worry about holes with different dimensionalities that's something that you do have to care about so the word hole has to get abstracted a bit um and we're going to be looking at what's called homological invariance which well homological is really saying number of holes and components are Zero Dimensional holes but there's other types of invariant as well um these types of invariant have known um properties of being able to compute them quickly and so that's one reason why this particular type of topological data analysis has expanded it's called persistent there's some Echo here okay okay sorry that was distracting um the the voice from The Ether above not liking what I just said um Okay so there are other types of invariants and one of the advances that is useful to do but is maybe there's less work on or there is less work on is trying to find good ways of computing other types of invariance so instead of just saying stretching or shrinking or whatever but some other thing you're allowed to do and getting good ways to do that okay so we want to do the data so what so so what I showed you was not Based on data it was based on sort of you know what would I see in intuitively in a textbook okay so we want to use those sorts of ideas that sort of perspective to say something about data and a long tradition so I might give you something like this um this is my spirit Pokemon um Jigglypuff technically IND technically indignant Jigglypuff is my spirit Pokemon but you know even whether or not you recognize this this character we're good at filling in these dots right we're good we see these dots and we're good at saying oh there're are eyes and there are ears and other things right humans are good at this what we want is to do something like this algorithmically and in particular you know we're going to get a data set where we don't know the answer in advance because if we could only solve problems where we know the answer in advance then well why would we bother doing this okay so this is one form data might take or might be an image or network or whatever and so we want to study the shape of data and I put shape in quotes top topologies about studying shapes of things we have to make sense what it means to do that right so this is what the sort of the key thing I'm trying to build up for today um and then I wanted to give some examples of what I do so algebraic methods to study the topology of data in some kind of systematic Manner and the data could be set of points in space that's what a point cloud is could be images could be networks could be could be videos although that gets that's going to get computationally intensive and the the type of of topological data analysis that is most common is known as persistent homology so homology has to do with counting holes and persistent which I have to explain what that is I mean the English word is going to be very very um I guess helpful for that but it has to do with with um features that exist over large sets of parameter values because you want to distinguish features from noise and so um this has algorithms that are fast enough to do this reasonably in certain cases although fast is a subjective word that depends on the field um and there are formalisms for doing this okay so this is kind of where we're going there are various applications um for partly accidental reasons there's been a lot of applications of TDA in neuroscience and there's been enough that there are actually multiple review articles of TDA specifically in Neuroscience um there's been work on things like vascular networks um little bit of stuff on spreading processes there's been a bunch of work on networks in general there's been a bunch of work on granular materials my one of my favorite types of materials because it lets me have this this is coffee okay um resource coverage which is an example I'll give you a little bit of spend a little bit of time on um detecting political Islands give you a little bit of time on spend a little time on that structure of city streets and so on so it's been a bunch of stuff okay some references I know this slide's a little bit text heavy but in case people are interested in this um a few of us wrote an article in physics today so this is geared towards undergraduate physicists about the topology of data so um you could take a look at that if if you're if you're interested um if you want a more complicated um introduction that is also in this case written for physicist um gunar Carlson who's one of the well-known kind of giants of the field um wrote something for nature reviews physics a few years ago um this paper by Anne seore at all is one of the examples of a review article on network on doing TDA for Neuroscience there's a couple other ones I purposely wrote this one down because this is the one that I like the best of those um if you want to get started in terms of actually even installing software and just doing persistent homology for the for the first time Nina otter and I and various other co-authors um wrote a paper to do that and that is literally meant for people who are I am now going to do this for the first time what should I do and what comparisons are there are out there so if you actually want to try doing it then this this last one is hopefully a helpful place to start um and then um I'm happy to post slides and and all that so so don't worry about if if if if you miss a slide now I'm I'm happy to do that okay so one example of resource coverage is if you know tired after a long day and want to get something to drink maybe you want a pub nearby so so this is an example that was in a in a paper that was actually a review article prospective piece of doing TDA for geospatial Sciences for geographic information sciences and they had this example that I wish I thought of um of okay let's do pubs as resource coverage so that's one of the examples in their paper and this is just pictures here so so so you know Manchester seems to be doing much better than Cardiff at least visually I don't know if that's what happens Ma atically um okay this is one from um uh well a former Master student who I co- mentored who just started her faculty position I forgot where in Germany last week so she got her PhD with Heather Harrington so this is bernardet stalt end company who's done a bunch of work on various types of vascular networks and applications of tumors um and so you could look up some of some of her stuff this is this is just a pipeline picture from one of her papers and my goal here is just to sort of illustrate stuff that people have done I'm not going to be able to you know I'm not going to be able to explain this figure in any reasonable way as far as my own knowledge is concerned but this is just to see some example of stuff they've done if you want to look it up um granular materials I have spent some time on this picture um is from quasi 2D um photo refractive discs um there are two sizes though it may be hard to see and they get these things called granular Force chains which are um The Brighter ones means there's more forces and you you think you you care about things like what are the sizes of the the different size distributions of stuff in between and so on and because things like contacts are so important both Network methods and topological methods have been very useful for it um there's a review article that I that I co-authored with various others on doing network analysis and there are sections in there on doing topological data analysis so if you're interested in these sorts of approaches on that family of problems there's a specific section of of our review article that you could you could you could start from um and there are a number of people who have been doing um um TDA on Gran materials and that's actually part of how I got into this in the first place I have not done TDN Gran materials but there was a sort of collaboration that started from that commonality of looking at Gran materials um this is a paper from Dane Taylor at all that I'm also involved in on spreading processes on networks where we took um we took a model from Network science known as the watch threshold model um and we're looking we were trying to look at when did um when did something go around this this this this this circle and when did something jump and so we were trying to in our way if we found the circle topology and some data analysis we did that was an indication that more things were going around a circle um so this is again I'm just showing this to give an example of types of things that we have thought about um one of them um another well I'll be talking about a different part of this particular paper later today but one thing that we that a couple of us that my former student Michelle fun and I looked at this with City street networks and we did a bit of a classification and you can ask if this classification of what the streets look like gives you something that sort of complement um or is consistent with other ways of looking at city street classifications um so Los Angeles is a bit boring here this is Center two maybe two kilometers by two kilometers but some of them are interrupted grids and others are not grid-like sometimes because there's just very sparse and other times because weird stuff is going on um these things on the botom I haven't explained yet and I will explain those so don't worry about them right now but just the idea is to say I have I get some object from this topological analysis for each City technically a 2 kilometer by 2 kilometer Center of each City and so then I can cluster different ones together and I can say from this approach which city streets are similar and which are not and compare it to other approaches and see how we do right so so this using as a classification problem okay so that was to give an idea of various things that I and others have thought about but now let's let's let's kind of go back back up a little bit and and and and do a little bit more math I'll try to be friendly about it I think I'm friendly about it okay so I've shown you this picture before we squinted this what does it look like okay well this was something that we created from this figure right um we're not going to do things like the colors but there's a key similarity and so um you can look at this so this this picture by the way um we wrote a paper on TD a for teens and pre-teens and we publish it in Frontiers for young minds so if you have if you have um a child who is in high school and wants to learn about TDA this is the paper to send them but there are parts of it that are also helpful for broader audiences this was a very challenging paper to write I have to say because I you know usually you assume linear algebra and obviously you're not going to be able to assume that okay so panel a is the panel I showed you earlier and what we do is that we take each of those dots now a point Cloud literally would have Zero Dimensional dots but to draw draw it we have to have some finite radius and we we take the dots at the same point and we increase the radius so B has larger radius than a and C in turn has larger radius and D in turn has larger radius and so on and what you see visually is that first the structures start getting more coherent and then eventually they start getting less coherent right eventually it's one blob so the number of holes is changing 1D holes and the number of pieces is changing now the number of pieces always goes down or well goes down or stays the same the number of holes goes up and then goes down okay um and what you're able to do in terms of making sense of the topology of data is that I can take object a and I can count the number of pieces and holes so I can measure the topology of a and I can take object B and independently count the number of pieces of and pieces and number of holes piece and component of the Same by the way a b and I can continue doing this for each for each one of these um and I want features that are persistent in the sense of for lots of values of the radius of this dot that's going to be called a filtration parameter for lots of values of this radius I have the feature persisting it is there for many things but so to make sense of topology of data I have to fix this radius or fix some other parameter and measure the topology and that's how you go from data to something that's continuous and then the persistence is that there are certain ma mathematical guarantees of what you're allowed to do in certain scenarios and when people do Forefront stuff on some methodologies is that they have lost that guarantee for some reason yes please well so the notion of continuity just means I have a space in which I'm allowed to do stuff and so so it just says within a given piece it's continuous but I'm counting the number of pieces thank you for the question it's just that um so the reason I was making the comment about continuous so maybe maybe I should say something to make to try to to make sure I'm clear on that is that if I have a doughnut in a coffee cup I mean I sort of doing classical topology and I have to have if I just have a data set it'd be like what does it mean to have a hole in a data set and what I'm trying to do is answer the question of what does it even mean to have a whole on a data set and that's why I have the sequence of stuff so that was why I made my prior comments now I'm glad you asked the question though because it makes me feel like I was not as clear as what I should have been in terms of how I phrased it okay so this is a of the table the number of components number of pieces is H knot this is Zero Dimensional holes it's what are called Betty numbers we didn't use the term Betty numbers in the paper of course or in this paper and H1 1D holes and so this is just a counting of the number of pieces so this is the same figures as before with The Blob doing that um and then so we do some count and the pieces has to go down cannot go up by construction and the number of holes starts at zero but you know humans are good at this this two the two is actually may not be the two i's depending on what's actually connected six and so on right and then by the time you get to a blob okay something was there before but if I only give you that blob who knows okay so we want algorithmic methods to study potentially High dimensional data this was not high dimensional in a quantitative manner the data can come from point clouds which is what happens here networks images could come from time series there are people who do this for different types of Time series analysis and so the shape of data is this counting of pieces and holes and higher dimensional holes as you change some parameter and so persistent homology is the type of TDA that does that and this is for a certain type of invariant which counts holes there are other types of TDA that use different invariants and those are less developed partly because there are some mathematical guarantees that are that are here but not there or at least not there yet and algorithms are there are known faster algorithms for for this type of invariance so there are people who do like homotopy which is deforming of Curves for instance and try to do a version of analysis with deforming of Curves right so so there there do exist other things but when most people say topological data analysis they are probably doing persistent homology okay so I'm doing a little bit of a backup um so I need the notion of simplicial complex um I did actually still show this slide to the science fiction crowd I was still okay um a k Simplex is a k dimensional poope that's a convex hole of its K plus1 vertices so I might have a point an edge a triangle a tetrahedron and so on okay so those are things I care about the faces will be of whatever Dimension so the tetrahedron of course has faces that are triangles but its edges are also faces it's just that those are lower dimensional faces okay so I'm going to actually put the M on the faces because I care about all the lower dimensional ones as well um a simpal complex is going to be a set of these things that satisfies two rules that I need and one is a downward closure rule um that every face of a Simplex of s is of a Simplex is also in my complex so if my tetrahedron is in my complex this triangle has to also be in my complex is what that is saying and then a non-empty intersection has to be a face of both and so what that means and I I'll I'll I'll I mean okay what that means is that I cannot have two edges that are partly overlapping they can completely overlap or they can intersect at a point or they cannot intersect they cannot partly overlap that's what's not allowed so this is a picture from Wikipedia that shows up in a lot of these talks and some papers of a simplicial complex and so here these edges are are overlapping but if I shifted this triangle it would not be allowed okay so I can build these things together and this is something of what it might look like and when we are changing one of these parameters the idea is that this particular object a simpal complex will change as a function of well we had Epsilon which is I didn't call it Epsilon before okay it's Epsilon now the radius of of the dots right or a function of something else and when when we're developing some methods and and and and for for a problem that we're interested in it might not literally be the radius of a DOT that's changing it might be something else that's changing but as a function of some parameter that you're controlling this simplical complex is changing and so the set of things that you're studying is a set of all of these at once okay persistent hology so use ideas from algebraic topology from chapter one of algebraic topology U to analyze data okay um I actually did show this slide at the science fiction Convention as well but I I told them not to worry too much um so the concept that we have of having the collection of all of these is known as a filtered simpal complex times just called a filtration so the radius of these dots would be called a filtration parameter and this is a sequence so s notot would be the set of dots actually with zero radius and um SN would be the blob and these all would be the ones in between and so we think of each of these as looking at a data set at a different scale so the dots increasing in radius in our example and we ask a question of which structures exist so s notot is I measure the top of s I measure the topology of S1 I measure the topology of S2 so I I therefore count the number of holes and pieces and whatever of S1 count the number of holes and pieces and whatever of S2 and I ask which ones persist and not just the counting but in principle also the actual holes so there can be some trickiness there okay so we want things that exist across a range of values because probably I cannot justify a specific value of Epsilon as being the right value and so I want a lot of values over which they exist to hopefully find a feature of the of the data rather than noise um huh that's odd okay well that was not left intentionally blank I'm not sure what's happening there that's really weird all right I don't know what happened there anyway um so this is a picture of what we're doing um so the K's here or the S is from before this this um um slide comes from from one of my former students from Abby Hickok so we have k r not so we think of these as the dots of a certain radius and we have this um this nestedness the nestedness what the nestedness means is that the the simplicial complex KR not is contained in the simpal complex this one so I so so I'm required to have this nestedness property that's actually one of the things that gives me a guarantee that allows me to do certain things and some of the generalizations that people study so if I have something that is both growing and shrinking I have to I I lose some mathematical guarantees and have to work harder at certain things okay so there's this nestedness in here that's actually important for what we do so we have the dots we have the radi around the dots and we look at Whenever two pairs so I have here I have two pairs of dots where the circles overlap so I draw an edge between them here I have three dots where all them mutually overlap so I draw a triangle I increase the radius further I have four things where all the dots overlap and so I have a tetrahedron okay so you look at how many mutually overlap and that's how you go from the The Blob with the dots around it or the point cloud with the dots around it to a simpal complex okay and and this simpal complex here is a subset of the one here and that is by construction that has to be true okay does that make sense okay so what we did actually has a name and the name is the vator rips filtration um and so This this term also does not show up in the paper for teens and preens but this is what we did we fixed a radius and for each point in the point Cloud we had a center we centered a ball of that radius on it and so K plus one of these balls overlapping pair wise would mean that we construct a k simplex and then the resulting collection of them is this whole object so this thing here is one object um and then we increment Epsilon and do steps again now I say increment Epsilon I may have to worry about how much I increment Epsilon right that's some choice that I might have to make and have to worry about um but we do this and once we get a giant blob we stop in this example okay so I didn't use these words before but I use things like them and these are things that we care about and this is the birth and death of features yes please that is possible so this is a good question so yeah let me let me comment on that there's actually something called the check filtration in which I take in which I track that and then combinatorially will then lead to very um expensive computations and so this one here this particular choice of only doing pairwise is exactly an approximation that can get that one wrong there are some nestedness theorems something um that that actually guarantee that if I increase the value of Epsilon I have um it will be one type of filtration with a certain value of Epsilon kind of sandwiched by another so there's some theoretical guarantees that will say this will only get things wrong by a certain amount but this is an approximation that is specifically made because computationally not doing it will run into trouble quickly but yes that is correct um but so check filtration is the one where you don't make that approximation via taist RPS filtration is the one where you do make that approximation okay um so the birth and death of features um so the int the the the terminology is fairly intuitive which is good math does not always succeed in that when it chooses terminology a feature is born at a certain resolution certain value of Epsilon in this example if it is the smallest value where it exists so a whole suddenly exists it was born there a feature dies if it's the largest value in which a feature exists I know it's very professional to munch a cookie into the microphone when you give your a talk um I'm known for my professionalism as people who know me know um some features live forever so there are ways of saying I track things as long as I could the feature didn't die yet that does happen in practice one does have to worry about that um and then there's various ways to summarize it I'm going to show two just because those show up in a couple of different um things that I did um but there's others as well um this one's called a barcode so you have a barcode for each Dimension so this is the barcode for number of components this is the barcode for number of pieces and we are tracking when things are born and when they die um Epsilon I think here actually might mean something else but we're tracking some parameter so analogous to the radius of those of those dots and so each feature was born at a certain point and dies at a certain point and it's called a barcode because of its resemblance to barcodes and Visually longer features are more persistent and the sort of Hope though there's some caveats to this is that longer features are the ones that should be actual features of your data and shorter featur should be noise there's actually strong caveats to that um another one that we've used more recently or sorry more frequently in subsequent papers I think um uh persistence diagrams so you have the birth on the horizontal axis the death on the vertical axis there was one slide earlier where I showed this but said I was going to explain it later so the hor the the the the the the diagonal line diagonal is the word I want would say that something's born and dies at the same time um so these pink circles are saying I was this one says I was born at one and I died at two I suppose it was and so everything all the pieces were born at the same time in this imaginary example but the holes were born at different times and they die at certain times as well so the way this is plotted you cannot have anything below the the um below the diagonal line that is a choice there are versions of this that that have that different ly um this top vertical line those are the features that live forever so it says I've only tracked up to whatever time and this feature has not died yet so I'm just going to put it here and say it's liveed forever okay um persistence diagrams um there is a notion of a distance between different persistence diagrams and it's a little more convenient than for barcodes um so I'm just going to state that and not not go into the math and I'd have to probably look it up to make sure I remind myself to do the math correctly anyway but if I have persist diagrams as an output of something so there's both a persistance diagram for pieces and for holes or for higher dimensional ones if you're tracking them you can then put those into clustering algorithms and this is what we did with the cities that because we're allowed to measure a distance between dist different persistence diagrams we now have a distance Matrix and can cluster it in whatever way we want as like a good Network scientist I turn everything into a community detection problem um okay so I want to give a little bit of a couple examp just to some stuff I've thought about um but my main focus was the sort of approach you know because there's different problems people studying those might be interesting so one of them was published a few years ago now and we were trying to look at political Islands so islands of red and a sea of blue or light blue voors and see of dark blue and we are good at doing that um as humans but we want an algorithm to do it and one of the things that arises is that the the the constructions that I showed you were very heavily dependent on distance but if you look at different precincts so this is Precinct level data that the LA Times um collected for a project a few years ago um the number the number of papers that I've gotten on topics related to the 2016 election makes me feel like an ambulance Chaser in terms of what happened and then I wrote stuff so so anyway um but this is large and I'm not trying to detect how large this is I really care about who voted for whom um so in this case darker blue is more Clinton and and darker red that looks orange for accidental reasons is more Trump um and and and so I don't care though that this is geographically large this this one piece I care about the relative numbers of people who voted right and and I had a construction that used distance and so that actually would be a problem here okay so Precinct level voting data um let me just since there's time is an issue I want to talk about other things too we constructed a couple different simplical complexes one of them was based on adjacencies and I believe that we used Queen adjacency if I remember correctly there's also Rook adjacency um and and so we said okay well if n plus1 nodes are all par wise adjacent then we're going to have an nlic so we don't care about the radius of a DOT now we're actually looking at some notion of network adjacency to construct things um and then given appropriate node data or Edge data we constructed filtration in the sense of I would keep I can say I can keep all of the precincts that voted at least 95% for for Clinton put dots there connect those and then could keep all the precincts that voted at least 90% for Clinton so now I have a super set of that and connect all those okay so we gradually loosen how much of of a of a lead we demand and that's how we do our filtration and so the percentage that voted for a certain candidate is playing the role of the radius of the dots in the prior example okay so that's how we did that and and we had another construction that we also used and um since I'm a UCLA um in the applied math group of course we've got to use the level set method at some point um Stan oer was down the hall so of course we had to use the level set method at some point and what we did is that we had the data in a surface form um format and we kind of had an initial condition and we evolved the level set equations and we looked at how that evolved and so our our our parameter that plays this role of Epsilon was actually time okay by the way this is a slide I did not show the science fiction people because you can see I'm getting a bit more technical here um but we we started things we actually had a manifold as an initial condition so we had a surface as initial condition evolved it in time and we saw what holes filled and when they filled okay I know I'm doing that a that too quickly to understand the details but hopefully I'm giving some of the intuition um the reason this works in terms of having a nestedness is this is a front propagation if I change this PD to something that did not have a strict propagation then I would I would lose this this nestedness that that I've said I've needed but have not told you why I needed um so you can do different constructions um Alpha is approx a further approximation to Via tourus rips and I have not told you how alpha Works um you do different constructions and you get different different um diagrams and you can ask which ones work better and here I'm just kind of showing you the fact that they're different um adjacency was the one that we thought would work better in terms of our intuition and how we constructed it the level set one was the one that actually worked better and what worked better means was getting the islands getting more of the islands having more more true positives and less false negatives basically so here we're getting Islands that are actually corresponding to Islands here we are actually getting some but imperfectly and here we're getting some but even less even less good and the distance the the the sort of physical distance here was getting in the way okay so I haven't explained it fully but I've given you hopefully some intuition okay we're not going to do this talk without doing spiders on drugs because can't do that um so this is another example from this 2020 paper by the way the 2021 paper actually comes before the 2020 paper but the publishing speed in applied math is slower than physics and so they're they came out in the published version in the reverse order but if you care about the methods of 20121 paper is the one that actually comes first it happens okay so um NASA is involved in this story um but the story goes back to 1940s and there's this swi pharmac Swiss pharmacologist Peter nwit whose friend did not like the fact that spiders were were spinning webs at 2 in the morning and waking him up I don't know why that would be loud but anyway that was part of the story and he told his friend hey you're a pharmacologist can you do something so so being a pharmacologist in the mid 20th century what did he do he gave drugs to animals and saw what happens um and and so there were different webs of different drugs given to spiders and just looking at the structure of the webs and then there's this Tech brief it's only like a two page Tech brief so you could read in a couple minutes um so in the Marshall space flight center studied the webs of SP ERS that were exposed to various chemicals and did some basic statistics and so on showed a couple pictures so some of these are images that come from Wht and some of them are images that come from NASA we have a couple others and I don't remember which is which so we only have seven of these things um I'm guessing though they do not actually say this in the tech brief that they maybe wanted to have something that you know non-private animals or so on is my guess or maybe they wanted to create Spider-Man I don't know um so you've got the drug-free one which is looks pretty good you've got caffeine spider Everyone likes caffeine spider and at this point I'm going to sit my coffee chair I will be spinning some strange spider webs later um the marijuana spider does okay speed spider I suppose does okay chlorohydrate runs into all sorts of trouble and in case you're wondering chlorohydrate is one of the things they put in sleeping pills I mean I'm not I'm not trying to give you a positive outlook on life with this with this with this thing okay so we're so we were like okay here these cool pictures these cool images image data is something that you're allowed to do let's let's have that as an input do the level set filtration so you start this initial condition in the empty spots and just fill it in and see what happens and you get some stuff that admittedly is a little bit hard to read but you get seven different persistence diagrams um and I am allowed to construct a distance between them so I can cluster them and I know normally you would not bother clustering seven things because that's not you know you really cluster many things like a couple hundred city streets which is also in that paper but this example is fun so the drug-free spider it's on its own if you um this is a dendrogram and speed and chlorohydrate caffeine over here and these are the three that looked not so good and marijana P and LSD are there okay so again you don't really classify seven things um and I should also say another example that we did in that paper and it's one where the method we have is not good enough because we're not picking up some of the stuff we need is classification of snowflakes we only use 12 images but but people who study snowflakes so Ken lre from Caltech is a good example of this they do care about classifying different types of snowflakes and finding different types of bifurcation diagrams you would need to change the construction from how we did it to do it well and what ends up happening and this is sort of our example that didn't work one in the paper just to illustrate there's more stuff to do with the methods the sixfold Symmetry was overriding everything else is what was happening so that one needs to somehow take that into account in designing the methods so you can but in principle you can use this on classification problems that people actually do but the spider example is fun and this is the one I always show in the talks because CA everyone loves caffeine spider um okay so I also want to talk about another one and this is from the final version of this particular paper um came out a month ago and this is on um resource coverage um so I showed an example with pubs so now you have a bunch of stuff that is somewhere on a map you do have to worry about things like city streets and travel time versus travel distance and so on um this project started as a class project I had a I had a special topics class on math and social systems where where the sort of requirement had to be somewhere in that intersection it could be pure math and doing proving theorems that are that are that are motivated by it or it could be um you know even advocacy stuff and and and so one of them eventually led to a paper that was published in final form a month ago um so let's see actually yeah now all the well all these people now either have jobs or have jobs waiting for them that was not even true a couple weeks ago so that's good um okay so naive approach versus pH approach and I mean pH is not the only non-naive approach I should make that clear but one of the things that is often done and there's actually some actual legislation that people have had that so so Joe Biden once um said okay everybody should be within five miles of a polling site to be able to vote um and and and and was suggesting that as a rule now there's actually a lot of problems with that because for one thing you know five miles five five miles here in an arbor is not the same as five miles in Los Angeles if you're talking about how long it takes to get there right so first of all distance is not the right thing that you should be measuring so the rule should not be based on distance that's number one number two um hopefully based on examples that I've shown just saying some arbitrary threshold D equals 5 is probably not the way you want to do this you want to look at what happens for different different values and see how things things move right so so not only should your distance be measured in a way that's appropriate but you should also have flexibility again this is pH is not the only way to do this but it is a type of approach that is built towards that perspective um I have what two minutes three minutes couple minutes okay um so five anyway so C so you might calculate the percentage of people that live within a certain distance having fixed the distance of whatever or calculate which locations are within a certain distance right but but there's there's distance and there's fixing so we can do all scales at once so that's that's a that's a nice feature of this and can identify entire zones that are not covered rather than doing pointwise which can sometimes be good especially if there's sort of demographic features of those zones um unsurprisingly if you look at the data there are um people of certain demographics who are systematically I think the technical word is screwed over um um I was going to sugarcoat it a little bit but I mean honestly that is what it is um okay um I I mean I'll be careful if I give this talk in Texas um okay so so let's measure distance in terms of time so I'm putting distance in quote so there's a couple types of distance there's distance it's literal Geographic distance and there's distance in a more mathematical sense it doesn't necessarily have to be the strictest version of it doesn't have to be a metric so I don't have to I don't have to satisfy every property of mathematical metric but I need something that is distance like and time is a good one for voting um and in particular there's two components that we we use of time um travel time and waiting time there is going to be a big issue of data that we can get and data that we can trust and how much that costs so that can be a big deal but we're going to say okay we are say somewhere living somewhere working somewhere we go to the polling site we wait in line possibly a long time we vote we go back right this is how much there's there and we also have to worry about things like different modes of transportation and this is going to be different across cities so it might be that in a certain zip code 70% of the people have cars so those people can use cars we assume and others don't so they might have to use bus or they might have to walk right okay so there's various Cho there's going to be various data cleaning and choices there that have all sorts of warts in them that one has to worry about this paper should be viewed as a proof of concept because we were willing to spend a few hundred dollars for data and the API if you re for Google if you really wanted re very rich finely grained detail would have been more like a few hundred thousand dollar okay so so Fidelity of data and data sources does creep in this very seriously um and we worrying about waiting time that wouldn't be true for all applications but it is true here what that means in the context of what I showed you remember I was showing balls of certain radi expanding if I have to wait an hour what I do at a certain place is I wait an hour and only after an hour do I expand the ball if at another place I'm waiting two hours I wait two hours and then I expand the ball so you have this amount of time that the ball is not expanding till the waiting time so this is known as a weighted vurus rips filtration so it's a modified version of the example that I first showed you um we use used some um so so our waiting times were at the level of congressional districts not individual precincts right so we assumed each PR was the same because this is the data that we were able to get this is not a correct assumption but this is the data we were able to get um and the the there's a certain Paper um that did this um and so we were using data from that paper um okay and to give we used we did six cities technically LA County was one of our cities um we were motivated initially by Atlanta um Stacy Abrams um was kind of doing was was was talking about about that back in the day and then the second City that we thought about was actually um New York City because of its public transportation so we felt it would probably be a lot better than than um than Atlanta so one particular figure in there is Atlanta versus Chicago and what we're showing is the death time on the horizontal axis so this is when either a connected component or a piece dies or when um a hole dies and so you should view a hole as um a political desert that has three polling sites involved and a piece as a political desert that has two polling sites involved and differently from many applications we care about the death time we don't actually do the length death minus birth which is common we care about when it dies because that says how long it took to vote okay so it's okay if I was born at 75 if I die at 90 it takes 90 to vote okay and so basically having Atlanta farther to the right here means that there are more areas in Atlanta that took longer okay so you don't want to be as far to the right all right um we are working on parks in Chicago one thing there that we're doing is called two parameter filtration because Parks can have different qualities and we now care about that we then lose some mathematical guarantees and so this property of the system is now motivating what we do mathematically but we don't have waiting times okay so this is there's a paper in progress on this and just I will show the concluding slid since I know I'm running short on time okay so topological data analysis can give insights into certain systems I would not say that there is a killer app in the sense of we're basically the way that I've been going about doing this saying here's a system that has some feature that where top topology seems like a reasonable way to do it what can I learn by doing that right so I'm not guaranteeing that you cannot look at the system some other way and all that but this is just the approach I've been taking we've been doing systems that live in low literal dimensions and that's allowed us to kind of get a little farther on certain comparisons and we've been doing spatial ones where we've been incorporating features of the system into our approach as opposed to just doing the standard methods the vurus rips is the standard one but we've been playing around with how we do these constructions and we've been doing that on purpose um and um yeah that's that's where I want to end so thank you so much yeah yeah yeah maybe yeah think you mentioned before that a lot of the um the quality of the data is really key because these um you might be doing community detection on a network that is assumed to be ful observed but sure I was wondering like you know is there a way to sort of turn this around and sort of you know if you have some you know persistent homology that turns out to be really interesting sort of using that as some sort of Pryer like in a generative context you know where you might be doing infilling or something like that okay um I'll comment a bit I don't know if that's hit the application so far but there are generative models for um for it would be generative models for simplicial complexes and there are ones that generalize various well-known um well-known models from Network so for instance there's something in networks called a configuration model and in turn there are configuration models for simplical complexes the work that I have seen with that has been at the level mostly of proving theorems for them so it's not even been mostly an applied math work it's been mostly theorem proof what I have not seen is those things subse subsequently used for say statistical inference so imagine if there were and there should be a way to construct it but I've not seen it a simpal complex analog of a stochastic block model that you then use for inference a block model I've never seen anybody take the step of using it for inference it's been more like let's study these random models for its own sake because these are people who come from Rand um kind of random topology right so there's been math papers that come up with generative models but I have not seen the inference step taken that is a worth while step I will say that most of those papers are not the easiest to read you know they're they're they're sort of written for people who already know certain mathematical language but I do agree with the I guess implied comment that one should be able to do a sort of generative and inferential thing from that approach I've just never seen it cool and just out of curiosity um I think you studied um like based on the like serious of fut like study that pieces and holes like when they're first time and death time minuts and how long they persist uh I'm just curious like whether um there could be more features or more complicated features than um pieces and holes and what that may um I guess like mean in the real world okay yeah so I can comment on that so if you're actually constructing these things those pieces certainly exist mathematically what happens is that each remember I was mentioning about fast algorithms the more higher dimensional pieces that I or High dimensional objects that I consider the um slower the algorithms take because they scale with a dimensionality there and that scaling will start getting bad um so I have seen people do the two-dimensional one those are known as like two-dimensional voids like like like a spherical shell I have seen people do that in some cases I would have to um I would have to look up which papers actually did that and so yes those are very relevant but you start coming you start getting into serious problems on computational complexity when you do that and and so I have actually purposely been concentrating on projects where I've learned stuff from the lower dimensional versions of that because that allowed me computationally to go farther but yeah you're absolutely correct yeah Mark I can always repeat the question if the mark doesn't land fast enough but actually an excuse for me to have a cookie um you mentioned that your distance measure doesn't need to be metric is it possible to have a non-metric space especially if it violates a triangle inequality that would break the nestedness of your simpl complexes right um so the stuff that I've done keeps it by construct the stuff that I've done keeps it by construction um you do need something that's distan like but you could for instance um do something asymmetric and have a Divergence for instance instead of a distance um but what you what what will not what will not satisfy the um triangle inequality is the distance Matrix you get of the PA wise distances so you still so so this won't break the nestedness but it breaks other things so so the reason I made the comment is that I don't literally have a metric space but I basically have I think mathematically would be called a pseudometric space or something but um the the type of thing that would trying to think if there's a way to okay so I think that we make choices that don't break that I'm trying to think of if somebody were not careful if it would break it I'm less sure about that answer to the question a thing that breaks the nestedness and there there are actually generalizations of these so zigzag persistence is the name of one generalization if I thought of a network that changes in time and I have edges coming in and like leaving and entering that's something that would break nestedness right whereas if I had a strictly growing Network I'm not going to break nestedness and a measure that I do later with distance that's distance like but not literally a metric doesn't doesn't because it's occurring later in the pipeline it's not causing those problems so I don't know if that's a complete answer to your question but maybe partial at least thank you very much thanks for coming it was really great to have you yeah thank you oh thanks