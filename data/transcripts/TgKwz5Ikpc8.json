[
    {
        "text": "I'd like to revisit a deceptively simple question ",
        "start": 16.88,
        "duration": 2.509
    },
    {
        "text": "that I asked in the very first video of this series.",
        "start": 19.389,
        "duration": 2.611
    },
    {
        "text": "What are vectors?",
        "start": 22.7,
        "duration": 0.86
    },
    {
        "text": "Is a two-dimensional vector, for example, fundamentally an arrow on ",
        "start": 24.48,
        "duration": 3.082
    },
    {
        "text": "a flat plane that we can describe with coordinates for convenience?",
        "start": 27.562,
        "duration": 3.038
    },
    {
        "text": "Or is it fundamentally that pair of real numbers which ",
        "start": 30.86,
        "duration": 3.461
    },
    {
        "text": "is just nicely visualized as an arrow on a flat plane?",
        "start": 34.321,
        "duration": 3.399
    },
    {
        "text": "Or are both of these just manifestations of something deeper?",
        "start": 38.48,
        "duration": 2.88
    },
    {
        "text": "On the one hand, defining vectors as primarily being ",
        "start": 42.3,
        "duration": 3.18
    },
    {
        "text": "a list of numbers feels clear-cut and unambiguous.",
        "start": 45.48,
        "duration": 3.0
    },
    {
        "text": "It makes things like four-dimensional vectors or 100-dimensional vectors sound like real, ",
        "start": 49.06,
        "duration": 4.375
    },
    {
        "text": "concrete ideas that you can actually work with.",
        "start": 53.435,
        "duration": 2.285
    },
    {
        "text": "When otherwise, an idea like four dimensions is just a vague geometric ",
        "start": 55.72,
        "duration": 4.055
    },
    {
        "text": "notion that's difficult to describe without waving your hands a bit.",
        "start": 59.775,
        "duration": 3.885
    },
    {
        "text": "But on the other hand, a common sensation for those who actually work with ",
        "start": 65.54,
        "duration": 3.707
    },
    {
        "text": "linear algebra, especially as you get more fluent with changing your basis, ",
        "start": 69.247,
        "duration": 3.756
    },
    {
        "text": "is that you're dealing with a space that exists independently from the ",
        "start": 73.003,
        "duration": 3.509
    },
    {
        "text": "coordinates that you give it, and that coordinates are actually somewhat arbitrary, ",
        "start": 76.512,
        "duration": 4.152
    },
    {
        "text": "depending on what you happen to choose as your basis vectors.",
        "start": 80.664,
        "duration": 3.016
    },
    {
        "text": "Core topics in linear algebra, like determinants and eigenvectors, ",
        "start": 84.48,
        "duration": 3.41
    },
    {
        "text": "seem indifferent to your choice of coordinate systems.",
        "start": 87.89,
        "duration": 2.75
    },
    {
        "text": "The determinant tells you how much a transformation scales areas, ",
        "start": 91.44,
        "duration": 3.514
    },
    {
        "text": "and eigenvectors are the ones that stay on their own span during a transformation.",
        "start": 94.954,
        "duration": 4.366
    },
    {
        "text": "But both of these properties are inherently spatial, ",
        "start": 100.0,
        "duration": 2.851
    },
    {
        "text": "and you can freely change your coordinate system without changing the underlying ",
        "start": 102.851,
        "duration": 4.359
    },
    {
        "text": "values of either one.",
        "start": 107.21,
        "duration": 1.13
    },
    {
        "text": "But if vectors are not fundamentally lists of real numbers, ",
        "start": 110.76,
        "duration": 3.214
    },
    {
        "text": "and if their underlying essence is something more spatial, ",
        "start": 113.974,
        "duration": 3.161
    },
    {
        "text": "that just begs the question of what mathematicians mean when they use a ",
        "start": 117.135,
        "duration": 3.858
    },
    {
        "text": "word like space or spatial.",
        "start": 120.993,
        "duration": 1.447
    },
    {
        "text": "To build up to where this is going, I'd actually like to spend the ",
        "start": 123.4,
        "duration": 3.17
    },
    {
        "text": "bulk of this video talking about something which is neither an arrow ",
        "start": 126.57,
        "duration": 3.265
    },
    {
        "text": "nor a list of numbers, but also has vector-ish qualities \u2013 functions.",
        "start": 129.835,
        "duration": 3.265
    },
    {
        "text": "You see, there's a sense in which functions are actually just another type of vector.",
        "start": 133.74,
        "duration": 4.14
    },
    {
        "text": "In the same way that you can add two vectors together, ",
        "start": 139.76,
        "duration": 2.832
    },
    {
        "text": "there's also a sensible notion for adding two functions, f and g, ",
        "start": 142.592,
        "duration": 3.399
    },
    {
        "text": "to get a new function, f plus g.",
        "start": 145.991,
        "duration": 1.649
    },
    {
        "text": "It's one of those things where you kind of already know what it's going to be, ",
        "start": 148.2,
        "duration": 3.307
    },
    {
        "text": "but actually phrasing it is a mouthful.",
        "start": 151.507,
        "duration": 1.633
    },
    {
        "text": "The output of this new function at any given input, like negative four, ",
        "start": 153.96,
        "duration": 4.446
    },
    {
        "text": "is the sum of the outputs of f and g when you evaluate them each at that same input, ",
        "start": 158.406,
        "duration": 5.249
    },
    {
        "text": "negative four.",
        "start": 163.655,
        "duration": 0.865
    },
    {
        "text": "Or more generally, the value of the sum function at any ",
        "start": 165.42,
        "duration": 4.087
    },
    {
        "text": "given input x is the sum of the values f of x plus g of x.",
        "start": 169.507,
        "duration": 4.233
    },
    {
        "text": "This is pretty similar to adding vectors coordinate by coordinate, ",
        "start": 180.7,
        "duration": 3.579
    },
    {
        "text": "it's just that there are, in a sense, infinitely many coordinates to deal with.",
        "start": 184.279,
        "duration": 4.221
    },
    {
        "text": "Similarly, there's a sensible notion for scaling a function by a real number, ",
        "start": 191.1,
        "duration": 4.489
    },
    {
        "text": "just scale all of the outputs by that number.",
        "start": 195.589,
        "duration": 2.591
    },
    {
        "text": "And again, this is analogous to scaling a vector coordinate by coordinate, ",
        "start": 200.24,
        "duration": 3.45
    },
    {
        "text": "it just feels like there's infinitely many coordinates.",
        "start": 203.69,
        "duration": 2.53
    },
    {
        "text": "Now, given that the only thing vectors can really do is get added together or scaled, ",
        "start": 208.9,
        "duration": 4.646
    },
    {
        "text": "it feels like we should be able to take the same useful constructs and problem ",
        "start": 213.546,
        "duration": 4.268
    },
    {
        "text": "solving techniques of linear algebra that were originally thought about in ",
        "start": 217.814,
        "duration": 4.052
    },
    {
        "text": "the context of arrows and space and apply them to functions as well.",
        "start": 221.866,
        "duration": 3.674
    },
    {
        "text": "For example, there's a perfectly reasonable notion of a linear transformation ",
        "start": 226.54,
        "duration": 4.53
    },
    {
        "text": "for functions, something that takes in one function and turns it into another.",
        "start": 231.07,
        "duration": 4.53
    },
    {
        "text": "One familiar example comes from calculus, the derivative.",
        "start": 239.82,
        "duration": 2.96
    },
    {
        "text": "It's something which transforms one function into another function.",
        "start": 243.42,
        "duration": 3.72
    },
    {
        "text": "Sometimes in this context you'll hear these called operators instead of transformations, ",
        "start": 248.72,
        "duration": 4.001
    },
    {
        "text": "but the meaning is the same.",
        "start": 252.721,
        "duration": 1.259
    },
    {
        "text": "A natural question you might want to ask is what it ",
        "start": 256.24,
        "duration": 2.624
    },
    {
        "text": "means for a transformation of functions to be linear.",
        "start": 258.864,
        "duration": 2.676
    },
    {
        "text": "The formal definition of linearity is relatively abstract and symbolically driven ",
        "start": 262.44,
        "duration": 4.125
    },
    {
        "text": "compared to the way that I first talked about it in chapter 3 of this series.",
        "start": 266.565,
        "duration": 3.875
    },
    {
        "text": "But the reward of abstractness is that we'll get something ",
        "start": 270.44,
        "duration": 3.312
    },
    {
        "text": "general enough to apply to functions as well as arrows.",
        "start": 273.752,
        "duration": 3.088
    },
    {
        "text": "A transformation is linear if it satisfies two properties, ",
        "start": 279.18,
        "duration": 3.503
    },
    {
        "text": "commonly called additivity and scaling.",
        "start": 282.683,
        "duration": 2.317
    },
    {
        "text": "Additivity means that if you add two vectors, v and w, ",
        "start": 286.04,
        "duration": 4.514
    },
    {
        "text": "then apply a transformation to their sum, you get the same result as if you added the ",
        "start": 290.554,
        "duration": 7.059
    },
    {
        "text": "transformed versions of v and w.",
        "start": 297.613,
        "duration": 2.627
    },
    {
        "text": "The scaling property is that when you scale a vector v by some number, ",
        "start": 304.52,
        "duration": 5.086
    },
    {
        "text": "then apply the transformation, you get the same ultimate vector as ",
        "start": 309.606,
        "duration": 4.8
    },
    {
        "text": "if you scaled the transformed version of v by that same amount.",
        "start": 314.406,
        "duration": 4.514
    },
    {
        "text": "The way you'll often hear this described is that linear transformations ",
        "start": 321.7,
        "duration": 3.778
    },
    {
        "text": "preserve the operations of vector addition and scalar multiplication.",
        "start": 325.478,
        "duration": 3.622
    },
    {
        "text": "The idea of gridlines remaining parallel and evenly spaced that I've ",
        "start": 332.2,
        "duration": 3.971
    },
    {
        "text": "talked about in past videos is really just an illustration of what ",
        "start": 336.171,
        "duration": 3.857
    },
    {
        "text": "these two properties mean in the specific case of points in 2D space.",
        "start": 340.028,
        "duration": 3.972
    },
    {
        "text": "One of the most important consequences of these properties, ",
        "start": 344.88,
        "duration": 3.286
    },
    {
        "text": "which makes matrix vector multiplication possible, ",
        "start": 348.166,
        "duration": 2.794
    },
    {
        "text": "is that a linear transformation is completely described by where it ",
        "start": 350.96,
        "duration": 3.725
    },
    {
        "text": "takes the basis vectors.",
        "start": 354.685,
        "duration": 1.315
    },
    {
        "text": "Since any vector can be expressed by scaling and adding the basis vectors in some way, ",
        "start": 357.72,
        "duration": 4.875
    },
    {
        "text": "finding the transformed version of a vector comes down to scaling and adding ",
        "start": 362.595,
        "duration": 4.314
    },
    {
        "text": "the transformed versions of the basis vectors in that same way.",
        "start": 366.909,
        "duration": 3.531
    },
    {
        "text": "As you'll see in just a moment, this is as true for functions as it is for arrows.",
        "start": 372.28,
        "duration": 4.5
    },
    {
        "text": "For example, calculus students are always using the fact that the derivative is ",
        "start": 378.36,
        "duration": 4.077
    },
    {
        "text": "additive and has the scaling property, even if they haven't heard it phrased that way.",
        "start": 382.437,
        "duration": 4.383
    },
    {
        "text": "If you add two functions, then take the derivative, ",
        "start": 388.14,
        "duration": 3.047
    },
    {
        "text": "it's the same as first taking the derivative of each one separately, ",
        "start": 391.187,
        "duration": 4.044
    },
    {
        "text": "then adding the result.",
        "start": 395.231,
        "duration": 1.349
    },
    {
        "text": "Similarly, if you scale a function, then take the derivative, ",
        "start": 400.14,
        "duration": 3.165
    },
    {
        "text": "it's the same as first taking the derivative, then scaling the result.",
        "start": 403.305,
        "duration": 3.575
    },
    {
        "text": "To really drill in the parallel, let's see what it ",
        "start": 410.28,
        "duration": 2.757
    },
    {
        "text": "might look like to describe the derivative with a matrix.",
        "start": 413.037,
        "duration": 3.083
    },
    {
        "text": "This will be a little tricky, since function spaces have a tendency to be ",
        "start": 416.98,
        "duration": 3.352
    },
    {
        "text": "infinite dimensional, but I think this exercise is actually quite satisfying.",
        "start": 420.332,
        "duration": 3.488
    },
    {
        "text": "Let's limit ourselves to polynomials, things like x squared plus 3x plus 5, ",
        "start": 424.84,
        "duration": 4.68
    },
    {
        "text": "or 4x to the seventh minus 5x squared.",
        "start": 429.52,
        "duration": 2.34
    },
    {
        "text": "Each of the polynomials in our space will only have finitely many terms, ",
        "start": 432.33,
        "duration": 4.109
    },
    {
        "text": "but the full space is going to include polynomials with arbitrarily large degree.",
        "start": 436.439,
        "duration": 4.561
    },
    {
        "text": "The first thing we need to do is give coordinates to this space, ",
        "start": 442.22,
        "duration": 3.377
    },
    {
        "text": "which requires choosing a basis.",
        "start": 445.597,
        "duration": 1.663
    },
    {
        "text": "Since polynomials are already written down as the sum of scaled powers of the variable x, ",
        "start": 448.18,
        "duration": 5.213
    },
    {
        "text": "it's pretty natural to just choose pure powers of x as the basis function.",
        "start": 453.393,
        "duration": 4.287
    },
    {
        "text": "In other words, our first basis function will be the constant function, b0 of x equals 1.",
        "start": 458.28,
        "duration": 5.42
    },
    {
        "text": "The second basis function will be b1 of x equals x, ",
        "start": 464.18,
        "duration": 3.895
    },
    {
        "text": "then b2 of x equals x squared, then b3 of x equals x cubed, and so on.",
        "start": 468.075,
        "duration": 5.245
    },
    {
        "text": "The role that these basis functions serve will be similar to the roles of i-hat, ",
        "start": 473.86,
        "duration": 4.369
    },
    {
        "text": "j-hat, and k-hat in the world of vectors as arrows.",
        "start": 478.229,
        "duration": 2.751
    },
    {
        "text": "Since our polynomials can have arbitrarily large degree, ",
        "start": 482.12,
        "duration": 3.149
    },
    {
        "text": "this set of basis functions is infinite.",
        "start": 485.269,
        "duration": 2.211
    },
    {
        "text": "But that's okay, it just means that when we treat our polynomials as vectors, ",
        "start": 488.24,
        "duration": 3.583
    },
    {
        "text": "they're going to have infinitely many coordinates.",
        "start": 491.823,
        "duration": 2.297
    },
    {
        "text": "A polynomial like x squared plus 3x plus 5, for example, ",
        "start": 495.6,
        "duration": 4.242
    },
    {
        "text": "would be described with the coordinates 5, 3, 1, then infinitely many zeros.",
        "start": 499.842,
        "duration": 5.658
    },
    {
        "text": "You'd read this as saying that it's 5 times the first basis function, ",
        "start": 506.1,
        "duration": 4.021
    },
    {
        "text": "plus 3 times that second basis function, plus 1 times the third basis function, ",
        "start": 510.121,
        "duration": 4.597
    },
    {
        "text": "and then none of the other basis functions should be added from that point on.",
        "start": 514.718,
        "duration": 4.482
    },
    {
        "text": "The polynomial 4x to the seventh minus 5x squared would have the coordinates 0, ",
        "start": 520.62,
        "duration": 6.556
    },
    {
        "text": "0, negative 5, 0, 0, 0, 0, 4, then an infinite string of zeros.",
        "start": 527.176,
        "duration": 5.164
    },
    {
        "text": "In general, since every individual polynomial has only finitely many terms, ",
        "start": 533.26,
        "duration": 4.597
    },
    {
        "text": "its coordinates will be some finite string of numbers with an infinite tail of zeros.",
        "start": 537.857,
        "duration": 5.143
    },
    {
        "text": "In this coordinate system, the derivative is described with ",
        "start": 546.9,
        "duration": 3.527
    },
    {
        "text": "an infinite matrix that's mostly full of zeros, ",
        "start": 550.427,
        "duration": 2.822
    },
    {
        "text": "but which has the positive integers counting down on this offset diagonal.",
        "start": 553.249,
        "duration": 4.351
    },
    {
        "text": "I'll talk about how you could find this matrix in just a moment, ",
        "start": 558.4,
        "duration": 2.912
    },
    {
        "text": "but the best way to get a feel for it is to just watch it in action.",
        "start": 561.312,
        "duration": 3.048
    },
    {
        "text": "Take the coordinates representing the polynomial x cubed plus 5x squared plus 4x plus 5, ",
        "start": 564.97,
        "duration": 6.205
    },
    {
        "text": "then put those coordinates on the right of the matrix.",
        "start": 571.175,
        "duration": 3.765
    },
    {
        "text": "The only term that contributes to the first coordinate of the result is 1 times 4, ",
        "start": 580.41,
        "duration": 4.828
    },
    {
        "text": "which means the constant term in the result will be 4.",
        "start": 585.238,
        "duration": 3.142
    },
    {
        "text": "This corresponds to the fact that the derivative of 4x is the constant 4.",
        "start": 590.1,
        "duration": 4.28
    },
    {
        "text": "The only term contributing to the second coordinate of the matrix vector product ",
        "start": 595.64,
        "duration": 5.081
    },
    {
        "text": "is 2 times 5, which means the coefficient in front of x in the derivative is 10.",
        "start": 600.721,
        "duration": 5.019
    },
    {
        "text": "That one corresponds to the derivative of 5x squared.",
        "start": 606.5,
        "duration": 2.78
    },
    {
        "text": "Similarly, the third coordinate in the matrix ",
        "start": 610.78,
        "duration": 2.65
    },
    {
        "text": "vector product comes down to taking 3 times 1.",
        "start": 613.43,
        "duration": 2.65
    },
    {
        "text": "This one corresponds to the derivative of x cubed being 3x squared.",
        "start": 617.66,
        "duration": 4.08
    },
    {
        "text": "And after that, it'll be nothing but zeros.",
        "start": 623.08,
        "duration": 1.94
    },
    {
        "text": "What makes this possible is that the derivative is linear.",
        "start": 626.88,
        "duration": 2.92
    },
    {
        "text": "And for those of you who like to pause and ponder, ",
        "start": 631.64,
        "duration": 2.66
    },
    {
        "text": "you could construct this matrix by taking the derivative of each ",
        "start": 634.3,
        "duration": 3.391
    },
    {
        "text": "basis function and putting the coordinates of the results in each column.",
        "start": 637.691,
        "duration": 3.809
    },
    {
        "text": "So, surprisingly, matrix vector multiplication and taking a derivative, ",
        "start": 659.78,
        "duration": 4.138
    },
    {
        "text": "which at first seem like completely different animals, ",
        "start": 663.918,
        "duration": 3.162
    },
    {
        "text": "are both just really members of the same family.",
        "start": 667.08,
        "duration": 2.76
    },
    {
        "text": "In fact, most of the concepts I've talked about in this series with ",
        "start": 671.22,
        "duration": 3.629
    },
    {
        "text": "respect to vectors as arrows in space, things like the dot product or eigenvectors, ",
        "start": 674.849,
        "duration": 4.484
    },
    {
        "text": "have direct analogs in the world of functions, ",
        "start": 679.333,
        "duration": 2.509
    },
    {
        "text": "though sometimes they go by different names, things like inner product or eigenfunction.",
        "start": 681.842,
        "duration": 4.698
    },
    {
        "text": "So back to the question of what is a vector.",
        "start": 688.4,
        "duration": 2.48
    },
    {
        "text": "The point I want to make here is that there are lots of vectorish things in math.",
        "start": 691.56,
        "duration": 4.28
    },
    {
        "text": "As long as you're dealing with a set of objects where there's a reasonable notion of ",
        "start": 695.84,
        "duration": 4.696
    },
    {
        "text": "scaling and adding, whether that's a set of arrows in space, lists of numbers, functions, ",
        "start": 700.536,
        "duration": 4.972
    },
    {
        "text": "or whatever other crazy thing you choose to define, ",
        "start": 705.508,
        "duration": 2.874
    },
    {
        "text": "all of the tools developed in linear algebra regarding vectors, ",
        "start": 708.382,
        "duration": 3.536
    },
    {
        "text": "linear transformations and all that stuff, should be able to apply.",
        "start": 711.918,
        "duration": 3.702
    },
    {
        "text": "Take a moment to imagine yourself right now as a ",
        "start": 717.48,
        "duration": 2.359
    },
    {
        "text": "mathematician developing the theory of linear algebra.",
        "start": 719.839,
        "duration": 2.601
    },
    {
        "text": "You want all of the definitions and discoveries of your work to apply to ",
        "start": 722.44,
        "duration": 4.283
    },
    {
        "text": "all of the vectorish things in full generality, not just to one specific case.",
        "start": 726.723,
        "duration": 4.577
    },
    {
        "text": "These sets of vectorish things, like arrows or lists of numbers or functions, ",
        "start": 733.4,
        "duration": 4.786
    },
    {
        "text": "are called vector spaces.",
        "start": 738.186,
        "duration": 1.534
    },
    {
        "text": "And what you as the mathematician might want to do is say, ",
        "start": 740.58,
        "duration": 2.724
    },
    {
        "text": "hey everyone, I don't want to have to think about all the ",
        "start": 743.304,
        "duration": 2.677
    },
    {
        "text": "different types of crazy vector spaces that you all might come up with.",
        "start": 745.981,
        "duration": 3.279
    },
    {
        "text": "So what you do is establish a list of rules that ",
        "start": 749.26,
        "duration": 3.127
    },
    {
        "text": "vector addition and scaling have to abide by.",
        "start": 752.387,
        "duration": 2.873
    },
    {
        "text": "These rules are called axioms, and in the modern theory of linear algebra, ",
        "start": 756.4,
        "duration": 3.799
    },
    {
        "text": "there are eight axioms that any vector space must satisfy if all of ",
        "start": 760.199,
        "duration": 3.446
    },
    {
        "text": "the theory and constructs that we've discovered are going to apply.",
        "start": 763.645,
        "duration": 3.395
    },
    {
        "text": "I'll leave them on the screen here for anyone who wants to pause and ponder, ",
        "start": 767.7,
        "duration": 3.48
    },
    {
        "text": "but basically it's just a checklist to make sure that the notions of vector ",
        "start": 771.18,
        "duration": 3.434
    },
    {
        "text": "addition and scalar multiplication do the things that you'd expect them to do.",
        "start": 774.614,
        "duration": 3.526
    },
    {
        "text": "These axioms are not so much fundamental rules of nature as they are an ",
        "start": 778.72,
        "duration": 3.848
    },
    {
        "text": "interface between you, the mathematician, discovering results, ",
        "start": 782.568,
        "duration": 3.368
    },
    {
        "text": "and other people who might want to apply those results to new sorts of vector spaces.",
        "start": 785.936,
        "duration": 4.544
    },
    {
        "text": "If, for example, someone defines some crazy type of vector space, ",
        "start": 791.42,
        "duration": 3.559
    },
    {
        "text": "like the set of all pi creatures with some definition of adding and scaling pi creatures, ",
        "start": 794.979,
        "duration": 4.854
    },
    {
        "text": "these axioms are like a checklist of things that they need to verify about ",
        "start": 799.833,
        "duration": 4.046
    },
    {
        "text": "their definitions before they can start applying the results of linear algebra.",
        "start": 803.879,
        "duration": 4.261
    },
    {
        "text": "And you, as the mathematician, never have to think about ",
        "start": 808.82,
        "duration": 2.76
    },
    {
        "text": "all the possible crazy vector spaces people might define.",
        "start": 811.58,
        "duration": 2.76
    },
    {
        "text": "You just have to prove your results in terms of these axioms so ",
        "start": 814.86,
        "duration": 3.496
    },
    {
        "text": "anyone whose definitions satisfy those axioms can happily apply your results, ",
        "start": 818.356,
        "duration": 4.261
    },
    {
        "text": "even if you never thought about their situation.",
        "start": 822.617,
        "duration": 2.623
    },
    {
        "text": "As a consequence, you'd tend to phrase all of your results pretty abstractly, ",
        "start": 826.52,
        "duration": 4.326
    },
    {
        "text": "which is to say, only in terms of these axioms, ",
        "start": 830.846,
        "duration": 2.663
    },
    {
        "text": "rather than centering on a specific type of vector, like arrows in space or functions.",
        "start": 833.509,
        "duration": 4.771
    },
    {
        "text": "For example, this is why just about every textbook you'll find will ",
        "start": 841.86,
        "duration": 3.744
    },
    {
        "text": "define linear transformations in terms of additivity and scaling, ",
        "start": 845.604,
        "duration": 3.635
    },
    {
        "text": "rather than talking about gridlines remaining parallel and evenly spaced.",
        "start": 849.239,
        "duration": 4.021
    },
    {
        "text": "Even though the latter is more intuitive, and at least in my view, ",
        "start": 853.26,
        "duration": 3.696
    },
    {
        "text": "more helpful for first-time learners, even if it is specific to one situation.",
        "start": 856.956,
        "duration": 4.304
    },
    {
        "text": "So the mathematician's answer to what are vectors is to just ignore the question.",
        "start": 862.62,
        "duration": 4.3
    },
    {
        "text": "In the modern theory, the form that vectors take doesn't really matter.",
        "start": 867.5,
        "duration": 3.76
    },
    {
        "text": "Arrows, lists of numbers, functions, pi creatures, really, it can be anything, ",
        "start": 871.86,
        "duration": 4.481
    },
    {
        "text": "so long as there's some notion of adding and scaling vectors that follows these rules.",
        "start": 876.341,
        "duration": 4.879
    },
    {
        "text": "It's like asking what the number 3 really is.",
        "start": 881.86,
        "duration": 3.02
    },
    {
        "text": "Whenever it comes up concretely, it's in the context of some triplet of things, ",
        "start": 885.38,
        "duration": 4.436
    },
    {
        "text": "but in math, it's treated as an abstraction for all possible triplets of things, ",
        "start": 889.816,
        "duration": 4.492
    },
    {
        "text": "and lets you reason about all possible triplets using a single idea.",
        "start": 894.308,
        "duration": 3.772
    },
    {
        "text": "Same goes with vectors, which have many embodiments, ",
        "start": 899.12,
        "duration": 3.163
    },
    {
        "text": "but math abstracts them all into a single, intangible notion of a vector space.",
        "start": 902.283,
        "duration": 4.717
    },
    {
        "text": "But, as anyone watching this series knows, I think it's better ",
        "start": 908.86,
        "duration": 3.494
    },
    {
        "text": "to begin reasoning about vectors in a concrete, visualizable setting, ",
        "start": 912.354,
        "duration": 3.883
    },
    {
        "text": "like 2D space, with arrows rooted at the origin.",
        "start": 916.237,
        "duration": 2.663
    },
    {
        "text": "But as you learn more linear algebra, know that these tools apply much more generally, ",
        "start": 919.66,
        "duration": 4.775
    },
    {
        "text": "and that this is the underlying reason why textbooks and lectures tend to be phrased, ",
        "start": 924.435,
        "duration": 4.721
    },
    {
        "text": "well, abstractly.",
        "start": 929.156,
        "duration": 0.934
    },
    {
        "text": "So with that, folks, I think I'll call it an in to this essence of linear algebra series.",
        "start": 931.94,
        "duration": 4.2
    },
    {
        "text": "If you've watched and understood the videos, I really do believe that ",
        "start": 936.14,
        "duration": 3.697
    },
    {
        "text": "you have a solid foundation in the underlying intuitions of linear algebra.",
        "start": 939.837,
        "duration": 3.963
    },
    {
        "text": "This is not the same thing as learning the full topic, of course, ",
        "start": 944.64,
        "duration": 2.855
    },
    {
        "text": "that's something that can only really come from working through problems, ",
        "start": 947.495,
        "duration": 3.202
    },
    {
        "text": "but the learning you do moving forward could be substantially more efficient if you have ",
        "start": 950.697,
        "duration": 3.851
    },
    {
        "text": "all the right intuitions in place.",
        "start": 954.548,
        "duration": 1.472
    },
    {
        "text": "So, have fun applying those intuitions, and best of luck with your future learning.",
        "start": 956.66,
        "duration": 3.34
    }
]